########################
logging outputs to  /home/jaehyun-jeong/UCBerkeley_cs285/hw2/cs285/scripts/../../data/q2_pg_cartpole_CartPole-v0_17-08-2024_01-02-02
########################
Using GPU id 0
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/envs/registration.py:593: UserWarning: [33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.[0m
  logger.warn(
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/core.py:317: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(

********** Iteration 0 ************
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):

Collecting data for eval...
Eval_AverageReturn : 42.099998474121094
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/tensorboardX/summary.py:153: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
  scalar = float(scalar)
Eval_StdReturn : 9.353608131408691
Eval_MaxReturn : 64.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 42.1
Train_AverageReturn : 38.80769348144531
Train_StdReturn : 17.155441284179688
Train_MaxReturn : 99.0
Train_MinReturn : 21.0
Train_AverageEpLen : 38.80769230769231
Actor Loss : 31873.3828125
Train_EnvstepsSoFar : 1009
TimeSinceStart : 1.6360070705413818
Initial_DataCollection_AverageReturn : 38.80769348144531
Done logging...



********** Iteration 1 ************

Collecting data for eval...
Eval_AverageReturn : 69.0
Eval_StdReturn : 38.500465393066406
Eval_MaxReturn : 142.0
Eval_MinReturn : 39.0
Eval_AverageEpLen : 69.0
Train_AverageReturn : 38.51852035522461
Train_StdReturn : 12.635547637939453
Train_MaxReturn : 77.0
Train_MinReturn : 24.0
Train_AverageEpLen : 38.51851851851852
Actor Loss : 28236.24609375
Train_EnvstepsSoFar : 2049
TimeSinceStart : 2.5606818199157715
Done logging...



********** Iteration 2 ************

Collecting data for eval...
Eval_AverageReturn : 60.28571319580078
Eval_StdReturn : 14.269990921020508
Eval_MaxReturn : 89.0
Eval_MinReturn : 42.0
Eval_AverageEpLen : 60.285714285714285
Train_AverageReturn : 58.882354736328125
Train_StdReturn : 25.99294662475586
Train_MaxReturn : 121.0
Train_MinReturn : 35.0
Train_AverageEpLen : 58.88235294117647
Actor Loss : 41747.8984375
Train_EnvstepsSoFar : 3050
TimeSinceStart : 3.614746332168579
Done logging...



********** Iteration 3 ************

Collecting data for eval...
Eval_AverageReturn : 95.5999984741211
Eval_StdReturn : 43.269386291503906
Eval_MaxReturn : 176.0
Eval_MinReturn : 54.0
Eval_AverageEpLen : 95.6
Train_AverageReturn : 61.411766052246094
Train_StdReturn : 20.445219039916992
Train_MaxReturn : 112.0
Train_MinReturn : 40.0
Train_AverageEpLen : 61.411764705882355
Actor Loss : 39089.15625
Train_EnvstepsSoFar : 4094
TimeSinceStart : 4.534269332885742
Done logging...



********** Iteration 4 ************

Collecting data for eval...
Eval_AverageReturn : 88.4000015258789
Eval_StdReturn : 20.20494842529297
Eval_MaxReturn : 120.0
Eval_MinReturn : 63.0
Eval_AverageEpLen : 88.4
Train_AverageReturn : 88.58333587646484
Train_StdReturn : 37.91758346557617
Train_MaxReturn : 200.0
Train_MinReturn : 58.0
Train_AverageEpLen : 88.58333333333333
Actor Loss : 56200.80078125
Train_EnvstepsSoFar : 5157
TimeSinceStart : 5.425404071807861
Done logging...



********** Iteration 5 ************

Collecting data for eval...
Eval_AverageReturn : 110.0
Eval_StdReturn : 47.21758270263672
Eval_MaxReturn : 188.0
Eval_MinReturn : 70.0
Eval_AverageEpLen : 110.0
Train_AverageReturn : 111.77777862548828
Train_StdReturn : 31.438751220703125
Train_MaxReturn : 191.0
Train_MinReturn : 81.0
Train_AverageEpLen : 111.77777777777777
Actor Loss : 55355.984375
Train_EnvstepsSoFar : 6163
TimeSinceStart : 6.2192840576171875
Done logging...



********** Iteration 6 ************

Collecting data for eval...
Eval_AverageReturn : 155.6666717529297
Eval_StdReturn : 32.10745620727539
Eval_MaxReturn : 200.0
Eval_MinReturn : 125.0
Eval_AverageEpLen : 155.66666666666666
Train_AverageReturn : 107.80000305175781
Train_StdReturn : 47.09946823120117
Train_MaxReturn : 197.0
Train_MinReturn : 61.0
Train_AverageEpLen : 107.8
Actor Loss : 57004.6328125
Train_EnvstepsSoFar : 7241
TimeSinceStart : 7.159968614578247
Done logging...



********** Iteration 7 ************

Collecting data for eval...
Eval_AverageReturn : 88.5999984741211
Eval_StdReturn : 35.103275299072266
Eval_MaxReturn : 157.0
Eval_MinReturn : 63.0
Eval_AverageEpLen : 88.6
Train_AverageReturn : 85.91666412353516
Train_StdReturn : 24.0605411529541
Train_MaxReturn : 138.0
Train_MinReturn : 57.0
Train_AverageEpLen : 85.91666666666667
Actor Loss : 34494.46875
Train_EnvstepsSoFar : 8272
TimeSinceStart : 8.36295223236084
Done logging...



********** Iteration 8 ************

Collecting data for eval...
Eval_AverageReturn : 113.5
Eval_StdReturn : 38.356876373291016
Eval_MaxReturn : 169.0
Eval_MinReturn : 68.0
Eval_AverageEpLen : 113.5
Train_AverageReturn : 104.4000015258789
Train_StdReturn : 34.223384857177734
Train_MaxReturn : 161.0
Train_MinReturn : 61.0
Train_AverageEpLen : 104.4
Actor Loss : 38921.0859375
Train_EnvstepsSoFar : 9316
TimeSinceStart : 9.455641984939575
Done logging...



********** Iteration 9 ************

Collecting data for eval...
Eval_AverageReturn : 151.3333282470703
Eval_StdReturn : 45.90085983276367
Eval_MaxReturn : 191.0
Eval_MinReturn : 87.0
Eval_AverageEpLen : 151.33333333333334
Train_AverageReturn : 90.91666412353516
Train_StdReturn : 20.134790420532227
Train_MaxReturn : 137.0
Train_MinReturn : 67.0
Train_AverageEpLen : 90.91666666666667
Actor Loss : 28548.58203125
Train_EnvstepsSoFar : 10407
TimeSinceStart : 11.147535562515259
Done logging...



********** Iteration 10 ************

Collecting data for eval...
Eval_AverageReturn : 153.0
Eval_StdReturn : 43.5660400390625
Eval_MaxReturn : 200.0
Eval_MinReturn : 95.0
Eval_AverageEpLen : 153.0
Train_AverageReturn : 91.09091186523438
Train_StdReturn : 29.336463928222656
Train_MaxReturn : 159.0
Train_MinReturn : 61.0
Train_AverageEpLen : 91.0909090909091
Actor Loss : 24484.33984375
Train_EnvstepsSoFar : 11409
TimeSinceStart : 12.356946229934692
Done logging...



********** Iteration 11 ************

Collecting data for eval...
Eval_AverageReturn : 126.0
Eval_StdReturn : 43.5660400390625
Eval_MaxReturn : 182.0
Eval_MinReturn : 60.0
Eval_AverageEpLen : 126.0
Train_AverageReturn : 117.77777862548828
Train_StdReturn : 34.1655387878418
Train_MaxReturn : 173.0
Train_MinReturn : 66.0
Train_AverageEpLen : 117.77777777777777
Actor Loss : 29972.134765625
Train_EnvstepsSoFar : 12469
TimeSinceStart : 13.949218988418579
Done logging...



********** Iteration 12 ************

Collecting data for eval...
Eval_AverageReturn : 134.0
Eval_StdReturn : 41.952354431152344
Eval_MaxReturn : 182.0
Eval_MinReturn : 78.0
Eval_AverageEpLen : 134.0
Train_AverageReturn : 148.2857208251953
Train_StdReturn : 44.16435241699219
Train_MaxReturn : 200.0
Train_MinReturn : 78.0
Train_AverageEpLen : 148.28571428571428
Actor Loss : 32328.93359375
Train_EnvstepsSoFar : 13507
TimeSinceStart : 15.513466358184814
Done logging...



********** Iteration 13 ************

Collecting data for eval...
Eval_AverageReturn : 106.0
Eval_StdReturn : 41.51505661010742
Eval_MaxReturn : 175.0
Eval_MinReturn : 67.0
Eval_AverageEpLen : 106.0
Train_AverageReturn : 98.7272720336914
Train_StdReturn : 43.44293975830078
Train_MaxReturn : 200.0
Train_MinReturn : 61.0
Train_AverageEpLen : 98.72727272727273
Actor Loss : 23788.609375
Train_EnvstepsSoFar : 14593
TimeSinceStart : 16.42205500602722
Done logging...



********** Iteration 14 ************

Collecting data for eval...
Eval_AverageReturn : 101.25
Eval_StdReturn : 34.12019348144531
Eval_MaxReturn : 157.0
Eval_MinReturn : 67.0
Eval_AverageEpLen : 101.25
Train_AverageReturn : 118.88888549804688
Train_StdReturn : 51.15433120727539
Train_MaxReturn : 198.0
Train_MinReturn : 54.0
Train_AverageEpLen : 118.88888888888889
Actor Loss : 22718.05859375
Train_EnvstepsSoFar : 15663
TimeSinceStart : 17.38859724998474
Done logging...



********** Iteration 15 ************

Collecting data for eval...
Eval_AverageReturn : 112.5
Eval_StdReturn : 23.03801155090332
Eval_MaxReturn : 142.0
Eval_MinReturn : 78.0
Eval_AverageEpLen : 112.5
Train_AverageReturn : 106.5
Train_StdReturn : 40.16777420043945
Train_MaxReturn : 200.0
Train_MinReturn : 71.0
Train_AverageEpLen : 106.5
Actor Loss : 17411.833984375
Train_EnvstepsSoFar : 16728
TimeSinceStart : 18.49114680290222
Done logging...



********** Iteration 16 ************

Collecting data for eval...
Eval_AverageReturn : 74.33333587646484
Eval_StdReturn : 15.14008617401123
Eval_MaxReturn : 101.0
Eval_MinReturn : 53.0
Eval_AverageEpLen : 74.33333333333333
Train_AverageReturn : 99.81818389892578
Train_StdReturn : 28.698488235473633
Train_MaxReturn : 173.0
Train_MinReturn : 71.0
Train_AverageEpLen : 99.81818181818181
Actor Loss : 14219.98828125
Train_EnvstepsSoFar : 17826
TimeSinceStart : 19.626956701278687
Done logging...



********** Iteration 17 ************

Collecting data for eval...
Eval_AverageReturn : 103.25
Eval_StdReturn : 36.485443115234375
Eval_MaxReturn : 163.0
Eval_MinReturn : 65.0
Eval_AverageEpLen : 103.25
Train_AverageReturn : 84.16666412353516
Train_StdReturn : 30.118745803833008
Train_MaxReturn : 174.0
Train_MinReturn : 51.0
Train_AverageEpLen : 84.16666666666667
Actor Loss : 9389.17578125
Train_EnvstepsSoFar : 18836
TimeSinceStart : 20.480361223220825
Done logging...



********** Iteration 18 ************

Collecting data for eval...
Eval_AverageReturn : 68.0
Eval_StdReturn : 9.9666109085083
Eval_MaxReturn : 83.0
Eval_MinReturn : 57.0
Eval_AverageEpLen : 68.0
Train_AverageReturn : 77.92308044433594
Train_StdReturn : 22.158388137817383
Train_MaxReturn : 137.0
Train_MinReturn : 58.0
Train_AverageEpLen : 77.92307692307692
Actor Loss : 9079.59765625
Train_EnvstepsSoFar : 19849
TimeSinceStart : 21.523101806640625
Done logging...



********** Iteration 19 ************

Collecting data for eval...
Eval_AverageReturn : 83.0
Eval_StdReturn : 25.432262420654297
Eval_MaxReturn : 126.0
Eval_MinReturn : 48.0
Eval_AverageEpLen : 83.0
Train_AverageReturn : 80.38461303710938
Train_StdReturn : 27.373592376708984
Train_MaxReturn : 143.0
Train_MinReturn : 51.0
Train_AverageEpLen : 80.38461538461539
Actor Loss : 8038.6875
Train_EnvstepsSoFar : 20894
TimeSinceStart : 22.45146608352661
Done logging...



********** Iteration 20 ************

Collecting data for eval...
Eval_AverageReturn : 74.0
Eval_StdReturn : 21.102922439575195
Eval_MaxReturn : 118.0
Eval_MinReturn : 55.0
Eval_AverageEpLen : 74.0
Train_AverageReturn : 77.46154022216797
Train_StdReturn : 24.02119255065918
Train_MaxReturn : 141.0
Train_MinReturn : 46.0
Train_AverageEpLen : 77.46153846153847
Actor Loss : 6807.08642578125
Train_EnvstepsSoFar : 21901
TimeSinceStart : 23.369943141937256
Done logging...



********** Iteration 21 ************

Collecting data for eval...
Eval_AverageReturn : 85.0
Eval_StdReturn : 36.19852828979492
Eval_MaxReturn : 148.0
Eval_MinReturn : 51.0
Eval_AverageEpLen : 85.0
Train_AverageReturn : 70.66666412353516
Train_StdReturn : 14.563271522521973
Train_MaxReturn : 106.0
Train_MinReturn : 50.0
Train_AverageEpLen : 70.66666666666667
Actor Loss : 5401.80126953125
Train_EnvstepsSoFar : 22961
TimeSinceStart : 24.55474877357483
Done logging...



********** Iteration 22 ************

Collecting data for eval...
Eval_AverageReturn : 90.19999694824219
Eval_StdReturn : 52.9920768737793
Eval_MaxReturn : 195.0
Eval_MinReturn : 50.0
Eval_AverageEpLen : 90.2
Train_AverageReturn : 78.46154022216797
Train_StdReturn : 19.967723846435547
Train_MaxReturn : 116.0
Train_MinReturn : 50.0
Train_AverageEpLen : 78.46153846153847
Actor Loss : 6252.6640625
Train_EnvstepsSoFar : 23981
TimeSinceStart : 25.438695430755615
Done logging...



********** Iteration 23 ************

Collecting data for eval...
Eval_AverageReturn : 81.80000305175781
Eval_StdReturn : 29.01999282836914
Eval_MaxReturn : 133.0
Eval_MinReturn : 53.0
Eval_AverageEpLen : 81.8
Train_AverageReturn : 94.36363983154297
Train_StdReturn : 40.58049774169922
Train_MaxReturn : 200.0
Train_MinReturn : 61.0
Train_AverageEpLen : 94.36363636363636
Actor Loss : 6062.45947265625
Train_EnvstepsSoFar : 25019
TimeSinceStart : 26.50179100036621
Done logging...



********** Iteration 24 ************

Collecting data for eval...
Eval_AverageReturn : 70.33333587646484
Eval_StdReturn : 18.336362838745117
Eval_MaxReturn : 105.0
Eval_MinReturn : 48.0
Eval_AverageEpLen : 70.33333333333333
Train_AverageReturn : 71.42857360839844
Train_StdReturn : 22.553791046142578
Train_MaxReturn : 126.0
Train_MinReturn : 46.0
Train_AverageEpLen : 71.42857142857143
Actor Loss : 5357.4189453125
Train_EnvstepsSoFar : 26019
TimeSinceStart : 27.529776096343994
Done logging...



********** Iteration 25 ************

Collecting data for eval...
Eval_AverageReturn : 91.5999984741211
Eval_StdReturn : 54.518253326416016
Eval_MaxReturn : 200.0
Eval_MinReturn : 54.0
Eval_AverageEpLen : 91.6
Train_AverageReturn : 62.6875
Train_StdReturn : 9.51786994934082
Train_MaxReturn : 78.0
Train_MinReturn : 49.0
Train_AverageEpLen : 62.6875
Actor Loss : 3463.980712890625
Train_EnvstepsSoFar : 27022
TimeSinceStart : 28.56341314315796
Done logging...



********** Iteration 26 ************

Collecting data for eval...
Eval_AverageReturn : 78.16666412353516
Eval_StdReturn : 22.50493812561035
Eval_MaxReturn : 115.0
Eval_MinReturn : 53.0
Eval_AverageEpLen : 78.16666666666667
Train_AverageReturn : 68.53333282470703
Train_StdReturn : 19.855701446533203
Train_MaxReturn : 133.0
Train_MinReturn : 48.0
Train_AverageEpLen : 68.53333333333333
Actor Loss : 3654.380615234375
Train_EnvstepsSoFar : 28050
TimeSinceStart : 29.407636404037476
Done logging...



********** Iteration 27 ************

Collecting data for eval...
Eval_AverageReturn : 52.5
Eval_StdReturn : 5.722761631011963
Eval_MaxReturn : 60.0
Eval_MinReturn : 44.0
Eval_AverageEpLen : 52.5
Train_AverageReturn : 65.625
Train_StdReturn : 14.802343368530273
Train_MaxReturn : 110.0
Train_MinReturn : 48.0
Train_AverageEpLen : 65.625
Actor Loss : 3493.30859375
Train_EnvstepsSoFar : 29100
TimeSinceStart : 30.442235231399536
Done logging...



********** Iteration 28 ************

Collecting data for eval...
Eval_AverageReturn : 86.4000015258789
Eval_StdReturn : 25.63279151916504
Eval_MaxReturn : 126.0
Eval_MinReturn : 49.0
Eval_AverageEpLen : 86.4
Train_AverageReturn : 69.66666412353516
Train_StdReturn : 24.989776611328125
Train_MaxReturn : 130.0
Train_MinReturn : 41.0
Train_AverageEpLen : 69.66666666666667
Actor Loss : 3648.698974609375
Train_EnvstepsSoFar : 30145
TimeSinceStart : 31.46093726158142
Done logging...



********** Iteration 29 ************

Collecting data for eval...
Eval_AverageReturn : 61.42856979370117
Eval_StdReturn : 19.286243438720703
Eval_MaxReturn : 105.0
Eval_MinReturn : 44.0
Eval_AverageEpLen : 61.42857142857143
Train_AverageReturn : 59.33333206176758
Train_StdReturn : 22.89104652404785
Train_MaxReturn : 147.0
Train_MinReturn : 43.0
Train_AverageEpLen : 59.333333333333336
Actor Loss : 3360.07568359375
Train_EnvstepsSoFar : 31213
TimeSinceStart : 32.56002950668335
Done logging...



********** Iteration 30 ************

Collecting data for eval...
Eval_AverageReturn : 69.5
Eval_StdReturn : 42.1297607421875
Eval_MaxReturn : 161.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 69.5
Train_AverageReturn : 59.5
Train_StdReturn : 23.949600219726562
Train_MaxReturn : 125.0
Train_MinReturn : 40.0
Train_AverageEpLen : 59.5
Actor Loss : 3145.966796875
Train_EnvstepsSoFar : 32284
TimeSinceStart : 33.44490957260132
Done logging...



********** Iteration 31 ************

Collecting data for eval...
Eval_AverageReturn : 69.0
Eval_StdReturn : 25.761728286743164
Eval_MaxReturn : 113.0
Eval_MinReturn : 43.0
Eval_AverageEpLen : 69.0
Train_AverageReturn : 61.588233947753906
Train_StdReturn : 24.550209045410156
Train_MaxReturn : 125.0
Train_MinReturn : 37.0
Train_AverageEpLen : 61.588235294117645
Actor Loss : 2523.417236328125
Train_EnvstepsSoFar : 33331
TimeSinceStart : 34.46915674209595
Done logging...



********** Iteration 32 ************

Collecting data for eval...
Eval_AverageReturn : 47.11111068725586
Eval_StdReturn : 9.397924423217773
Eval_MaxReturn : 64.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 47.111111111111114
Train_AverageReturn : 61.235294342041016
Train_StdReturn : 21.90495491027832
Train_MaxReturn : 131.0
Train_MinReturn : 39.0
Train_AverageEpLen : 61.23529411764706
Actor Loss : 2460.995849609375
Train_EnvstepsSoFar : 34372
TimeSinceStart : 35.33938407897949
Done logging...



********** Iteration 33 ************

Collecting data for eval...
Eval_AverageReturn : 41.29999923706055
Eval_StdReturn : 3.3481338024139404
Eval_MaxReturn : 47.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 41.3
Train_AverageReturn : 56.27777862548828
Train_StdReturn : 16.90432357788086
Train_MaxReturn : 100.0
Train_MinReturn : 37.0
Train_AverageEpLen : 56.27777777777778
Actor Loss : 1938.953125
Train_EnvstepsSoFar : 35385
TimeSinceStart : 36.284672260284424
Done logging...



********** Iteration 34 ************

Collecting data for eval...
Eval_AverageReturn : 63.28571319580078
Eval_StdReturn : 24.65020751953125
Eval_MaxReturn : 115.0
Eval_MinReturn : 45.0
Eval_AverageEpLen : 63.285714285714285
Train_AverageReturn : 57.5
Train_StdReturn : 20.02012825012207
Train_MaxReturn : 113.0
Train_MinReturn : 36.0
Train_AverageEpLen : 57.5
Actor Loss : 2423.3583984375
Train_EnvstepsSoFar : 36420
TimeSinceStart : 37.25677227973938
Done logging...



********** Iteration 35 ************

Collecting data for eval...
Eval_AverageReturn : 56.5
Eval_StdReturn : 20.4083309173584
Eval_MaxReturn : 95.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 56.5
Train_AverageReturn : 51.29999923706055
Train_StdReturn : 14.73465347290039
Train_MaxReturn : 87.0
Train_MinReturn : 36.0
Train_AverageEpLen : 51.3
Actor Loss : 1656.4658203125
Train_EnvstepsSoFar : 37446
TimeSinceStart : 38.24416923522949
Done logging...



********** Iteration 36 ************

Collecting data for eval...
Eval_AverageReturn : 52.625
Eval_StdReturn : 18.714550018310547
Eval_MaxReturn : 94.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 52.625
Train_AverageReturn : 57.16666793823242
Train_StdReturn : 25.981294631958008
Train_MaxReturn : 131.0
Train_MinReturn : 33.0
Train_AverageEpLen : 57.166666666666664
Actor Loss : 2189.33056640625
Train_EnvstepsSoFar : 38475
TimeSinceStart : 39.31208086013794
Done logging...



********** Iteration 37 ************

Collecting data for eval...
Eval_AverageReturn : 64.28571319580078
Eval_StdReturn : 30.155380249023438
Eval_MaxReturn : 125.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 64.28571428571429
Train_AverageReturn : 48.19047546386719
Train_StdReturn : 17.056262969970703
Train_MaxReturn : 87.0
Train_MinReturn : 30.0
Train_AverageEpLen : 48.19047619047619
Actor Loss : 2025.1075439453125
Train_EnvstepsSoFar : 39487
TimeSinceStart : 40.391315937042236
Done logging...



********** Iteration 38 ************

Collecting data for eval...
Eval_AverageReturn : 45.33333206176758
Eval_StdReturn : 19.578899383544922
Eval_MaxReturn : 98.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 45.333333333333336
Train_AverageReturn : 50.25
Train_StdReturn : 18.0689640045166
Train_MaxReturn : 94.0
Train_MinReturn : 32.0
Train_AverageEpLen : 50.25
Actor Loss : 2068.1474609375
Train_EnvstepsSoFar : 40492
TimeSinceStart : 41.43092322349548
Done logging...



********** Iteration 39 ************

Collecting data for eval...
Eval_AverageReturn : 54.75
Eval_StdReturn : 21.111312866210938
Eval_MaxReturn : 100.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 54.75
Train_AverageReturn : 46.09090805053711
Train_StdReturn : 13.790343284606934
Train_MaxReturn : 86.0
Train_MinReturn : 35.0
Train_AverageEpLen : 46.09090909090909
Actor Loss : 1617.028564453125
Train_EnvstepsSoFar : 41506
TimeSinceStart : 42.39575004577637
Done logging...



********** Iteration 40 ************

Collecting data for eval...
Eval_AverageReturn : 56.875
Eval_StdReturn : 16.518455505371094
Eval_MaxReturn : 80.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 56.875
Train_AverageReturn : 50.0
Train_StdReturn : 15.375304222106934
Train_MaxReturn : 90.0
Train_MinReturn : 31.0
Train_AverageEpLen : 50.0
Actor Loss : 1902.2392578125
Train_EnvstepsSoFar : 42506
TimeSinceStart : 43.180737257003784
Done logging...



********** Iteration 41 ************

Collecting data for eval...
Eval_AverageReturn : 50.66666793823242
Eval_StdReturn : 11.59501838684082
Eval_MaxReturn : 74.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 50.666666666666664
Train_AverageReturn : 51.599998474121094
Train_StdReturn : 15.78416919708252
Train_MaxReturn : 80.0
Train_MinReturn : 32.0
Train_AverageEpLen : 51.6
Actor Loss : 1935.8433837890625
Train_EnvstepsSoFar : 43538
TimeSinceStart : 43.98457169532776
Done logging...



********** Iteration 42 ************

Collecting data for eval...
Eval_AverageReturn : 43.0
Eval_StdReturn : 10.917875289916992
Eval_MaxReturn : 67.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 43.0
Train_AverageReturn : 48.238094329833984
Train_StdReturn : 18.12103271484375
Train_MaxReturn : 94.0
Train_MinReturn : 31.0
Train_AverageEpLen : 48.23809523809524
Actor Loss : 1372.92822265625
Train_EnvstepsSoFar : 44551
TimeSinceStart : 44.759743452072144
Done logging...



********** Iteration 43 ************

Collecting data for eval...
Eval_AverageReturn : 46.0
Eval_StdReturn : 15.484759330749512
Eval_MaxReturn : 68.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 46.0
Train_AverageReturn : 48.45454406738281
Train_StdReturn : 17.73985481262207
Train_MaxReturn : 87.0
Train_MinReturn : 29.0
Train_AverageEpLen : 48.45454545454545
Actor Loss : 2654.72021484375
Train_EnvstepsSoFar : 45617
TimeSinceStart : 45.556490898132324
Done logging...



********** Iteration 44 ************

Collecting data for eval...
Eval_AverageReturn : 44.29999923706055
Eval_StdReturn : 14.9268217086792
Eval_MaxReturn : 86.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 44.3
Train_AverageReturn : 53.78947448730469
Train_StdReturn : 27.134323120117188
Train_MaxReturn : 132.0
Train_MinReturn : 30.0
Train_AverageEpLen : 53.78947368421053
Actor Loss : 2904.403076171875
Train_EnvstepsSoFar : 46639
TimeSinceStart : 46.349000215530396
Done logging...



********** Iteration 45 ************

Collecting data for eval...
Eval_AverageReturn : 46.5
Eval_StdReturn : 17.670597076416016
Eval_MaxReturn : 86.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 46.5
Train_AverageReturn : 54.157894134521484
Train_StdReturn : 17.667285919189453
Train_MaxReturn : 84.0
Train_MinReturn : 32.0
Train_AverageEpLen : 54.1578947368421
Actor Loss : 1943.060302734375
Train_EnvstepsSoFar : 47668
TimeSinceStart : 47.226295709609985
Done logging...



********** Iteration 46 ************

Collecting data for eval...
Eval_AverageReturn : 47.66666793823242
Eval_StdReturn : 12.970050811767578
Eval_MaxReturn : 66.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 47.666666666666664
Train_AverageReturn : 52.6315803527832
Train_StdReturn : 19.607223510742188
Train_MaxReturn : 93.0
Train_MinReturn : 31.0
Train_AverageEpLen : 52.63157894736842
Actor Loss : 1426.729248046875
Train_EnvstepsSoFar : 48668
TimeSinceStart : 48.00034236907959
Done logging...



********** Iteration 47 ************

Collecting data for eval...
Eval_AverageReturn : 53.625
Eval_StdReturn : 18.913867950439453
Eval_MaxReturn : 87.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 53.625
Train_AverageReturn : 48.40909194946289
Train_StdReturn : 15.358323097229004
Train_MaxReturn : 90.0
Train_MinReturn : 33.0
Train_AverageEpLen : 48.40909090909091
Actor Loss : 1668.353271484375
Train_EnvstepsSoFar : 49733
TimeSinceStart : 48.81462907791138
Done logging...



********** Iteration 48 ************

Collecting data for eval...
Eval_AverageReturn : 45.77777862548828
Eval_StdReturn : 12.856280326843262
Eval_MaxReturn : 81.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 45.77777777777778
Train_AverageReturn : 45.78260803222656
Train_StdReturn : 16.05413818359375
Train_MaxReturn : 102.0
Train_MinReturn : 31.0
Train_AverageEpLen : 45.78260869565217
Actor Loss : 1610.9755859375
Train_EnvstepsSoFar : 50786
TimeSinceStart : 49.61207556724548
Done logging...



********** Iteration 49 ************

Collecting data for eval...
Eval_AverageReturn : 50.625
Eval_StdReturn : 21.136091232299805
Eval_MaxReturn : 90.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 50.625
Train_AverageReturn : 57.05555725097656
Train_StdReturn : 19.951251983642578
Train_MaxReturn : 99.0
Train_MinReturn : 32.0
Train_AverageEpLen : 57.05555555555556
Actor Loss : 1712.970458984375
Train_EnvstepsSoFar : 51813
TimeSinceStart : 50.36691498756409
Done logging...



********** Iteration 50 ************

Collecting data for eval...
Eval_AverageReturn : 64.85713958740234
Eval_StdReturn : 20.615032196044922
Eval_MaxReturn : 94.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 64.85714285714286
Train_AverageReturn : 53.05263137817383
Train_StdReturn : 18.687101364135742
Train_MaxReturn : 100.0
Train_MinReturn : 33.0
Train_AverageEpLen : 53.05263157894737
Actor Loss : 1921.353515625
Train_EnvstepsSoFar : 52821
TimeSinceStart : 51.14804434776306
Done logging...



********** Iteration 51 ************

Collecting data for eval...
Eval_AverageReturn : 50.375
Eval_StdReturn : 13.701619148254395
Eval_MaxReturn : 76.0
Eval_MinReturn : 36.0
Eval_AverageEpLen : 50.375
Train_AverageReturn : 52.73684310913086
Train_StdReturn : 20.216829299926758
Train_MaxReturn : 100.0
Train_MinReturn : 33.0
Train_AverageEpLen : 52.73684210526316
Actor Loss : 1349.393310546875
Train_EnvstepsSoFar : 53823
TimeSinceStart : 51.88837265968323
Done logging...



********** Iteration 52 ************

Collecting data for eval...
Eval_AverageReturn : 51.375
Eval_StdReturn : 19.823833465576172
Eval_MaxReturn : 101.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 51.375
Train_AverageReturn : 50.95000076293945
Train_StdReturn : 19.893404006958008
Train_MaxReturn : 102.0
Train_MinReturn : 31.0
Train_AverageEpLen : 50.95
Actor Loss : 1422.2083740234375
Train_EnvstepsSoFar : 54842
TimeSinceStart : 52.6631875038147
Done logging...



********** Iteration 53 ************

Collecting data for eval...
Eval_AverageReturn : 50.0
Eval_StdReturn : 12.54990005493164
Eval_MaxReturn : 78.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 50.0
Train_AverageReturn : 50.19047546386719
Train_StdReturn : 17.55703353881836
Train_MaxReturn : 92.0
Train_MinReturn : 33.0
Train_AverageEpLen : 50.19047619047619
Actor Loss : 1517.8214111328125
Train_EnvstepsSoFar : 55896
TimeSinceStart : 53.45230269432068
Done logging...



********** Iteration 54 ************

Collecting data for eval...
Eval_AverageReturn : 54.33333206176758
Eval_StdReturn : 27.450965881347656
Eval_MaxReturn : 109.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 54.333333333333336
Train_AverageReturn : 58.882354736328125
Train_StdReturn : 30.348724365234375
Train_MaxReturn : 155.0
Train_MinReturn : 35.0
Train_AverageEpLen : 58.88235294117647
Actor Loss : 1592.810302734375
Train_EnvstepsSoFar : 56897
TimeSinceStart : 54.53863763809204
Done logging...



********** Iteration 55 ************

Collecting data for eval...
Eval_AverageReturn : 47.22222137451172
Eval_StdReturn : 15.504679679870605
Eval_MaxReturn : 89.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 47.22222222222222
Train_AverageReturn : 62.9375
Train_StdReturn : 29.484039306640625
Train_MaxReturn : 123.0
Train_MinReturn : 30.0
Train_AverageEpLen : 62.9375
Actor Loss : 2075.2509765625
Train_EnvstepsSoFar : 57904
TimeSinceStart : 55.29913830757141
Done logging...



********** Iteration 56 ************

Collecting data for eval...
Eval_AverageReturn : 51.44444274902344
Eval_StdReturn : 16.02852439880371
Eval_MaxReturn : 95.0
Eval_MinReturn : 39.0
Eval_AverageEpLen : 51.44444444444444
Train_AverageReturn : 60.35293960571289
Train_StdReturn : 32.62251281738281
Train_MaxReturn : 160.0
Train_MinReturn : 30.0
Train_AverageEpLen : 60.35294117647059
Actor Loss : 1856.076904296875
Train_EnvstepsSoFar : 58930
TimeSinceStart : 56.09592413902283
Done logging...



********** Iteration 57 ************

Collecting data for eval...
Eval_AverageReturn : 67.0
Eval_StdReturn : 36.660606384277344
Eval_MaxReturn : 150.0
Eval_MinReturn : 36.0
Eval_AverageEpLen : 67.0
Train_AverageReturn : 50.150001525878906
Train_StdReturn : 15.05415153503418
Train_MaxReturn : 98.0
Train_MinReturn : 33.0
Train_AverageEpLen : 50.15
Actor Loss : 1210.48388671875
Train_EnvstepsSoFar : 59933
TimeSinceStart : 56.92779898643494
Done logging...



********** Iteration 58 ************

Collecting data for eval...
Eval_AverageReturn : 60.42856979370117
Eval_StdReturn : 23.981285095214844
Eval_MaxReturn : 102.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 60.42857142857143
Train_AverageReturn : 50.20000076293945
Train_StdReturn : 21.462993621826172
Train_MaxReturn : 127.0
Train_MinReturn : 34.0
Train_AverageEpLen : 50.2
Actor Loss : 1437.51123046875
Train_EnvstepsSoFar : 60937
TimeSinceStart : 58.08132362365723
Done logging...



********** Iteration 59 ************

Collecting data for eval...
Eval_AverageReturn : 59.42856979370117
Eval_StdReturn : 30.184467315673828
Eval_MaxReturn : 112.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 59.42857142857143
Train_AverageReturn : 66.4375
Train_StdReturn : 23.764387130737305
Train_MaxReturn : 115.0
Train_MinReturn : 32.0
Train_AverageEpLen : 66.4375
Actor Loss : 1463.580078125
Train_EnvstepsSoFar : 62000
TimeSinceStart : 59.16271090507507
Done logging...



********** Iteration 60 ************

Collecting data for eval...
Eval_AverageReturn : 51.66666793823242
Eval_StdReturn : 15.634718894958496
Eval_MaxReturn : 80.0
Eval_MinReturn : 36.0
Eval_AverageEpLen : 51.666666666666664
Train_AverageReturn : 60.235294342041016
Train_StdReturn : 26.794490814208984
Train_MaxReturn : 134.0
Train_MinReturn : 33.0
Train_AverageEpLen : 60.23529411764706
Actor Loss : 1575.1231689453125
Train_EnvstepsSoFar : 63024
TimeSinceStart : 59.937169790267944
Done logging...



********** Iteration 61 ************

Collecting data for eval...
Eval_AverageReturn : 52.25
Eval_StdReturn : 22.71976089477539
Eval_MaxReturn : 96.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 52.25
Train_AverageReturn : 59.235294342041016
Train_StdReturn : 25.517074584960938
Train_MaxReturn : 118.0
Train_MinReturn : 33.0
Train_AverageEpLen : 59.23529411764706
Actor Loss : 1985.478515625
Train_EnvstepsSoFar : 64031
TimeSinceStart : 60.69358539581299
Done logging...



********** Iteration 62 ************

Collecting data for eval...
Eval_AverageReturn : 57.85714340209961
Eval_StdReturn : 25.519899368286133
Eval_MaxReturn : 96.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 57.857142857142854
Train_AverageReturn : 54.47368240356445
Train_StdReturn : 17.9454402923584
Train_MaxReturn : 86.0
Train_MinReturn : 35.0
Train_AverageEpLen : 54.473684210526315
Actor Loss : 1524.0811767578125
Train_EnvstepsSoFar : 65066
TimeSinceStart : 61.594414472579956
Done logging...



********** Iteration 63 ************

Collecting data for eval...
Eval_AverageReturn : 57.28571319580078
Eval_StdReturn : 23.20538330078125
Eval_MaxReturn : 111.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 57.285714285714285
Train_AverageReturn : 60.764705657958984
Train_StdReturn : 26.210750579833984
Train_MaxReturn : 122.0
Train_MinReturn : 32.0
Train_AverageEpLen : 60.76470588235294
Actor Loss : 1672.9580078125
Train_EnvstepsSoFar : 66099
TimeSinceStart : 62.38428473472595
Done logging...



********** Iteration 64 ************

Collecting data for eval...
Eval_AverageReturn : 52.875
Eval_StdReturn : 23.224111557006836
Eval_MaxReturn : 97.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 52.875
Train_AverageReturn : 59.588233947753906
Train_StdReturn : 19.50583267211914
Train_MaxReturn : 112.0
Train_MinReturn : 35.0
Train_AverageEpLen : 59.588235294117645
Actor Loss : 1747.453125
Train_EnvstepsSoFar : 67112
TimeSinceStart : 63.90281438827515
Done logging...



********** Iteration 65 ************

Collecting data for eval...
Eval_AverageReturn : 50.0
Eval_StdReturn : 16.633298873901367
Eval_MaxReturn : 82.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 50.0
Train_AverageReturn : 51.849998474121094
Train_StdReturn : 18.390962600708008
Train_MaxReturn : 87.0
Train_MinReturn : 31.0
Train_AverageEpLen : 51.85
Actor Loss : 1322.7733154296875
Train_EnvstepsSoFar : 68149
TimeSinceStart : 64.69815373420715
Done logging...



********** Iteration 66 ************

Collecting data for eval...
Eval_AverageReturn : 61.71428680419922
Eval_StdReturn : 20.267595291137695
Eval_MaxReturn : 87.0
Eval_MinReturn : 36.0
Eval_AverageEpLen : 61.714285714285715
Train_AverageReturn : 44.565216064453125
Train_StdReturn : 11.705910682678223
Train_MaxReturn : 75.0
Train_MinReturn : 30.0
Train_AverageEpLen : 44.56521739130435
Actor Loss : 930.6530151367188
Train_EnvstepsSoFar : 69174
TimeSinceStart : 65.46730303764343
Done logging...



********** Iteration 67 ************

Collecting data for eval...
Eval_AverageReturn : 43.0
Eval_StdReturn : 7.8358154296875
Eval_MaxReturn : 53.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 43.0
Train_AverageReturn : 55.73684310913086
Train_StdReturn : 19.493162155151367
Train_MaxReturn : 91.0
Train_MinReturn : 31.0
Train_AverageEpLen : 55.73684210526316
Actor Loss : 1732.1673583984375
Train_EnvstepsSoFar : 70233
TimeSinceStart : 66.27928948402405
Done logging...



********** Iteration 68 ************

Collecting data for eval...
Eval_AverageReturn : 50.5
Eval_StdReturn : 18.055469512939453
Eval_MaxReturn : 83.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 50.5
Train_AverageReturn : 51.75
Train_StdReturn : 19.467601776123047
Train_MaxReturn : 105.0
Train_MinReturn : 33.0
Train_AverageEpLen : 51.75
Actor Loss : 1499.3612060546875
Train_EnvstepsSoFar : 71268
TimeSinceStart : 67.61847925186157
Done logging...



********** Iteration 69 ************

Collecting data for eval...
Eval_AverageReturn : 50.33333206176758
Eval_StdReturn : 16.51262092590332
Eval_MaxReturn : 82.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 50.333333333333336
Train_AverageReturn : 51.75
Train_StdReturn : 16.37643051147461
Train_MaxReturn : 97.0
Train_MinReturn : 31.0
Train_AverageEpLen : 51.75
Actor Loss : 1434.07470703125
Train_EnvstepsSoFar : 72303
TimeSinceStart : 68.42592453956604
Done logging...



********** Iteration 70 ************

Collecting data for eval...
Eval_AverageReturn : 54.25
Eval_StdReturn : 21.59137535095215
Eval_MaxReturn : 102.0
Eval_MinReturn : 36.0
Eval_AverageEpLen : 54.25
Train_AverageReturn : 40.720001220703125
Train_StdReturn : 11.867670059204102
Train_MaxReturn : 83.0
Train_MinReturn : 29.0
Train_AverageEpLen : 40.72
Actor Loss : 1308.986328125
Train_EnvstepsSoFar : 73321
TimeSinceStart : 69.18789601325989
Done logging...



********** Iteration 71 ************

Collecting data for eval...
Eval_AverageReturn : 52.625
Eval_StdReturn : 17.96480941772461
Eval_MaxReturn : 88.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 52.625
Train_AverageReturn : 47.3636360168457
Train_StdReturn : 15.956033706665039
Train_MaxReturn : 84.0
Train_MinReturn : 29.0
Train_AverageEpLen : 47.36363636363637
Actor Loss : 1133.914306640625
Train_EnvstepsSoFar : 74363
TimeSinceStart : 70.0699954032898
Done logging...



********** Iteration 72 ************

Collecting data for eval...
Eval_AverageReturn : 47.0
Eval_StdReturn : 18.702346801757812
Eval_MaxReturn : 84.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 47.0
Train_AverageReturn : 53.05263137817383
Train_StdReturn : 18.144084930419922
Train_MaxReturn : 80.0
Train_MinReturn : 30.0
Train_AverageEpLen : 53.05263157894737
Actor Loss : 1839.9808349609375
Train_EnvstepsSoFar : 75371
TimeSinceStart : 70.82259845733643
Done logging...



********** Iteration 73 ************

Collecting data for eval...
Eval_AverageReturn : 43.400001525878906
Eval_StdReturn : 13.850631713867188
Eval_MaxReturn : 70.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 43.4
Train_AverageReturn : 50.900001525878906
Train_StdReturn : 22.06785011291504
Train_MaxReturn : 104.0
Train_MinReturn : 30.0
Train_AverageEpLen : 50.9
Actor Loss : 1497.385498046875
Train_EnvstepsSoFar : 76389
TimeSinceStart : 71.59218096733093
Done logging...



********** Iteration 74 ************

Collecting data for eval...
Eval_AverageReturn : 48.33333206176758
Eval_StdReturn : 11.469767570495605
Eval_MaxReturn : 69.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 48.333333333333336
Train_AverageReturn : 53.52631759643555
Train_StdReturn : 14.14722728729248
Train_MaxReturn : 79.0
Train_MinReturn : 28.0
Train_AverageEpLen : 53.526315789473685
Actor Loss : 931.759033203125
Train_EnvstepsSoFar : 77406
TimeSinceStart : 72.36843299865723
Done logging...



********** Iteration 75 ************

Collecting data for eval...
Eval_AverageReturn : 42.099998474121094
Eval_StdReturn : 9.093404769897461
Eval_MaxReturn : 58.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 42.1
Train_AverageReturn : 44.869564056396484
Train_StdReturn : 13.718613624572754
Train_MaxReturn : 76.0
Train_MinReturn : 28.0
Train_AverageEpLen : 44.869565217391305
Actor Loss : 1687.473876953125
Train_EnvstepsSoFar : 78438
TimeSinceStart : 73.13927721977234
Done logging...



********** Iteration 76 ************

Collecting data for eval...
Eval_AverageReturn : 44.88888931274414
Eval_StdReturn : 14.425629615783691
Eval_MaxReturn : 75.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 44.888888888888886
Train_AverageReturn : 49.0
Train_StdReturn : 15.537972450256348
Train_MaxReturn : 78.0
Train_MinReturn : 28.0
Train_AverageEpLen : 49.0
Actor Loss : 1020.628662109375
Train_EnvstepsSoFar : 79467
TimeSinceStart : 73.90962767601013
Done logging...



********** Iteration 77 ************

Collecting data for eval...
Eval_AverageReturn : 47.11111068725586
Eval_StdReturn : 17.01923370361328
Eval_MaxReturn : 82.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 47.111111111111114
Train_AverageReturn : 46.227272033691406
Train_StdReturn : 12.139086723327637
Train_MaxReturn : 74.0
Train_MinReturn : 31.0
Train_AverageEpLen : 46.22727272727273
Actor Loss : 1299.32177734375
Train_EnvstepsSoFar : 80484
TimeSinceStart : 74.67964267730713
Done logging...



********** Iteration 78 ************

Collecting data for eval...
Eval_AverageReturn : 40.90909194946289
Eval_StdReturn : 10.731894493103027
Eval_MaxReturn : 59.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 40.90909090909091
Train_AverageReturn : 44.30434799194336
Train_StdReturn : 16.217100143432617
Train_MaxReturn : 84.0
Train_MinReturn : 28.0
Train_AverageEpLen : 44.30434782608695
Actor Loss : 1344.9019775390625
Train_EnvstepsSoFar : 81503
TimeSinceStart : 75.44366502761841
Done logging...



********** Iteration 79 ************

Collecting data for eval...
Eval_AverageReturn : 59.0
Eval_StdReturn : 16.309507369995117
Eval_MaxReturn : 78.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 59.0
Train_AverageReturn : 48.380950927734375
Train_StdReturn : 14.197504997253418
Train_MaxReturn : 80.0
Train_MinReturn : 26.0
Train_AverageEpLen : 48.38095238095238
Actor Loss : 1178.0341796875
Train_EnvstepsSoFar : 82519
TimeSinceStart : 76.2135763168335
Done logging...



********** Iteration 80 ************

Collecting data for eval...
Eval_AverageReturn : 47.66666793823242
Eval_StdReturn : 13.207742691040039
Eval_MaxReturn : 68.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 47.666666666666664
Train_AverageReturn : 42.79166793823242
Train_StdReturn : 12.776864051818848
Train_MaxReturn : 74.0
Train_MinReturn : 29.0
Train_AverageEpLen : 42.791666666666664
Actor Loss : 1013.457763671875
Train_EnvstepsSoFar : 83546
TimeSinceStart : 76.9637701511383
Done logging...



********** Iteration 81 ************

Collecting data for eval...
Eval_AverageReturn : 42.20000076293945
Eval_StdReturn : 13.40746021270752
Eval_MaxReturn : 66.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 42.2
Train_AverageReturn : 43.5217399597168
Train_StdReturn : 12.71722412109375
Train_MaxReturn : 67.0
Train_MinReturn : 28.0
Train_AverageEpLen : 43.52173913043478
Actor Loss : 1145.48876953125
Train_EnvstepsSoFar : 84547
TimeSinceStart : 77.62752389907837
Done logging...



********** Iteration 82 ************

Collecting data for eval...
Eval_AverageReturn : 42.181819915771484
Eval_StdReturn : 10.675530433654785
Eval_MaxReturn : 68.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 42.18181818181818
Train_AverageReturn : 40.400001525878906
Train_StdReturn : 8.8904447555542
Train_MaxReturn : 56.0
Train_MinReturn : 28.0
Train_AverageEpLen : 40.4
Actor Loss : 849.2449340820312
Train_EnvstepsSoFar : 85557
TimeSinceStart : 78.32678031921387
Done logging...



********** Iteration 83 ************

Collecting data for eval...
Eval_AverageReturn : 45.0
Eval_StdReturn : 12.780192375183105
Eval_MaxReturn : 62.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 45.0
Train_AverageReturn : 42.45833206176758
Train_StdReturn : 12.61275577545166
Train_MaxReturn : 70.0
Train_MinReturn : 28.0
Train_AverageEpLen : 42.458333333333336
Actor Loss : 937.68603515625
Train_EnvstepsSoFar : 86576
TimeSinceStart : 78.99417495727539
Done logging...



********** Iteration 84 ************

Collecting data for eval...
Eval_AverageReturn : 51.875
Eval_StdReturn : 19.585948944091797
Eval_MaxReturn : 77.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 51.875
Train_AverageReturn : 44.91304397583008
Train_StdReturn : 13.243252754211426
Train_MaxReturn : 72.0
Train_MinReturn : 26.0
Train_AverageEpLen : 44.91304347826087
Actor Loss : 1164.783447265625
Train_EnvstepsSoFar : 87609
TimeSinceStart : 79.6985514163971
Done logging...



********** Iteration 85 ************

Collecting data for eval...
Eval_AverageReturn : 38.0
Eval_StdReturn : 5.526793956756592
Eval_MaxReturn : 48.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 38.0
Train_AverageReturn : 44.65217208862305
Train_StdReturn : 11.52165699005127
Train_MaxReturn : 70.0
Train_MinReturn : 30.0
Train_AverageEpLen : 44.65217391304348
Actor Loss : 1151.5870361328125
Train_EnvstepsSoFar : 88636
TimeSinceStart : 80.43170595169067
Done logging...



********** Iteration 86 ************

Collecting data for eval...
Eval_AverageReturn : 40.29999923706055
Eval_StdReturn : 13.000384330749512
Eval_MaxReturn : 71.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 40.3
Train_AverageReturn : 41.70833206176758
Train_StdReturn : 13.74311637878418
Train_MaxReturn : 84.0
Train_MinReturn : 29.0
Train_AverageEpLen : 41.708333333333336
Actor Loss : 1364.051025390625
Train_EnvstepsSoFar : 89637
TimeSinceStart : 81.15288209915161
Done logging...



********** Iteration 87 ************

Collecting data for eval...
Eval_AverageReturn : 50.0
Eval_StdReturn : 12.927145957946777
Eval_MaxReturn : 64.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 50.0
Train_AverageReturn : 45.08695602416992
Train_StdReturn : 10.926286697387695
Train_MaxReturn : 64.0
Train_MinReturn : 28.0
Train_AverageEpLen : 45.08695652173913
Actor Loss : 1145.3758544921875
Train_EnvstepsSoFar : 90674
TimeSinceStart : 81.92509245872498
Done logging...



********** Iteration 88 ************

Collecting data for eval...
Eval_AverageReturn : 40.09090805053711
Eval_StdReturn : 11.540084838867188
Eval_MaxReturn : 71.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 40.09090909090909
Train_AverageReturn : 45.34782791137695
Train_StdReturn : 14.070037841796875
Train_MaxReturn : 66.0
Train_MinReturn : 28.0
Train_AverageEpLen : 45.34782608695652
Actor Loss : 1027.790771484375
Train_EnvstepsSoFar : 91717
TimeSinceStart : 82.6895318031311
Done logging...



********** Iteration 89 ************

Collecting data for eval...
Eval_AverageReturn : 47.77777862548828
Eval_StdReturn : 16.784767150878906
Eval_MaxReturn : 82.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 47.77777777777778
Train_AverageReturn : 45.5
Train_StdReturn : 12.19444751739502
Train_MaxReturn : 76.0
Train_MinReturn : 26.0
Train_AverageEpLen : 45.5
Actor Loss : 900.9420166015625
Train_EnvstepsSoFar : 92718
TimeSinceStart : 83.43929386138916
Done logging...



********** Iteration 90 ************

Collecting data for eval...
Eval_AverageReturn : 40.54545593261719
Eval_StdReturn : 11.105802536010742
Eval_MaxReturn : 61.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 40.54545454545455
Train_AverageReturn : 39.0
Train_StdReturn : 10.593902587890625
Train_MaxReturn : 64.0
Train_MinReturn : 26.0
Train_AverageEpLen : 39.0
Actor Loss : 857.0232543945312
Train_EnvstepsSoFar : 93732
TimeSinceStart : 84.19605803489685
Done logging...



********** Iteration 91 ************

Collecting data for eval...
Eval_AverageReturn : 41.900001525878906
Eval_StdReturn : 15.062868118286133
Eval_MaxReturn : 78.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 41.9
Train_AverageReturn : 45.95454406738281
Train_StdReturn : 15.058906555175781
Train_MaxReturn : 81.0
Train_MinReturn : 28.0
Train_AverageEpLen : 45.95454545454545
Actor Loss : 853.57275390625
Train_EnvstepsSoFar : 94743
TimeSinceStart : 84.94318342208862
Done logging...



********** Iteration 92 ************

Collecting data for eval...
Eval_AverageReturn : 45.79999923706055
Eval_StdReturn : 13.264991760253906
Eval_MaxReturn : 73.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 45.8
Train_AverageReturn : 42.45833206176758
Train_StdReturn : 11.782682418823242
Train_MaxReturn : 74.0
Train_MinReturn : 29.0
Train_AverageEpLen : 42.458333333333336
Actor Loss : 563.9468383789062
Train_EnvstepsSoFar : 95762
TimeSinceStart : 85.72270941734314
Done logging...



********** Iteration 93 ************

Collecting data for eval...
Eval_AverageReturn : 45.33333206176758
Eval_StdReturn : 8.692270278930664
Eval_MaxReturn : 57.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 45.333333333333336
Train_AverageReturn : 40.040000915527344
Train_StdReturn : 8.932994842529297
Train_MaxReturn : 55.0
Train_MinReturn : 26.0
Train_AverageEpLen : 40.04
Actor Loss : 849.8094482421875
Train_EnvstepsSoFar : 96763
TimeSinceStart : 86.45047760009766
Done logging...



********** Iteration 94 ************

Collecting data for eval...
Eval_AverageReturn : 37.45454406738281
Eval_StdReturn : 9.480732917785645
Eval_MaxReturn : 59.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 37.45454545454545
Train_AverageReturn : 41.83333206176758
Train_StdReturn : 14.129362106323242
Train_MaxReturn : 81.0
Train_MinReturn : 26.0
Train_AverageEpLen : 41.833333333333336
Actor Loss : 812.798583984375
Train_EnvstepsSoFar : 97767
TimeSinceStart : 87.29285049438477
Done logging...



********** Iteration 95 ************

Collecting data for eval...
Eval_AverageReturn : 38.09090805053711
Eval_StdReturn : 10.422480583190918
Eval_MaxReturn : 56.0
Eval_MinReturn : 26.0
Eval_AverageEpLen : 38.09090909090909
Train_AverageReturn : 39.69230651855469
Train_StdReturn : 9.388082504272461
Train_MaxReturn : 64.0
Train_MinReturn : 27.0
Train_AverageEpLen : 39.69230769230769
Actor Loss : 775.1537475585938
Train_EnvstepsSoFar : 98799
TimeSinceStart : 88.11778688430786
Done logging...



********** Iteration 96 ************

Collecting data for eval...
Eval_AverageReturn : 44.20000076293945
Eval_StdReturn : 13.40746021270752
Eval_MaxReturn : 66.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 44.2
Train_AverageReturn : 44.565216064453125
Train_StdReturn : 14.073800086975098
Train_MaxReturn : 73.0
Train_MinReturn : 30.0
Train_AverageEpLen : 44.56521739130435
Actor Loss : 1732.2099609375
Train_EnvstepsSoFar : 99824
TimeSinceStart : 89.09730243682861
Done logging...



********** Iteration 97 ************

Collecting data for eval...
Eval_AverageReturn : 42.5
Eval_StdReturn : 8.78919792175293
Eval_MaxReturn : 61.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 42.5
Train_AverageReturn : 40.15999984741211
Train_StdReturn : 9.540146827697754
Train_MaxReturn : 61.0
Train_MinReturn : 28.0
Train_AverageEpLen : 40.16
Actor Loss : 693.4832153320312
Train_EnvstepsSoFar : 100828
TimeSinceStart : 89.93574261665344
Done logging...



********** Iteration 98 ************

Collecting data for eval...
Eval_AverageReturn : 48.33333206176758
Eval_StdReturn : 10.984837532043457
Eval_MaxReturn : 60.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 48.333333333333336
Train_AverageReturn : 47.54545593261719
Train_StdReturn : 15.14993953704834
Train_MaxReturn : 78.0
Train_MinReturn : 27.0
Train_AverageEpLen : 47.54545454545455
Actor Loss : 1235.210205078125
Train_EnvstepsSoFar : 101874
TimeSinceStart : 90.79559135437012
Done logging...



********** Iteration 99 ************

Collecting data for eval...
Eval_AverageReturn : 44.88888931274414
Eval_StdReturn : 14.517762184143066
Eval_MaxReturn : 62.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 44.888888888888886
Train_AverageReturn : 43.16666793823242
Train_StdReturn : 13.180373191833496
Train_MaxReturn : 75.0
Train_MinReturn : 27.0
Train_AverageEpLen : 43.166666666666664
Actor Loss : 1027.063720703125
Train_EnvstepsSoFar : 102910
TimeSinceStart : 91.77412939071655
Done logging...



********** Iteration 100 ************

Collecting data for eval...
Eval_AverageReturn : 42.70000076293945
Eval_StdReturn : 11.44596004486084
Eval_MaxReturn : 61.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 42.7
Train_AverageReturn : 40.08000183105469
Train_StdReturn : 12.721383094787598
Train_MaxReturn : 72.0
Train_MinReturn : 28.0
Train_AverageEpLen : 40.08
Actor Loss : 937.181884765625
Train_EnvstepsSoFar : 103912
TimeSinceStart : 92.6074447631836
Done logging...



********** Iteration 101 ************

Collecting data for eval...
Eval_AverageReturn : 45.5
Eval_StdReturn : 10.660675048828125
Eval_MaxReturn : 62.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 45.5
Train_AverageReturn : 51.0
Train_StdReturn : 17.779067993164062
Train_MaxReturn : 108.0
Train_MinReturn : 28.0
Train_AverageEpLen : 51.0
Actor Loss : 1222.0732421875
Train_EnvstepsSoFar : 104983
TimeSinceStart : 93.41227388381958
Done logging...



********** Iteration 102 ************

Collecting data for eval...
Eval_AverageReturn : 40.818180084228516
Eval_StdReturn : 11.093144416809082
Eval_MaxReturn : 61.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 40.81818181818182
Train_AverageReturn : 43.45833206176758
Train_StdReturn : 13.079816818237305
Train_MaxReturn : 82.0
Train_MinReturn : 28.0
Train_AverageEpLen : 43.458333333333336
Actor Loss : 1074.0887451171875
Train_EnvstepsSoFar : 106026
TimeSinceStart : 94.38941621780396
Done logging...



********** Iteration 103 ************

Collecting data for eval...
Eval_AverageReturn : 45.88888931274414
Eval_StdReturn : 13.08471965789795
Eval_MaxReturn : 66.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 45.888888888888886
Train_AverageReturn : 39.03845977783203
Train_StdReturn : 10.044059753417969
Train_MaxReturn : 68.0
Train_MinReturn : 28.0
Train_AverageEpLen : 39.03846153846154
Actor Loss : 871.8975830078125
Train_EnvstepsSoFar : 107041
TimeSinceStart : 95.35440587997437
Done logging...



********** Iteration 104 ************

Collecting data for eval...
Eval_AverageReturn : 54.125
Eval_StdReturn : 22.68500328063965
Eval_MaxReturn : 96.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 54.125
Train_AverageReturn : 39.30769348144531
Train_StdReturn : 10.876118659973145
Train_MaxReturn : 66.0
Train_MinReturn : 28.0
Train_AverageEpLen : 39.30769230769231
Actor Loss : 878.4864501953125
Train_EnvstepsSoFar : 108063
TimeSinceStart : 96.68316864967346
Done logging...



********** Iteration 105 ************

Collecting data for eval...
Eval_AverageReturn : 46.66666793823242
Eval_StdReturn : 12.310790061950684
Eval_MaxReturn : 69.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 46.666666666666664
Train_AverageReturn : 42.875
Train_StdReturn : 17.09608268737793
Train_MaxReturn : 107.0
Train_MinReturn : 28.0
Train_AverageEpLen : 42.875
Actor Loss : 755.2427978515625
Train_EnvstepsSoFar : 109092
TimeSinceStart : 98.09637594223022
Done logging...



********** Iteration 106 ************

Collecting data for eval...
Eval_AverageReturn : 53.5
Eval_StdReturn : 16.822603225708008
Eval_MaxReturn : 78.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 53.5
Train_AverageReturn : 43.91304397583008
Train_StdReturn : 12.043086051940918
Train_MaxReturn : 77.0
Train_MinReturn : 29.0
Train_AverageEpLen : 43.91304347826087
Actor Loss : 1024.352294921875
Train_EnvstepsSoFar : 110102
TimeSinceStart : 99.42577934265137
Done logging...



********** Iteration 107 ************

Collecting data for eval...
Eval_AverageReturn : 50.75
Eval_StdReturn : 16.76119041442871
Eval_MaxReturn : 83.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 50.75
Train_AverageReturn : 43.65217208862305
Train_StdReturn : 10.369725227355957
Train_MaxReturn : 66.0
Train_MinReturn : 28.0
Train_AverageEpLen : 43.65217391304348
Actor Loss : 749.6386108398438
Train_EnvstepsSoFar : 111106
TimeSinceStart : 100.29060363769531
Done logging...



********** Iteration 108 ************

Collecting data for eval...
Eval_AverageReturn : 46.22222137451172
Eval_StdReturn : 10.90135383605957
Eval_MaxReturn : 64.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 46.22222222222222
Train_AverageReturn : 51.599998474121094
Train_StdReturn : 18.042726516723633
Train_MaxReturn : 89.0
Train_MinReturn : 29.0
Train_AverageEpLen : 51.6
Actor Loss : 1155.2255859375
Train_EnvstepsSoFar : 112138
TimeSinceStart : 101.26472449302673
Done logging...



********** Iteration 109 ************

Collecting data for eval...
Eval_AverageReturn : 48.66666793823242
Eval_StdReturn : 14.809906005859375
Eval_MaxReturn : 75.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 48.666666666666664
Train_AverageReturn : 40.68000030517578
Train_StdReturn : 11.667801856994629
Train_MaxReturn : 74.0
Train_MinReturn : 27.0
Train_AverageEpLen : 40.68
Actor Loss : 953.2741088867188
Train_EnvstepsSoFar : 113155
TimeSinceStart : 102.24861216545105
Done logging...



********** Iteration 110 ************

Collecting data for eval...
Eval_AverageReturn : 43.0
Eval_StdReturn : 11.099549293518066
Eval_MaxReturn : 66.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 43.0
Train_AverageReturn : 41.95833206176758
Train_StdReturn : 10.918177604675293
Train_MaxReturn : 71.0
Train_MinReturn : 28.0
Train_AverageEpLen : 41.958333333333336
Actor Loss : 751.8460083007812
Train_EnvstepsSoFar : 114162
TimeSinceStart : 103.23900008201599
Done logging...



********** Iteration 111 ************

Collecting data for eval...
Eval_AverageReturn : 47.11111068725586
Eval_StdReturn : 9.882019996643066
Eval_MaxReturn : 62.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 47.111111111111114
Train_AverageReturn : 46.5
Train_StdReturn : 14.28842544555664
Train_MaxReturn : 74.0
Train_MinReturn : 27.0
Train_AverageEpLen : 46.5
Actor Loss : 745.030029296875
Train_EnvstepsSoFar : 115185
TimeSinceStart : 104.2282395362854
Done logging...



********** Iteration 112 ************

Collecting data for eval...
Eval_AverageReturn : 40.45454406738281
Eval_StdReturn : 11.649141311645508
Eval_MaxReturn : 69.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 40.45454545454545
Train_AverageReturn : 49.42856979370117
Train_StdReturn : 16.617752075195312
Train_MaxReturn : 94.0
Train_MinReturn : 27.0
Train_AverageEpLen : 49.42857142857143
Actor Loss : 1214.6572265625
Train_EnvstepsSoFar : 116223
TimeSinceStart : 105.23455953598022
Done logging...



********** Iteration 113 ************

Collecting data for eval...
Eval_AverageReturn : 45.44444274902344
Eval_StdReturn : 15.011929512023926
Eval_MaxReturn : 68.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 45.44444444444444
Train_AverageReturn : 41.400001525878906
Train_StdReturn : 10.954450607299805
Train_MaxReturn : 63.0
Train_MinReturn : 27.0
Train_AverageEpLen : 41.4
Actor Loss : 812.4706420898438
Train_EnvstepsSoFar : 117258
TimeSinceStart : 106.2147376537323
Done logging...



********** Iteration 114 ************

Collecting data for eval...
Eval_AverageReturn : 41.099998474121094
Eval_StdReturn : 11.785161018371582
Eval_MaxReturn : 65.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 41.1
Train_AverageReturn : 44.0
Train_StdReturn : 16.90907096862793
Train_MaxReturn : 87.0
Train_MinReturn : 28.0
Train_AverageEpLen : 44.0
Actor Loss : 1315.51611328125
Train_EnvstepsSoFar : 118314
TimeSinceStart : 107.21006417274475
Done logging...



********** Iteration 115 ************

Collecting data for eval...
Eval_AverageReturn : 41.70000076293945
Eval_StdReturn : 14.007497787475586
Eval_MaxReturn : 71.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 41.7
Train_AverageReturn : 45.727272033691406
Train_StdReturn : 16.70650863647461
Train_MaxReturn : 86.0
Train_MinReturn : 28.0
Train_AverageEpLen : 45.72727272727273
Actor Loss : 1156.8997802734375
Train_EnvstepsSoFar : 119320
TimeSinceStart : 108.75877666473389
Done logging...



********** Iteration 116 ************

Collecting data for eval...
Eval_AverageReturn : 36.5
Eval_StdReturn : 5.423713207244873
Eval_MaxReturn : 47.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 36.5
Train_AverageReturn : 48.9523811340332
Train_StdReturn : 14.387415885925293
Train_MaxReturn : 93.0
Train_MinReturn : 30.0
Train_AverageEpLen : 48.95238095238095
Actor Loss : 788.1390991210938
Train_EnvstepsSoFar : 120348
TimeSinceStart : 110.1575231552124
Done logging...



********** Iteration 117 ************

Collecting data for eval...
Eval_AverageReturn : 47.55555725097656
Eval_StdReturn : 16.486433029174805
Eval_MaxReturn : 74.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 47.55555555555556
Train_AverageReturn : 50.095237731933594
Train_StdReturn : 15.880220413208008
Train_MaxReturn : 88.0
Train_MinReturn : 31.0
Train_AverageEpLen : 50.095238095238095
Actor Loss : 914.008544921875
Train_EnvstepsSoFar : 121400
TimeSinceStart : 111.34398007392883
Done logging...



********** Iteration 118 ************

Collecting data for eval...
Eval_AverageReturn : 50.22222137451172
Eval_StdReturn : 12.993825912475586
Eval_MaxReturn : 66.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 50.22222222222222
Train_AverageReturn : 52.04999923706055
Train_StdReturn : 24.595680236816406
Train_MaxReturn : 142.0
Train_MinReturn : 33.0
Train_AverageEpLen : 52.05
Actor Loss : 1442.356201171875
Train_EnvstepsSoFar : 122441
TimeSinceStart : 112.57372403144836
Done logging...



********** Iteration 119 ************

Collecting data for eval...
Eval_AverageReturn : 43.0
Eval_StdReturn : 14.049910545349121
Eval_MaxReturn : 70.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 43.0
Train_AverageReturn : 46.318180084228516
Train_StdReturn : 17.0943546295166
Train_MaxReturn : 88.0
Train_MinReturn : 27.0
Train_AverageEpLen : 46.31818181818182
Actor Loss : 1058.3590087890625
Train_EnvstepsSoFar : 123460
TimeSinceStart : 114.06389856338501
Done logging...



********** Iteration 120 ************

Collecting data for eval...
Eval_AverageReturn : 50.375
Eval_StdReturn : 19.273929595947266
Eval_MaxReturn : 90.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 50.375
Train_AverageReturn : 50.400001525878906
Train_StdReturn : 16.737382888793945
Train_MaxReturn : 79.0
Train_MinReturn : 29.0
Train_AverageEpLen : 50.4
Actor Loss : 1162.1959228515625
Train_EnvstepsSoFar : 124468
TimeSinceStart : 114.86140155792236
Done logging...



********** Iteration 121 ************

Collecting data for eval...
Eval_AverageReturn : 53.75
Eval_StdReturn : 19.350387573242188
Eval_MaxReturn : 86.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 53.75
Train_AverageReturn : 46.772727966308594
Train_StdReturn : 15.776656150817871
Train_MaxReturn : 78.0
Train_MinReturn : 28.0
Train_AverageEpLen : 46.77272727272727
Actor Loss : 1074.4486083984375
Train_EnvstepsSoFar : 125497
TimeSinceStart : 116.35340213775635
Done logging...



********** Iteration 122 ************

Collecting data for eval...
Eval_AverageReturn : 43.20000076293945
Eval_StdReturn : 15.315352439880371
Eval_MaxReturn : 82.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 43.2
Train_AverageReturn : 50.75
Train_StdReturn : 20.666095733642578
Train_MaxReturn : 115.0
Train_MinReturn : 29.0
Train_AverageEpLen : 50.75
Actor Loss : 1356.952880859375
Train_EnvstepsSoFar : 126512
TimeSinceStart : 117.84130358695984
Done logging...



********** Iteration 123 ************

Collecting data for eval...
Eval_AverageReturn : 46.5
Eval_StdReturn : 14.840822219848633
Eval_MaxReturn : 74.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 46.5
Train_AverageReturn : 53.3684196472168
Train_StdReturn : 17.469404220581055
Train_MaxReturn : 86.0
Train_MinReturn : 28.0
Train_AverageEpLen : 53.36842105263158
Actor Loss : 894.813720703125
Train_EnvstepsSoFar : 127526
TimeSinceStart : 118.6503529548645
Done logging...



********** Iteration 124 ************

Collecting data for eval...
Eval_AverageReturn : 48.22222137451172
Eval_StdReturn : 11.726302146911621
Eval_MaxReturn : 64.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 48.22222222222222
Train_AverageReturn : 48.0
Train_StdReturn : 16.538555145263672
Train_MaxReturn : 82.0
Train_MinReturn : 30.0
Train_AverageEpLen : 48.0
Actor Loss : 900.9891357421875
Train_EnvstepsSoFar : 128534
TimeSinceStart : 120.11316061019897
Done logging...



********** Iteration 125 ************

Collecting data for eval...
Eval_AverageReturn : 45.55555725097656
Eval_StdReturn : 15.521391868591309
Eval_MaxReturn : 76.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 45.55555555555556
Train_AverageReturn : 46.40909194946289
Train_StdReturn : 14.941275596618652
Train_MaxReturn : 88.0
Train_MinReturn : 30.0
Train_AverageEpLen : 46.40909090909091
Actor Loss : 1070.3447265625
Train_EnvstepsSoFar : 129555
TimeSinceStart : 121.5441780090332
Done logging...



********** Iteration 126 ************

Collecting data for eval...
Eval_AverageReturn : 44.55555725097656
Eval_StdReturn : 15.578554153442383
Eval_MaxReturn : 77.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 44.55555555555556
Train_AverageReturn : 49.19047546386719
Train_StdReturn : 17.442747116088867
Train_MaxReturn : 83.0
Train_MinReturn : 29.0
Train_AverageEpLen : 49.19047619047619
Actor Loss : 1158.87841796875
Train_EnvstepsSoFar : 130588
TimeSinceStart : 123.106698513031
Done logging...



********** Iteration 127 ************

Collecting data for eval...
Eval_AverageReturn : 50.5
Eval_StdReturn : 14.73091983795166
Eval_MaxReturn : 68.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 50.5
Train_AverageReturn : 48.9523811340332
Train_StdReturn : 17.83115577697754
Train_MaxReturn : 78.0
Train_MinReturn : 28.0
Train_AverageEpLen : 48.95238095238095
Actor Loss : 761.36474609375
Train_EnvstepsSoFar : 131616
TimeSinceStart : 124.55728721618652
Done logging...



********** Iteration 128 ************

Collecting data for eval...
Eval_AverageReturn : 46.77777862548828
Eval_StdReturn : 15.55476188659668
Eval_MaxReturn : 78.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 46.77777777777778
Train_AverageReturn : 43.4782600402832
Train_StdReturn : 13.752058029174805
Train_MaxReturn : 76.0
Train_MinReturn : 29.0
Train_AverageEpLen : 43.47826086956522
Actor Loss : 650.2353515625
Train_EnvstepsSoFar : 132616
TimeSinceStart : 125.86981415748596
Done logging...



********** Iteration 129 ************

Collecting data for eval...
Eval_AverageReturn : 50.625
Eval_StdReturn : 18.117238998413086
Eval_MaxReturn : 82.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 50.625
Train_AverageReturn : 43.625
Train_StdReturn : 14.834678649902344
Train_MaxReturn : 91.0
Train_MinReturn : 29.0
Train_AverageEpLen : 43.625
Actor Loss : 771.6671142578125
Train_EnvstepsSoFar : 133663
TimeSinceStart : 127.23348927497864
Done logging...



********** Iteration 130 ************

Collecting data for eval...
Eval_AverageReturn : 45.44444274902344
Eval_StdReturn : 13.233888626098633
Eval_MaxReturn : 75.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 45.44444444444444
Train_AverageReturn : 48.71428680419922
Train_StdReturn : 15.829877853393555
Train_MaxReturn : 90.0
Train_MinReturn : 30.0
Train_AverageEpLen : 48.714285714285715
Actor Loss : 877.097412109375
Train_EnvstepsSoFar : 134686
TimeSinceStart : 128.62699007987976
Done logging...



********** Iteration 131 ************

Collecting data for eval...
Eval_AverageReturn : 47.88888931274414
Eval_StdReturn : 17.44479751586914
Eval_MaxReturn : 79.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 47.888888888888886
Train_AverageReturn : 45.39130401611328
Train_StdReturn : 19.848861694335938
Train_MaxReturn : 121.0
Train_MinReturn : 26.0
Train_AverageEpLen : 45.391304347826086
Actor Loss : 692.7977905273438
Train_EnvstepsSoFar : 135730
TimeSinceStart : 129.97737288475037
Done logging...



********** Iteration 132 ************

Collecting data for eval...
Eval_AverageReturn : 44.66666793823242
Eval_StdReturn : 13.324997901916504
Eval_MaxReturn : 70.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 44.666666666666664
Train_AverageReturn : 43.69565200805664
Train_StdReturn : 15.490347862243652
Train_MaxReturn : 86.0
Train_MinReturn : 28.0
Train_AverageEpLen : 43.69565217391305
Actor Loss : 667.996337890625
Train_EnvstepsSoFar : 136735
TimeSinceStart : 131.42058563232422
Done logging...



********** Iteration 133 ************

Collecting data for eval...
Eval_AverageReturn : 41.727272033691406
Eval_StdReturn : 15.591902732849121
Eval_MaxReturn : 69.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 41.72727272727273
Train_AverageReturn : 47.66666793823242
Train_StdReturn : 19.443037033081055
Train_MaxReturn : 98.0
Train_MinReturn : 26.0
Train_AverageEpLen : 47.666666666666664
Actor Loss : 737.6661987304688
Train_EnvstepsSoFar : 137736
TimeSinceStart : 132.7763020992279
Done logging...



********** Iteration 134 ************

Collecting data for eval...
Eval_AverageReturn : 45.11111068725586
Eval_StdReturn : 13.67434310913086
Eval_MaxReturn : 80.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 45.111111111111114
Train_AverageReturn : 41.95833206176758
Train_StdReturn : 18.52808380126953
Train_MaxReturn : 92.0
Train_MinReturn : 24.0
Train_AverageEpLen : 41.958333333333336
Actor Loss : 683.7393798828125
Train_EnvstepsSoFar : 138743
TimeSinceStart : 133.7223243713379
Done logging...



********** Iteration 135 ************

Collecting data for eval...
Eval_AverageReturn : 42.0
Eval_StdReturn : 9.5498685836792
Eval_MaxReturn : 56.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 42.0
Train_AverageReturn : 41.279998779296875
Train_StdReturn : 10.351888656616211
Train_MaxReturn : 69.0
Train_MinReturn : 28.0
Train_AverageEpLen : 41.28
Actor Loss : 803.1171875
Train_EnvstepsSoFar : 139775
TimeSinceStart : 135.16749811172485
Done logging...



********** Iteration 136 ************

Collecting data for eval...
Eval_AverageReturn : 46.77777862548828
Eval_StdReturn : 15.82387638092041
Eval_MaxReturn : 81.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 46.77777777777778
Train_AverageReturn : 43.04166793823242
Train_StdReturn : 19.53731346130371
Train_MaxReturn : 102.0
Train_MinReturn : 28.0
Train_AverageEpLen : 43.041666666666664
Actor Loss : 705.7742309570312
Train_EnvstepsSoFar : 140808
TimeSinceStart : 136.58375096321106
Done logging...



********** Iteration 137 ************

Collecting data for eval...
Eval_AverageReturn : 46.0
Eval_StdReturn : 16.911535263061523
Eval_MaxReturn : 80.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 46.0
Train_AverageReturn : 41.599998474121094
Train_StdReturn : 12.936769485473633
Train_MaxReturn : 73.0
Train_MinReturn : 26.0
Train_AverageEpLen : 41.6
Actor Loss : 619.1776733398438
Train_EnvstepsSoFar : 141848
TimeSinceStart : 137.9928777217865
Done logging...



********** Iteration 138 ************

Collecting data for eval...
Eval_AverageReturn : 38.818180084228516
Eval_StdReturn : 10.886340141296387
Eval_MaxReturn : 62.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 38.81818181818182
Train_AverageReturn : 38.69230651855469
Train_StdReturn : 14.7094144821167
Train_MaxReturn : 86.0
Train_MinReturn : 26.0
Train_AverageEpLen : 38.69230769230769
Actor Loss : 558.4539794921875
Train_EnvstepsSoFar : 142854
TimeSinceStart : 139.00415682792664
Done logging...



********** Iteration 139 ************

Collecting data for eval...
Eval_AverageReturn : 41.900001525878906
Eval_StdReturn : 8.203048706054688
Eval_MaxReturn : 61.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 41.9
Train_AverageReturn : 42.29166793823242
Train_StdReturn : 13.68234634399414
Train_MaxReturn : 75.0
Train_MinReturn : 28.0
Train_AverageEpLen : 42.291666666666664
Actor Loss : 758.1383056640625
Train_EnvstepsSoFar : 143869
TimeSinceStart : 139.9988181591034
Done logging...



********** Iteration 140 ************

Collecting data for eval...
Eval_AverageReturn : 38.6363639831543
Eval_StdReturn : 13.431798934936523
Eval_MaxReturn : 72.0
Eval_MinReturn : 26.0
Eval_AverageEpLen : 38.63636363636363
Train_AverageReturn : 46.59090805053711
Train_StdReturn : 17.507553100585938
Train_MaxReturn : 76.0
Train_MinReturn : 26.0
Train_AverageEpLen : 46.59090909090909
Actor Loss : 1567.3701171875
Train_EnvstepsSoFar : 144894
TimeSinceStart : 141.05566692352295
Done logging...



********** Iteration 141 ************

Collecting data for eval...
Eval_AverageReturn : 38.272727966308594
Eval_StdReturn : 12.196057319641113
Eval_MaxReturn : 74.0
Eval_MinReturn : 26.0
Eval_AverageEpLen : 38.27272727272727
Train_AverageReturn : 46.272727966308594
Train_StdReturn : 17.260520935058594
Train_MaxReturn : 82.0
Train_MinReturn : 26.0
Train_AverageEpLen : 46.27272727272727
Actor Loss : 778.2171630859375
Train_EnvstepsSoFar : 145912
TimeSinceStart : 142.61553931236267
Done logging...



********** Iteration 142 ************

Collecting data for eval...
Eval_AverageReturn : 37.272727966308594
Eval_StdReturn : 9.449298858642578
Eval_MaxReturn : 60.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 37.27272727272727
Train_AverageReturn : 50.099998474121094
Train_StdReturn : 16.48908805847168
Train_MaxReturn : 98.0
Train_MinReturn : 32.0
Train_AverageEpLen : 50.1
Actor Loss : 846.3051147460938
Train_EnvstepsSoFar : 146914
TimeSinceStart : 144.05705881118774
Done logging...



********** Iteration 143 ************

Collecting data for eval...
Eval_AverageReturn : 41.0
Eval_StdReturn : 11.636150360107422
Eval_MaxReturn : 68.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 41.0
Train_AverageReturn : 43.69565200805664
Train_StdReturn : 14.516661643981934
Train_MaxReturn : 75.0
Train_MinReturn : 27.0
Train_AverageEpLen : 43.69565217391305
Actor Loss : 926.103759765625
Train_EnvstepsSoFar : 147919
TimeSinceStart : 145.59213519096375
Done logging...



********** Iteration 144 ************

Collecting data for eval...
Eval_AverageReturn : 47.44444274902344
Eval_StdReturn : 19.026947021484375
Eval_MaxReturn : 94.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 47.44444444444444
Train_AverageReturn : 46.565216064453125
Train_StdReturn : 15.994091987609863
Train_MaxReturn : 79.0
Train_MinReturn : 28.0
Train_AverageEpLen : 46.56521739130435
Actor Loss : 858.767578125
Train_EnvstepsSoFar : 148990
TimeSinceStart : 146.89150619506836
Done logging...



********** Iteration 145 ************

Collecting data for eval...
Eval_AverageReturn : 50.44444274902344
Eval_StdReturn : 18.07460594177246
Eval_MaxReturn : 77.0
Eval_MinReturn : 26.0
Eval_AverageEpLen : 50.44444444444444
Train_AverageReturn : 37.44444274902344
Train_StdReturn : 11.544867515563965
Train_MaxReturn : 66.0
Train_MinReturn : 25.0
Train_AverageEpLen : 37.44444444444444
Actor Loss : 871.5850830078125
Train_EnvstepsSoFar : 150001
TimeSinceStart : 147.92937970161438
Done logging...



********** Iteration 146 ************

Collecting data for eval...
Eval_AverageReturn : 38.41666793823242
Eval_StdReturn : 10.789334297180176
Eval_MaxReturn : 69.0
Eval_MinReturn : 26.0
Eval_AverageEpLen : 38.416666666666664
Train_AverageReturn : 37.96296310424805
Train_StdReturn : 10.871237754821777
Train_MaxReturn : 62.0
Train_MinReturn : 26.0
Train_AverageEpLen : 37.96296296296296
Actor Loss : 754.4028930664062
Train_EnvstepsSoFar : 151026
TimeSinceStart : 148.9757854938507
Done logging...



********** Iteration 147 ************

Collecting data for eval...
Eval_AverageReturn : 39.45454406738281
Eval_StdReturn : 9.819865226745605
Eval_MaxReturn : 55.0
Eval_MinReturn : 26.0
Eval_AverageEpLen : 39.45454545454545
Train_AverageReturn : 46.227272033691406
Train_StdReturn : 20.1312313079834
Train_MaxReturn : 98.0
Train_MinReturn : 26.0
Train_AverageEpLen : 46.22727272727273
Actor Loss : 1138.9744873046875
Train_EnvstepsSoFar : 152043
TimeSinceStart : 149.9881980419159
Done logging...



********** Iteration 148 ************

Collecting data for eval...
Eval_AverageReturn : 43.20000076293945
Eval_StdReturn : 13.541049003601074
Eval_MaxReturn : 70.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 43.2
Train_AverageReturn : 41.560001373291016
Train_StdReturn : 14.212895393371582
Train_MaxReturn : 77.0
Train_MinReturn : 25.0
Train_AverageEpLen : 41.56
Actor Loss : 639.815673828125
Train_EnvstepsSoFar : 153082
TimeSinceStart : 150.9984700679779
Done logging...



********** Iteration 149 ************

Collecting data for eval...
Eval_AverageReturn : 36.727272033691406
Eval_StdReturn : 8.068918228149414
Eval_MaxReturn : 56.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 36.72727272727273
Train_AverageReturn : 50.85714340209961
Train_StdReturn : 15.821281433105469
Train_MaxReturn : 79.0
Train_MinReturn : 26.0
Train_AverageEpLen : 50.857142857142854
Actor Loss : 1072.270751953125
Train_EnvstepsSoFar : 154150
TimeSinceStart : 152.56704092025757
Done logging...



********** Iteration 150 ************

Collecting data for eval...
Eval_AverageReturn : 37.45454406738281
Eval_StdReturn : 8.049433708190918
Eval_MaxReturn : 57.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 37.45454545454545
Train_AverageReturn : 39.30769348144531
Train_StdReturn : 12.04724407196045
Train_MaxReturn : 77.0
Train_MinReturn : 26.0
Train_AverageEpLen : 39.30769230769231
Actor Loss : 701.2489013671875
Train_EnvstepsSoFar : 155172
TimeSinceStart : 153.55411052703857
Done logging...



********** Iteration 151 ************

Collecting data for eval...
Eval_AverageReturn : 53.875
Eval_StdReturn : 13.204521179199219
Eval_MaxReturn : 69.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 53.875
Train_AverageReturn : 43.95833206176758
Train_StdReturn : 16.87078094482422
Train_MaxReturn : 98.0
Train_MinReturn : 25.0
Train_AverageEpLen : 43.958333333333336
Actor Loss : 1062.36328125
Train_EnvstepsSoFar : 156227
TimeSinceStart : 155.13968992233276
Done logging...



********** Iteration 152 ************

Collecting data for eval...
Eval_AverageReturn : 46.599998474121094
Eval_StdReturn : 14.752626419067383
Eval_MaxReturn : 72.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 46.6
Train_AverageReturn : 45.08695602416992
Train_StdReturn : 17.596721649169922
Train_MaxReturn : 80.0
Train_MinReturn : 24.0
Train_AverageEpLen : 45.08695652173913
Actor Loss : 806.3250732421875
Train_EnvstepsSoFar : 157264
TimeSinceStart : 156.19451427459717
Done logging...



********** Iteration 153 ************

Collecting data for eval...
Eval_AverageReturn : 39.3636360168457
Eval_StdReturn : 12.418993949890137
Eval_MaxReturn : 66.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 39.36363636363637
Train_AverageReturn : 50.54999923706055
Train_StdReturn : 20.40704345703125
Train_MaxReturn : 111.0
Train_MinReturn : 25.0
Train_AverageEpLen : 50.55
Actor Loss : 1699.824462890625
Train_EnvstepsSoFar : 158275
TimeSinceStart : 157.64880752563477
Done logging...



********** Iteration 154 ************

Collecting data for eval...
Eval_AverageReturn : 42.900001525878906
Eval_StdReturn : 20.23091697692871
Eval_MaxReturn : 80.0
Eval_MinReturn : 26.0
Eval_AverageEpLen : 42.9
Train_AverageReturn : 52.150001525878906
Train_StdReturn : 17.87533187866211
Train_MaxReturn : 83.0
Train_MinReturn : 24.0
Train_AverageEpLen : 52.15
Actor Loss : 965.5689086914062
Train_EnvstepsSoFar : 159318
TimeSinceStart : 158.68104529380798
Done logging...



********** Iteration 155 ************

Collecting data for eval...
Eval_AverageReturn : 40.45454406738281
Eval_StdReturn : 9.178667068481445
Eval_MaxReturn : 56.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 40.45454545454545
Train_AverageReturn : 43.4782600402832
Train_StdReturn : 16.056610107421875
Train_MaxReturn : 83.0
Train_MinReturn : 24.0
Train_AverageEpLen : 43.47826086956522
Actor Loss : 912.75732421875
Train_EnvstepsSoFar : 160318
TimeSinceStart : 160.2409393787384
Done logging...



********** Iteration 156 ************

Collecting data for eval...
Eval_AverageReturn : 46.0
Eval_StdReturn : 14.544949531555176
Eval_MaxReturn : 79.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 46.0
Train_AverageReturn : 50.650001525878906
Train_StdReturn : 16.938934326171875
Train_MaxReturn : 88.0
Train_MinReturn : 29.0
Train_AverageEpLen : 50.65
Actor Loss : 1111.358642578125
Train_EnvstepsSoFar : 161331
TimeSinceStart : 161.3184313774109
Done logging...



********** Iteration 157 ************

Collecting data for eval...
Eval_AverageReturn : 52.25
Eval_StdReturn : 18.04681396484375
Eval_MaxReturn : 80.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 52.25
Train_AverageReturn : 41.11538314819336
Train_StdReturn : 15.988761901855469
Train_MaxReturn : 87.0
Train_MinReturn : 25.0
Train_AverageEpLen : 41.11538461538461
Actor Loss : 521.7877197265625
Train_EnvstepsSoFar : 162400
TimeSinceStart : 162.48086500167847
Done logging...



********** Iteration 158 ************

Collecting data for eval...
Eval_AverageReturn : 45.66666793823242
Eval_StdReturn : 10.509254455566406
Eval_MaxReturn : 70.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 45.666666666666664
Train_AverageReturn : 46.727272033691406
Train_StdReturn : 31.373384475708008
Train_MaxReturn : 165.0
Train_MinReturn : 26.0
Train_AverageEpLen : 46.72727272727273
Actor Loss : 912.4671630859375
Train_EnvstepsSoFar : 163428
TimeSinceStart : 163.95505571365356
Done logging...



********** Iteration 159 ************

Collecting data for eval...
Eval_AverageReturn : 70.16666412353516
Eval_StdReturn : 16.787065505981445
Eval_MaxReturn : 93.0
Eval_MinReturn : 40.0
Eval_AverageEpLen : 70.16666666666667
Train_AverageReturn : 44.30434799194336
Train_StdReturn : 17.139923095703125
Train_MaxReturn : 85.0
Train_MinReturn : 26.0
Train_AverageEpLen : 44.30434782608695
Actor Loss : 581.783447265625
Train_EnvstepsSoFar : 164447
TimeSinceStart : 165.3379144668579
Done logging...



********** Iteration 160 ************

Collecting data for eval...
Eval_AverageReturn : 40.79999923706055
Eval_StdReturn : 17.110231399536133
Eval_MaxReturn : 75.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 40.8
Train_AverageReturn : 42.36000061035156
Train_StdReturn : 13.430950164794922
Train_MaxReturn : 81.0
Train_MinReturn : 27.0
Train_AverageEpLen : 42.36
Actor Loss : 709.7568359375
Train_EnvstepsSoFar : 165506
TimeSinceStart : 166.5342047214508
Done logging...



********** Iteration 161 ************

Collecting data for eval...
Eval_AverageReturn : 43.54545593261719
Eval_StdReturn : 17.43227767944336
Eval_MaxReturn : 83.0
Eval_MinReturn : 25.0
Eval_AverageEpLen : 43.54545454545455
Train_AverageReturn : 42.83333206176758
Train_StdReturn : 15.85524845123291
Train_MaxReturn : 95.0
Train_MinReturn : 26.0
Train_AverageEpLen : 42.833333333333336
Actor Loss : 578.1822509765625
Train_EnvstepsSoFar : 166534
TimeSinceStart : 167.89829349517822
Done logging...



********** Iteration 162 ************

Collecting data for eval...
Eval_AverageReturn : 48.77777862548828
Eval_StdReturn : 22.144865036010742
Eval_MaxReturn : 109.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 48.77777777777778
Train_AverageReturn : 46.227272033691406
Train_StdReturn : 19.050010681152344
Train_MaxReturn : 92.0
Train_MinReturn : 26.0
Train_AverageEpLen : 46.22727272727273
Actor Loss : 846.1778564453125
Train_EnvstepsSoFar : 167551
TimeSinceStart : 168.92314648628235
Done logging...



********** Iteration 163 ************

Collecting data for eval...
Eval_AverageReturn : 39.0
Eval_StdReturn : 9.7421293258667
Eval_MaxReturn : 64.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 39.0
Train_AverageReturn : 44.79166793823242
Train_StdReturn : 18.450336456298828
Train_MaxReturn : 99.0
Train_MinReturn : 26.0
Train_AverageEpLen : 44.791666666666664
Actor Loss : 618.5416870117188
Train_EnvstepsSoFar : 168626
TimeSinceStart : 169.91052389144897
Done logging...



********** Iteration 164 ************

Collecting data for eval...
Eval_AverageReturn : 38.0
Eval_StdReturn : 7.885544776916504
Eval_MaxReturn : 49.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 38.0
Train_AverageReturn : 49.0476188659668
Train_StdReturn : 19.43113899230957
Train_MaxReturn : 95.0
Train_MinReturn : 28.0
Train_AverageEpLen : 49.04761904761905
Actor Loss : 629.3123779296875
Train_EnvstepsSoFar : 169656
TimeSinceStart : 171.4087619781494
Done logging...



********** Iteration 165 ************

Collecting data for eval...
Eval_AverageReturn : 40.5
Eval_StdReturn : 15.337862014770508
Eval_MaxReturn : 73.0
Eval_MinReturn : 26.0
Eval_AverageEpLen : 40.5
Train_AverageReturn : 43.29166793823242
Train_StdReturn : 17.133007049560547
Train_MaxReturn : 87.0
Train_MinReturn : 26.0
Train_AverageEpLen : 43.291666666666664
Actor Loss : 834.1640625
Train_EnvstepsSoFar : 170695
TimeSinceStart : 172.8064317703247
Done logging...



********** Iteration 166 ************

Collecting data for eval...
Eval_AverageReturn : 66.0
Eval_StdReturn : 34.34696960449219
Eval_MaxReturn : 128.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 66.0
Train_AverageReturn : 45.434783935546875
Train_StdReturn : 20.05606460571289
Train_MaxReturn : 104.0
Train_MinReturn : 28.0
Train_AverageEpLen : 45.43478260869565
Actor Loss : 731.7177124023438
Train_EnvstepsSoFar : 171740
TimeSinceStart : 174.2471981048584
Done logging...



********** Iteration 167 ************

Collecting data for eval...
Eval_AverageReturn : 54.625
Eval_StdReturn : 24.26384925842285
Eval_MaxReturn : 114.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 54.625
Train_AverageReturn : 39.42307662963867
Train_StdReturn : 10.514360427856445
Train_MaxReturn : 78.0
Train_MinReturn : 28.0
Train_AverageEpLen : 39.42307692307692
Actor Loss : 503.66754150390625
Train_EnvstepsSoFar : 172765
TimeSinceStart : 175.4674949645996
Done logging...



********** Iteration 168 ************

Collecting data for eval...
Eval_AverageReturn : 57.28571319580078
Eval_StdReturn : 21.028650283813477
Eval_MaxReturn : 95.0
Eval_MinReturn : 36.0
Eval_AverageEpLen : 57.285714285714285
Train_AverageReturn : 56.349998474121094
Train_StdReturn : 34.58796691894531
Train_MaxReturn : 160.0
Train_MinReturn : 28.0
Train_AverageEpLen : 56.35
Actor Loss : 958.1210327148438
Train_EnvstepsSoFar : 173892
TimeSinceStart : 176.5033257007599
Done logging...



********** Iteration 169 ************

Collecting data for eval...
Eval_AverageReturn : 63.57143020629883
Eval_StdReturn : 24.382999420166016
Eval_MaxReturn : 95.0
Eval_MinReturn : 36.0
Eval_AverageEpLen : 63.57142857142857
Train_AverageReturn : 48.19047546386719
Train_StdReturn : 25.811805725097656
Train_MaxReturn : 129.0
Train_MinReturn : 26.0
Train_AverageEpLen : 48.19047619047619
Actor Loss : 705.4442138671875
Train_EnvstepsSoFar : 174904
TimeSinceStart : 178.01380705833435
Done logging...



********** Iteration 170 ************

Collecting data for eval...
Eval_AverageReturn : 43.099998474121094
Eval_StdReturn : 9.873703002929688
Eval_MaxReturn : 67.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 43.1
Train_AverageReturn : 64.4375
Train_StdReturn : 39.0735969543457
Train_MaxReturn : 170.0
Train_MinReturn : 28.0
Train_AverageEpLen : 64.4375
Actor Loss : 1239.118896484375
Train_EnvstepsSoFar : 175935
TimeSinceStart : 179.585928440094
Done logging...



********** Iteration 171 ************

Collecting data for eval...
Eval_AverageReturn : 43.0
Eval_StdReturn : 13.667479515075684
Eval_MaxReturn : 74.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 43.0
Train_AverageReturn : 45.21739196777344
Train_StdReturn : 18.05536460876465
Train_MaxReturn : 99.0
Train_MinReturn : 29.0
Train_AverageEpLen : 45.21739130434783
Actor Loss : 842.7775268554688
Train_EnvstepsSoFar : 176975
TimeSinceStart : 180.98507070541382
Done logging...



********** Iteration 172 ************

Collecting data for eval...
Eval_AverageReturn : 43.599998474121094
Eval_StdReturn : 14.506550788879395
Eval_MaxReturn : 83.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 43.6
Train_AverageReturn : 56.11111068725586
Train_StdReturn : 24.95304298400879
Train_MaxReturn : 108.0
Train_MinReturn : 31.0
Train_AverageEpLen : 56.111111111111114
Actor Loss : 1025.969970703125
Train_EnvstepsSoFar : 177985
TimeSinceStart : 182.39552688598633
Done logging...



********** Iteration 173 ************

Collecting data for eval...
Eval_AverageReturn : 49.55555725097656
Eval_StdReturn : 13.639086723327637
Eval_MaxReturn : 79.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 49.55555555555556
Train_AverageReturn : 51.5
Train_StdReturn : 23.427547454833984
Train_MaxReturn : 110.0
Train_MinReturn : 32.0
Train_AverageEpLen : 51.5
Actor Loss : 764.2919921875
Train_EnvstepsSoFar : 179015
TimeSinceStart : 183.9238841533661
Done logging...



********** Iteration 174 ************

Collecting data for eval...
Eval_AverageReturn : 63.42856979370117
Eval_StdReturn : 23.31680679321289
Eval_MaxReturn : 95.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 63.42857142857143
Train_AverageReturn : 46.09090805053711
Train_StdReturn : 20.174036026000977
Train_MaxReturn : 106.0
Train_MinReturn : 30.0
Train_AverageEpLen : 46.09090909090909
Actor Loss : 729.3836669921875
Train_EnvstepsSoFar : 180029
TimeSinceStart : 184.9429943561554
Done logging...



********** Iteration 175 ************

Collecting data for eval...
Eval_AverageReturn : 51.625
Eval_StdReturn : 17.91603660583496
Eval_MaxReturn : 81.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 51.625
Train_AverageReturn : 40.040000915527344
Train_StdReturn : 15.137979507446289
Train_MaxReturn : 104.0
Train_MinReturn : 30.0
Train_AverageEpLen : 40.04
Actor Loss : 541.0404052734375
Train_EnvstepsSoFar : 181030
TimeSinceStart : 186.46839928627014
Done logging...



********** Iteration 176 ************

Collecting data for eval...
Eval_AverageReturn : 52.0
Eval_StdReturn : 19.430788040161133
Eval_MaxReturn : 90.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 52.0
Train_AverageReturn : 44.043479919433594
Train_StdReturn : 19.581443786621094
Train_MaxReturn : 88.0
Train_MinReturn : 28.0
Train_AverageEpLen : 44.04347826086956
Actor Loss : 757.8289794921875
Train_EnvstepsSoFar : 182043
TimeSinceStart : 187.82630038261414
Done logging...



********** Iteration 177 ************

Collecting data for eval...
Eval_AverageReturn : 47.11111068725586
Eval_StdReturn : 19.37033462524414
Eval_MaxReturn : 84.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 47.111111111111114
Train_AverageReturn : 46.681819915771484
Train_StdReturn : 18.54328155517578
Train_MaxReturn : 93.0
Train_MinReturn : 30.0
Train_AverageEpLen : 46.68181818181818
Actor Loss : 547.960205078125
Train_EnvstepsSoFar : 183070
TimeSinceStart : 189.3808524608612
Done logging...



********** Iteration 178 ************

Collecting data for eval...
Eval_AverageReturn : 40.099998474121094
Eval_StdReturn : 8.780091285705566
Eval_MaxReturn : 57.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 40.1
Train_AverageReturn : 46.04545593261719
Train_StdReturn : 16.934303283691406
Train_MaxReturn : 86.0
Train_MinReturn : 28.0
Train_AverageEpLen : 46.04545454545455
Actor Loss : 665.494384765625
Train_EnvstepsSoFar : 184083
TimeSinceStart : 190.82958817481995
Done logging...



********** Iteration 179 ************

Collecting data for eval...
Eval_AverageReturn : 53.5
Eval_StdReturn : 19.563997268676758
Eval_MaxReturn : 92.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 53.5
Train_AverageReturn : 48.52381134033203
Train_StdReturn : 19.50242805480957
Train_MaxReturn : 97.0
Train_MinReturn : 27.0
Train_AverageEpLen : 48.523809523809526
Actor Loss : 612.7258911132812
Train_EnvstepsSoFar : 185102
TimeSinceStart : 192.28447842597961
Done logging...



********** Iteration 180 ************

Collecting data for eval...
Eval_AverageReturn : 43.900001525878906
Eval_StdReturn : 16.658029556274414
Eval_MaxReturn : 88.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 43.9
Train_AverageReturn : 46.6363639831543
Train_StdReturn : 17.938138961791992
Train_MaxReturn : 96.0
Train_MinReturn : 28.0
Train_AverageEpLen : 46.63636363636363
Actor Loss : 535.1356811523438
Train_EnvstepsSoFar : 186128
TimeSinceStart : 193.69593214988708
Done logging...



********** Iteration 181 ************

Collecting data for eval...
Eval_AverageReturn : 42.29999923706055
Eval_StdReturn : 11.243219375610352
Eval_MaxReturn : 75.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 42.3
Train_AverageReturn : 47.9523811340332
Train_StdReturn : 18.2247257232666
Train_MaxReturn : 88.0
Train_MinReturn : 27.0
Train_AverageEpLen : 47.95238095238095
Actor Loss : 838.1652221679688
Train_EnvstepsSoFar : 187135
TimeSinceStart : 194.70420265197754
Done logging...



********** Iteration 182 ************

Collecting data for eval...
Eval_AverageReturn : 35.66666793823242
Eval_StdReturn : 5.878397464752197
Eval_MaxReturn : 48.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 35.666666666666664
Train_AverageReturn : 45.043479919433594
Train_StdReturn : 15.61347770690918
Train_MaxReturn : 80.0
Train_MinReturn : 27.0
Train_AverageEpLen : 45.04347826086956
Actor Loss : 477.6361389160156
Train_EnvstepsSoFar : 188171
TimeSinceStart : 195.70580434799194
Done logging...



********** Iteration 183 ************

Collecting data for eval...
Eval_AverageReturn : 57.57143020629883
Eval_StdReturn : 23.463388442993164
Eval_MaxReturn : 90.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 57.57142857142857
Train_AverageReturn : 42.625
Train_StdReturn : 14.117992401123047
Train_MaxReturn : 84.0
Train_MinReturn : 31.0
Train_AverageEpLen : 42.625
Actor Loss : 456.2032470703125
Train_EnvstepsSoFar : 189194
TimeSinceStart : 197.1633801460266
Done logging...



********** Iteration 184 ************

Collecting data for eval...
Eval_AverageReturn : 51.25
Eval_StdReturn : 18.978607177734375
Eval_MaxReturn : 85.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 51.25
Train_AverageReturn : 47.181819915771484
Train_StdReturn : 20.326061248779297
Train_MaxReturn : 111.0
Train_MinReturn : 27.0
Train_AverageEpLen : 47.18181818181818
Actor Loss : 1073.476318359375
Train_EnvstepsSoFar : 190232
TimeSinceStart : 198.56996321678162
Done logging...



********** Iteration 185 ************

Collecting data for eval...
Eval_AverageReturn : 41.818180084228516
Eval_StdReturn : 16.010326385498047
Eval_MaxReturn : 80.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 41.81818181818182
Train_AverageReturn : 40.959999084472656
Train_StdReturn : 13.512896537780762
Train_MaxReturn : 74.0
Train_MinReturn : 26.0
Train_AverageEpLen : 40.96
Actor Loss : 563.034423828125
Train_EnvstepsSoFar : 191256
TimeSinceStart : 199.93534660339355
Done logging...



********** Iteration 186 ************

Collecting data for eval...
Eval_AverageReturn : 40.400001525878906
Eval_StdReturn : 15.014659881591797
Eval_MaxReturn : 80.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 40.4
Train_AverageReturn : 45.130435943603516
Train_StdReturn : 15.100545883178711
Train_MaxReturn : 78.0
Train_MinReturn : 29.0
Train_AverageEpLen : 45.130434782608695
Actor Loss : 646.9794311523438
Train_EnvstepsSoFar : 192294
TimeSinceStart : 200.8606255054474
Done logging...



********** Iteration 187 ************

Collecting data for eval...
Eval_AverageReturn : 44.5
Eval_StdReturn : 20.353132247924805
Eval_MaxReturn : 82.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 44.5
Train_AverageReturn : 45.681819915771484
Train_StdReturn : 19.886920928955078
Train_MaxReturn : 112.0
Train_MinReturn : 28.0
Train_AverageEpLen : 45.68181818181818
Actor Loss : 384.19805908203125
Train_EnvstepsSoFar : 193299
TimeSinceStart : 201.8855276107788
Done logging...



********** Iteration 188 ************

Collecting data for eval...
Eval_AverageReturn : 56.125
Eval_StdReturn : 9.77800464630127
Eval_MaxReturn : 72.0
Eval_MinReturn : 41.0
Eval_AverageEpLen : 56.125
Train_AverageReturn : 50.20000076293945
Train_StdReturn : 17.3510799407959
Train_MaxReturn : 83.0
Train_MinReturn : 26.0
Train_AverageEpLen : 50.2
Actor Loss : 1039.402587890625
Train_EnvstepsSoFar : 194303
TimeSinceStart : 203.43467140197754
Done logging...



********** Iteration 189 ************

Collecting data for eval...
Eval_AverageReturn : 45.70000076293945
Eval_StdReturn : 17.053152084350586
Eval_MaxReturn : 82.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 45.7
Train_AverageReturn : 41.2400016784668
Train_StdReturn : 15.77156925201416
Train_MaxReturn : 90.0
Train_MinReturn : 27.0
Train_AverageEpLen : 41.24
Actor Loss : 553.451171875
Train_EnvstepsSoFar : 195334
TimeSinceStart : 205.00832343101501
Done logging...



********** Iteration 190 ************

Collecting data for eval...
Eval_AverageReturn : 47.33333206176758
Eval_StdReturn : 21.674358367919922
Eval_MaxReturn : 84.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 47.333333333333336
Train_AverageReturn : 44.130435943603516
Train_StdReturn : 13.82280445098877
Train_MaxReturn : 75.0
Train_MinReturn : 28.0
Train_AverageEpLen : 44.130434782608695
Actor Loss : 618.0230712890625
Train_EnvstepsSoFar : 196349
TimeSinceStart : 206.01492381095886
Done logging...



********** Iteration 191 ************

Collecting data for eval...
Eval_AverageReturn : 48.33333206176758
Eval_StdReturn : 18.123037338256836
Eval_MaxReturn : 83.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 48.333333333333336
Train_AverageReturn : 43.20833206176758
Train_StdReturn : 15.34866714477539
Train_MaxReturn : 81.0
Train_MinReturn : 25.0
Train_AverageEpLen : 43.208333333333336
Actor Loss : 560.8058471679688
Train_EnvstepsSoFar : 197386
TimeSinceStart : 207.06530904769897
Done logging...



********** Iteration 192 ************

Collecting data for eval...
Eval_AverageReturn : 53.5
Eval_StdReturn : 16.896745681762695
Eval_MaxReturn : 81.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 53.5
Train_AverageReturn : 45.5
Train_StdReturn : 14.584393501281738
Train_MaxReturn : 81.0
Train_MinReturn : 27.0
Train_AverageEpLen : 45.5
Actor Loss : 572.3240356445312
Train_EnvstepsSoFar : 198387
TimeSinceStart : 208.08157062530518
Done logging...



********** Iteration 193 ************

Collecting data for eval...
Eval_AverageReturn : 47.22222137451172
Eval_StdReturn : 16.22602653503418
Eval_MaxReturn : 74.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 47.22222222222222
Train_AverageReturn : 48.28571319580078
Train_StdReturn : 17.74728012084961
Train_MaxReturn : 86.0
Train_MinReturn : 28.0
Train_AverageEpLen : 48.285714285714285
Actor Loss : 794.0559692382812
Train_EnvstepsSoFar : 199401
TimeSinceStart : 209.41169452667236
Done logging...



********** Iteration 194 ************

Collecting data for eval...
Eval_AverageReturn : 51.75
Eval_StdReturn : 19.708818435668945
Eval_MaxReturn : 82.0
Eval_MinReturn : 26.0
Eval_AverageEpLen : 51.75
Train_AverageReturn : 45.043479919433594
Train_StdReturn : 18.04216766357422
Train_MaxReturn : 87.0
Train_MinReturn : 29.0
Train_AverageEpLen : 45.04347826086956
Actor Loss : 756.1058959960938
Train_EnvstepsSoFar : 200437
TimeSinceStart : 210.6686487197876
Done logging...



********** Iteration 195 ************

Collecting data for eval...
Eval_AverageReturn : 47.55555725097656
Eval_StdReturn : 17.60751724243164
Eval_MaxReturn : 79.0
Eval_MinReturn : 26.0
Eval_AverageEpLen : 47.55555555555556
Train_AverageReturn : 51.95000076293945
Train_StdReturn : 27.71908187866211
Train_MaxReturn : 133.0
Train_MinReturn : 27.0
Train_AverageEpLen : 51.95
Actor Loss : 580.7294921875
Train_EnvstepsSoFar : 201476
TimeSinceStart : 212.23627376556396
Done logging...



********** Iteration 196 ************

Collecting data for eval...
Eval_AverageReturn : 45.44444274902344
Eval_StdReturn : 20.78520393371582
Eval_MaxReturn : 88.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 45.44444444444444
Train_AverageReturn : 45.818180084228516
Train_StdReturn : 16.134763717651367
Train_MaxReturn : 80.0
Train_MinReturn : 26.0
Train_AverageEpLen : 45.81818181818182
Actor Loss : 610.0791015625
Train_EnvstepsSoFar : 202484
TimeSinceStart : 213.74123978614807
Done logging...



********** Iteration 197 ************

Collecting data for eval...
Eval_AverageReturn : 72.83333587646484
Eval_StdReturn : 34.483890533447266
Eval_MaxReturn : 139.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 72.83333333333333
Train_AverageReturn : 46.181819915771484
Train_StdReturn : 14.48396110534668
Train_MaxReturn : 75.0
Train_MinReturn : 30.0
Train_AverageEpLen : 46.18181818181818
Actor Loss : 654.6888427734375
Train_EnvstepsSoFar : 203500
TimeSinceStart : 214.74866580963135
Done logging...



********** Iteration 198 ************

Collecting data for eval...
Eval_AverageReturn : 41.400001525878906
Eval_StdReturn : 15.615377426147461
Eval_MaxReturn : 76.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 41.4
Train_AverageReturn : 56.55555725097656
Train_StdReturn : 29.754966735839844
Train_MaxReturn : 131.0
Train_MinReturn : 30.0
Train_AverageEpLen : 56.55555555555556
Actor Loss : 611.4415283203125
Train_EnvstepsSoFar : 204518
TimeSinceStart : 216.26992630958557
Done logging...



********** Iteration 199 ************

Collecting data for eval...
Eval_AverageReturn : 48.66666793823242
Eval_StdReturn : 13.824294090270996
Eval_MaxReturn : 76.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 48.666666666666664
Train_AverageReturn : 61.588233947753906
Train_StdReturn : 30.501800537109375
Train_MaxReturn : 125.0
Train_MinReturn : 32.0
Train_AverageEpLen : 61.588235294117645
Actor Loss : 1083.75244140625
Train_EnvstepsSoFar : 205565
TimeSinceStart : 217.31251883506775
Done logging...



********** Iteration 200 ************

Collecting data for eval...
Eval_AverageReturn : 40.0
Eval_StdReturn : 12.0
Eval_MaxReturn : 66.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 40.0
Train_AverageReturn : 59.29411697387695
Train_StdReturn : 29.33330726623535
Train_MaxReturn : 123.0
Train_MinReturn : 28.0
Train_AverageEpLen : 59.294117647058826
Actor Loss : 747.7388305664062
Train_EnvstepsSoFar : 206573
TimeSinceStart : 218.28576278686523
Done logging...



********** Iteration 201 ************

Collecting data for eval...
Eval_AverageReturn : 41.599998474121094
Eval_StdReturn : 24.45894432067871
Eval_MaxReturn : 113.0
Eval_MinReturn : 26.0
Eval_AverageEpLen : 41.6
Train_AverageReturn : 51.5
Train_StdReturn : 26.659894943237305
Train_MaxReturn : 130.0
Train_MinReturn : 29.0
Train_AverageEpLen : 51.5
Actor Loss : 798.760986328125
Train_EnvstepsSoFar : 207603
TimeSinceStart : 219.3861382007599
Done logging...



********** Iteration 202 ************

Collecting data for eval...
Eval_AverageReturn : 50.11111068725586
Eval_StdReturn : 17.609621047973633
Eval_MaxReturn : 94.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 50.111111111111114
Train_AverageReturn : 49.9523811340332
Train_StdReturn : 22.179948806762695
Train_MaxReturn : 102.0
Train_MinReturn : 32.0
Train_AverageEpLen : 49.95238095238095
Actor Loss : 891.9692993164062
Train_EnvstepsSoFar : 208652
TimeSinceStart : 220.98909783363342
Done logging...



********** Iteration 203 ************

Collecting data for eval...
Eval_AverageReturn : 45.55555725097656
Eval_StdReturn : 22.891584396362305
Eval_MaxReturn : 109.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 45.55555555555556
Train_AverageReturn : 55.150001525878906
Train_StdReturn : 35.86680221557617
Train_MaxReturn : 177.0
Train_MinReturn : 31.0
Train_AverageEpLen : 55.15
Actor Loss : 962.7083740234375
Train_EnvstepsSoFar : 209755
TimeSinceStart : 222.0317223072052
Done logging...



********** Iteration 204 ************

Collecting data for eval...
Eval_AverageReturn : 48.0
Eval_StdReturn : 13.190905570983887
Eval_MaxReturn : 78.0
Eval_MinReturn : 36.0
Eval_AverageEpLen : 48.0
Train_AverageReturn : 46.173912048339844
Train_StdReturn : 13.967827796936035
Train_MaxReturn : 82.0
Train_MinReturn : 30.0
Train_AverageEpLen : 46.17391304347826
Actor Loss : 608.2701416015625
Train_EnvstepsSoFar : 210817
TimeSinceStart : 222.9198763370514
Done logging...



********** Iteration 205 ************

Collecting data for eval...
Eval_AverageReturn : 60.28571319580078
Eval_StdReturn : 39.92033004760742
Eval_MaxReturn : 146.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 60.285714285714285
Train_AverageReturn : 60.33333206176758
Train_StdReturn : 33.9263916015625
Train_MaxReturn : 153.0
Train_MinReturn : 30.0
Train_AverageEpLen : 60.333333333333336
Actor Loss : 1194.7784423828125
Train_EnvstepsSoFar : 211903
TimeSinceStart : 223.97555327415466
Done logging...



********** Iteration 206 ************

Collecting data for eval...
Eval_AverageReturn : 63.57143020629883
Eval_StdReturn : 26.326831817626953
Eval_MaxReturn : 110.0
Eval_MinReturn : 40.0
Eval_AverageEpLen : 63.57142857142857
Train_AverageReturn : 59.94117736816406
Train_StdReturn : 25.440752029418945
Train_MaxReturn : 137.0
Train_MinReturn : 36.0
Train_AverageEpLen : 59.94117647058823
Actor Loss : 570.318603515625
Train_EnvstepsSoFar : 212922
TimeSinceStart : 225.56170344352722
Done logging...



********** Iteration 207 ************

Collecting data for eval...
Eval_AverageReturn : 52.44444274902344
Eval_StdReturn : 21.995512008666992
Eval_MaxReturn : 87.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 52.44444444444444
Train_AverageReturn : 50.54999923706055
Train_StdReturn : 22.08953285217285
Train_MaxReturn : 122.0
Train_MinReturn : 33.0
Train_AverageEpLen : 50.55
Actor Loss : 774.353759765625
Train_EnvstepsSoFar : 213933
TimeSinceStart : 227.1670880317688
Done logging...



********** Iteration 208 ************

Collecting data for eval...
Eval_AverageReturn : 41.79999923706055
Eval_StdReturn : 9.558242797851562
Eval_MaxReturn : 67.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 41.8
Train_AverageReturn : 50.54999923706055
Train_StdReturn : 24.93686866760254
Train_MaxReturn : 119.0
Train_MinReturn : 28.0
Train_AverageEpLen : 50.55
Actor Loss : 827.4616088867188
Train_EnvstepsSoFar : 214944
TimeSinceStart : 228.17023873329163
Done logging...



********** Iteration 209 ************

Collecting data for eval...
Eval_AverageReturn : 59.85714340209961
Eval_StdReturn : 18.434659957885742
Eval_MaxReturn : 98.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 59.857142857142854
Train_AverageReturn : 52.6363639831543
Train_StdReturn : 28.74898338317871
Train_MaxReturn : 160.0
Train_MinReturn : 31.0
Train_AverageEpLen : 52.63636363636363
Actor Loss : 1053.778564453125
Train_EnvstepsSoFar : 216102
TimeSinceStart : 229.2759232521057
Done logging...



********** Iteration 210 ************

Collecting data for eval...
Eval_AverageReturn : 41.09090805053711
Eval_StdReturn : 5.869095325469971
Eval_MaxReturn : 54.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 41.09090909090909
Train_AverageReturn : 55.421051025390625
Train_StdReturn : 15.187654495239258
Train_MaxReturn : 90.0
Train_MinReturn : 37.0
Train_AverageEpLen : 55.421052631578945
Actor Loss : 623.8878784179688
Train_EnvstepsSoFar : 217155
TimeSinceStart : 230.91532111167908
Done logging...



********** Iteration 211 ************

Collecting data for eval...
Eval_AverageReturn : 43.5
Eval_StdReturn : 11.21828842163086
Eval_MaxReturn : 69.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 43.5
Train_AverageReturn : 56.157894134521484
Train_StdReturn : 26.799964904785156
Train_MaxReturn : 153.0
Train_MinReturn : 34.0
Train_AverageEpLen : 56.1578947368421
Actor Loss : 912.6517944335938
Train_EnvstepsSoFar : 218222
TimeSinceStart : 231.97681307792664
Done logging...



********** Iteration 212 ************

Collecting data for eval...
Eval_AverageReturn : 50.75
Eval_StdReturn : 19.973419189453125
Eval_MaxReturn : 102.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 50.75
Train_AverageReturn : 51.099998474121094
Train_StdReturn : 10.118794441223145
Train_MaxReturn : 77.0
Train_MinReturn : 38.0
Train_AverageEpLen : 51.1
Actor Loss : 663.9927978515625
Train_EnvstepsSoFar : 219244
TimeSinceStart : 233.4783661365509
Done logging...



********** Iteration 213 ************

Collecting data for eval...
Eval_AverageReturn : 50.75
Eval_StdReturn : 17.53389549255371
Eval_MaxReturn : 86.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 50.75
Train_AverageReturn : 48.80952453613281
Train_StdReturn : 15.148845672607422
Train_MaxReturn : 85.0
Train_MinReturn : 31.0
Train_AverageEpLen : 48.80952380952381
Actor Loss : 534.468994140625
Train_EnvstepsSoFar : 220269
TimeSinceStart : 234.318293094635
Done logging...



********** Iteration 214 ************

Collecting data for eval...
Eval_AverageReturn : 47.55555725097656
Eval_StdReturn : 9.238940238952637
Eval_MaxReturn : 60.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 47.55555555555556
Train_AverageReturn : 53.157894134521484
Train_StdReturn : 22.79949951171875
Train_MaxReturn : 133.0
Train_MinReturn : 31.0
Train_AverageEpLen : 53.1578947368421
Actor Loss : 856.6461181640625
Train_EnvstepsSoFar : 221279
TimeSinceStart : 235.53349494934082
Done logging...



********** Iteration 215 ************

Collecting data for eval...
Eval_AverageReturn : 46.88888931274414
Eval_StdReturn : 10.51395320892334
Eval_MaxReturn : 70.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 46.888888888888886
Train_AverageReturn : 63.25
Train_StdReturn : 19.527225494384766
Train_MaxReturn : 109.0
Train_MinReturn : 36.0
Train_AverageEpLen : 63.25
Actor Loss : 782.572998046875
Train_EnvstepsSoFar : 222291
TimeSinceStart : 236.20964574813843
Done logging...



********** Iteration 216 ************

Collecting data for eval...
Eval_AverageReturn : 53.5
Eval_StdReturn : 15.612495422363281
Eval_MaxReturn : 88.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 53.5
Train_AverageReturn : 49.47618865966797
Train_StdReturn : 14.080107688903809
Train_MaxReturn : 93.0
Train_MinReturn : 36.0
Train_AverageEpLen : 49.476190476190474
Actor Loss : 759.5272216796875
Train_EnvstepsSoFar : 223330
TimeSinceStart : 236.90369868278503
Done logging...



********** Iteration 217 ************

Collecting data for eval...
Eval_AverageReturn : 55.5
Eval_StdReturn : 12.50999641418457
Eval_MaxReturn : 75.0
Eval_MinReturn : 42.0
Eval_AverageEpLen : 55.5
Train_AverageReturn : 50.79999923706055
Train_StdReturn : 9.113725662231445
Train_MaxReturn : 64.0
Train_MinReturn : 37.0
Train_AverageEpLen : 50.8
Actor Loss : 727.7783203125
Train_EnvstepsSoFar : 224346
TimeSinceStart : 237.58104372024536
Done logging...



********** Iteration 218 ************

Collecting data for eval...
Eval_AverageReturn : 47.88888931274414
Eval_StdReturn : 11.139962196350098
Eval_MaxReturn : 71.0
Eval_MinReturn : 36.0
Eval_AverageEpLen : 47.888888888888886
Train_AverageReturn : 50.400001525878906
Train_StdReturn : 17.298555374145508
Train_MaxReturn : 111.0
Train_MinReturn : 35.0
Train_AverageEpLen : 50.4
Actor Loss : 683.6734008789062
Train_EnvstepsSoFar : 225354
TimeSinceStart : 238.28501510620117
Done logging...



********** Iteration 219 ************

Collecting data for eval...
Eval_AverageReturn : 51.0
Eval_StdReturn : 12.192893981933594
Eval_MaxReturn : 74.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 51.0
Train_AverageReturn : 56.83333206176758
Train_StdReturn : 20.144615173339844
Train_MaxReturn : 101.0
Train_MinReturn : 34.0
Train_AverageEpLen : 56.833333333333336
Actor Loss : 775.566162109375
Train_EnvstepsSoFar : 226377
TimeSinceStart : 239.0438985824585
Done logging...



********** Iteration 220 ************

Collecting data for eval...
Eval_AverageReturn : 47.0
Eval_StdReturn : 11.264496803283691
Eval_MaxReturn : 74.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 47.0
Train_AverageReturn : 57.421051025390625
Train_StdReturn : 20.26486587524414
Train_MaxReturn : 119.0
Train_MinReturn : 32.0
Train_AverageEpLen : 57.421052631578945
Actor Loss : 663.2962646484375
Train_EnvstepsSoFar : 227468
TimeSinceStart : 239.8174455165863
Done logging...



********** Iteration 221 ************

Collecting data for eval...
Eval_AverageReturn : 53.625
Eval_StdReturn : 16.499526977539062
Eval_MaxReturn : 82.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 53.625
Train_AverageReturn : 50.349998474121094
Train_StdReturn : 14.990914344787598
Train_MaxReturn : 92.0
Train_MinReturn : 33.0
Train_AverageEpLen : 50.35
Actor Loss : 544.4927368164062
Train_EnvstepsSoFar : 228475
TimeSinceStart : 240.55879402160645
Done logging...



********** Iteration 222 ************

Collecting data for eval...
Eval_AverageReturn : 57.875
Eval_StdReturn : 17.098520278930664
Eval_MaxReturn : 83.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 57.875
Train_AverageReturn : 51.25
Train_StdReturn : 12.660470008850098
Train_MaxReturn : 78.0
Train_MinReturn : 32.0
Train_AverageEpLen : 51.25
Actor Loss : 722.4168701171875
Train_EnvstepsSoFar : 229500
TimeSinceStart : 241.31263279914856
Done logging...



********** Iteration 223 ************

Collecting data for eval...
Eval_AverageReturn : 56.0
Eval_StdReturn : 29.676029205322266
Eval_MaxReturn : 130.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 56.0
Train_AverageReturn : 54.842105865478516
Train_StdReturn : 12.48689079284668
Train_MaxReturn : 78.0
Train_MinReturn : 38.0
Train_AverageEpLen : 54.8421052631579
Actor Loss : 755.9791259765625
Train_EnvstepsSoFar : 230542
TimeSinceStart : 242.10231232643127
Done logging...



********** Iteration 224 ************

Collecting data for eval...
Eval_AverageReturn : 50.5
Eval_StdReturn : 23.64318084716797
Eval_MaxReturn : 98.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 50.5
Train_AverageReturn : 47.66666793823242
Train_StdReturn : 15.326086044311523
Train_MaxReturn : 94.0
Train_MinReturn : 30.0
Train_AverageEpLen : 47.666666666666664
Actor Loss : 651.530029296875
Train_EnvstepsSoFar : 231543
TimeSinceStart : 242.81900548934937
Done logging...



********** Iteration 225 ************

Collecting data for eval...
Eval_AverageReturn : 67.33333587646484
Eval_StdReturn : 15.260698318481445
Eval_MaxReturn : 90.0
Eval_MinReturn : 40.0
Eval_AverageEpLen : 67.33333333333333
Train_AverageReturn : 54.0
Train_StdReturn : 18.191959381103516
Train_MaxReturn : 114.0
Train_MinReturn : 34.0
Train_AverageEpLen : 54.0
Actor Loss : 469.8700866699219
Train_EnvstepsSoFar : 232569
TimeSinceStart : 243.5545334815979
Done logging...



********** Iteration 226 ************

Collecting data for eval...
Eval_AverageReturn : 43.29999923706055
Eval_StdReturn : 8.854942321777344
Eval_MaxReturn : 61.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 43.3
Train_AverageReturn : 51.47618865966797
Train_StdReturn : 16.97510528564453
Train_MaxReturn : 100.0
Train_MinReturn : 32.0
Train_AverageEpLen : 51.476190476190474
Actor Loss : 682.9490966796875
Train_EnvstepsSoFar : 233650
TimeSinceStart : 244.31751155853271
Done logging...



********** Iteration 227 ************

Collecting data for eval...
Eval_AverageReturn : 40.181819915771484
Eval_StdReturn : 9.123578071594238
Eval_MaxReturn : 58.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 40.18181818181818
Train_AverageReturn : 48.85714340209961
Train_StdReturn : 18.421741485595703
Train_MaxReturn : 92.0
Train_MinReturn : 30.0
Train_AverageEpLen : 48.857142857142854
Actor Loss : 546.50732421875
Train_EnvstepsSoFar : 234676
TimeSinceStart : 245.05893898010254
Done logging...



********** Iteration 228 ************

Collecting data for eval...
Eval_AverageReturn : 46.44444274902344
Eval_StdReturn : 14.476886749267578
Eval_MaxReturn : 84.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 46.44444444444444
Train_AverageReturn : 49.095237731933594
Train_StdReturn : 12.019447326660156
Train_MaxReturn : 78.0
Train_MinReturn : 33.0
Train_AverageEpLen : 49.095238095238095
Actor Loss : 597.9618530273438
Train_EnvstepsSoFar : 235707
TimeSinceStart : 245.7854950428009
Done logging...



********** Iteration 229 ************

Collecting data for eval...
Eval_AverageReturn : 50.375
Eval_StdReturn : 15.18171215057373
Eval_MaxReturn : 69.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 50.375
Train_AverageReturn : 47.9523811340332
Train_StdReturn : 14.001619338989258
Train_MaxReturn : 86.0
Train_MinReturn : 32.0
Train_AverageEpLen : 47.95238095238095
Actor Loss : 557.7936401367188
Train_EnvstepsSoFar : 236714
TimeSinceStart : 246.55571126937866
Done logging...



********** Iteration 230 ************

Collecting data for eval...
Eval_AverageReturn : 64.14286041259766
Eval_StdReturn : 27.946012496948242
Eval_MaxReturn : 125.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 64.14285714285714
Train_AverageReturn : 45.869564056396484
Train_StdReturn : 16.72879409790039
Train_MaxReturn : 98.0
Train_MinReturn : 29.0
Train_AverageEpLen : 45.869565217391305
Actor Loss : 526.1112670898438
Train_EnvstepsSoFar : 237769
TimeSinceStart : 247.38995385169983
Done logging...



********** Iteration 231 ************

Collecting data for eval...
Eval_AverageReturn : 38.181819915771484
Eval_StdReturn : 6.191169261932373
Eval_MaxReturn : 53.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 38.18181818181818
Train_AverageReturn : 51.849998474121094
Train_StdReturn : 31.204607009887695
Train_MaxReturn : 176.0
Train_MinReturn : 30.0
Train_AverageEpLen : 51.85
Actor Loss : 551.0460205078125
Train_EnvstepsSoFar : 238806
TimeSinceStart : 248.1122760772705
Done logging...



********** Iteration 232 ************

Collecting data for eval...
Eval_AverageReturn : 40.20000076293945
Eval_StdReturn : 11.214277267456055
Eval_MaxReturn : 70.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 40.2
Train_AverageReturn : 48.761905670166016
Train_StdReturn : 19.856401443481445
Train_MaxReturn : 111.0
Train_MinReturn : 32.0
Train_AverageEpLen : 48.76190476190476
Actor Loss : 622.7919921875
Train_EnvstepsSoFar : 239830
TimeSinceStart : 248.80359292030334
Done logging...



********** Iteration 233 ************

Collecting data for eval...
Eval_AverageReturn : 60.71428680419922
Eval_StdReturn : 30.348989486694336
Eval_MaxReturn : 119.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 60.714285714285715
Train_AverageReturn : 45.565216064453125
Train_StdReturn : 11.134849548339844
Train_MaxReturn : 77.0
Train_MinReturn : 25.0
Train_AverageEpLen : 45.56521739130435
Actor Loss : 582.0189208984375
Train_EnvstepsSoFar : 240878
TimeSinceStart : 250.3812689781189
Done logging...



********** Iteration 234 ************

Collecting data for eval...
Eval_AverageReturn : 54.5
Eval_StdReturn : 19.968725204467773
Eval_MaxReturn : 88.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 54.5
Train_AverageReturn : 49.227272033691406
Train_StdReturn : 23.583375930786133
Train_MaxReturn : 118.0
Train_MinReturn : 28.0
Train_AverageEpLen : 49.22727272727273
Actor Loss : 778.3427124023438
Train_EnvstepsSoFar : 241961
TimeSinceStart : 251.21130084991455
Done logging...



********** Iteration 235 ************

Collecting data for eval...
Eval_AverageReturn : 47.29999923706055
Eval_StdReturn : 14.220056533813477
Eval_MaxReturn : 74.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 47.3
Train_AverageReturn : 48.238094329833984
Train_StdReturn : 14.90575122833252
Train_MaxReturn : 82.0
Train_MinReturn : 29.0
Train_AverageEpLen : 48.23809523809524
Actor Loss : 490.71832275390625
Train_EnvstepsSoFar : 242974
TimeSinceStart : 251.97389245033264
Done logging...



********** Iteration 236 ************

Collecting data for eval...
Eval_AverageReturn : 40.20000076293945
Eval_StdReturn : 11.461238861083984
Eval_MaxReturn : 66.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 40.2
Train_AverageReturn : 42.625
Train_StdReturn : 16.834518432617188
Train_MaxReturn : 104.0
Train_MinReturn : 29.0
Train_AverageEpLen : 42.625
Actor Loss : 528.3605346679688
Train_EnvstepsSoFar : 243997
TimeSinceStart : 252.6958954334259
Done logging...



********** Iteration 237 ************

Collecting data for eval...
Eval_AverageReturn : 51.75
Eval_StdReturn : 17.21735954284668
Eval_MaxReturn : 82.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 51.75
Train_AverageReturn : 49.14285659790039
Train_StdReturn : 20.56646728515625
Train_MaxReturn : 116.0
Train_MinReturn : 30.0
Train_AverageEpLen : 49.142857142857146
Actor Loss : 519.2747192382812
Train_EnvstepsSoFar : 245029
TimeSinceStart : 253.59295344352722
Done logging...



********** Iteration 238 ************

Collecting data for eval...
Eval_AverageReturn : 40.099998474121094
Eval_StdReturn : 10.596698760986328
Eval_MaxReturn : 64.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 40.1
Train_AverageReturn : 50.54999923706055
Train_StdReturn : 21.193099975585938
Train_MaxReturn : 108.0
Train_MinReturn : 30.0
Train_AverageEpLen : 50.55
Actor Loss : 605.9801025390625
Train_EnvstepsSoFar : 246040
TimeSinceStart : 254.31795930862427
Done logging...



********** Iteration 239 ************

Collecting data for eval...
Eval_AverageReturn : 47.44444274902344
Eval_StdReturn : 20.423904418945312
Eval_MaxReturn : 101.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 47.44444444444444
Train_AverageReturn : 49.095237731933594
Train_StdReturn : 22.692359924316406
Train_MaxReturn : 136.0
Train_MinReturn : 28.0
Train_AverageEpLen : 49.095238095238095
Actor Loss : 718.8953857421875
Train_EnvstepsSoFar : 247071
TimeSinceStart : 255.07936429977417
Done logging...



********** Iteration 240 ************

Collecting data for eval...
Eval_AverageReturn : 40.900001525878906
Eval_StdReturn : 12.421353340148926
Eval_MaxReturn : 70.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 40.9
Train_AverageReturn : 47.272727966308594
Train_StdReturn : 16.74184226989746
Train_MaxReturn : 93.0
Train_MinReturn : 29.0
Train_AverageEpLen : 47.27272727272727
Actor Loss : 599.2368774414062
Train_EnvstepsSoFar : 248111
TimeSinceStart : 255.8202247619629
Done logging...



********** Iteration 241 ************

Collecting data for eval...
Eval_AverageReturn : 41.599998474121094
Eval_StdReturn : 10.02197551727295
Eval_MaxReturn : 62.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 41.6
Train_AverageReturn : 49.42856979370117
Train_StdReturn : 11.516329765319824
Train_MaxReturn : 72.0
Train_MinReturn : 30.0
Train_AverageEpLen : 49.42857142857143
Actor Loss : 516.780517578125
Train_EnvstepsSoFar : 249149
TimeSinceStart : 257.33859491348267
Done logging...



********** Iteration 242 ************

Collecting data for eval...
Eval_AverageReturn : 47.77777862548828
Eval_StdReturn : 15.440048217773438
Eval_MaxReturn : 70.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 47.77777777777778
Train_AverageReturn : 49.761905670166016
Train_StdReturn : 20.484384536743164
Train_MaxReturn : 113.0
Train_MinReturn : 31.0
Train_AverageEpLen : 49.76190476190476
Actor Loss : 509.4892578125
Train_EnvstepsSoFar : 250194
TimeSinceStart : 258.83433294296265
Done logging...



********** Iteration 243 ************

Collecting data for eval...
Eval_AverageReturn : 53.375
Eval_StdReturn : 15.651976585388184
Eval_MaxReturn : 76.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 53.375
Train_AverageReturn : 48.54545593261719
Train_StdReturn : 15.593493461608887
Train_MaxReturn : 85.0
Train_MinReturn : 28.0
Train_AverageEpLen : 48.54545454545455
Actor Loss : 558.4319458007812
Train_EnvstepsSoFar : 251262
TimeSinceStart : 259.77294278144836
Done logging...



********** Iteration 244 ************

Collecting data for eval...
Eval_AverageReturn : 45.5
Eval_StdReturn : 9.80051040649414
Eval_MaxReturn : 61.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 45.5
Train_AverageReturn : 46.681819915771484
Train_StdReturn : 14.023961067199707
Train_MaxReturn : 87.0
Train_MinReturn : 32.0
Train_AverageEpLen : 46.68181818181818
Actor Loss : 604.644287109375
Train_EnvstepsSoFar : 252289
TimeSinceStart : 261.20156931877136
Done logging...



********** Iteration 245 ************

Collecting data for eval...
Eval_AverageReturn : 60.28571319580078
Eval_StdReturn : 16.376937866210938
Eval_MaxReturn : 80.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 60.285714285714285
Train_AverageReturn : 55.157894134521484
Train_StdReturn : 16.918575286865234
Train_MaxReturn : 84.0
Train_MinReturn : 30.0
Train_AverageEpLen : 55.1578947368421
Actor Loss : 605.893798828125
Train_EnvstepsSoFar : 253337
TimeSinceStart : 262.5044026374817
Done logging...



********** Iteration 246 ************

Collecting data for eval...
Eval_AverageReturn : 50.25
Eval_StdReturn : 9.256753921508789
Eval_MaxReturn : 70.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 50.25
Train_AverageReturn : 47.1363639831543
Train_StdReturn : 14.410524368286133
Train_MaxReturn : 88.0
Train_MinReturn : 34.0
Train_AverageEpLen : 47.13636363636363
Actor Loss : 588.3482055664062
Train_EnvstepsSoFar : 254374
TimeSinceStart : 263.5094587802887
Done logging...



********** Iteration 247 ************

Collecting data for eval...
Eval_AverageReturn : 49.55555725097656
Eval_StdReturn : 15.875285148620605
Eval_MaxReturn : 76.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 49.55555555555556
Train_AverageReturn : 52.6315803527832
Train_StdReturn : 11.494668960571289
Train_MaxReturn : 70.0
Train_MinReturn : 33.0
Train_AverageEpLen : 52.63157894736842
Actor Loss : 651.7669677734375
Train_EnvstepsSoFar : 255374
TimeSinceStart : 264.28850746154785
Done logging...



********** Iteration 248 ************

Collecting data for eval...
Eval_AverageReturn : 54.625
Eval_StdReturn : 12.844624519348145
Eval_MaxReturn : 76.0
Eval_MinReturn : 40.0
Eval_AverageEpLen : 54.625
Train_AverageReturn : 48.42856979370117
Train_StdReturn : 12.69635009765625
Train_MaxReturn : 72.0
Train_MinReturn : 31.0
Train_AverageEpLen : 48.42857142857143
Actor Loss : 563.636962890625
Train_EnvstepsSoFar : 256391
TimeSinceStart : 265.0941162109375
Done logging...



********** Iteration 249 ************

Collecting data for eval...
Eval_AverageReturn : 51.0
Eval_StdReturn : 7.176350116729736
Eval_MaxReturn : 60.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 51.0
Train_AverageReturn : 46.181819915771484
Train_StdReturn : 9.96191120147705
Train_MaxReturn : 66.0
Train_MinReturn : 30.0
Train_AverageEpLen : 46.18181818181818
Actor Loss : 569.6414794921875
Train_EnvstepsSoFar : 257407
TimeSinceStart : 265.86322712898254
Done logging...



********** Iteration 250 ************

Collecting data for eval...
Eval_AverageReturn : 50.25
Eval_StdReturn : 11.924240112304688
Eval_MaxReturn : 73.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 50.25
Train_AverageReturn : 48.761905670166016
Train_StdReturn : 11.69820785522461
Train_MaxReturn : 88.0
Train_MinReturn : 34.0
Train_AverageEpLen : 48.76190476190476
Actor Loss : 665.7415771484375
Train_EnvstepsSoFar : 258431
TimeSinceStart : 266.6248257160187
Done logging...



********** Iteration 251 ************

Collecting data for eval...
Eval_AverageReturn : 57.125
Eval_StdReturn : 22.68500328063965
Eval_MaxReturn : 95.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 57.125
Train_AverageReturn : 46.227272033691406
Train_StdReturn : 11.681110382080078
Train_MaxReturn : 72.0
Train_MinReturn : 30.0
Train_AverageEpLen : 46.22727272727273
Actor Loss : 638.9395751953125
Train_EnvstepsSoFar : 259448
TimeSinceStart : 267.4235591888428
Done logging...



********** Iteration 252 ************

Collecting data for eval...
Eval_AverageReturn : 43.599998474121094
Eval_StdReturn : 13.872274398803711
Eval_MaxReturn : 77.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 43.6
Train_AverageReturn : 53.73684310913086
Train_StdReturn : 17.456235885620117
Train_MaxReturn : 86.0
Train_MinReturn : 30.0
Train_AverageEpLen : 53.73684210526316
Actor Loss : 654.1322021484375
Train_EnvstepsSoFar : 260469
TimeSinceStart : 268.19766759872437
Done logging...



********** Iteration 253 ************

Collecting data for eval...
Eval_AverageReturn : 52.5
Eval_StdReturn : 19.48717498779297
Eval_MaxReturn : 92.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 52.5
Train_AverageReturn : 46.09090805053711
Train_StdReturn : 12.989188194274902
Train_MaxReturn : 83.0
Train_MinReturn : 30.0
Train_AverageEpLen : 46.09090909090909
Actor Loss : 647.4107666015625
Train_EnvstepsSoFar : 261483
TimeSinceStart : 268.9696276187897
Done logging...



********** Iteration 254 ************

Collecting data for eval...
Eval_AverageReturn : 54.0
Eval_StdReturn : 14.282856941223145
Eval_MaxReturn : 72.0
Eval_MinReturn : 36.0
Eval_AverageEpLen : 54.0
Train_AverageReturn : 46.5
Train_StdReturn : 10.24140453338623
Train_MaxReturn : 66.0
Train_MinReturn : 30.0
Train_AverageEpLen : 46.5
Actor Loss : 563.740478515625
Train_EnvstepsSoFar : 262506
TimeSinceStart : 269.7470922470093
Done logging...



********** Iteration 255 ************

Collecting data for eval...
Eval_AverageReturn : 45.5
Eval_StdReturn : 20.742467880249023
Eval_MaxReturn : 98.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 45.5
Train_AverageReturn : 48.14285659790039
Train_StdReturn : 15.154084205627441
Train_MaxReturn : 84.0
Train_MinReturn : 29.0
Train_AverageEpLen : 48.142857142857146
Actor Loss : 566.45849609375
Train_EnvstepsSoFar : 263517
TimeSinceStart : 270.5220584869385
Done logging...



********** Iteration 256 ************

Collecting data for eval...
Eval_AverageReturn : 46.55555725097656
Eval_StdReturn : 12.41066837310791
Eval_MaxReturn : 74.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 46.55555555555556
Train_AverageReturn : 47.619049072265625
Train_StdReturn : 16.081565856933594
Train_MaxReturn : 94.0
Train_MinReturn : 28.0
Train_AverageEpLen : 47.61904761904762
Actor Loss : 447.46661376953125
Train_EnvstepsSoFar : 264517
TimeSinceStart : 271.2850580215454
Done logging...



********** Iteration 257 ************

Collecting data for eval...
Eval_AverageReturn : 43.29999923706055
Eval_StdReturn : 13.791664123535156
Eval_MaxReturn : 74.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 43.3
Train_AverageReturn : 45.8636360168457
Train_StdReturn : 12.80374813079834
Train_MaxReturn : 72.0
Train_MinReturn : 30.0
Train_AverageEpLen : 45.86363636363637
Actor Loss : 646.6578979492188
Train_EnvstepsSoFar : 265526
TimeSinceStart : 272.04520535469055
Done logging...



********** Iteration 258 ************

Collecting data for eval...
Eval_AverageReturn : 44.099998474121094
Eval_StdReturn : 11.54512882232666
Eval_MaxReturn : 66.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 44.1
Train_AverageReturn : 41.66666793823242
Train_StdReturn : 7.792446136474609
Train_MaxReturn : 55.0
Train_MinReturn : 28.0
Train_AverageEpLen : 41.666666666666664
Actor Loss : 496.5833740234375
Train_EnvstepsSoFar : 266526
TimeSinceStart : 272.8196244239807
Done logging...



********** Iteration 259 ************

Collecting data for eval...
Eval_AverageReturn : 48.33333206176758
Eval_StdReturn : 13.021349906921387
Eval_MaxReturn : 66.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 48.333333333333336
Train_AverageReturn : 50.0
Train_StdReturn : 21.260292053222656
Train_MaxReturn : 118.0
Train_MinReturn : 32.0
Train_AverageEpLen : 50.0
Actor Loss : 406.0889892578125
Train_EnvstepsSoFar : 267526
TimeSinceStart : 273.567786693573
Done logging...



********** Iteration 260 ************

Collecting data for eval...
Eval_AverageReturn : 51.0
Eval_StdReturn : 20.607440948486328
Eval_MaxReturn : 104.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 51.0
Train_AverageReturn : 48.14285659790039
Train_StdReturn : 13.108651161193848
Train_MaxReturn : 72.0
Train_MinReturn : 28.0
Train_AverageEpLen : 48.142857142857146
Actor Loss : 506.1623840332031
Train_EnvstepsSoFar : 268537
TimeSinceStart : 274.37458324432373
Done logging...



********** Iteration 261 ************

Collecting data for eval...
Eval_AverageReturn : 38.818180084228516
Eval_StdReturn : 6.991139888763428
Eval_MaxReturn : 50.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 38.81818181818182
Train_AverageReturn : 46.1363639831543
Train_StdReturn : 14.007451057434082
Train_MaxReturn : 78.0
Train_MinReturn : 28.0
Train_AverageEpLen : 46.13636363636363
Actor Loss : 608.194091796875
Train_EnvstepsSoFar : 269552
TimeSinceStart : 275.15423464775085
Done logging...



********** Iteration 262 ************

Collecting data for eval...
Eval_AverageReturn : 54.0
Eval_StdReturn : 22.35508918762207
Eval_MaxReturn : 90.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 54.0
Train_AverageReturn : 55.83333206176758
Train_StdReturn : 18.13299560546875
Train_MaxReturn : 99.0
Train_MinReturn : 33.0
Train_AverageEpLen : 55.833333333333336
Actor Loss : 530.7152099609375
Train_EnvstepsSoFar : 270557
TimeSinceStart : 275.9245853424072
Done logging...



********** Iteration 263 ************

Collecting data for eval...
Eval_AverageReturn : 47.0
Eval_StdReturn : 10.208928108215332
Eval_MaxReturn : 65.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 47.0
Train_AverageReturn : 53.0
Train_StdReturn : 16.78031349182129
Train_MaxReturn : 100.0
Train_MinReturn : 32.0
Train_AverageEpLen : 53.0
Actor Loss : 491.63970947265625
Train_EnvstepsSoFar : 271564
TimeSinceStart : 276.6995475292206
Done logging...



********** Iteration 264 ************

Collecting data for eval...
Eval_AverageReturn : 47.11111068725586
Eval_StdReturn : 14.670032501220703
Eval_MaxReturn : 71.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 47.111111111111114
Train_AverageReturn : 50.5
Train_StdReturn : 9.861541748046875
Train_MaxReturn : 68.0
Train_MinReturn : 35.0
Train_AverageEpLen : 50.5
Actor Loss : 580.3176879882812
Train_EnvstepsSoFar : 272574
TimeSinceStart : 277.461630821228
Done logging...



********** Iteration 265 ************

Collecting data for eval...
Eval_AverageReturn : 52.125
Eval_StdReturn : 12.494373321533203
Eval_MaxReturn : 76.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 52.125
Train_AverageReturn : 47.66666793823242
Train_StdReturn : 10.947203636169434
Train_MaxReturn : 69.0
Train_MinReturn : 34.0
Train_AverageEpLen : 47.666666666666664
Actor Loss : 655.7760009765625
Train_EnvstepsSoFar : 273575
TimeSinceStart : 278.2246069908142
Done logging...



********** Iteration 266 ************

Collecting data for eval...
Eval_AverageReturn : 47.22222137451172
Eval_StdReturn : 11.093318939208984
Eval_MaxReturn : 70.0
Eval_MinReturn : 36.0
Eval_AverageEpLen : 47.22222222222222
Train_AverageReturn : 42.70833206176758
Train_StdReturn : 12.607799530029297
Train_MaxReturn : 91.0
Train_MinReturn : 30.0
Train_AverageEpLen : 42.708333333333336
Actor Loss : 557.9326782226562
Train_EnvstepsSoFar : 274600
TimeSinceStart : 279.0151422023773
Done logging...



********** Iteration 267 ************

Collecting data for eval...
Eval_AverageReturn : 49.55555725097656
Eval_StdReturn : 12.606093406677246
Eval_MaxReturn : 81.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 49.55555555555556
Train_AverageReturn : 49.380950927734375
Train_StdReturn : 16.14657974243164
Train_MaxReturn : 78.0
Train_MinReturn : 32.0
Train_AverageEpLen : 49.38095238095238
Actor Loss : 495.13720703125
Train_EnvstepsSoFar : 275637
TimeSinceStart : 279.8082973957062
Done logging...



********** Iteration 268 ************

Collecting data for eval...
Eval_AverageReturn : 60.0
Eval_StdReturn : 22.469026565551758
Eval_MaxReturn : 90.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 60.0
Train_AverageReturn : 44.043479919433594
Train_StdReturn : 10.268052101135254
Train_MaxReturn : 76.0
Train_MinReturn : 31.0
Train_AverageEpLen : 44.04347826086956
Actor Loss : 482.8289794921875
Train_EnvstepsSoFar : 276650
TimeSinceStart : 280.57656741142273
Done logging...



********** Iteration 269 ************

Collecting data for eval...
Eval_AverageReturn : 54.25
Eval_StdReturn : 21.69533348083496
Eval_MaxReturn : 99.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 54.25
Train_AverageReturn : 47.80952453613281
Train_StdReturn : 12.556990623474121
Train_MaxReturn : 83.0
Train_MinReturn : 30.0
Train_AverageEpLen : 47.80952380952381
Actor Loss : 447.0316162109375
Train_EnvstepsSoFar : 277654
TimeSinceStart : 281.3347315788269
Done logging...



********** Iteration 270 ************

Collecting data for eval...
Eval_AverageReturn : 46.66666793823242
Eval_StdReturn : 18.920888900756836
Eval_MaxReturn : 92.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 46.666666666666664
Train_AverageReturn : 46.956520080566406
Train_StdReturn : 11.16858196258545
Train_MaxReturn : 81.0
Train_MinReturn : 35.0
Train_AverageEpLen : 46.95652173913044
Actor Loss : 522.599609375
Train_EnvstepsSoFar : 278734
TimeSinceStart : 282.1399075984955
Done logging...



********** Iteration 271 ************

Collecting data for eval...
Eval_AverageReturn : 52.0
Eval_StdReturn : 11.169154167175293
Eval_MaxReturn : 66.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 52.0
Train_AverageReturn : 56.27777862548828
Train_StdReturn : 14.96590805053711
Train_MaxReturn : 86.0
Train_MinReturn : 28.0
Train_AverageEpLen : 56.27777777777778
Actor Loss : 754.666015625
Train_EnvstepsSoFar : 279747
TimeSinceStart : 283.208607673645
Done logging...



********** Iteration 272 ************

Collecting data for eval...
Eval_AverageReturn : 52.25
Eval_StdReturn : 16.976085662841797
Eval_MaxReturn : 90.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 52.25
Train_AverageReturn : 52.78947448730469
Train_StdReturn : 17.169675827026367
Train_MaxReturn : 98.0
Train_MinReturn : 32.0
Train_AverageEpLen : 52.78947368421053
Actor Loss : 615.7188720703125
Train_EnvstepsSoFar : 280750
TimeSinceStart : 283.97954082489014
Done logging...



********** Iteration 273 ************

Collecting data for eval...
Eval_AverageReturn : 50.125
Eval_StdReturn : 10.599970817565918
Eval_MaxReturn : 71.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 50.125
Train_AverageReturn : 50.099998474121094
Train_StdReturn : 13.96030044555664
Train_MaxReturn : 98.0
Train_MinReturn : 36.0
Train_AverageEpLen : 50.1
Actor Loss : 516.7245483398438
Train_EnvstepsSoFar : 281752
TimeSinceStart : 284.74205708503723
Done logging...



********** Iteration 274 ************

Collecting data for eval...
Eval_AverageReturn : 45.900001525878906
Eval_StdReturn : 15.115885734558105
Eval_MaxReturn : 79.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 45.9
Train_AverageReturn : 47.681819915771484
Train_StdReturn : 10.797248840332031
Train_MaxReturn : 71.0
Train_MinReturn : 31.0
Train_AverageEpLen : 47.68181818181818
Actor Loss : 565.205810546875
Train_EnvstepsSoFar : 282801
TimeSinceStart : 285.5666151046753
Done logging...



********** Iteration 275 ************

Collecting data for eval...
Eval_AverageReturn : 52.875
Eval_StdReturn : 20.09003257751465
Eval_MaxReturn : 88.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 52.875
Train_AverageReturn : 46.318180084228516
Train_StdReturn : 17.439208984375
Train_MaxReturn : 92.0
Train_MinReturn : 30.0
Train_AverageEpLen : 46.31818181818182
Actor Loss : 492.5426025390625
Train_EnvstepsSoFar : 283820
TimeSinceStart : 286.3372025489807
Done logging...



********** Iteration 276 ************

Collecting data for eval...
Eval_AverageReturn : 47.33333206176758
Eval_StdReturn : 14.794894218444824
Eval_MaxReturn : 68.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 47.333333333333336
Train_AverageReturn : 46.5
Train_StdReturn : 13.047987937927246
Train_MaxReturn : 76.0
Train_MinReturn : 30.0
Train_AverageEpLen : 46.5
Actor Loss : 595.7194213867188
Train_EnvstepsSoFar : 284843
TimeSinceStart : 287.09636926651
Done logging...



********** Iteration 277 ************

Collecting data for eval...
Eval_AverageReturn : 52.375
Eval_StdReturn : 15.231033325195312
Eval_MaxReturn : 73.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 52.375
Train_AverageReturn : 45.727272033691406
Train_StdReturn : 18.273632049560547
Train_MaxReturn : 108.0
Train_MinReturn : 28.0
Train_AverageEpLen : 45.72727272727273
Actor Loss : 446.145263671875
Train_EnvstepsSoFar : 285849
TimeSinceStart : 287.8605282306671
Done logging...



********** Iteration 278 ************

Collecting data for eval...
Eval_AverageReturn : 40.272727966308594
Eval_StdReturn : 9.05629825592041
Eval_MaxReturn : 60.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 40.27272727272727
Train_AverageReturn : 40.47999954223633
Train_StdReturn : 7.705166816711426
Train_MaxReturn : 55.0
Train_MinReturn : 27.0
Train_AverageEpLen : 40.48
Actor Loss : 428.254150390625
Train_EnvstepsSoFar : 286861
TimeSinceStart : 289.06478357315063
Done logging...



********** Iteration 279 ************

Collecting data for eval...
Eval_AverageReturn : 44.099998474121094
Eval_StdReturn : 10.624970436096191
Eval_MaxReturn : 61.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 44.1
Train_AverageReturn : 52.400001525878906
Train_StdReturn : 20.981897354125977
Train_MaxReturn : 97.0
Train_MinReturn : 28.0
Train_AverageEpLen : 52.4
Actor Loss : 487.11346435546875
Train_EnvstepsSoFar : 287909
TimeSinceStart : 289.87399673461914
Done logging...



********** Iteration 280 ************

Collecting data for eval...
Eval_AverageReturn : 47.33333206176758
Eval_StdReturn : 14.282856941223145
Eval_MaxReturn : 69.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 47.333333333333336
Train_AverageReturn : 53.578948974609375
Train_StdReturn : 14.28402042388916
Train_MaxReturn : 80.0
Train_MinReturn : 31.0
Train_AverageEpLen : 53.578947368421055
Actor Loss : 421.84747314453125
Train_EnvstepsSoFar : 288927
TimeSinceStart : 290.6727430820465
Done logging...



********** Iteration 281 ************

Collecting data for eval...
Eval_AverageReturn : 52.125
Eval_StdReturn : 21.75107765197754
Eval_MaxReturn : 85.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 52.125
Train_AverageReturn : 48.0
Train_StdReturn : 19.736356735229492
Train_MaxReturn : 105.0
Train_MinReturn : 29.0
Train_AverageEpLen : 48.0
Actor Loss : 380.429443359375
Train_EnvstepsSoFar : 289935
TimeSinceStart : 291.4547290802002
Done logging...



********** Iteration 282 ************

Collecting data for eval...
Eval_AverageReturn : 51.875
Eval_StdReturn : 16.182069778442383
Eval_MaxReturn : 87.0
Eval_MinReturn : 36.0
Eval_AverageEpLen : 51.875
Train_AverageReturn : 45.173912048339844
Train_StdReturn : 10.953070640563965
Train_MaxReturn : 73.0
Train_MinReturn : 30.0
Train_AverageEpLen : 45.17391304347826
Actor Loss : 506.41119384765625
Train_EnvstepsSoFar : 290974
TimeSinceStart : 292.2427055835724
Done logging...



********** Iteration 283 ************

Collecting data for eval...
Eval_AverageReturn : 47.22222137451172
Eval_StdReturn : 15.41844367980957
Eval_MaxReturn : 70.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 47.22222222222222
Train_AverageReturn : 47.40909194946289
Train_StdReturn : 15.964902877807617
Train_MaxReturn : 109.0
Train_MinReturn : 30.0
Train_AverageEpLen : 47.40909090909091
Actor Loss : 363.8759460449219
Train_EnvstepsSoFar : 292017
TimeSinceStart : 293.1986436843872
Done logging...



********** Iteration 284 ************

Collecting data for eval...
Eval_AverageReturn : 49.0
Eval_StdReturn : 17.21110725402832
Eval_MaxReturn : 81.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 49.0
Train_AverageReturn : 48.904762268066406
Train_StdReturn : 19.777101516723633
Train_MaxReturn : 103.0
Train_MinReturn : 28.0
Train_AverageEpLen : 48.904761904761905
Actor Loss : 416.81329345703125
Train_EnvstepsSoFar : 293044
TimeSinceStart : 293.9933671951294
Done logging...



********** Iteration 285 ************

Collecting data for eval...
Eval_AverageReturn : 42.70000076293945
Eval_StdReturn : 7.416872501373291
Eval_MaxReturn : 54.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 42.7
Train_AverageReturn : 44.60869598388672
Train_StdReturn : 14.487592697143555
Train_MaxReturn : 81.0
Train_MinReturn : 30.0
Train_AverageEpLen : 44.608695652173914
Actor Loss : 401.07073974609375
Train_EnvstepsSoFar : 294070
TimeSinceStart : 294.7794635295868
Done logging...



********** Iteration 286 ************

Collecting data for eval...
Eval_AverageReturn : 51.25
Eval_StdReturn : 13.599172592163086
Eval_MaxReturn : 78.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 51.25
Train_AverageReturn : 53.26315689086914
Train_StdReturn : 15.804203033447266
Train_MaxReturn : 83.0
Train_MinReturn : 32.0
Train_AverageEpLen : 53.26315789473684
Actor Loss : 391.63262939453125
Train_EnvstepsSoFar : 295082
TimeSinceStart : 295.5470771789551
Done logging...



********** Iteration 287 ************

Collecting data for eval...
Eval_AverageReturn : 49.0
Eval_StdReturn : 16.845705032348633
Eval_MaxReturn : 85.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 49.0
Train_AverageReturn : 49.57143020629883
Train_StdReturn : 19.092683792114258
Train_MaxReturn : 96.0
Train_MinReturn : 28.0
Train_AverageEpLen : 49.57142857142857
Actor Loss : 482.8874206542969
Train_EnvstepsSoFar : 296123
TimeSinceStart : 296.4685654640198
Done logging...



********** Iteration 288 ************

Collecting data for eval...
Eval_AverageReturn : 44.44444274902344
Eval_StdReturn : 16.94508171081543
Eval_MaxReturn : 87.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 44.44444444444444
Train_AverageReturn : 44.0
Train_StdReturn : 11.729592323303223
Train_MaxReturn : 78.0
Train_MinReturn : 30.0
Train_AverageEpLen : 44.0
Actor Loss : 584.833251953125
Train_EnvstepsSoFar : 297179
TimeSinceStart : 297.2513666152954
Done logging...



********** Iteration 289 ************

Collecting data for eval...
Eval_AverageReturn : 49.33333206176758
Eval_StdReturn : 13.759844779968262
Eval_MaxReturn : 69.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 49.333333333333336
Train_AverageReturn : 49.47618865966797
Train_StdReturn : 12.179682731628418
Train_MaxReturn : 91.0
Train_MinReturn : 33.0
Train_AverageEpLen : 49.476190476190474
Actor Loss : 514.4686279296875
Train_EnvstepsSoFar : 298218
TimeSinceStart : 298.0547339916229
Done logging...



********** Iteration 290 ************

Collecting data for eval...
Eval_AverageReturn : 48.77777862548828
Eval_StdReturn : 9.623786926269531
Eval_MaxReturn : 64.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 48.77777777777778
Train_AverageReturn : 51.52381134033203
Train_StdReturn : 16.37541389465332
Train_MaxReturn : 84.0
Train_MinReturn : 31.0
Train_AverageEpLen : 51.523809523809526
Actor Loss : 544.4905395507812
Train_EnvstepsSoFar : 299300
TimeSinceStart : 298.89859342575073
Done logging...



********** Iteration 291 ************

Collecting data for eval...
Eval_AverageReturn : 45.77777862548828
Eval_StdReturn : 12.145211219787598
Eval_MaxReturn : 75.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 45.77777777777778
Train_AverageReturn : 49.0
Train_StdReturn : 15.644867897033691
Train_MaxReturn : 96.0
Train_MinReturn : 31.0
Train_AverageEpLen : 49.0
Actor Loss : 454.54742431640625
Train_EnvstepsSoFar : 300329
TimeSinceStart : 299.68687105178833
Done logging...



********** Iteration 292 ************

Collecting data for eval...
Eval_AverageReturn : 47.33333206176758
Eval_StdReturn : 6.289320468902588
Eval_MaxReturn : 60.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 47.333333333333336
Train_AverageReturn : 49.9523811340332
Train_StdReturn : 15.388544082641602
Train_MaxReturn : 83.0
Train_MinReturn : 30.0
Train_AverageEpLen : 49.95238095238095
Actor Loss : 470.34564208984375
Train_EnvstepsSoFar : 301378
TimeSinceStart : 300.4747278690338
Done logging...



********** Iteration 293 ************

Collecting data for eval...
Eval_AverageReturn : 56.0
Eval_StdReturn : 20.457273483276367
Eval_MaxReturn : 103.0
Eval_MinReturn : 36.0
Eval_AverageEpLen : 56.0
Train_AverageReturn : 50.849998474121094
Train_StdReturn : 20.010683059692383
Train_MaxReturn : 106.0
Train_MinReturn : 30.0
Train_AverageEpLen : 50.85
Actor Loss : 516.8985595703125
Train_EnvstepsSoFar : 302395
TimeSinceStart : 301.25256752967834
Done logging...



********** Iteration 294 ************

Collecting data for eval...
Eval_AverageReturn : 57.85714340209961
Eval_StdReturn : 10.42563533782959
Eval_MaxReturn : 73.0
Eval_MinReturn : 41.0
Eval_AverageEpLen : 57.857142857142854
Train_AverageReturn : 46.8636360168457
Train_StdReturn : 12.534662246704102
Train_MaxReturn : 92.0
Train_MinReturn : 33.0
Train_AverageEpLen : 46.86363636363637
Actor Loss : 489.37139892578125
Train_EnvstepsSoFar : 303426
TimeSinceStart : 302.02080488204956
Done logging...



********** Iteration 295 ************

Collecting data for eval...
Eval_AverageReturn : 46.0
Eval_StdReturn : 11.115554809570312
Eval_MaxReturn : 66.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 46.0
Train_AverageReturn : 44.173912048339844
Train_StdReturn : 13.949136734008789
Train_MaxReturn : 97.0
Train_MinReturn : 31.0
Train_AverageEpLen : 44.17391304347826
Actor Loss : 429.17620849609375
Train_EnvstepsSoFar : 304442
TimeSinceStart : 302.79514956474304
Done logging...



********** Iteration 296 ************

Collecting data for eval...
Eval_AverageReturn : 57.14285659790039
Eval_StdReturn : 22.787391662597656
Eval_MaxReturn : 96.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 57.142857142857146
Train_AverageReturn : 55.66666793823242
Train_StdReturn : 22.52406120300293
Train_MaxReturn : 110.0
Train_MinReturn : 31.0
Train_AverageEpLen : 55.666666666666664
Actor Loss : 551.8460083007812
Train_EnvstepsSoFar : 305444
TimeSinceStart : 304.08165073394775
Done logging...



********** Iteration 297 ************

Collecting data for eval...
Eval_AverageReturn : 52.375
Eval_StdReturn : 12.989779472351074
Eval_MaxReturn : 72.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 52.375
Train_AverageReturn : 46.227272033691406
Train_StdReturn : 9.690350532531738
Train_MaxReturn : 69.0
Train_MinReturn : 32.0
Train_AverageEpLen : 46.22727272727273
Actor Loss : 461.12939453125
Train_EnvstepsSoFar : 306461
TimeSinceStart : 305.5722439289093
Done logging...



********** Iteration 298 ************

Collecting data for eval...
Eval_AverageReturn : 45.66666793823242
Eval_StdReturn : 7.745966911315918
Eval_MaxReturn : 60.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 45.666666666666664
Train_AverageReturn : 53.349998474121094
Train_StdReturn : 14.217154502868652
Train_MaxReturn : 86.0
Train_MinReturn : 35.0
Train_AverageEpLen : 53.35
Actor Loss : 532.7381591796875
Train_EnvstepsSoFar : 307528
TimeSinceStart : 307.172158241272
Done logging...



********** Iteration 299 ************

Collecting data for eval...
Eval_AverageReturn : 43.0
Eval_StdReturn : 10.779610633850098
Eval_MaxReturn : 66.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 43.0
Train_AverageReturn : 58.66666793823242
Train_StdReturn : 18.141420364379883
Train_MaxReturn : 102.0
Train_MinReturn : 30.0
Train_AverageEpLen : 58.666666666666664
Actor Loss : 510.5323791503906
Train_EnvstepsSoFar : 308584
TimeSinceStart : 308.1499135494232
Done logging...



********** Iteration 300 ************

Collecting data for eval...
Eval_AverageReturn : 44.20000076293945
Eval_StdReturn : 12.592061042785645
Eval_MaxReturn : 63.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 44.2
Train_AverageReturn : 63.4375
Train_StdReturn : 38.92776870727539
Train_MaxReturn : 200.0
Train_MinReturn : 32.0
Train_AverageEpLen : 63.4375
Actor Loss : 493.0568542480469
Train_EnvstepsSoFar : 309599
TimeSinceStart : 309.1777653694153
Done logging...



********** Iteration 301 ************

Collecting data for eval...
Eval_AverageReturn : 50.25
Eval_StdReturn : 13.589978218078613
Eval_MaxReturn : 73.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 50.25
Train_AverageReturn : 54.68421173095703
Train_StdReturn : 18.890411376953125
Train_MaxReturn : 115.0
Train_MinReturn : 34.0
Train_AverageEpLen : 54.68421052631579
Actor Loss : 532.8062744140625
Train_EnvstepsSoFar : 310638
TimeSinceStart : 310.19049072265625
Done logging...



********** Iteration 302 ************

Collecting data for eval...
Eval_AverageReturn : 41.79999923706055
Eval_StdReturn : 11.373653411865234
Eval_MaxReturn : 66.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 41.8
Train_AverageReturn : 43.739131927490234
Train_StdReturn : 15.70438003540039
Train_MaxReturn : 94.0
Train_MinReturn : 27.0
Train_AverageEpLen : 43.73913043478261
Actor Loss : 424.7806396484375
Train_EnvstepsSoFar : 311644
TimeSinceStart : 311.1913869380951
Done logging...



********** Iteration 303 ************

Collecting data for eval...
Eval_AverageReturn : 47.22222137451172
Eval_StdReturn : 12.899420738220215
Eval_MaxReturn : 68.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 47.22222222222222
Train_AverageReturn : 49.095237731933594
Train_StdReturn : 18.186613082885742
Train_MaxReturn : 108.0
Train_MinReturn : 28.0
Train_AverageEpLen : 49.095238095238095
Actor Loss : 420.5871887207031
Train_EnvstepsSoFar : 312675
TimeSinceStart : 312.7664828300476
Done logging...



********** Iteration 304 ************

Collecting data for eval...
Eval_AverageReturn : 41.400001525878906
Eval_StdReturn : 7.592101573944092
Eval_MaxReturn : 56.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 41.4
Train_AverageReturn : 43.69565200805664
Train_StdReturn : 11.841102600097656
Train_MaxReturn : 79.0
Train_MinReturn : 28.0
Train_AverageEpLen : 43.69565217391305
Actor Loss : 476.09857177734375
Train_EnvstepsSoFar : 313680
TimeSinceStart : 314.30702352523804
Done logging...



********** Iteration 305 ************

Collecting data for eval...
Eval_AverageReturn : 50.375
Eval_StdReturn : 22.890705108642578
Eval_MaxReturn : 104.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 50.375
Train_AverageReturn : 47.5
Train_StdReturn : 16.191328048706055
Train_MaxReturn : 104.0
Train_MinReturn : 30.0
Train_AverageEpLen : 47.5
Actor Loss : 538.89892578125
Train_EnvstepsSoFar : 314725
TimeSinceStart : 315.8630225658417
Done logging...



********** Iteration 306 ************

Collecting data for eval...
Eval_AverageReturn : 43.79999923706055
Eval_StdReturn : 10.5337553024292
Eval_MaxReturn : 69.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 43.8
Train_AverageReturn : 45.08695602416992
Train_StdReturn : 11.232379913330078
Train_MaxReturn : 64.0
Train_MinReturn : 30.0
Train_AverageEpLen : 45.08695652173913
Actor Loss : 634.3223876953125
Train_EnvstepsSoFar : 315762
TimeSinceStart : 316.6547772884369
Done logging...



********** Iteration 307 ************

Collecting data for eval...
Eval_AverageReturn : 50.375
Eval_StdReturn : 20.657550811767578
Eval_MaxReturn : 103.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 50.375
Train_AverageReturn : 46.09090805053711
Train_StdReturn : 12.280468940734863
Train_MaxReturn : 67.0
Train_MinReturn : 30.0
Train_AverageEpLen : 46.09090909090909
Actor Loss : 436.38055419921875
Train_EnvstepsSoFar : 316776
TimeSinceStart : 317.4320511817932
Done logging...



********** Iteration 308 ************

Collecting data for eval...
Eval_AverageReturn : 46.55555725097656
Eval_StdReturn : 10.802376747131348
Eval_MaxReturn : 70.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 46.55555555555556
Train_AverageReturn : 44.130435943603516
Train_StdReturn : 11.260953903198242
Train_MaxReturn : 72.0
Train_MinReturn : 27.0
Train_AverageEpLen : 44.130434782608695
Actor Loss : 519.7471923828125
Train_EnvstepsSoFar : 317791
TimeSinceStart : 318.21939969062805
Done logging...



********** Iteration 309 ************

Collecting data for eval...
Eval_AverageReturn : 51.125
Eval_StdReturn : 17.04726791381836
Eval_MaxReturn : 90.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 51.125
Train_AverageReturn : 55.578948974609375
Train_StdReturn : 23.00644302368164
Train_MaxReturn : 130.0
Train_MinReturn : 33.0
Train_AverageEpLen : 55.578947368421055
Actor Loss : 462.3664245605469
Train_EnvstepsSoFar : 318847
TimeSinceStart : 319.0157034397125
Done logging...



********** Iteration 310 ************

Collecting data for eval...
Eval_AverageReturn : 50.25
Eval_StdReturn : 15.031217575073242
Eval_MaxReturn : 73.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 50.25
Train_AverageReturn : 46.8636360168457
Train_StdReturn : 12.443674087524414
Train_MaxReturn : 70.0
Train_MinReturn : 28.0
Train_AverageEpLen : 46.86363636363637
Actor Loss : 376.93408203125
Train_EnvstepsSoFar : 319878
TimeSinceStart : 319.7949802875519
Done logging...



********** Iteration 311 ************

Collecting data for eval...
Eval_AverageReturn : 52.33333206176758
Eval_StdReturn : 12.489995956420898
Eval_MaxReturn : 78.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 52.333333333333336
Train_AverageReturn : 45.4782600402832
Train_StdReturn : 14.820284843444824
Train_MaxReturn : 84.0
Train_MinReturn : 28.0
Train_AverageEpLen : 45.47826086956522
Actor Loss : 532.2158203125
Train_EnvstepsSoFar : 320924
TimeSinceStart : 320.62135338783264
Done logging...



********** Iteration 312 ************

Collecting data for eval...
Eval_AverageReturn : 48.0
Eval_StdReturn : 11.30388355255127
Eval_MaxReturn : 72.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 48.0
Train_AverageReturn : 48.71428680419922
Train_StdReturn : 15.826869010925293
Train_MaxReturn : 79.0
Train_MinReturn : 29.0
Train_AverageEpLen : 48.714285714285715
Actor Loss : 479.64019775390625
Train_EnvstepsSoFar : 321947
TimeSinceStart : 321.3936483860016
Done logging...



********** Iteration 313 ************

Collecting data for eval...
Eval_AverageReturn : 49.0
Eval_StdReturn : 15.542057991027832
Eval_MaxReturn : 88.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 49.0
Train_AverageReturn : 46.04545593261719
Train_StdReturn : 14.76013469696045
Train_MaxReturn : 88.0
Train_MinReturn : 28.0
Train_AverageEpLen : 46.04545454545455
Actor Loss : 523.3746948242188
Train_EnvstepsSoFar : 322960
TimeSinceStart : 322.1732110977173
Done logging...



********** Iteration 314 ************

Collecting data for eval...
Eval_AverageReturn : 45.11111068725586
Eval_StdReturn : 12.887930870056152
Eval_MaxReturn : 75.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 45.111111111111114
Train_AverageReturn : 53.157894134521484
Train_StdReturn : 17.15337371826172
Train_MaxReturn : 95.0
Train_MinReturn : 29.0
Train_AverageEpLen : 53.1578947368421
Actor Loss : 521.019775390625
Train_EnvstepsSoFar : 323970
TimeSinceStart : 322.9933433532715
Done logging...



********** Iteration 315 ************

Collecting data for eval...
Eval_AverageReturn : 45.33333206176758
Eval_StdReturn : 9.368979454040527
Eval_MaxReturn : 60.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 45.333333333333336
Train_AverageReturn : 51.150001525878906
Train_StdReturn : 18.876638412475586
Train_MaxReturn : 103.0
Train_MinReturn : 33.0
Train_AverageEpLen : 51.15
Actor Loss : 528.3165283203125
Train_EnvstepsSoFar : 324993
TimeSinceStart : 323.77414083480835
Done logging...



********** Iteration 316 ************

Collecting data for eval...
Eval_AverageReturn : 43.400001525878906
Eval_StdReturn : 8.66256332397461
Eval_MaxReturn : 60.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 43.4
Train_AverageReturn : 50.761905670166016
Train_StdReturn : 16.767044067382812
Train_MaxReturn : 105.0
Train_MinReturn : 34.0
Train_AverageEpLen : 50.76190476190476
Actor Loss : 485.3613586425781
Train_EnvstepsSoFar : 326059
TimeSinceStart : 324.57381653785706
Done logging...



********** Iteration 317 ************

Collecting data for eval...
Eval_AverageReturn : 59.14285659790039
Eval_StdReturn : 21.74152374267578
Eval_MaxReturn : 93.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 59.142857142857146
Train_AverageReturn : 47.85714340209961
Train_StdReturn : 13.850513458251953
Train_MaxReturn : 79.0
Train_MinReturn : 29.0
Train_AverageEpLen : 47.857142857142854
Actor Loss : 540.1046142578125
Train_EnvstepsSoFar : 327064
TimeSinceStart : 325.32247948646545
Done logging...



********** Iteration 318 ************

Collecting data for eval...
Eval_AverageReturn : 51.375
Eval_StdReturn : 13.27532958984375
Eval_MaxReturn : 69.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 51.375
Train_AverageReturn : 56.61111068725586
Train_StdReturn : 14.87779426574707
Train_MaxReturn : 92.0
Train_MinReturn : 32.0
Train_AverageEpLen : 56.611111111111114
Actor Loss : 398.74127197265625
Train_EnvstepsSoFar : 328083
TimeSinceStart : 326.09252095222473
Done logging...



********** Iteration 319 ************

Collecting data for eval...
Eval_AverageReturn : 52.55555725097656
Eval_StdReturn : 23.7164306640625
Eval_MaxReturn : 91.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 52.55555555555556
Train_AverageReturn : 49.14285659790039
Train_StdReturn : 14.942065238952637
Train_MaxReturn : 96.0
Train_MinReturn : 31.0
Train_AverageEpLen : 49.142857142857146
Actor Loss : 464.7747802734375
Train_EnvstepsSoFar : 329115
TimeSinceStart : 326.89083456993103
Done logging...



********** Iteration 320 ************

Collecting data for eval...
Eval_AverageReturn : 52.875
Eval_StdReturn : 12.810518264770508
Eval_MaxReturn : 77.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 52.875
Train_AverageReturn : 49.0476188659668
Train_StdReturn : 15.788712501525879
Train_MaxReturn : 99.0
Train_MinReturn : 32.0
Train_AverageEpLen : 49.04761904761905
Actor Loss : 441.9788818359375
Train_EnvstepsSoFar : 330145
TimeSinceStart : 327.6751353740692
Done logging...



********** Iteration 321 ************

Collecting data for eval...
Eval_AverageReturn : 43.099998474121094
Eval_StdReturn : 13.604779243469238
Eval_MaxReturn : 74.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 43.1
Train_AverageReturn : 51.20000076293945
Train_StdReturn : 17.241230010986328
Train_MaxReturn : 108.0
Train_MinReturn : 34.0
Train_AverageEpLen : 51.2
Actor Loss : 384.3365783691406
Train_EnvstepsSoFar : 331169
TimeSinceStart : 328.45405411720276
Done logging...



********** Iteration 322 ************

Collecting data for eval...
Eval_AverageReturn : 46.88888931274414
Eval_StdReturn : 15.102938652038574
Eval_MaxReturn : 68.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 46.888888888888886
Train_AverageReturn : 49.19047546386719
Train_StdReturn : 17.622007369995117
Train_MaxReturn : 108.0
Train_MinReturn : 32.0
Train_AverageEpLen : 49.19047619047619
Actor Loss : 529.9773559570312
Train_EnvstepsSoFar : 332202
TimeSinceStart : 329.22759652137756
Done logging...



********** Iteration 323 ************

Collecting data for eval...
Eval_AverageReturn : 45.11111068725586
Eval_StdReturn : 11.892522811889648
Eval_MaxReturn : 65.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 45.111111111111114
Train_AverageReturn : 48.095237731933594
Train_StdReturn : 14.615402221679688
Train_MaxReturn : 87.0
Train_MinReturn : 30.0
Train_AverageEpLen : 48.095238095238095
Actor Loss : 423.05859375
Train_EnvstepsSoFar : 333212
TimeSinceStart : 330.20458340644836
Done logging...



********** Iteration 324 ************

Collecting data for eval...
Eval_AverageReturn : 53.625
Eval_StdReturn : 17.712549209594727
Eval_MaxReturn : 85.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 53.625
Train_AverageReturn : 48.14285659790039
Train_StdReturn : 12.840730667114258
Train_MaxReturn : 88.0
Train_MinReturn : 30.0
Train_AverageEpLen : 48.142857142857146
Actor Loss : 532.826904296875
Train_EnvstepsSoFar : 334223
TimeSinceStart : 331.2778887748718
Done logging...



********** Iteration 325 ************

Collecting data for eval...
Eval_AverageReturn : 53.125
Eval_StdReturn : 17.47453498840332
Eval_MaxReturn : 82.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 53.125
Train_AverageReturn : 44.30434799194336
Train_StdReturn : 13.44048023223877
Train_MaxReturn : 80.0
Train_MinReturn : 30.0
Train_AverageEpLen : 44.30434782608695
Actor Loss : 480.0106201171875
Train_EnvstepsSoFar : 335242
TimeSinceStart : 332.0513548851013
Done logging...



********** Iteration 326 ************

Collecting data for eval...
Eval_AverageReturn : 46.44444274902344
Eval_StdReturn : 10.719775199890137
Eval_MaxReturn : 65.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 46.44444444444444
Train_AverageReturn : 44.60869598388672
Train_StdReturn : 11.389312744140625
Train_MaxReturn : 70.0
Train_MinReturn : 32.0
Train_AverageEpLen : 44.608695652173914
Actor Loss : 478.05108642578125
Train_EnvstepsSoFar : 336268
TimeSinceStart : 333.1838901042938
Done logging...



********** Iteration 327 ************

Collecting data for eval...
Eval_AverageReturn : 44.44444274902344
Eval_StdReturn : 11.898749351501465
Eval_MaxReturn : 64.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 44.44444444444444
Train_AverageReturn : 53.599998474121094
Train_StdReturn : 19.696191787719727
Train_MaxReturn : 100.0
Train_MinReturn : 29.0
Train_AverageEpLen : 53.6
Actor Loss : 567.8532104492188
Train_EnvstepsSoFar : 337340
TimeSinceStart : 333.9751048088074
Done logging...



********** Iteration 328 ************

Collecting data for eval...
Eval_AverageReturn : 42.099998474121094
Eval_StdReturn : 6.122908115386963
Eval_MaxReturn : 53.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 42.1
Train_AverageReturn : 54.894737243652344
Train_StdReturn : 20.27935218811035
Train_MaxReturn : 96.0
Train_MinReturn : 32.0
Train_AverageEpLen : 54.89473684210526
Actor Loss : 469.799560546875
Train_EnvstepsSoFar : 338383
TimeSinceStart : 335.2021770477295
Done logging...



********** Iteration 329 ************

Collecting data for eval...
Eval_AverageReturn : 50.625
Eval_StdReturn : 16.054107666015625
Eval_MaxReturn : 72.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 50.625
Train_AverageReturn : 50.0
Train_StdReturn : 15.139352798461914
Train_MaxReturn : 83.0
Train_MinReturn : 28.0
Train_AverageEpLen : 50.0
Actor Loss : 379.86968994140625
Train_EnvstepsSoFar : 339383
TimeSinceStart : 335.9451973438263
Done logging...



********** Iteration 330 ************

Collecting data for eval...
Eval_AverageReturn : 44.66666793823242
Eval_StdReturn : 11.585432052612305
Eval_MaxReturn : 64.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 44.666666666666664
Train_AverageReturn : 50.349998474121094
Train_StdReturn : 14.457783699035645
Train_MaxReturn : 85.0
Train_MinReturn : 31.0
Train_AverageEpLen : 50.35
Actor Loss : 354.05938720703125
Train_EnvstepsSoFar : 340390
TimeSinceStart : 336.7139263153076
Done logging...



********** Iteration 331 ************

Collecting data for eval...
Eval_AverageReturn : 46.0
Eval_StdReturn : 9.368979454040527
Eval_MaxReturn : 61.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 46.0
Train_AverageReturn : 48.0
Train_StdReturn : 12.63027286529541
Train_MaxReturn : 81.0
Train_MinReturn : 34.0
Train_AverageEpLen : 48.0
Actor Loss : 383.5417785644531
Train_EnvstepsSoFar : 341398
TimeSinceStart : 337.47824931144714
Done logging...



********** Iteration 332 ************

Collecting data for eval...
Eval_AverageReturn : 47.66666793823242
Eval_StdReturn : 13.848384857177734
Eval_MaxReturn : 75.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 47.666666666666664
Train_AverageReturn : 46.04545593261719
Train_StdReturn : 13.319422721862793
Train_MaxReturn : 85.0
Train_MinReturn : 28.0
Train_AverageEpLen : 46.04545454545455
Actor Loss : 490.12811279296875
Train_EnvstepsSoFar : 342411
TimeSinceStart : 338.2495837211609
Done logging...



********** Iteration 333 ************

Collecting data for eval...
Eval_AverageReturn : 54.875
Eval_StdReturn : 19.952678680419922
Eval_MaxReturn : 96.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 54.875
Train_AverageReturn : 60.38888931274414
Train_StdReturn : 29.760412216186523
Train_MaxReturn : 130.0
Train_MinReturn : 30.0
Train_AverageEpLen : 60.388888888888886
Actor Loss : 487.47442626953125
Train_EnvstepsSoFar : 343498
TimeSinceStart : 339.5236301422119
Done logging...



********** Iteration 334 ************

Collecting data for eval...
Eval_AverageReturn : 48.44444274902344
Eval_StdReturn : 11.393088340759277
Eval_MaxReturn : 66.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 48.44444444444444
Train_AverageReturn : 47.904762268066406
Train_StdReturn : 12.656278610229492
Train_MaxReturn : 70.0
Train_MinReturn : 32.0
Train_AverageEpLen : 47.904761904761905
Actor Loss : 479.732421875
Train_EnvstepsSoFar : 344504
TimeSinceStart : 340.28565979003906
Done logging...



********** Iteration 335 ************

Collecting data for eval...
Eval_AverageReturn : 52.75
Eval_StdReturn : 20.35159683227539
Eval_MaxReturn : 89.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 52.75
Train_AverageReturn : 49.33333206176758
Train_StdReturn : 17.28289222717285
Train_MaxReturn : 101.0
Train_MinReturn : 32.0
Train_AverageEpLen : 49.333333333333336
Actor Loss : 381.0142822265625
Train_EnvstepsSoFar : 345540
TimeSinceStart : 341.0664486885071
Done logging...



********** Iteration 336 ************

Collecting data for eval...
Eval_AverageReturn : 44.29999923706055
Eval_StdReturn : 14.574292182922363
Eval_MaxReturn : 80.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 44.3
Train_AverageReturn : 48.80952453613281
Train_StdReturn : 12.17186164855957
Train_MaxReturn : 74.0
Train_MinReturn : 28.0
Train_AverageEpLen : 48.80952380952381
Actor Loss : 423.95135498046875
Train_EnvstepsSoFar : 346565
TimeSinceStart : 341.8491439819336
Done logging...



********** Iteration 337 ************

Collecting data for eval...
Eval_AverageReturn : 39.272727966308594
Eval_StdReturn : 7.944018840789795
Eval_MaxReturn : 58.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 39.27272727272727
Train_AverageReturn : 47.818180084228516
Train_StdReturn : 13.49625015258789
Train_MaxReturn : 75.0
Train_MinReturn : 30.0
Train_AverageEpLen : 47.81818181818182
Actor Loss : 413.22186279296875
Train_EnvstepsSoFar : 347617
TimeSinceStart : 342.6484272480011
Done logging...



********** Iteration 338 ************

Collecting data for eval...
Eval_AverageReturn : 42.099998474121094
Eval_StdReturn : 7.660940170288086
Eval_MaxReturn : 57.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 42.1
Train_AverageReturn : 46.818180084228516
Train_StdReturn : 16.48590660095215
Train_MaxReturn : 91.0
Train_MinReturn : 29.0
Train_AverageEpLen : 46.81818181818182
Actor Loss : 395.89825439453125
Train_EnvstepsSoFar : 348647
TimeSinceStart : 343.85927987098694
Done logging...



********** Iteration 339 ************

Collecting data for eval...
Eval_AverageReturn : 44.88888931274414
Eval_StdReturn : 12.39573860168457
Eval_MaxReturn : 66.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 44.888888888888886
Train_AverageReturn : 42.08333206176758
Train_StdReturn : 11.736398696899414
Train_MaxReturn : 85.0
Train_MinReturn : 28.0
Train_AverageEpLen : 42.083333333333336
Actor Loss : 407.4007568359375
Train_EnvstepsSoFar : 349657
TimeSinceStart : 344.60882782936096
Done logging...



********** Iteration 340 ************

Collecting data for eval...
Eval_AverageReturn : 49.11111068725586
Eval_StdReturn : 15.242079734802246
Eval_MaxReturn : 74.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 49.111111111111114
Train_AverageReturn : 51.599998474121094
Train_StdReturn : 27.163209915161133
Train_MaxReturn : 148.0
Train_MinReturn : 31.0
Train_AverageEpLen : 51.6
Actor Loss : 436.0220642089844
Train_EnvstepsSoFar : 350689
TimeSinceStart : 345.40543031692505
Done logging...



********** Iteration 341 ************

Collecting data for eval...
Eval_AverageReturn : 45.88888931274414
Eval_StdReturn : 12.591394424438477
Eval_MaxReturn : 79.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 45.888888888888886
Train_AverageReturn : 48.0476188659668
Train_StdReturn : 19.357479095458984
Train_MaxReturn : 92.0
Train_MinReturn : 29.0
Train_AverageEpLen : 48.04761904761905
Actor Loss : 571.3665771484375
Train_EnvstepsSoFar : 351698
TimeSinceStart : 346.1681890487671
Done logging...



********** Iteration 342 ************

Collecting data for eval...
Eval_AverageReturn : 45.20000076293945
Eval_StdReturn : 13.098091125488281
Eval_MaxReturn : 72.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 45.2
Train_AverageReturn : 47.80952453613281
Train_StdReturn : 18.732755661010742
Train_MaxReturn : 93.0
Train_MinReturn : 28.0
Train_AverageEpLen : 47.80952380952381
Actor Loss : 454.9980773925781
Train_EnvstepsSoFar : 352702
TimeSinceStart : 346.9446790218353
Done logging...



********** Iteration 343 ************

Collecting data for eval...
Eval_AverageReturn : 52.25
Eval_StdReturn : 13.064743041992188
Eval_MaxReturn : 80.0
Eval_MinReturn : 41.0
Eval_AverageEpLen : 52.25
Train_AverageReturn : 59.64706039428711
Train_StdReturn : 29.609102249145508
Train_MaxReturn : 132.0
Train_MinReturn : 28.0
Train_AverageEpLen : 59.64705882352941
Actor Loss : 528.264892578125
Train_EnvstepsSoFar : 353716
TimeSinceStart : 347.71910095214844
Done logging...



********** Iteration 344 ************

Collecting data for eval...
Eval_AverageReturn : 39.45454406738281
Eval_StdReturn : 8.239192962646484
Eval_MaxReturn : 54.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 39.45454545454545
Train_AverageReturn : 43.66666793823242
Train_StdReturn : 15.082181930541992
Train_MaxReturn : 77.0
Train_MinReturn : 26.0
Train_AverageEpLen : 43.666666666666664
Actor Loss : 374.08642578125
Train_EnvstepsSoFar : 354764
TimeSinceStart : 348.84296226501465
Done logging...



********** Iteration 345 ************

Collecting data for eval...
Eval_AverageReturn : 52.25
Eval_StdReturn : 32.387306213378906
Eval_MaxReturn : 109.0
Eval_MinReturn : 25.0
Eval_AverageEpLen : 52.25
Train_AverageReturn : 45.59090805053711
Train_StdReturn : 15.990506172180176
Train_MaxReturn : 97.0
Train_MinReturn : 25.0
Train_AverageEpLen : 45.59090909090909
Actor Loss : 327.51910400390625
Train_EnvstepsSoFar : 355767
TimeSinceStart : 349.61134791374207
Done logging...



********** Iteration 346 ************

Collecting data for eval...
Eval_AverageReturn : 52.5
Eval_StdReturn : 10.977249145507812
Eval_MaxReturn : 67.0
Eval_MinReturn : 36.0
Eval_AverageEpLen : 52.5
Train_AverageReturn : 43.5
Train_StdReturn : 17.670597076416016
Train_MaxReturn : 104.0
Train_MinReturn : 28.0
Train_AverageEpLen : 43.5
Actor Loss : 520.1713256835938
Train_EnvstepsSoFar : 356811
TimeSinceStart : 350.7044620513916
Done logging...



********** Iteration 347 ************

Collecting data for eval...
Eval_AverageReturn : 53.375
Eval_StdReturn : 15.337352752685547
Eval_MaxReturn : 76.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 53.375
Train_AverageReturn : 48.19047546386719
Train_StdReturn : 21.351076126098633
Train_MaxReturn : 114.0
Train_MinReturn : 26.0
Train_AverageEpLen : 48.19047619047619
Actor Loss : 366.2727966308594
Train_EnvstepsSoFar : 357823
TimeSinceStart : 351.4881966114044
Done logging...



********** Iteration 348 ************

Collecting data for eval...
Eval_AverageReturn : 43.599998474121094
Eval_StdReturn : 10.17054557800293
Eval_MaxReturn : 61.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 43.6
Train_AverageReturn : 51.04999923706055
Train_StdReturn : 15.679525375366211
Train_MaxReturn : 84.0
Train_MinReturn : 32.0
Train_AverageEpLen : 51.05
Actor Loss : 333.4923095703125
Train_EnvstepsSoFar : 358844
TimeSinceStart : 352.28486466407776
Done logging...



********** Iteration 349 ************

Collecting data for eval...
Eval_AverageReturn : 41.20000076293945
Eval_StdReturn : 12.204916954040527
Eval_MaxReturn : 72.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 41.2
Train_AverageReturn : 51.29999923706055
Train_StdReturn : 21.43618392944336
Train_MaxReturn : 107.0
Train_MinReturn : 28.0
Train_AverageEpLen : 51.3
Actor Loss : 407.859130859375
Train_EnvstepsSoFar : 359870
TimeSinceStart : 353.08052134513855
Done logging...



********** Iteration 350 ************

Collecting data for eval...
Eval_AverageReturn : 60.14285659790039
Eval_StdReturn : 32.10887145996094
Eval_MaxReturn : 126.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 60.142857142857146
Train_AverageReturn : 46.6363639831543
Train_StdReturn : 22.153484344482422
Train_MaxReturn : 126.0
Train_MinReturn : 29.0
Train_AverageEpLen : 46.63636363636363
Actor Loss : 320.709716796875
Train_EnvstepsSoFar : 360896
TimeSinceStart : 353.8603322505951
Done logging...



********** Iteration 351 ************

Collecting data for eval...
Eval_AverageReturn : 50.25
Eval_StdReturn : 23.736839294433594
Eval_MaxReturn : 99.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 50.25
Train_AverageReturn : 45.90909194946289
Train_StdReturn : 13.88232707977295
Train_MaxReturn : 81.0
Train_MinReturn : 30.0
Train_AverageEpLen : 45.90909090909091
Actor Loss : 310.2738952636719
Train_EnvstepsSoFar : 361906
TimeSinceStart : 354.62141966819763
Done logging...



********** Iteration 352 ************

Collecting data for eval...
Eval_AverageReturn : 47.33333206176758
Eval_StdReturn : 12.849556922912598
Eval_MaxReturn : 76.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 47.333333333333336
Train_AverageReturn : 44.30434799194336
Train_StdReturn : 16.969114303588867
Train_MaxReturn : 96.0
Train_MinReturn : 29.0
Train_AverageEpLen : 44.30434782608695
Actor Loss : 416.41534423828125
Train_EnvstepsSoFar : 362925
TimeSinceStart : 355.41381573677063
Done logging...



********** Iteration 353 ************

Collecting data for eval...
Eval_AverageReturn : 59.71428680419922
Eval_StdReturn : 13.8328218460083
Eval_MaxReturn : 74.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 59.714285714285715
Train_AverageReturn : 49.71428680419922
Train_StdReturn : 15.486223220825195
Train_MaxReturn : 101.0
Train_MinReturn : 31.0
Train_AverageEpLen : 49.714285714285715
Actor Loss : 418.3330078125
Train_EnvstepsSoFar : 363969
TimeSinceStart : 356.2269546985626
Done logging...



********** Iteration 354 ************

Collecting data for eval...
Eval_AverageReturn : 50.0
Eval_StdReturn : 8.845903396606445
Eval_MaxReturn : 62.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 50.0
Train_AverageReturn : 44.260868072509766
Train_StdReturn : 10.334482192993164
Train_MaxReturn : 63.0
Train_MinReturn : 29.0
Train_AverageEpLen : 44.26086956521739
Actor Loss : 410.69122314453125
Train_EnvstepsSoFar : 364987
TimeSinceStart : 357.01854157447815
Done logging...



********** Iteration 355 ************

Collecting data for eval...
Eval_AverageReturn : 43.099998474121094
Eval_StdReturn : 9.137286186218262
Eval_MaxReturn : 66.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 43.1
Train_AverageReturn : 59.64706039428711
Train_StdReturn : 22.402576446533203
Train_MaxReturn : 122.0
Train_MinReturn : 34.0
Train_AverageEpLen : 59.64705882352941
Actor Loss : 488.820068359375
Train_EnvstepsSoFar : 366001
TimeSinceStart : 358.2144055366516
Done logging...



********** Iteration 356 ************

Collecting data for eval...
Eval_AverageReturn : 46.0
Eval_StdReturn : 9.752492904663086
Eval_MaxReturn : 69.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 46.0
Train_AverageReturn : 50.380950927734375
Train_StdReturn : 11.874246597290039
Train_MaxReturn : 83.0
Train_MinReturn : 34.0
Train_AverageEpLen : 50.38095238095238
Actor Loss : 515.8359375
Train_EnvstepsSoFar : 367059
TimeSinceStart : 359.00557231903076
Done logging...



********** Iteration 357 ************

Collecting data for eval...
Eval_AverageReturn : 44.70000076293945
Eval_StdReturn : 11.550324440002441
Eval_MaxReturn : 65.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 44.7
Train_AverageReturn : 46.45454406738281
Train_StdReturn : 7.918489933013916
Train_MaxReturn : 59.0
Train_MinReturn : 30.0
Train_AverageEpLen : 46.45454545454545
Actor Loss : 534.6129150390625
Train_EnvstepsSoFar : 368081
TimeSinceStart : 359.80221462249756
Done logging...



********** Iteration 358 ************

Collecting data for eval...
Eval_AverageReturn : 48.22222137451172
Eval_StdReturn : 10.041887283325195
Eval_MaxReturn : 65.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 48.22222222222222
Train_AverageReturn : 52.150001525878906
Train_StdReturn : 14.990914344787598
Train_MaxReturn : 86.0
Train_MinReturn : 32.0
Train_AverageEpLen : 52.15
Actor Loss : 527.85498046875
Train_EnvstepsSoFar : 369124
TimeSinceStart : 360.6005446910858
Done logging...



********** Iteration 359 ************

Collecting data for eval...
Eval_AverageReturn : 49.33333206176758
Eval_StdReturn : 11.284207344055176
Eval_MaxReturn : 65.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 49.333333333333336
Train_AverageReturn : 54.78947448730469
Train_StdReturn : 15.66618537902832
Train_MaxReturn : 89.0
Train_MinReturn : 32.0
Train_AverageEpLen : 54.78947368421053
Actor Loss : 500.755126953125
Train_EnvstepsSoFar : 370165
TimeSinceStart : 361.39534425735474
Done logging...



********** Iteration 360 ************

Collecting data for eval...
Eval_AverageReturn : 46.22222137451172
Eval_StdReturn : 10.538582801818848
Eval_MaxReturn : 65.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 46.22222222222222
Train_AverageReturn : 57.38888931274414
Train_StdReturn : 14.670979499816895
Train_MaxReturn : 98.0
Train_MinReturn : 41.0
Train_AverageEpLen : 57.388888888888886
Actor Loss : 587.5889892578125
Train_EnvstepsSoFar : 371198
TimeSinceStart : 362.17281889915466
Done logging...



********** Iteration 361 ************

Collecting data for eval...
Eval_AverageReturn : 50.22222137451172
Eval_StdReturn : 5.513171672821045
Eval_MaxReturn : 59.0
Eval_MinReturn : 42.0
Eval_AverageEpLen : 50.22222222222222
Train_AverageReturn : 58.27777862548828
Train_StdReturn : 18.81136131286621
Train_MaxReturn : 110.0
Train_MinReturn : 32.0
Train_AverageEpLen : 58.27777777777778
Actor Loss : 636.5342407226562
Train_EnvstepsSoFar : 372247
TimeSinceStart : 362.98975467681885
Done logging...



********** Iteration 362 ************

Collecting data for eval...
Eval_AverageReturn : 57.28571319580078
Eval_StdReturn : 8.564282417297363
Eval_MaxReturn : 72.0
Eval_MinReturn : 44.0
Eval_AverageEpLen : 57.285714285714285
Train_AverageReturn : 54.842105865478516
Train_StdReturn : 17.150304794311523
Train_MaxReturn : 90.0
Train_MinReturn : 32.0
Train_AverageEpLen : 54.8421052631579
Actor Loss : 782.9310913085938
Train_EnvstepsSoFar : 373289
TimeSinceStart : 363.7685089111328
Done logging...



********** Iteration 363 ************

Collecting data for eval...
Eval_AverageReturn : 68.5
Eval_StdReturn : 15.649813652038574
Eval_MaxReturn : 103.0
Eval_MinReturn : 59.0
Eval_AverageEpLen : 68.5
Train_AverageReturn : 62.05882263183594
Train_StdReturn : 28.517221450805664
Train_MaxReturn : 148.0
Train_MinReturn : 36.0
Train_AverageEpLen : 62.05882352941177
Actor Loss : 691.228759765625
Train_EnvstepsSoFar : 374344
TimeSinceStart : 364.99182510375977
Done logging...



********** Iteration 364 ************

Collecting data for eval...
Eval_AverageReturn : 57.375
Eval_StdReturn : 15.723688125610352
Eval_MaxReturn : 80.0
Eval_MinReturn : 36.0
Eval_AverageEpLen : 57.375
Train_AverageReturn : 55.72222137451172
Train_StdReturn : 15.065802574157715
Train_MaxReturn : 85.0
Train_MinReturn : 30.0
Train_AverageEpLen : 55.72222222222222
Actor Loss : 883.561767578125
Train_EnvstepsSoFar : 375347
TimeSinceStart : 365.7848014831543
Done logging...



********** Iteration 365 ************

Collecting data for eval...
Eval_AverageReturn : 55.0
Eval_StdReturn : 12.062337875366211
Eval_MaxReturn : 77.0
Eval_MinReturn : 40.0
Eval_AverageEpLen : 55.0
Train_AverageReturn : 83.15384674072266
Train_StdReturn : 37.036048889160156
Train_MaxReturn : 181.0
Train_MinReturn : 41.0
Train_AverageEpLen : 83.15384615384616
Actor Loss : 925.8408203125
Train_EnvstepsSoFar : 376428
TimeSinceStart : 367.00243282318115
Done logging...



********** Iteration 366 ************

Collecting data for eval...
Eval_AverageReturn : 65.57142639160156
Eval_StdReturn : 17.26976776123047
Eval_MaxReturn : 99.0
Eval_MinReturn : 43.0
Eval_AverageEpLen : 65.57142857142857
Train_AverageReturn : 67.86666870117188
Train_StdReturn : 23.246124267578125
Train_MaxReturn : 110.0
Train_MinReturn : 38.0
Train_AverageEpLen : 67.86666666666666
Actor Loss : 889.4827880859375
Train_EnvstepsSoFar : 377446
TimeSinceStart : 367.78977131843567
Done logging...



********** Iteration 367 ************

Collecting data for eval...
Eval_AverageReturn : 60.0
Eval_StdReturn : 8.502100944519043
Eval_MaxReturn : 77.0
Eval_MinReturn : 50.0
Eval_AverageEpLen : 60.0
Train_AverageReturn : 60.882354736328125
Train_StdReturn : 14.93075180053711
Train_MaxReturn : 101.0
Train_MinReturn : 39.0
Train_AverageEpLen : 60.88235294117647
Actor Loss : 764.2835693359375
Train_EnvstepsSoFar : 378481
TimeSinceStart : 368.6666257381439
Done logging...



********** Iteration 368 ************

Collecting data for eval...
Eval_AverageReturn : 60.85714340209961
Eval_StdReturn : 15.596963882446289
Eval_MaxReturn : 86.0
Eval_MinReturn : 39.0
Eval_AverageEpLen : 60.857142857142854
Train_AverageReturn : 63.9375
Train_StdReturn : 21.22930908203125
Train_MaxReturn : 109.0
Train_MinReturn : 39.0
Train_AverageEpLen : 63.9375
Actor Loss : 821.9573974609375
Train_EnvstepsSoFar : 379504
TimeSinceStart : 369.44797587394714
Done logging...



********** Iteration 369 ************

Collecting data for eval...
Eval_AverageReturn : 59.14285659790039
Eval_StdReturn : 19.393877029418945
Eval_MaxReturn : 90.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 59.142857142857146
Train_AverageReturn : 77.53845977783203
Train_StdReturn : 19.369346618652344
Train_MaxReturn : 119.0
Train_MinReturn : 47.0
Train_AverageEpLen : 77.53846153846153
Actor Loss : 1341.4227294921875
Train_EnvstepsSoFar : 380512
TimeSinceStart : 370.2254447937012
Done logging...



********** Iteration 370 ************

Collecting data for eval...
Eval_AverageReturn : 62.71428680419922
Eval_StdReturn : 17.910207748413086
Eval_MaxReturn : 95.0
Eval_MinReturn : 42.0
Eval_AverageEpLen : 62.714285714285715
Train_AverageReturn : 60.35293960571289
Train_StdReturn : 14.982110977172852
Train_MaxReturn : 85.0
Train_MinReturn : 38.0
Train_AverageEpLen : 60.35294117647059
Actor Loss : 752.032958984375
Train_EnvstepsSoFar : 381538
TimeSinceStart : 371.0263624191284
Done logging...



********** Iteration 371 ************

Collecting data for eval...
Eval_AverageReturn : 63.42856979370117
Eval_StdReturn : 15.918158531188965
Eval_MaxReturn : 83.0
Eval_MinReturn : 44.0
Eval_AverageEpLen : 63.42857142857143
Train_AverageReturn : 62.875
Train_StdReturn : 18.096529006958008
Train_MaxReturn : 112.0
Train_MinReturn : 40.0
Train_AverageEpLen : 62.875
Actor Loss : 819.9545288085938
Train_EnvstepsSoFar : 382544
TimeSinceStart : 371.8063380718231
Done logging...



********** Iteration 372 ************

Collecting data for eval...
Eval_AverageReturn : 58.85714340209961
Eval_StdReturn : 16.330764770507812
Eval_MaxReturn : 91.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 58.857142857142854
Train_AverageReturn : 61.52941131591797
Train_StdReturn : 16.539142608642578
Train_MaxReturn : 107.0
Train_MinReturn : 41.0
Train_AverageEpLen : 61.529411764705884
Actor Loss : 924.3485107421875
Train_EnvstepsSoFar : 383590
TimeSinceStart : 372.82306957244873
Done logging...



********** Iteration 373 ************

Collecting data for eval...
Eval_AverageReturn : 61.28571319580078
Eval_StdReturn : 11.208597183227539
Eval_MaxReturn : 78.0
Eval_MinReturn : 39.0
Eval_AverageEpLen : 61.285714285714285
Train_AverageReturn : 58.27777862548828
Train_StdReturn : 11.179373741149902
Train_MaxReturn : 86.0
Train_MinReturn : 41.0
Train_AverageEpLen : 58.27777777777778
Actor Loss : 747.861328125
Train_EnvstepsSoFar : 384639
TimeSinceStart : 373.6126353740692
Done logging...



********** Iteration 374 ************

Collecting data for eval...
Eval_AverageReturn : 68.33333587646484
Eval_StdReturn : 19.58457374572754
Eval_MaxReturn : 107.0
Eval_MinReturn : 46.0
Eval_AverageEpLen : 68.33333333333333
Train_AverageReturn : 68.06666564941406
Train_StdReturn : 30.415931701660156
Train_MaxReturn : 147.0
Train_MinReturn : 39.0
Train_AverageEpLen : 68.06666666666666
Actor Loss : 1117.281005859375
Train_EnvstepsSoFar : 385660
TimeSinceStart : 374.3879749774933
Done logging...



********** Iteration 375 ************

Collecting data for eval...
Eval_AverageReturn : 66.66666412353516
Eval_StdReturn : 16.244657516479492
Eval_MaxReturn : 83.0
Eval_MinReturn : 44.0
Eval_AverageEpLen : 66.66666666666667
Train_AverageReturn : 72.64286041259766
Train_StdReturn : 25.552766799926758
Train_MaxReturn : 143.0
Train_MinReturn : 46.0
Train_AverageEpLen : 72.64285714285714
Actor Loss : 929.4900512695312
Train_EnvstepsSoFar : 386677
TimeSinceStart : 375.14786076545715
Done logging...



********** Iteration 376 ************

Collecting data for eval...
Eval_AverageReturn : 72.0
Eval_StdReturn : 19.561866760253906
Eval_MaxReturn : 99.0
Eval_MinReturn : 43.0
Eval_AverageEpLen : 72.0
Train_AverageReturn : 57.88888931274414
Train_StdReturn : 10.115384101867676
Train_MaxReturn : 74.0
Train_MinReturn : 40.0
Train_AverageEpLen : 57.888888888888886
Actor Loss : 786.3482666015625
Train_EnvstepsSoFar : 387719
TimeSinceStart : 375.9446511268616
Done logging...



********** Iteration 377 ************

Collecting data for eval...
Eval_AverageReturn : 70.5
Eval_StdReturn : 21.4844913482666
Eval_MaxReturn : 114.0
Eval_MinReturn : 47.0
Eval_AverageEpLen : 70.5
Train_AverageReturn : 68.73332977294922
Train_StdReturn : 25.519840240478516
Train_MaxReturn : 131.0
Train_MinReturn : 44.0
Train_AverageEpLen : 68.73333333333333
Actor Loss : 1163.880615234375
Train_EnvstepsSoFar : 388750
TimeSinceStart : 377.1416687965393
Done logging...



********** Iteration 378 ************

Collecting data for eval...
Eval_AverageReturn : 54.875
Eval_StdReturn : 11.274279594421387
Eval_MaxReturn : 77.0
Eval_MinReturn : 43.0
Eval_AverageEpLen : 54.875
Train_AverageReturn : 68.53333282470703
Train_StdReturn : 12.087825775146484
Train_MaxReturn : 93.0
Train_MinReturn : 51.0
Train_AverageEpLen : 68.53333333333333
Actor Loss : 762.3641357421875
Train_EnvstepsSoFar : 389778
TimeSinceStart : 377.94866704940796
Done logging...



********** Iteration 379 ************

Collecting data for eval...
Eval_AverageReturn : 55.25
Eval_StdReturn : 6.796138763427734
Eval_MaxReturn : 61.0
Eval_MinReturn : 41.0
Eval_AverageEpLen : 55.25
Train_AverageReturn : 68.73332977294922
Train_StdReturn : 15.476720809936523
Train_MaxReturn : 94.0
Train_MinReturn : 45.0
Train_AverageEpLen : 68.73333333333333
Actor Loss : 1119.5992431640625
Train_EnvstepsSoFar : 390809
TimeSinceStart : 378.7605457305908
Done logging...



********** Iteration 380 ************

Collecting data for eval...
Eval_AverageReturn : 61.42856979370117
Eval_StdReturn : 11.499777793884277
Eval_MaxReturn : 78.0
Eval_MinReturn : 44.0
Eval_AverageEpLen : 61.42857142857143
Train_AverageReturn : 65.0
Train_StdReturn : 27.76913833618164
Train_MaxReturn : 149.0
Train_MinReturn : 36.0
Train_AverageEpLen : 65.0
Actor Loss : 929.7861938476562
Train_EnvstepsSoFar : 391849
TimeSinceStart : 379.55062437057495
Done logging...



********** Iteration 381 ************

Collecting data for eval...
Eval_AverageReturn : 65.42857360839844
Eval_StdReturn : 19.711179733276367
Eval_MaxReturn : 101.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 65.42857142857143
Train_AverageReturn : 71.19999694824219
Train_StdReturn : 19.18402099609375
Train_MaxReturn : 109.0
Train_MinReturn : 37.0
Train_AverageEpLen : 71.2
Actor Loss : 859.469970703125
Train_EnvstepsSoFar : 392917
TimeSinceStart : 380.5227837562561
Done logging...



********** Iteration 382 ************

Collecting data for eval...
Eval_AverageReturn : 70.33333587646484
Eval_StdReturn : 25.759571075439453
Eval_MaxReturn : 115.0
Eval_MinReturn : 47.0
Eval_AverageEpLen : 70.33333333333333
Train_AverageReturn : 55.105262756347656
Train_StdReturn : 9.278695106506348
Train_MaxReturn : 74.0
Train_MinReturn : 36.0
Train_AverageEpLen : 55.10526315789474
Actor Loss : 574.537353515625
Train_EnvstepsSoFar : 393964
TimeSinceStart : 381.3160741329193
Done logging...



********** Iteration 383 ************

Collecting data for eval...
Eval_AverageReturn : 53.125
Eval_StdReturn : 18.14826011657715
Eval_MaxReturn : 86.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 53.125
Train_AverageReturn : 59.64706039428711
Train_StdReturn : 23.366493225097656
Train_MaxReturn : 125.0
Train_MinReturn : 32.0
Train_AverageEpLen : 59.64705882352941
Actor Loss : 895.7875366210938
Train_EnvstepsSoFar : 394978
TimeSinceStart : 382.36826372146606
Done logging...



********** Iteration 384 ************

Collecting data for eval...
Eval_AverageReturn : 51.375
Eval_StdReturn : 8.214887619018555
Eval_MaxReturn : 67.0
Eval_MinReturn : 43.0
Eval_AverageEpLen : 51.375
Train_AverageReturn : 60.52941131591797
Train_StdReturn : 20.551563262939453
Train_MaxReturn : 107.0
Train_MinReturn : 34.0
Train_AverageEpLen : 60.529411764705884
Actor Loss : 653.8548583984375
Train_EnvstepsSoFar : 396007
TimeSinceStart : 383.16005873680115
Done logging...



********** Iteration 385 ************

Collecting data for eval...
Eval_AverageReturn : 51.375
Eval_StdReturn : 11.10109806060791
Eval_MaxReturn : 77.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 51.375
Train_AverageReturn : 66.73332977294922
Train_StdReturn : 24.553251266479492
Train_MaxReturn : 144.0
Train_MinReturn : 40.0
Train_AverageEpLen : 66.73333333333333
Actor Loss : 944.045166015625
Train_EnvstepsSoFar : 397008
TimeSinceStart : 383.92976093292236
Done logging...



********** Iteration 386 ************

Collecting data for eval...
Eval_AverageReturn : 51.33333206176758
Eval_StdReturn : 18.427032470703125
Eval_MaxReturn : 102.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 51.333333333333336
Train_AverageReturn : 55.61111068725586
Train_StdReturn : 14.107282638549805
Train_MaxReturn : 93.0
Train_MinReturn : 34.0
Train_AverageEpLen : 55.611111111111114
Actor Loss : 909.9169921875
Train_EnvstepsSoFar : 398009
TimeSinceStart : 385.1310760974884
Done logging...



********** Iteration 387 ************

Collecting data for eval...
Eval_AverageReturn : 53.125
Eval_StdReturn : 17.744277954101562
Eval_MaxReturn : 88.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 53.125
Train_AverageReturn : 54.26315689086914
Train_StdReturn : 14.304368019104004
Train_MaxReturn : 88.0
Train_MinReturn : 34.0
Train_AverageEpLen : 54.26315789473684
Actor Loss : 444.76898193359375
Train_EnvstepsSoFar : 399040
TimeSinceStart : 385.9133598804474
Done logging...



********** Iteration 388 ************

Collecting data for eval...
Eval_AverageReturn : 57.28571319580078
Eval_StdReturn : 15.79976749420166
Eval_MaxReturn : 93.0
Eval_MinReturn : 40.0
Eval_AverageEpLen : 57.285714285714285
Train_AverageReturn : 59.882354736328125
Train_StdReturn : 17.90787696838379
Train_MaxReturn : 105.0
Train_MinReturn : 39.0
Train_AverageEpLen : 59.88235294117647
Actor Loss : 750.610107421875
Train_EnvstepsSoFar : 400058
TimeSinceStart : 386.6837725639343
Done logging...



********** Iteration 389 ************

Collecting data for eval...
Eval_AverageReturn : 48.55555725097656
Eval_StdReturn : 13.483414649963379
Eval_MaxReturn : 74.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 48.55555555555556
Train_AverageReturn : 49.761905670166016
Train_StdReturn : 11.413880348205566
Train_MaxReturn : 73.0
Train_MinReturn : 34.0
Train_AverageEpLen : 49.76190476190476
Actor Loss : 528.6549682617188
Train_EnvstepsSoFar : 401103
TimeSinceStart : 387.4901490211487
Done logging...



********** Iteration 390 ************

Collecting data for eval...
Eval_AverageReturn : 68.28571319580078
Eval_StdReturn : 17.33464241027832
Eval_MaxReturn : 96.0
Eval_MinReturn : 51.0
Eval_AverageEpLen : 68.28571428571429
Train_AverageReturn : 49.57143020629883
Train_StdReturn : 12.992934226989746
Train_MaxReturn : 78.0
Train_MinReturn : 33.0
Train_AverageEpLen : 49.57142857142857
Actor Loss : 467.395263671875
Train_EnvstepsSoFar : 402144
TimeSinceStart : 388.31480836868286
Done logging...



********** Iteration 391 ************

Collecting data for eval...
Eval_AverageReturn : 54.25
Eval_StdReturn : 22.725261688232422
Eval_MaxReturn : 108.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 54.25
Train_AverageReturn : 58.77777862548828
Train_StdReturn : 16.827739715576172
Train_MaxReturn : 98.0
Train_MinReturn : 37.0
Train_AverageEpLen : 58.77777777777778
Actor Loss : 516.7029418945312
Train_EnvstepsSoFar : 403202
TimeSinceStart : 389.11612725257874
Done logging...



********** Iteration 392 ************

Collecting data for eval...
Eval_AverageReturn : 55.125
Eval_StdReturn : 9.739577293395996
Eval_MaxReturn : 73.0
Eval_MinReturn : 45.0
Eval_AverageEpLen : 55.125
Train_AverageReturn : 59.05882263183594
Train_StdReturn : 14.56615924835205
Train_MaxReturn : 92.0
Train_MinReturn : 37.0
Train_AverageEpLen : 59.05882352941177
Actor Loss : 432.4400634765625
Train_EnvstepsSoFar : 404206
TimeSinceStart : 389.9016742706299
Done logging...



********** Iteration 393 ************

Collecting data for eval...
Eval_AverageReturn : 50.66666793823242
Eval_StdReturn : 21.380157470703125
Eval_MaxReturn : 105.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 50.666666666666664
Train_AverageReturn : 51.650001525878906
Train_StdReturn : 17.71235466003418
Train_MaxReturn : 98.0
Train_MinReturn : 32.0
Train_AverageEpLen : 51.65
Actor Loss : 505.9947814941406
Train_EnvstepsSoFar : 405239
TimeSinceStart : 390.8610441684723
Done logging...



********** Iteration 394 ************

Collecting data for eval...
Eval_AverageReturn : 50.875
Eval_StdReturn : 8.192030906677246
Eval_MaxReturn : 66.0
Eval_MinReturn : 40.0
Eval_AverageEpLen : 50.875
Train_AverageReturn : 54.6315803527832
Train_StdReturn : 20.724281311035156
Train_MaxReturn : 116.0
Train_MinReturn : 35.0
Train_AverageEpLen : 54.63157894736842
Actor Loss : 525.247314453125
Train_EnvstepsSoFar : 406277
TimeSinceStart : 391.6671214103699
Done logging...



********** Iteration 395 ************

Collecting data for eval...
Eval_AverageReturn : 63.0
Eval_StdReturn : 9.211793899536133
Eval_MaxReturn : 75.0
Eval_MinReturn : 48.0
Eval_AverageEpLen : 63.0
Train_AverageReturn : 50.599998474121094
Train_StdReturn : 11.871814727783203
Train_MaxReturn : 84.0
Train_MinReturn : 33.0
Train_AverageEpLen : 50.6
Actor Loss : 426.46759033203125
Train_EnvstepsSoFar : 407289
TimeSinceStart : 392.46143794059753
Done logging...



********** Iteration 396 ************

Collecting data for eval...
Eval_AverageReturn : 43.900001525878906
Eval_StdReturn : 8.190848350524902
Eval_MaxReturn : 63.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 43.9
Train_AverageReturn : 43.91304397583008
Train_StdReturn : 10.12922191619873
Train_MaxReturn : 70.0
Train_MinReturn : 32.0
Train_AverageEpLen : 43.91304347826087
Actor Loss : 281.1295166015625
Train_EnvstepsSoFar : 408299
TimeSinceStart : 393.26826763153076
Done logging...



********** Iteration 397 ************

Collecting data for eval...
Eval_AverageReturn : 57.85714340209961
Eval_StdReturn : 27.126312255859375
Eval_MaxReturn : 108.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 57.857142857142854
Train_AverageReturn : 54.05263137817383
Train_StdReturn : 15.059439659118652
Train_MaxReturn : 84.0
Train_MinReturn : 36.0
Train_AverageEpLen : 54.05263157894737
Actor Loss : 236.61691284179688
Train_EnvstepsSoFar : 409326
TimeSinceStart : 394.04528188705444
Done logging...



********** Iteration 398 ************

Collecting data for eval...
Eval_AverageReturn : 50.5
Eval_StdReturn : 16.147754669189453
Eval_MaxReturn : 85.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 50.5
Train_AverageReturn : 53.29999923706055
Train_StdReturn : 16.309812545776367
Train_MaxReturn : 83.0
Train_MinReturn : 29.0
Train_AverageEpLen : 53.3
Actor Loss : 456.4326477050781
Train_EnvstepsSoFar : 410392
TimeSinceStart : 394.84061098098755
Done logging...



********** Iteration 399 ************

Collecting data for eval...
Eval_AverageReturn : 46.5
Eval_StdReturn : 13.009612083435059
Eval_MaxReturn : 77.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 46.5
Train_AverageReturn : 44.30434799194336
Train_StdReturn : 13.083127975463867
Train_MaxReturn : 80.0
Train_MinReturn : 31.0
Train_AverageEpLen : 44.30434782608695
Actor Loss : 267.8834533691406
Train_EnvstepsSoFar : 411411
TimeSinceStart : 395.65091729164124
Done logging...



********** Iteration 400 ************

Collecting data for eval...
Eval_AverageReturn : 47.66666793823242
Eval_StdReturn : 18.384777069091797
Eval_MaxReturn : 92.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 47.666666666666664
Train_AverageReturn : 44.260868072509766
Train_StdReturn : 11.84030532836914
Train_MaxReturn : 73.0
Train_MinReturn : 30.0
Train_AverageEpLen : 44.26086956521739
Actor Loss : 287.75286865234375
Train_EnvstepsSoFar : 412429
TimeSinceStart : 396.4515585899353
Done logging...



********** Iteration 401 ************

Collecting data for eval...
Eval_AverageReturn : 49.55555725097656
Eval_StdReturn : 19.2648868560791
Eval_MaxReturn : 91.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 49.55555555555556
Train_AverageReturn : 53.26315689086914
Train_StdReturn : 28.147809982299805
Train_MaxReturn : 152.0
Train_MinReturn : 30.0
Train_AverageEpLen : 53.26315789473684
Actor Loss : 391.6721496582031
Train_EnvstepsSoFar : 413441
TimeSinceStart : 397.26086688041687
Done logging...



********** Iteration 402 ************

Collecting data for eval...
Eval_AverageReturn : 58.71428680419922
Eval_StdReturn : 32.16792678833008
Eval_MaxReturn : 128.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 58.714285714285715
Train_AverageReturn : 44.130435943603516
Train_StdReturn : 9.728060722351074
Train_MaxReturn : 76.0
Train_MinReturn : 33.0
Train_AverageEpLen : 44.130434782608695
Actor Loss : 366.79119873046875
Train_EnvstepsSoFar : 414456
TimeSinceStart : 398.0468499660492
Done logging...



********** Iteration 403 ************

Collecting data for eval...
Eval_AverageReturn : 50.22222137451172
Eval_StdReturn : 18.383434295654297
Eval_MaxReturn : 82.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 50.22222222222222
Train_AverageReturn : 48.904762268066406
Train_StdReturn : 15.27807331085205
Train_MaxReturn : 96.0
Train_MinReturn : 35.0
Train_AverageEpLen : 48.904761904761905
Actor Loss : 359.857666015625
Train_EnvstepsSoFar : 415483
TimeSinceStart : 398.84519505500793
Done logging...



********** Iteration 404 ************

Collecting data for eval...
Eval_AverageReturn : 40.70000076293945
Eval_StdReturn : 10.354226112365723
Eval_MaxReturn : 62.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 40.7
Train_AverageReturn : 47.80952453613281
Train_StdReturn : 13.297401428222656
Train_MaxReturn : 78.0
Train_MinReturn : 32.0
Train_AverageEpLen : 47.80952380952381
Actor Loss : 291.67156982421875
Train_EnvstepsSoFar : 416487
TimeSinceStart : 399.6178779602051
Done logging...



********** Iteration 405 ************

Collecting data for eval...
Eval_AverageReturn : 51.375
Eval_StdReturn : 14.123893737792969
Eval_MaxReturn : 84.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 51.375
Train_AverageReturn : 59.17647171020508
Train_StdReturn : 29.476282119750977
Train_MaxReturn : 134.0
Train_MinReturn : 34.0
Train_AverageEpLen : 59.1764705882353
Actor Loss : 608.1314697265625
Train_EnvstepsSoFar : 417493
TimeSinceStart : 400.40146231651306
Done logging...



********** Iteration 406 ************

Collecting data for eval...
Eval_AverageReturn : 46.11111068725586
Eval_StdReturn : 11.0799560546875
Eval_MaxReturn : 70.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 46.111111111111114
Train_AverageReturn : 42.625
Train_StdReturn : 13.297282218933105
Train_MaxReturn : 75.0
Train_MinReturn : 28.0
Train_AverageEpLen : 42.625
Actor Loss : 172.84487915039062
Train_EnvstepsSoFar : 418516
TimeSinceStart : 401.1939935684204
Done logging...



********** Iteration 407 ************

Collecting data for eval...
Eval_AverageReturn : 50.88888931274414
Eval_StdReturn : 20.206953048706055
Eval_MaxReturn : 86.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 50.888888888888886
Train_AverageReturn : 56.38888931274414
Train_StdReturn : 32.43821334838867
Train_MaxReturn : 171.0
Train_MinReturn : 30.0
Train_AverageEpLen : 56.388888888888886
Actor Loss : 392.4877624511719
Train_EnvstepsSoFar : 419531
TimeSinceStart : 401.9952576160431
Done logging...



********** Iteration 408 ************

Collecting data for eval...
Eval_AverageReturn : 49.0
Eval_StdReturn : 19.731531143188477
Eval_MaxReturn : 94.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 49.0
Train_AverageReturn : 48.9523811340332
Train_StdReturn : 22.455196380615234
Train_MaxReturn : 114.0
Train_MinReturn : 28.0
Train_AverageEpLen : 48.95238095238095
Actor Loss : 350.3717041015625
Train_EnvstepsSoFar : 420559
TimeSinceStart : 402.781715631485
Done logging...



********** Iteration 409 ************

Collecting data for eval...
Eval_AverageReturn : 40.20000076293945
Eval_StdReturn : 7.6131463050842285
Eval_MaxReturn : 52.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 40.2
Train_AverageReturn : 44.21739196777344
Train_StdReturn : 23.5093994140625
Train_MaxReturn : 136.0
Train_MinReturn : 27.0
Train_AverageEpLen : 44.21739130434783
Actor Loss : 287.79534912109375
Train_EnvstepsSoFar : 421576
TimeSinceStart : 403.557119846344
Done logging...



********** Iteration 410 ************

Collecting data for eval...
Eval_AverageReturn : 60.0
Eval_StdReturn : 30.326791763305664
Eval_MaxReturn : 115.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 60.0
Train_AverageReturn : 56.31578826904297
Train_StdReturn : 27.235912322998047
Train_MaxReturn : 137.0
Train_MinReturn : 28.0
Train_AverageEpLen : 56.31578947368421
Actor Loss : 365.693603515625
Train_EnvstepsSoFar : 422646
TimeSinceStart : 404.37436389923096
Done logging...



********** Iteration 411 ************

Collecting data for eval...
Eval_AverageReturn : 42.599998474121094
Eval_StdReturn : 12.199999809265137
Eval_MaxReturn : 67.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 42.6
Train_AverageReturn : 51.04999923706055
Train_StdReturn : 24.10285186767578
Train_MaxReturn : 137.0
Train_MinReturn : 27.0
Train_AverageEpLen : 51.05
Actor Loss : 425.97039794921875
Train_EnvstepsSoFar : 423667
TimeSinceStart : 405.19362568855286
Done logging...



********** Iteration 412 ************

Collecting data for eval...
Eval_AverageReturn : 47.22222137451172
Eval_StdReturn : 13.036511421203613
Eval_MaxReturn : 76.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 47.22222222222222
Train_AverageReturn : 61.05882263183594
Train_StdReturn : 29.054655075073242
Train_MaxReturn : 122.0
Train_MinReturn : 27.0
Train_AverageEpLen : 61.05882352941177
Actor Loss : 465.8052978515625
Train_EnvstepsSoFar : 424705
TimeSinceStart : 406.0230164527893
Done logging...



********** Iteration 413 ************

Collecting data for eval...
Eval_AverageReturn : 44.88888931274414
Eval_StdReturn : 31.7470703125
Eval_MaxReturn : 133.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 44.888888888888886
Train_AverageReturn : 38.03703689575195
Train_StdReturn : 8.448018074035645
Train_MaxReturn : 72.0
Train_MinReturn : 26.0
Train_AverageEpLen : 38.03703703703704
Actor Loss : 333.60406494140625
Train_EnvstepsSoFar : 425732
TimeSinceStart : 406.8581042289734
Done logging...



********** Iteration 414 ************

Collecting data for eval...
Eval_AverageReturn : 42.272727966308594
Eval_StdReturn : 14.832954406738281
Eval_MaxReturn : 85.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 42.27272727272727
Train_AverageReturn : 44.08695602416992
Train_StdReturn : 15.393146514892578
Train_MaxReturn : 84.0
Train_MinReturn : 25.0
Train_AverageEpLen : 44.08695652173913
Actor Loss : 265.1481628417969
Train_EnvstepsSoFar : 426746
TimeSinceStart : 407.69231033325195
Done logging...



********** Iteration 415 ************

Collecting data for eval...
Eval_AverageReturn : 54.0
Eval_StdReturn : 25.139610290527344
Eval_MaxReturn : 106.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 54.0
Train_AverageReturn : 39.53845977783203
Train_StdReturn : 13.417069435119629
Train_MaxReturn : 82.0
Train_MinReturn : 28.0
Train_AverageEpLen : 39.53846153846154
Actor Loss : 347.69921875
Train_EnvstepsSoFar : 427774
TimeSinceStart : 409.2925262451172
Done logging...



********** Iteration 416 ************

Collecting data for eval...
Eval_AverageReturn : 59.85714340209961
Eval_StdReturn : 28.925661087036133
Eval_MaxReturn : 112.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 59.857142857142854
Train_AverageReturn : 41.70833206176758
Train_StdReturn : 17.424789428710938
Train_MaxReturn : 91.0
Train_MinReturn : 28.0
Train_AverageEpLen : 41.708333333333336
Actor Loss : 358.277587890625
Train_EnvstepsSoFar : 428775
TimeSinceStart : 410.08889150619507
Done logging...



********** Iteration 417 ************

Collecting data for eval...
Eval_AverageReturn : 51.25
Eval_StdReturn : 20.76505470275879
Eval_MaxReturn : 88.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 51.25
Train_AverageReturn : 46.45454406738281
Train_StdReturn : 19.340787887573242
Train_MaxReturn : 117.0
Train_MinReturn : 28.0
Train_AverageEpLen : 46.45454545454545
Actor Loss : 275.045166015625
Train_EnvstepsSoFar : 429797
TimeSinceStart : 410.91021823883057
Done logging...



********** Iteration 418 ************

Collecting data for eval...
Eval_AverageReturn : 47.599998474121094
Eval_StdReturn : 20.02098846435547
Eval_MaxReturn : 85.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 47.6
Train_AverageReturn : 46.09090805053711
Train_StdReturn : 20.8040828704834
Train_MaxReturn : 99.0
Train_MinReturn : 24.0
Train_AverageEpLen : 46.09090909090909
Actor Loss : 394.44342041015625
Train_EnvstepsSoFar : 430811
TimeSinceStart : 411.7303194999695
Done logging...



********** Iteration 419 ************

Collecting data for eval...
Eval_AverageReturn : 52.88888931274414
Eval_StdReturn : 29.08777618408203
Eval_MaxReturn : 108.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 52.888888888888886
Train_AverageReturn : 50.599998474121094
Train_StdReturn : 25.38976287841797
Train_MaxReturn : 114.0
Train_MinReturn : 27.0
Train_AverageEpLen : 50.6
Actor Loss : 299.874267578125
Train_EnvstepsSoFar : 431823
TimeSinceStart : 412.5776448249817
Done logging...



********** Iteration 420 ************

Collecting data for eval...
Eval_AverageReturn : 44.44444274902344
Eval_StdReturn : 16.680736541748047
Eval_MaxReturn : 78.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 44.44444444444444
Train_AverageReturn : 46.681819915771484
Train_StdReturn : 22.124414443969727
Train_MaxReturn : 117.0
Train_MinReturn : 28.0
Train_AverageEpLen : 46.68181818181818
Actor Loss : 465.94329833984375
Train_EnvstepsSoFar : 432850
TimeSinceStart : 413.37180042266846
Done logging...



********** Iteration 421 ************

Collecting data for eval...
Eval_AverageReturn : 40.900001525878906
Eval_StdReturn : 23.935121536254883
Eval_MaxReturn : 111.0
Eval_MinReturn : 26.0
Eval_AverageEpLen : 40.9
Train_AverageReturn : 45.772727966308594
Train_StdReturn : 23.920190811157227
Train_MaxReturn : 120.0
Train_MinReturn : 26.0
Train_AverageEpLen : 45.77272727272727
Actor Loss : 427.3865661621094
Train_EnvstepsSoFar : 433857
TimeSinceStart : 414.1803114414215
Done logging...



********** Iteration 422 ************

Collecting data for eval...
Eval_AverageReturn : 40.099998474121094
Eval_StdReturn : 11.725613594055176
Eval_MaxReturn : 62.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 40.1
Train_AverageReturn : 49.71428680419922
Train_StdReturn : 22.669767379760742
Train_MaxReturn : 102.0
Train_MinReturn : 26.0
Train_AverageEpLen : 49.714285714285715
Actor Loss : 400.7132263183594
Train_EnvstepsSoFar : 434901
TimeSinceStart : 414.9864387512207
Done logging...



********** Iteration 423 ************

Collecting data for eval...
Eval_AverageReturn : 86.19999694824219
Eval_StdReturn : 58.965755462646484
Eval_MaxReturn : 192.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 86.2
Train_AverageReturn : 48.095237731933594
Train_StdReturn : 25.584415435791016
Train_MaxReturn : 115.0
Train_MinReturn : 28.0
Train_AverageEpLen : 48.095238095238095
Actor Loss : 391.18365478515625
Train_EnvstepsSoFar : 435911
TimeSinceStart : 415.7951648235321
Done logging...



********** Iteration 424 ************

Collecting data for eval...
Eval_AverageReturn : 36.54545593261719
Eval_StdReturn : 9.335792541503906
Eval_MaxReturn : 53.0
Eval_MinReturn : 25.0
Eval_AverageEpLen : 36.54545454545455
Train_AverageReturn : 52.42856979370117
Train_StdReturn : 30.852293014526367
Train_MaxReturn : 134.0
Train_MinReturn : 26.0
Train_AverageEpLen : 52.42857142857143
Actor Loss : 437.5922546386719
Train_EnvstepsSoFar : 437012
TimeSinceStart : 416.6311357021332
Done logging...



********** Iteration 425 ************

Collecting data for eval...
Eval_AverageReturn : 74.0
Eval_StdReturn : 10.082988739013672
Eval_MaxReturn : 88.0
Eval_MinReturn : 56.0
Eval_AverageEpLen : 74.0
Train_AverageReturn : 54.3684196472168
Train_StdReturn : 23.477224349975586
Train_MaxReturn : 114.0
Train_MinReturn : 26.0
Train_AverageEpLen : 54.36842105263158
Actor Loss : 393.826904296875
Train_EnvstepsSoFar : 438045
TimeSinceStart : 417.45918107032776
Done logging...



********** Iteration 426 ************

Collecting data for eval...
Eval_AverageReturn : 49.77777862548828
Eval_StdReturn : 30.297700881958008
Eval_MaxReturn : 123.0
Eval_MinReturn : 24.0
Eval_AverageEpLen : 49.77777777777778
Train_AverageReturn : 44.08695602416992
Train_StdReturn : 19.44649887084961
Train_MaxReturn : 106.0
Train_MinReturn : 26.0
Train_AverageEpLen : 44.08695652173913
Actor Loss : 387.93731689453125
Train_EnvstepsSoFar : 439059
TimeSinceStart : 419.19269347190857
Done logging...



********** Iteration 427 ************

Collecting data for eval...
Eval_AverageReturn : 61.125
Eval_StdReturn : 29.905841827392578
Eval_MaxReturn : 111.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 61.125
Train_AverageReturn : 43.33333206176758
Train_StdReturn : 19.07805633544922
Train_MaxReturn : 94.0
Train_MinReturn : 28.0
Train_AverageEpLen : 43.333333333333336
Actor Loss : 362.83880615234375
Train_EnvstepsSoFar : 440099
TimeSinceStart : 420.04890179634094
Done logging...



********** Iteration 428 ************

Collecting data for eval...
Eval_AverageReturn : 47.77777862548828
Eval_StdReturn : 26.393508911132812
Eval_MaxReturn : 90.0
Eval_MinReturn : 24.0
Eval_AverageEpLen : 47.77777777777778
Train_AverageReturn : 44.130435943603516
Train_StdReturn : 28.485395431518555
Train_MaxReturn : 140.0
Train_MinReturn : 26.0
Train_AverageEpLen : 44.130434782608695
Actor Loss : 334.7052917480469
Train_EnvstepsSoFar : 441114
TimeSinceStart : 421.47529697418213
Done logging...



********** Iteration 429 ************

Collecting data for eval...
Eval_AverageReturn : 68.66666412353516
Eval_StdReturn : 32.9123420715332
Eval_MaxReturn : 106.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 68.66666666666667
Train_AverageReturn : 54.68421173095703
Train_StdReturn : 29.316877365112305
Train_MaxReturn : 110.0
Train_MinReturn : 26.0
Train_AverageEpLen : 54.68421052631579
Actor Loss : 501.09698486328125
Train_EnvstepsSoFar : 442153
TimeSinceStart : 422.2684631347656
Done logging...



********** Iteration 430 ************

Collecting data for eval...
Eval_AverageReturn : 51.875
Eval_StdReturn : 27.227914810180664
Eval_MaxReturn : 107.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 51.875
Train_AverageReturn : 49.42856979370117
Train_StdReturn : 21.884050369262695
Train_MaxReturn : 113.0
Train_MinReturn : 29.0
Train_AverageEpLen : 49.42857142857143
Actor Loss : 321.0614013671875
Train_EnvstepsSoFar : 443191
TimeSinceStart : 423.35212326049805
Done logging...



********** Iteration 431 ************

Collecting data for eval...
Eval_AverageReturn : 50.44444274902344
Eval_StdReturn : 19.709619522094727
Eval_MaxReturn : 82.0
Eval_MinReturn : 25.0
Eval_AverageEpLen : 50.44444444444444
Train_AverageReturn : 47.80952453613281
Train_StdReturn : 18.422603607177734
Train_MaxReturn : 92.0
Train_MinReturn : 28.0
Train_AverageEpLen : 47.80952380952381
Actor Loss : 441.424560546875
Train_EnvstepsSoFar : 444195
TimeSinceStart : 424.161997795105
Done logging...



********** Iteration 432 ************

Collecting data for eval...
Eval_AverageReturn : 62.125
Eval_StdReturn : 22.132766723632812
Eval_MaxReturn : 110.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 62.125
Train_AverageReturn : 42.5
Train_StdReturn : 19.285140991210938
Train_MaxReturn : 101.0
Train_MinReturn : 23.0
Train_AverageEpLen : 42.5
Actor Loss : 376.236083984375
Train_EnvstepsSoFar : 445215
TimeSinceStart : 424.99450516700745
Done logging...



********** Iteration 433 ************

Collecting data for eval...
Eval_AverageReturn : 46.22222137451172
Eval_StdReturn : 17.17089080810547
Eval_MaxReturn : 76.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 46.22222222222222
Train_AverageReturn : 43.60869598388672
Train_StdReturn : 18.19397735595703
Train_MaxReturn : 112.0
Train_MinReturn : 29.0
Train_AverageEpLen : 43.608695652173914
Actor Loss : 272.7643737792969
Train_EnvstepsSoFar : 446218
TimeSinceStart : 425.7641382217407
Done logging...



********** Iteration 434 ************

Collecting data for eval...
Eval_AverageReturn : 48.33333206176758
Eval_StdReturn : 17.39093017578125
Eval_MaxReturn : 86.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 48.333333333333336
Train_AverageReturn : 49.0476188659668
Train_StdReturn : 24.43158721923828
Train_MaxReturn : 127.0
Train_MinReturn : 26.0
Train_AverageEpLen : 49.04761904761905
Actor Loss : 472.26092529296875
Train_EnvstepsSoFar : 447248
TimeSinceStart : 426.56605052948
Done logging...



********** Iteration 435 ************

Collecting data for eval...
Eval_AverageReturn : 93.80000305175781
Eval_StdReturn : 49.333152770996094
Eval_MaxReturn : 181.0
Eval_MinReturn : 46.0
Eval_AverageEpLen : 93.8
Train_AverageReturn : 51.099998474121094
Train_StdReturn : 30.26202392578125
Train_MaxReturn : 152.0
Train_MinReturn : 30.0
Train_AverageEpLen : 51.1
Actor Loss : 383.6895751953125
Train_EnvstepsSoFar : 448270
TimeSinceStart : 427.6286506652832
Done logging...



********** Iteration 436 ************

Collecting data for eval...
Eval_AverageReturn : 52.375
Eval_StdReturn : 23.53156089782715
Eval_MaxReturn : 113.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 52.375
Train_AverageReturn : 51.45000076293945
Train_StdReturn : 23.1656551361084
Train_MaxReturn : 121.0
Train_MinReturn : 28.0
Train_AverageEpLen : 51.45
Actor Loss : 314.34661865234375
Train_EnvstepsSoFar : 449299
TimeSinceStart : 429.2726979255676
Done logging...



********** Iteration 437 ************

Collecting data for eval...
Eval_AverageReturn : 55.5
Eval_StdReturn : 36.24913787841797
Eval_MaxReturn : 146.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 55.5
Train_AverageReturn : 63.0
Train_StdReturn : 35.11587905883789
Train_MaxReturn : 169.0
Train_MinReturn : 29.0
Train_AverageEpLen : 63.0
Actor Loss : 471.0650634765625
Train_EnvstepsSoFar : 450307
TimeSinceStart : 430.06655263900757
Done logging...



********** Iteration 438 ************

Collecting data for eval...
Eval_AverageReturn : 50.0
Eval_StdReturn : 19.29882049560547
Eval_MaxReturn : 85.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 50.0
Train_AverageReturn : 53.78947448730469
Train_StdReturn : 30.835006713867188
Train_MaxReturn : 148.0
Train_MinReturn : 33.0
Train_AverageEpLen : 53.78947368421053
Actor Loss : 523.781494140625
Train_EnvstepsSoFar : 451329
TimeSinceStart : 430.8759229183197
Done logging...



********** Iteration 439 ************

Collecting data for eval...
Eval_AverageReturn : 84.80000305175781
Eval_StdReturn : 28.86797523498535
Eval_MaxReturn : 123.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 84.8
Train_AverageReturn : 46.59090805053711
Train_StdReturn : 20.32387351989746
Train_MaxReturn : 128.0
Train_MinReturn : 28.0
Train_AverageEpLen : 46.59090909090909
Actor Loss : 407.9903259277344
Train_EnvstepsSoFar : 452354
TimeSinceStart : 431.6668815612793
Done logging...



********** Iteration 440 ************

Collecting data for eval...
Eval_AverageReturn : 45.44444274902344
Eval_StdReturn : 14.42306137084961
Eval_MaxReturn : 67.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 45.44444444444444
Train_AverageReturn : 45.6363639831543
Train_StdReturn : 22.300724029541016
Train_MaxReturn : 125.0
Train_MinReturn : 28.0
Train_AverageEpLen : 45.63636363636363
Actor Loss : 349.0863952636719
Train_EnvstepsSoFar : 453358
TimeSinceStart : 432.462078332901
Done logging...



********** Iteration 441 ************

Collecting data for eval...
Eval_AverageReturn : 39.54545593261719
Eval_StdReturn : 8.26123046875
Eval_MaxReturn : 51.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 39.54545454545455
Train_AverageReturn : 59.94117736816406
Train_StdReturn : 35.016754150390625
Train_MaxReturn : 157.0
Train_MinReturn : 29.0
Train_AverageEpLen : 59.94117647058823
Actor Loss : 348.5732116699219
Train_EnvstepsSoFar : 454377
TimeSinceStart : 433.2643859386444
Done logging...



********** Iteration 442 ************

Collecting data for eval...
Eval_AverageReturn : 59.42856979370117
Eval_StdReturn : 27.007179260253906
Eval_MaxReturn : 108.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 59.42857142857143
Train_AverageReturn : 51.29999923706055
Train_StdReturn : 28.36564826965332
Train_MaxReturn : 149.0
Train_MinReturn : 27.0
Train_AverageEpLen : 51.3
Actor Loss : 492.7798156738281
Train_EnvstepsSoFar : 455403
TimeSinceStart : 434.07099175453186
Done logging...



********** Iteration 443 ************

Collecting data for eval...
Eval_AverageReturn : 44.44444274902344
Eval_StdReturn : 11.557692527770996
Eval_MaxReturn : 73.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 44.44444444444444
Train_AverageReturn : 47.5
Train_StdReturn : 15.996448516845703
Train_MaxReturn : 87.0
Train_MinReturn : 27.0
Train_AverageEpLen : 47.5
Actor Loss : 263.9100036621094
Train_EnvstepsSoFar : 456448
TimeSinceStart : 434.88209342956543
Done logging...



********** Iteration 444 ************

Collecting data for eval...
Eval_AverageReturn : 50.125
Eval_StdReturn : 23.95536231994629
Eval_MaxReturn : 108.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 50.125
Train_AverageReturn : 55.66666793823242
Train_StdReturn : 23.440229415893555
Train_MaxReturn : 111.0
Train_MinReturn : 28.0
Train_AverageEpLen : 55.666666666666664
Actor Loss : 263.078125
Train_EnvstepsSoFar : 457450
TimeSinceStart : 435.6621606349945
Done logging...



********** Iteration 445 ************

Collecting data for eval...
Eval_AverageReturn : 45.5
Eval_StdReturn : 19.41262435913086
Eval_MaxReturn : 88.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 45.5
Train_AverageReturn : 48.5
Train_StdReturn : 20.87135887145996
Train_MaxReturn : 101.0
Train_MinReturn : 29.0
Train_AverageEpLen : 48.5
Actor Loss : 314.26776123046875
Train_EnvstepsSoFar : 458517
TimeSinceStart : 436.5037431716919
Done logging...



********** Iteration 446 ************

Collecting data for eval...
Eval_AverageReturn : 50.5
Eval_StdReturn : 15.14925765991211
Eval_MaxReturn : 84.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 50.5
Train_AverageReturn : 56.66666793823242
Train_StdReturn : 19.92764663696289
Train_MaxReturn : 103.0
Train_MinReturn : 33.0
Train_AverageEpLen : 56.666666666666664
Actor Loss : 526.787353515625
Train_EnvstepsSoFar : 459537
TimeSinceStart : 437.28691148757935
Done logging...



********** Iteration 447 ************

Collecting data for eval...
Eval_AverageReturn : 44.44444274902344
Eval_StdReturn : 12.148261070251465
Eval_MaxReturn : 71.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 44.44444444444444
Train_AverageReturn : 55.94736862182617
Train_StdReturn : 24.001039505004883
Train_MaxReturn : 130.0
Train_MinReturn : 29.0
Train_AverageEpLen : 55.94736842105263
Actor Loss : 287.5744934082031
Train_EnvstepsSoFar : 460600
TimeSinceStart : 438.0938091278076
Done logging...



********** Iteration 448 ************

Collecting data for eval...
Eval_AverageReturn : 58.125
Eval_StdReturn : 23.116214752197266
Eval_MaxReturn : 100.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 58.125
Train_AverageReturn : 50.79999923706055
Train_StdReturn : 15.964334487915039
Train_MaxReturn : 88.0
Train_MinReturn : 33.0
Train_AverageEpLen : 50.8
Actor Loss : 364.54022216796875
Train_EnvstepsSoFar : 461616
TimeSinceStart : 439.8388772010803
Done logging...



********** Iteration 449 ************

Collecting data for eval...
Eval_AverageReturn : 41.5
Eval_StdReturn : 16.113658905029297
Eval_MaxReturn : 86.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 41.5
Train_AverageReturn : 44.65217208862305
Train_StdReturn : 11.638051986694336
Train_MaxReturn : 71.0
Train_MinReturn : 30.0
Train_AverageEpLen : 44.65217391304348
Actor Loss : 319.64599609375
Train_EnvstepsSoFar : 462643
TimeSinceStart : 440.6190664768219
Done logging...



********** Iteration 450 ************

Collecting data for eval...
Eval_AverageReturn : 54.5
Eval_StdReturn : 16.2249813079834
Eval_MaxReturn : 89.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 54.5
Train_AverageReturn : 50.29999923706055
Train_StdReturn : 16.334320068359375
Train_MaxReturn : 90.0
Train_MinReturn : 32.0
Train_AverageEpLen : 50.3
Actor Loss : 307.53857421875
Train_EnvstepsSoFar : 463649
TimeSinceStart : 441.4172215461731
Done logging...



********** Iteration 451 ************

Collecting data for eval...
Eval_AverageReturn : 42.599998474121094
Eval_StdReturn : 8.627861976623535
Eval_MaxReturn : 64.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 42.6
Train_AverageReturn : 54.6315803527832
Train_StdReturn : 21.494701385498047
Train_MaxReturn : 105.0
Train_MinReturn : 34.0
Train_AverageEpLen : 54.63157894736842
Actor Loss : 368.0538024902344
Train_EnvstepsSoFar : 464687
TimeSinceStart : 442.21356749534607
Done logging...



********** Iteration 452 ************

Collecting data for eval...
Eval_AverageReturn : 41.79999923706055
Eval_StdReturn : 8.364209175109863
Eval_MaxReturn : 56.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 41.8
Train_AverageReturn : 48.0
Train_StdReturn : 21.1660099029541
Train_MaxReturn : 100.0
Train_MinReturn : 31.0
Train_AverageEpLen : 48.0
Actor Loss : 477.9375915527344
Train_EnvstepsSoFar : 465695
TimeSinceStart : 443.1299264431
Done logging...



********** Iteration 453 ************

Collecting data for eval...
Eval_AverageReturn : 68.71428680419922
Eval_StdReturn : 29.85543441772461
Eval_MaxReturn : 116.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 68.71428571428571
Train_AverageReturn : 45.5
Train_StdReturn : 11.06489086151123
Train_MaxReturn : 71.0
Train_MinReturn : 31.0
Train_AverageEpLen : 45.5
Actor Loss : 398.310791015625
Train_EnvstepsSoFar : 466696
TimeSinceStart : 443.9347400665283
Done logging...



********** Iteration 454 ************

Collecting data for eval...
Eval_AverageReturn : 53.125
Eval_StdReturn : 17.905569076538086
Eval_MaxReturn : 87.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 53.125
Train_AverageReturn : 53.5
Train_StdReturn : 28.814058303833008
Train_MaxReturn : 129.0
Train_MinReturn : 33.0
Train_AverageEpLen : 53.5
Actor Loss : 352.4852294921875
Train_EnvstepsSoFar : 467766
TimeSinceStart : 444.75797414779663
Done logging...



********** Iteration 455 ************

Collecting data for eval...
Eval_AverageReturn : 50.0
Eval_StdReturn : 21.760055541992188
Eval_MaxReturn : 105.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 50.0
Train_AverageReturn : 50.04999923706055
Train_StdReturn : 14.319478988647461
Train_MaxReturn : 80.0
Train_MinReturn : 30.0
Train_AverageEpLen : 50.05
Actor Loss : 341.8650817871094
Train_EnvstepsSoFar : 468767
TimeSinceStart : 445.6189203262329
Done logging...



********** Iteration 456 ************

Collecting data for eval...
Eval_AverageReturn : 53.25
Eval_StdReturn : 23.74736785888672
Eval_MaxReturn : 105.0
Eval_MinReturn : 36.0
Eval_AverageEpLen : 53.25
Train_AverageReturn : 45.6363639831543
Train_StdReturn : 16.430419921875
Train_MaxReturn : 103.0
Train_MinReturn : 30.0
Train_AverageEpLen : 45.63636363636363
Actor Loss : 350.755126953125
Train_EnvstepsSoFar : 469771
TimeSinceStart : 446.6829147338867
Done logging...



********** Iteration 457 ************

Collecting data for eval...
Eval_AverageReturn : 47.22222137451172
Eval_StdReturn : 18.754423141479492
Eval_MaxReturn : 97.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 47.22222222222222
Train_AverageReturn : 50.650001525878906
Train_StdReturn : 20.117841720581055
Train_MaxReturn : 109.0
Train_MinReturn : 32.0
Train_AverageEpLen : 50.65
Actor Loss : 408.6731872558594
Train_EnvstepsSoFar : 470784
TimeSinceStart : 447.75143671035767
Done logging...



********** Iteration 458 ************

Collecting data for eval...
Eval_AverageReturn : 51.44444274902344
Eval_StdReturn : 16.173442840576172
Eval_MaxReturn : 90.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 51.44444444444444
Train_AverageReturn : 42.04166793823242
Train_StdReturn : 8.526816368103027
Train_MaxReturn : 63.0
Train_MinReturn : 30.0
Train_AverageEpLen : 42.041666666666664
Actor Loss : 277.6586608886719
Train_EnvstepsSoFar : 471793
TimeSinceStart : 448.66378235816956
Done logging...



********** Iteration 459 ************

Collecting data for eval...
Eval_AverageReturn : 51.375
Eval_StdReturn : 15.619998931884766
Eval_MaxReturn : 88.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 51.375
Train_AverageReturn : 56.77777862548828
Train_StdReturn : 27.474342346191406
Train_MaxReturn : 129.0
Train_MinReturn : 32.0
Train_AverageEpLen : 56.77777777777778
Actor Loss : 491.2339782714844
Train_EnvstepsSoFar : 472815
TimeSinceStart : 449.4441463947296
Done logging...



********** Iteration 460 ************

Collecting data for eval...
Eval_AverageReturn : 44.44444274902344
Eval_StdReturn : 14.818241119384766
Eval_MaxReturn : 71.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 44.44444444444444
Train_AverageReturn : 53.421051025390625
Train_StdReturn : 25.643949508666992
Train_MaxReturn : 117.0
Train_MinReturn : 29.0
Train_AverageEpLen : 53.421052631578945
Actor Loss : 315.9244689941406
Train_EnvstepsSoFar : 473830
TimeSinceStart : 450.22216176986694
Done logging...



********** Iteration 461 ************

Collecting data for eval...
Eval_AverageReturn : 57.57143020629883
Eval_StdReturn : 26.885244369506836
Eval_MaxReturn : 116.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 57.57142857142857
Train_AverageReturn : 53.94736862182617
Train_StdReturn : 21.392261505126953
Train_MaxReturn : 123.0
Train_MinReturn : 36.0
Train_AverageEpLen : 53.94736842105263
Actor Loss : 540.4185791015625
Train_EnvstepsSoFar : 474855
TimeSinceStart : 451.0240137577057
Done logging...



********** Iteration 462 ************

Collecting data for eval...
Eval_AverageReturn : 54.625
Eval_StdReturn : 14.738872528076172
Eval_MaxReturn : 77.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 54.625
Train_AverageReturn : 49.772727966308594
Train_StdReturn : 20.880464553833008
Train_MaxReturn : 117.0
Train_MinReturn : 30.0
Train_AverageEpLen : 49.77272727272727
Actor Loss : 418.0967102050781
Train_EnvstepsSoFar : 475950
TimeSinceStart : 451.87046122550964
Done logging...



********** Iteration 463 ************

Collecting data for eval...
Eval_AverageReturn : 61.0
Eval_StdReturn : 35.73313903808594
Eval_MaxReturn : 145.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 61.0
Train_AverageReturn : 45.54545593261719
Train_StdReturn : 15.810604095458984
Train_MaxReturn : 92.0
Train_MinReturn : 29.0
Train_AverageEpLen : 45.54545454545455
Actor Loss : 405.9404296875
Train_EnvstepsSoFar : 476952
TimeSinceStart : 452.65588760375977
Done logging...



********** Iteration 464 ************

Collecting data for eval...
Eval_AverageReturn : 53.0
Eval_StdReturn : 30.793668746948242
Eval_MaxReturn : 113.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 53.0
Train_AverageReturn : 55.578948974609375
Train_StdReturn : 25.198822021484375
Train_MaxReturn : 131.0
Train_MinReturn : 31.0
Train_AverageEpLen : 55.578947368421055
Actor Loss : 537.9888305664062
Train_EnvstepsSoFar : 478008
TimeSinceStart : 453.877338886261
Done logging...



********** Iteration 465 ************

Collecting data for eval...
Eval_AverageReturn : 56.66666793823242
Eval_StdReturn : 23.80476188659668
Eval_MaxReturn : 113.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 56.666666666666664
Train_AverageReturn : 45.818180084228516
Train_StdReturn : 18.683090209960938
Train_MaxReturn : 114.0
Train_MinReturn : 31.0
Train_AverageEpLen : 45.81818181818182
Actor Loss : 375.4005126953125
Train_EnvstepsSoFar : 479016
TimeSinceStart : 454.7094202041626
Done logging...



********** Iteration 466 ************

Collecting data for eval...
Eval_AverageReturn : 53.5
Eval_StdReturn : 24.58658218383789
Eval_MaxReturn : 113.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 53.5
Train_AverageReturn : 52.73684310913086
Train_StdReturn : 21.16810417175293
Train_MaxReturn : 103.0
Train_MinReturn : 32.0
Train_AverageEpLen : 52.73684210526316
Actor Loss : 241.85110473632812
Train_EnvstepsSoFar : 480018
TimeSinceStart : 455.6604013442993
Done logging...



********** Iteration 467 ************

Collecting data for eval...
Eval_AverageReturn : 64.42857360839844
Eval_StdReturn : 21.698301315307617
Eval_MaxReturn : 103.0
Eval_MinReturn : 41.0
Eval_AverageEpLen : 64.42857142857143
Train_AverageReturn : 52.94736862182617
Train_StdReturn : 21.593063354492188
Train_MaxReturn : 111.0
Train_MinReturn : 31.0
Train_AverageEpLen : 52.94736842105263
Actor Loss : 283.62493896484375
Train_EnvstepsSoFar : 481024
TimeSinceStart : 456.66212916374207
Done logging...



********** Iteration 468 ************

Collecting data for eval...
Eval_AverageReturn : 57.85714340209961
Eval_StdReturn : 22.260974884033203
Eval_MaxReturn : 101.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 57.857142857142854
Train_AverageReturn : 53.31578826904297
Train_StdReturn : 24.135696411132812
Train_MaxReturn : 109.0
Train_MinReturn : 30.0
Train_AverageEpLen : 53.31578947368421
Actor Loss : 453.0893859863281
Train_EnvstepsSoFar : 482037
TimeSinceStart : 457.64309000968933
Done logging...



********** Iteration 469 ************

Collecting data for eval...
Eval_AverageReturn : 58.42856979370117
Eval_StdReturn : 25.82278823852539
Eval_MaxReturn : 101.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 58.42857142857143
Train_AverageReturn : 52.73684310913086
Train_StdReturn : 24.823251724243164
Train_MaxReturn : 120.0
Train_MinReturn : 28.0
Train_AverageEpLen : 52.73684210526316
Actor Loss : 317.8278503417969
Train_EnvstepsSoFar : 483039
TimeSinceStart : 458.4119129180908
Done logging...



********** Iteration 470 ************

Collecting data for eval...
Eval_AverageReturn : 57.57143020629883
Eval_StdReturn : 26.445940017700195
Eval_MaxReturn : 118.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 57.57142857142857
Train_AverageReturn : 51.45000076293945
Train_StdReturn : 20.50969123840332
Train_MaxReturn : 103.0
Train_MinReturn : 30.0
Train_AverageEpLen : 51.45
Actor Loss : 433.2337341308594
Train_EnvstepsSoFar : 484068
TimeSinceStart : 459.1975152492523
Done logging...



********** Iteration 471 ************

Collecting data for eval...
Eval_AverageReturn : 51.0
Eval_StdReturn : 25.073226928710938
Eval_MaxReturn : 110.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 51.0
Train_AverageReturn : 51.400001525878906
Train_StdReturn : 25.209917068481445
Train_MaxReturn : 119.0
Train_MinReturn : 30.0
Train_AverageEpLen : 51.4
Actor Loss : 377.5171813964844
Train_EnvstepsSoFar : 485096
TimeSinceStart : 460.45255613327026
Done logging...



********** Iteration 472 ************

Collecting data for eval...
Eval_AverageReturn : 44.88888931274414
Eval_StdReturn : 8.974587440490723
Eval_MaxReturn : 57.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 44.888888888888886
Train_AverageReturn : 69.06666564941406
Train_StdReturn : 34.70920181274414
Train_MaxReturn : 133.0
Train_MinReturn : 35.0
Train_AverageEpLen : 69.06666666666666
Actor Loss : 383.9758605957031
Train_EnvstepsSoFar : 486132
TimeSinceStart : 461.2374930381775
Done logging...



********** Iteration 473 ************

Collecting data for eval...
Eval_AverageReturn : 50.5
Eval_StdReturn : 22.538854598999023
Eval_MaxReturn : 106.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 50.5
Train_AverageReturn : 44.173912048339844
Train_StdReturn : 17.125247955322266
Train_MaxReturn : 112.0
Train_MinReturn : 30.0
Train_AverageEpLen : 44.17391304347826
Actor Loss : 336.2724609375
Train_EnvstepsSoFar : 487148
TimeSinceStart : 462.0279266834259
Done logging...



********** Iteration 474 ************

Collecting data for eval...
Eval_AverageReturn : 41.79999923706055
Eval_StdReturn : 8.435638427734375
Eval_MaxReturn : 52.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 41.8
Train_AverageReturn : 46.59090805053711
Train_StdReturn : 12.437695503234863
Train_MaxReturn : 81.0
Train_MinReturn : 31.0
Train_AverageEpLen : 46.59090909090909
Actor Loss : 418.72601318359375
Train_EnvstepsSoFar : 488173
TimeSinceStart : 462.9476885795593
Done logging...



********** Iteration 475 ************

Collecting data for eval...
Eval_AverageReturn : 45.77777862548828
Eval_StdReturn : 12.603155136108398
Eval_MaxReturn : 70.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 45.77777777777778
Train_AverageReturn : 58.0
Train_StdReturn : 27.243755340576172
Train_MaxReturn : 118.0
Train_MinReturn : 31.0
Train_AverageEpLen : 58.0
Actor Loss : 346.3625183105469
Train_EnvstepsSoFar : 489217
TimeSinceStart : 463.7419378757477
Done logging...



********** Iteration 476 ************

Collecting data for eval...
Eval_AverageReturn : 41.0
Eval_StdReturn : 12.14907455444336
Eval_MaxReturn : 74.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 41.0
Train_AverageReturn : 54.94736862182617
Train_StdReturn : 28.899961471557617
Train_MaxReturn : 135.0
Train_MinReturn : 30.0
Train_AverageEpLen : 54.94736842105263
Actor Loss : 390.71783447265625
Train_EnvstepsSoFar : 490261
TimeSinceStart : 464.5311315059662
Done logging...



********** Iteration 477 ************

Collecting data for eval...
Eval_AverageReturn : 67.83333587646484
Eval_StdReturn : 26.44753646850586
Eval_MaxReturn : 114.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 67.83333333333333
Train_AverageReturn : 59.47058868408203
Train_StdReturn : 20.98491668701172
Train_MaxReturn : 105.0
Train_MinReturn : 34.0
Train_AverageEpLen : 59.470588235294116
Actor Loss : 303.0286865234375
Train_EnvstepsSoFar : 491272
TimeSinceStart : 465.3045003414154
Done logging...



********** Iteration 478 ************

Collecting data for eval...
Eval_AverageReturn : 71.33333587646484
Eval_StdReturn : 40.93355178833008
Eval_MaxReturn : 160.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 71.33333333333333
Train_AverageReturn : 50.599998474121094
Train_StdReturn : 21.406539916992188
Train_MaxReturn : 110.0
Train_MinReturn : 31.0
Train_AverageEpLen : 50.6
Actor Loss : 273.9621887207031
Train_EnvstepsSoFar : 492284
TimeSinceStart : 466.09391164779663
Done logging...



********** Iteration 479 ************

Collecting data for eval...
Eval_AverageReturn : 52.0
Eval_StdReturn : 19.624248504638672
Eval_MaxReturn : 100.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 52.0
Train_AverageReturn : 50.45000076293945
Train_StdReturn : 17.491355895996094
Train_MaxReturn : 101.0
Train_MinReturn : 32.0
Train_AverageEpLen : 50.45
Actor Loss : 287.6277770996094
Train_EnvstepsSoFar : 493293
TimeSinceStart : 466.9054317474365
Done logging...



********** Iteration 480 ************

Collecting data for eval...
Eval_AverageReturn : 48.55555725097656
Eval_StdReturn : 14.667508125305176
Eval_MaxReturn : 80.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 48.55555555555556
Train_AverageReturn : 51.5
Train_StdReturn : 21.462759017944336
Train_MaxReturn : 116.0
Train_MinReturn : 29.0
Train_AverageEpLen : 51.5
Actor Loss : 228.6876220703125
Train_EnvstepsSoFar : 494323
TimeSinceStart : 467.72528195381165
Done logging...



********** Iteration 481 ************

Collecting data for eval...
Eval_AverageReturn : 54.5
Eval_StdReturn : 28.535066604614258
Eval_MaxReturn : 111.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 54.5
Train_AverageReturn : 49.0
Train_StdReturn : 17.912485122680664
Train_MaxReturn : 105.0
Train_MinReturn : 32.0
Train_AverageEpLen : 49.0
Actor Loss : 411.65582275390625
Train_EnvstepsSoFar : 495352
TimeSinceStart : 469.3419237136841
Done logging...



********** Iteration 482 ************

Collecting data for eval...
Eval_AverageReturn : 46.44444274902344
Eval_StdReturn : 15.847265243530273
Eval_MaxReturn : 88.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 46.44444444444444
Train_AverageReturn : 54.400001525878906
Train_StdReturn : 22.57963752746582
Train_MaxReturn : 106.0
Train_MinReturn : 33.0
Train_AverageEpLen : 54.4
Actor Loss : 276.05218505859375
Train_EnvstepsSoFar : 496440
TimeSinceStart : 470.17410922050476
Done logging...



********** Iteration 483 ************

Collecting data for eval...
Eval_AverageReturn : 60.0
Eval_StdReturn : 16.818357467651367
Eval_MaxReturn : 84.0
Eval_MinReturn : 39.0
Eval_AverageEpLen : 60.0
Train_AverageReturn : 50.5
Train_StdReturn : 16.939598083496094
Train_MaxReturn : 84.0
Train_MinReturn : 33.0
Train_AverageEpLen : 50.5
Actor Loss : 333.2711181640625
Train_EnvstepsSoFar : 497450
TimeSinceStart : 470.95386385917664
Done logging...



********** Iteration 484 ************

Collecting data for eval...
Eval_AverageReturn : 49.66666793823242
Eval_StdReturn : 8.485280990600586
Eval_MaxReturn : 67.0
Eval_MinReturn : 40.0
Eval_AverageEpLen : 49.666666666666664
Train_AverageReturn : 47.85714340209961
Train_StdReturn : 11.945453643798828
Train_MaxReturn : 71.0
Train_MinReturn : 28.0
Train_AverageEpLen : 47.857142857142854
Actor Loss : 348.01751708984375
Train_EnvstepsSoFar : 498455
TimeSinceStart : 471.777060508728
Done logging...



********** Iteration 485 ************

Collecting data for eval...
Eval_AverageReturn : 57.42856979370117
Eval_StdReturn : 35.75654602050781
Eval_MaxReturn : 142.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 57.42857142857143
Train_AverageReturn : 49.14285659790039
Train_StdReturn : 15.132072448730469
Train_MaxReturn : 85.0
Train_MinReturn : 31.0
Train_AverageEpLen : 49.142857142857146
Actor Loss : 292.3055419921875
Train_EnvstepsSoFar : 499487
TimeSinceStart : 472.5962727069855
Done logging...



********** Iteration 486 ************

Collecting data for eval...
Eval_AverageReturn : 59.71428680419922
Eval_StdReturn : 19.990814208984375
Eval_MaxReturn : 94.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 59.714285714285715
Train_AverageReturn : 51.349998474121094
Train_StdReturn : 16.638134002685547
Train_MaxReturn : 81.0
Train_MinReturn : 31.0
Train_AverageEpLen : 51.35
Actor Loss : 191.6790771484375
Train_EnvstepsSoFar : 500514
TimeSinceStart : 474.2933123111725
Done logging...



********** Iteration 487 ************

Collecting data for eval...
Eval_AverageReturn : 68.16666412353516
Eval_StdReturn : 31.275211334228516
Eval_MaxReturn : 128.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 68.16666666666667
Train_AverageReturn : 46.772727966308594
Train_StdReturn : 15.739157676696777
Train_MaxReturn : 92.0
Train_MinReturn : 29.0
Train_AverageEpLen : 46.77272727272727
Actor Loss : 498.53363037109375
Train_EnvstepsSoFar : 501543
TimeSinceStart : 475.0819525718689
Done logging...



********** Iteration 488 ************

Collecting data for eval...
Eval_AverageReturn : 59.5
Eval_StdReturn : 29.60996437072754
Eval_MaxReturn : 125.0
Eval_MinReturn : 36.0
Eval_AverageEpLen : 59.5
Train_AverageReturn : 51.54999923706055
Train_StdReturn : 16.971960067749023
Train_MaxReturn : 87.0
Train_MinReturn : 35.0
Train_AverageEpLen : 51.55
Actor Loss : 163.89398193359375
Train_EnvstepsSoFar : 502574
TimeSinceStart : 475.92103815078735
Done logging...



********** Iteration 489 ************

Collecting data for eval...
Eval_AverageReturn : 42.29999923706055
Eval_StdReturn : 10.383159637451172
Eval_MaxReturn : 67.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 42.3
Train_AverageReturn : 50.25
Train_StdReturn : 24.028888702392578
Train_MaxReturn : 124.0
Train_MinReturn : 29.0
Train_AverageEpLen : 50.25
Actor Loss : 299.860107421875
Train_EnvstepsSoFar : 503579
TimeSinceStart : 476.7164692878723
Done logging...



********** Iteration 490 ************

Collecting data for eval...
Eval_AverageReturn : 58.625
Eval_StdReturn : 30.951322555541992
Eval_MaxReturn : 130.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 58.625
Train_AverageReturn : 53.3684196472168
Train_StdReturn : 22.88233184814453
Train_MaxReturn : 129.0
Train_MinReturn : 30.0
Train_AverageEpLen : 53.36842105263158
Actor Loss : 259.79443359375
Train_EnvstepsSoFar : 504593
TimeSinceStart : 477.8202123641968
Done logging...



********** Iteration 491 ************

Collecting data for eval...
Eval_AverageReturn : 47.55555725097656
Eval_StdReturn : 12.329829216003418
Eval_MaxReturn : 76.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 47.55555555555556
Train_AverageReturn : 50.75
Train_StdReturn : 22.255056381225586
Train_MaxReturn : 133.0
Train_MinReturn : 33.0
Train_AverageEpLen : 50.75
Actor Loss : 267.50830078125
Train_EnvstepsSoFar : 505608
TimeSinceStart : 478.6188929080963
Done logging...



********** Iteration 492 ************

Collecting data for eval...
Eval_AverageReturn : 53.11111068725586
Eval_StdReturn : 20.49631118774414
Eval_MaxReturn : 104.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 53.111111111111114
Train_AverageReturn : 55.578948974609375
Train_StdReturn : 24.715892791748047
Train_MaxReturn : 136.0
Train_MinReturn : 32.0
Train_AverageEpLen : 55.578947368421055
Actor Loss : 322.5868835449219
Train_EnvstepsSoFar : 506664
TimeSinceStart : 479.72290563583374
Done logging...



********** Iteration 493 ************

Collecting data for eval...
Eval_AverageReturn : 58.57143020629883
Eval_StdReturn : 18.88958168029785
Eval_MaxReturn : 90.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 58.57142857142857
Train_AverageReturn : 45.772727966308594
Train_StdReturn : 11.874080657958984
Train_MaxReturn : 78.0
Train_MinReturn : 28.0
Train_AverageEpLen : 45.77272727272727
Actor Loss : 268.4467468261719
Train_EnvstepsSoFar : 507671
TimeSinceStart : 480.9056165218353
Done logging...



********** Iteration 494 ************

Collecting data for eval...
Eval_AverageReturn : 52.0
Eval_StdReturn : 11.832159996032715
Eval_MaxReturn : 66.0
Eval_MinReturn : 36.0
Eval_AverageEpLen : 52.0
Train_AverageReturn : 53.157894134521484
Train_StdReturn : 21.531526565551758
Train_MaxReturn : 98.0
Train_MinReturn : 32.0
Train_AverageEpLen : 53.1578947368421
Actor Loss : 314.6854553222656
Train_EnvstepsSoFar : 508681
TimeSinceStart : 481.68783235549927
Done logging...



********** Iteration 495 ************

Collecting data for eval...
Eval_AverageReturn : 51.875
Eval_StdReturn : 24.781230926513672
Eval_MaxReturn : 114.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 51.875
Train_AverageReturn : 53.0
Train_StdReturn : 21.655193328857422
Train_MaxReturn : 108.0
Train_MinReturn : 30.0
Train_AverageEpLen : 53.0
Actor Loss : 271.36248779296875
Train_EnvstepsSoFar : 509688
TimeSinceStart : 482.6762504577637
Done logging...



********** Iteration 496 ************

Collecting data for eval...
Eval_AverageReturn : 52.625
Eval_StdReturn : 18.49957847595215
Eval_MaxReturn : 94.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 52.625
Train_AverageReturn : 45.727272033691406
Train_StdReturn : 13.728477478027344
Train_MaxReturn : 77.0
Train_MinReturn : 29.0
Train_AverageEpLen : 45.72727272727273
Actor Loss : 254.7776336669922
Train_EnvstepsSoFar : 510694
TimeSinceStart : 483.6315267086029
Done logging...



********** Iteration 497 ************

Collecting data for eval...
Eval_AverageReturn : 41.0
Eval_StdReturn : 11.018166542053223
Eval_MaxReturn : 68.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 41.0
Train_AverageReturn : 61.235294342041016
Train_StdReturn : 25.680227279663086
Train_MaxReturn : 113.0
Train_MinReturn : 34.0
Train_AverageEpLen : 61.23529411764706
Actor Loss : 433.2043762207031
Train_EnvstepsSoFar : 511735
TimeSinceStart : 484.4598593711853
Done logging...



********** Iteration 498 ************

Collecting data for eval...
Eval_AverageReturn : 37.90909194946289
Eval_StdReturn : 5.899992942810059
Eval_MaxReturn : 49.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 37.90909090909091
Train_AverageReturn : 50.54999923706055
Train_StdReturn : 24.14637565612793
Train_MaxReturn : 130.0
Train_MinReturn : 30.0
Train_AverageEpLen : 50.55
Actor Loss : 291.7901306152344
Train_EnvstepsSoFar : 512746
TimeSinceStart : 485.41281819343567
Done logging...



********** Iteration 499 ************

Collecting data for eval...
Eval_AverageReturn : 69.85713958740234
Eval_StdReturn : 26.824447631835938
Eval_MaxReturn : 111.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 69.85714285714286
Train_AverageReturn : 44.565216064453125
Train_StdReturn : 15.477405548095703
Train_MaxReturn : 76.0
Train_MinReturn : 28.0
Train_AverageEpLen : 44.56521739130435
Actor Loss : 273.8375244140625
Train_EnvstepsSoFar : 513771
TimeSinceStart : 486.2620258331299
Done logging...


########################
logging outputs to  /home/jaehyun-jeong/UCBerkeley_cs285/hw2/cs285/scripts/../../data/q2_pg_cartpole_rtg_CartPole-v0_17-08-2024_01-10-15
########################
Using GPU id 0
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/envs/registration.py:593: UserWarning: [33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.[0m
  logger.warn(
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/core.py:317: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(

********** Iteration 0 ************
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):

Collecting data for eval...
Eval_AverageReturn : 26.933332443237305
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/tensorboardX/summary.py:153: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
  scalar = float(scalar)
Eval_StdReturn : 3.5863940715789795
Eval_MaxReturn : 35.0
Eval_MinReturn : 21.0
Eval_AverageEpLen : 26.933333333333334
Train_AverageReturn : 35.17241287231445
Train_StdReturn : 15.342231750488281
Train_MaxReturn : 81.0
Train_MinReturn : 20.0
Train_AverageEpLen : 35.172413793103445
Actor Loss : 14886.404296875
Train_EnvstepsSoFar : 1020
TimeSinceStart : 1.8138227462768555
Initial_DataCollection_AverageReturn : 35.17241287231445
Done logging...



********** Iteration 1 ************

Collecting data for eval...
Eval_AverageReturn : 23.38888931274414
Eval_StdReturn : 4.2964959144592285
Eval_MaxReturn : 33.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 23.38888888888889
Train_AverageReturn : 27.16216278076172
Train_StdReturn : 4.123194217681885
Train_MaxReturn : 37.0
Train_MinReturn : 21.0
Train_AverageEpLen : 27.16216216216216
Actor Loss : 9192.654296875
Train_EnvstepsSoFar : 2025
TimeSinceStart : 2.6243999004364014
Done logging...



********** Iteration 2 ************

Collecting data for eval...
Eval_AverageReturn : 22.5
Eval_StdReturn : 4.2328081130981445
Eval_MaxReturn : 29.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 22.5
Train_AverageReturn : 25.66666603088379
Train_StdReturn : 4.053066730499268
Train_MaxReturn : 32.0
Train_MinReturn : 19.0
Train_AverageEpLen : 25.666666666666668
Actor Loss : 8045.818359375
Train_EnvstepsSoFar : 3026
TimeSinceStart : 3.7976880073547363
Done logging...



********** Iteration 3 ************

Collecting data for eval...
Eval_AverageReturn : 23.11111068725586
Eval_StdReturn : 3.710179567337036
Eval_MaxReturn : 30.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 23.11111111111111
Train_AverageReturn : 23.511627197265625
Train_StdReturn : 4.122384071350098
Train_MaxReturn : 34.0
Train_MinReturn : 17.0
Train_AverageEpLen : 23.511627906976745
Actor Loss : 6881.44873046875
Train_EnvstepsSoFar : 4037
TimeSinceStart : 4.609002113342285
Done logging...



********** Iteration 4 ************

Collecting data for eval...
Eval_AverageReturn : 22.66666603088379
Eval_StdReturn : 3.448026657104492
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.666666666666668
Train_AverageReturn : 22.93181800842285
Train_StdReturn : 4.019258975982666
Train_MaxReturn : 30.0
Train_MinReturn : 16.0
Train_AverageEpLen : 22.931818181818183
Actor Loss : 6078.7080078125
Train_EnvstepsSoFar : 5046
TimeSinceStart : 5.4130425453186035
Done logging...



********** Iteration 5 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 3.7469985485076904
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 21.4255313873291
Train_StdReturn : 4.180729389190674
Train_MaxReturn : 33.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.425531914893618
Actor Loss : 5142.626953125
Train_EnvstepsSoFar : 6053
TimeSinceStart : 6.2093565464019775
Done logging...



********** Iteration 6 ************

Collecting data for eval...
Eval_AverageReturn : 22.27777862548828
Eval_StdReturn : 3.245604991912842
Eval_MaxReturn : 27.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.27777777777778
Train_AverageReturn : 23.06818199157715
Train_StdReturn : 3.839967727661133
Train_MaxReturn : 30.0
Train_MinReturn : 16.0
Train_AverageEpLen : 23.068181818181817
Actor Loss : 4921.88427734375
Train_EnvstepsSoFar : 7068
TimeSinceStart : 7.655202388763428
Done logging...



********** Iteration 7 ************

Collecting data for eval...
Eval_AverageReturn : 23.647058486938477
Eval_StdReturn : 4.100805759429932
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 23.647058823529413
Train_AverageReturn : 23.325580596923828
Train_StdReturn : 4.044640064239502
Train_MaxReturn : 32.0
Train_MinReturn : 17.0
Train_AverageEpLen : 23.325581395348838
Actor Loss : 4341.1962890625
Train_EnvstepsSoFar : 8071
TimeSinceStart : 8.44493579864502
Done logging...



********** Iteration 8 ************

Collecting data for eval...
Eval_AverageReturn : 23.16666603088379
Eval_StdReturn : 3.1666667461395264
Eval_MaxReturn : 33.0
Eval_MinReturn : 19.0
Eval_AverageEpLen : 23.166666666666668
Train_AverageReturn : 21.978260040283203
Train_StdReturn : 3.253687858581543
Train_MaxReturn : 31.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.97826086956522
Actor Loss : 3561.389404296875
Train_EnvstepsSoFar : 9082
TimeSinceStart : 9.695251226425171
Done logging...



********** Iteration 9 ************

Collecting data for eval...
Eval_AverageReturn : 21.473684310913086
Eval_StdReturn : 3.5743002891540527
Eval_MaxReturn : 29.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 21.473684210526315
Train_AverageReturn : 22.488889694213867
Train_StdReturn : 3.964409589767456
Train_MaxReturn : 32.0
Train_MinReturn : 17.0
Train_AverageEpLen : 22.488888888888887
Actor Loss : 3183.484375
Train_EnvstepsSoFar : 10094
TimeSinceStart : 10.490440607070923
Done logging...



********** Iteration 10 ************

Collecting data for eval...
Eval_AverageReturn : 22.88888931274414
Eval_StdReturn : 3.3975300788879395
Eval_MaxReturn : 28.0
Eval_MinReturn : 18.0
Eval_AverageEpLen : 22.88888888888889
Train_AverageReturn : 21.7608699798584
Train_StdReturn : 3.765892744064331
Train_MaxReturn : 32.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.76086956521739
Actor Loss : 2601.18359375
Train_EnvstepsSoFar : 11095
TimeSinceStart : 11.392377614974976
Done logging...



********** Iteration 11 ************

Collecting data for eval...
Eval_AverageReturn : 22.61111068725586
Eval_StdReturn : 4.52325963973999
Eval_MaxReturn : 30.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 22.61111111111111
Train_AverageReturn : 21.851064682006836
Train_StdReturn : 3.524858236312866
Train_MaxReturn : 30.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.851063829787233
Actor Loss : 2270.04443359375
Train_EnvstepsSoFar : 12122
TimeSinceStart : 12.204393863677979
Done logging...



********** Iteration 12 ************

Collecting data for eval...
Eval_AverageReturn : 24.647058486938477
Eval_StdReturn : 4.364848613739014
Eval_MaxReturn : 32.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 24.647058823529413
Train_AverageReturn : 23.255813598632812
Train_StdReturn : 4.605825424194336
Train_MaxReturn : 34.0
Train_MinReturn : 16.0
Train_AverageEpLen : 23.25581395348837
Actor Loss : 1996.731689453125
Train_EnvstepsSoFar : 13122
TimeSinceStart : 13.939631700515747
Done logging...



********** Iteration 13 ************

Collecting data for eval...
Eval_AverageReturn : 23.16666603088379
Eval_StdReturn : 4.099457740783691
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 23.166666666666668
Train_AverageReturn : 22.733333587646484
Train_StdReturn : 4.454211711883545
Train_MaxReturn : 32.0
Train_MinReturn : 16.0
Train_AverageEpLen : 22.733333333333334
Actor Loss : 1650.30126953125
Train_EnvstepsSoFar : 14145
TimeSinceStart : 14.748462438583374
Done logging...



********** Iteration 14 ************

Collecting data for eval...
Eval_AverageReturn : 22.72222137451172
Eval_StdReturn : 3.27966046333313
Eval_MaxReturn : 30.0
Eval_MinReturn : 18.0
Eval_AverageEpLen : 22.72222222222222
Train_AverageReturn : 23.06818199157715
Train_StdReturn : 4.474156856536865
Train_MaxReturn : 32.0
Train_MinReturn : 17.0
Train_AverageEpLen : 23.068181818181817
Actor Loss : 1422.6083984375
Train_EnvstepsSoFar : 15160
TimeSinceStart : 16.489612340927124
Done logging...



********** Iteration 15 ************

Collecting data for eval...
Eval_AverageReturn : 22.44444465637207
Eval_StdReturn : 4.099081516265869
Eval_MaxReturn : 32.0
Eval_MinReturn : 18.0
Eval_AverageEpLen : 22.444444444444443
Train_AverageReturn : 21.510639190673828
Train_StdReturn : 3.7636125087738037
Train_MaxReturn : 28.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.51063829787234
Actor Loss : 1145.453125
Train_EnvstepsSoFar : 16171
TimeSinceStart : 17.29621696472168
Done logging...



********** Iteration 16 ************

Collecting data for eval...
Eval_AverageReturn : 22.77777862548828
Eval_StdReturn : 3.2754228115081787
Eval_MaxReturn : 29.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 22.77777777777778
Train_AverageReturn : 22.288888931274414
Train_StdReturn : 4.107565879821777
Train_MaxReturn : 32.0
Train_MinReturn : 16.0
Train_AverageEpLen : 22.288888888888888
Actor Loss : 947.2357177734375
Train_EnvstepsSoFar : 17174
TimeSinceStart : 18.092148542404175
Done logging...



********** Iteration 17 ************

Collecting data for eval...
Eval_AverageReturn : 22.38888931274414
Eval_StdReturn : 4.057077407836914
Eval_MaxReturn : 32.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 22.38888888888889
Train_AverageReturn : 22.173913955688477
Train_StdReturn : 3.9359233379364014
Train_MaxReturn : 30.0
Train_MinReturn : 16.0
Train_AverageEpLen : 22.17391304347826
Actor Loss : 809.35400390625
Train_EnvstepsSoFar : 18194
TimeSinceStart : 18.910048246383667
Done logging...



********** Iteration 18 ************

Collecting data for eval...
Eval_AverageReturn : 22.3157901763916
Eval_StdReturn : 3.756434917449951
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.31578947368421
Train_AverageReturn : 23.25
Train_StdReturn : 4.3855390548706055
Train_MaxReturn : 32.0
Train_MinReturn : 17.0
Train_AverageEpLen : 23.25
Actor Loss : 729.0712280273438
Train_EnvstepsSoFar : 19217
TimeSinceStart : 20.603847980499268
Done logging...



********** Iteration 19 ************

Collecting data for eval...
Eval_AverageReturn : 22.0
Eval_StdReturn : 3.656285047531128
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.0
Train_AverageReturn : 21.510639190673828
Train_StdReturn : 3.637115716934204
Train_MaxReturn : 30.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.51063829787234
Actor Loss : 540.50439453125
Train_EnvstepsSoFar : 20228
TimeSinceStart : 21.407176971435547
Done logging...



********** Iteration 20 ************

Collecting data for eval...
Eval_AverageReturn : 20.350000381469727
Eval_StdReturn : 3.086664915084839
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.35
Train_AverageReturn : 23.06818199157715
Train_StdReturn : 4.15275239944458
Train_MaxReturn : 33.0
Train_MinReturn : 16.0
Train_AverageEpLen : 23.068181818181817
Actor Loss : 528.9019775390625
Train_EnvstepsSoFar : 21243
TimeSinceStart : 22.218565464019775
Done logging...



********** Iteration 21 ************

Collecting data for eval...
Eval_AverageReturn : 22.210525512695312
Eval_StdReturn : 3.981257915496826
Eval_MaxReturn : 30.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 22.210526315789473
Train_AverageReturn : 21.869565963745117
Train_StdReturn : 4.003306865692139
Train_MaxReturn : 31.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.869565217391305
Actor Loss : 462.34814453125
Train_EnvstepsSoFar : 22249
TimeSinceStart : 23.02389144897461
Done logging...



********** Iteration 22 ************

Collecting data for eval...
Eval_AverageReturn : 21.149999618530273
Eval_StdReturn : 3.863611936569214
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.15
Train_AverageReturn : 21.978260040283203
Train_StdReturn : 4.2039794921875
Train_MaxReturn : 30.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.97826086956522
Actor Loss : 410.2820739746094
Train_EnvstepsSoFar : 23260
TimeSinceStart : 23.84172558784485
Done logging...



********** Iteration 23 ************

Collecting data for eval...
Eval_AverageReturn : 23.823530197143555
Eval_StdReturn : 3.9591338634490967
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 23.823529411764707
Train_AverageReturn : 22.288888931274414
Train_StdReturn : 3.964409589767456
Train_MaxReturn : 32.0
Train_MinReturn : 16.0
Train_AverageEpLen : 22.288888888888888
Actor Loss : 349.212158203125
Train_EnvstepsSoFar : 24263
TimeSinceStart : 24.63141393661499
Done logging...



********** Iteration 24 ************

Collecting data for eval...
Eval_AverageReturn : 22.105262756347656
Eval_StdReturn : 3.338684320449829
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.105263157894736
Train_AverageReturn : 22.46666717529297
Train_StdReturn : 3.9810664653778076
Train_MaxReturn : 32.0
Train_MinReturn : 16.0
Train_AverageEpLen : 22.466666666666665
Actor Loss : 317.6280517578125
Train_EnvstepsSoFar : 25274
TimeSinceStart : 26.368699312210083
Done logging...



********** Iteration 25 ************

Collecting data for eval...
Eval_AverageReturn : 22.44444465637207
Eval_StdReturn : 4.798405170440674
Eval_MaxReturn : 32.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 22.444444444444443
Train_AverageReturn : 21.89130401611328
Train_StdReturn : 3.963026285171509
Train_MaxReturn : 30.0
Train_MinReturn : 17.0
Train_AverageEpLen : 21.891304347826086
Actor Loss : 294.48358154296875
Train_EnvstepsSoFar : 26281
TimeSinceStart : 27.17558193206787
Done logging...



********** Iteration 26 ************

Collecting data for eval...
Eval_AverageReturn : 23.0
Eval_StdReturn : 3.1797971725463867
Eval_MaxReturn : 28.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 23.0
Train_AverageReturn : 21.934782028198242
Train_StdReturn : 3.547210693359375
Train_MaxReturn : 28.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.934782608695652
Actor Loss : 270.96600341796875
Train_EnvstepsSoFar : 27290
TimeSinceStart : 27.970752716064453
Done logging...



********** Iteration 27 ************

Collecting data for eval...
Eval_AverageReturn : 22.66666603088379
Eval_StdReturn : 4.333333492279053
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.666666666666668
Train_AverageReturn : 21.826086044311523
Train_StdReturn : 4.034117221832275
Train_MaxReturn : 30.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.82608695652174
Actor Loss : 266.0521545410156
Train_EnvstepsSoFar : 28294
TimeSinceStart : 28.779053211212158
Done logging...



********** Iteration 28 ************

Collecting data for eval...
Eval_AverageReturn : 22.38888931274414
Eval_StdReturn : 4.084372520446777
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 22.38888888888889
Train_AverageReturn : 21.489360809326172
Train_StdReturn : 3.7352395057678223
Train_MaxReturn : 28.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.48936170212766
Actor Loss : 220.87017822265625
Train_EnvstepsSoFar : 29304
TimeSinceStart : 29.56894564628601
Done logging...



********** Iteration 29 ************

Collecting data for eval...
Eval_AverageReturn : 21.736841201782227
Eval_StdReturn : 3.864032506942749
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.736842105263158
Train_AverageReturn : 21.02083396911621
Train_StdReturn : 3.5088553428649902
Train_MaxReturn : 29.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.020833333333332
Actor Loss : 209.1162872314453
Train_EnvstepsSoFar : 30313
TimeSinceStart : 31.3641676902771
Done logging...



********** Iteration 30 ************

Collecting data for eval...
Eval_AverageReturn : 20.299999237060547
Eval_StdReturn : 3.508561134338379
Eval_MaxReturn : 26.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.3
Train_AverageReturn : 21.36170196533203
Train_StdReturn : 4.1227216720581055
Train_MaxReturn : 31.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.361702127659573
Actor Loss : 189.2314453125
Train_EnvstepsSoFar : 31317
TimeSinceStart : 32.17271590232849
Done logging...



********** Iteration 31 ************

Collecting data for eval...
Eval_AverageReturn : 21.157894134521484
Eval_StdReturn : 3.5874509811401367
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.157894736842106
Train_AverageReturn : 20.83333396911621
Train_StdReturn : 3.6647722721099854
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.833333333333332
Actor Loss : 188.62493896484375
Train_EnvstepsSoFar : 32317
TimeSinceStart : 32.9627423286438
Done logging...



********** Iteration 32 ************

Collecting data for eval...
Eval_AverageReturn : 20.75
Eval_StdReturn : 4.181805610656738
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.75
Train_AverageReturn : 21.680850982666016
Train_StdReturn : 4.136533737182617
Train_MaxReturn : 32.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.680851063829788
Actor Loss : 163.337158203125
Train_EnvstepsSoFar : 33336
TimeSinceStart : 33.77196288108826
Done logging...



********** Iteration 33 ************

Collecting data for eval...
Eval_AverageReturn : 20.200000762939453
Eval_StdReturn : 3.1240997314453125
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.2
Train_AverageReturn : 21.489360809326172
Train_StdReturn : 3.6778366565704346
Train_MaxReturn : 28.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.48936170212766
Actor Loss : 165.52066040039062
Train_EnvstepsSoFar : 34346
TimeSinceStart : 34.5741765499115
Done logging...



********** Iteration 34 ************

Collecting data for eval...
Eval_AverageReturn : 21.157894134521484
Eval_StdReturn : 4.416037082672119
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.157894736842106
Train_AverageReturn : 20.97916603088379
Train_StdReturn : 3.9554266929626465
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.979166666666668
Actor Loss : 176.46749877929688
Train_EnvstepsSoFar : 35353
TimeSinceStart : 35.36896014213562
Done logging...



********** Iteration 35 ************

Collecting data for eval...
Eval_AverageReturn : 19.238094329833984
Eval_StdReturn : 3.490187168121338
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.238095238095237
Train_AverageReturn : 21.20833396911621
Train_StdReturn : 4.257142543792725
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.208333333333332
Actor Loss : 186.59613037109375
Train_EnvstepsSoFar : 36371
TimeSinceStart : 36.17875790596008
Done logging...



********** Iteration 36 ************

Collecting data for eval...
Eval_AverageReturn : 21.157894134521484
Eval_StdReturn : 3.557988166809082
Eval_MaxReturn : 29.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 21.157894736842106
Train_AverageReturn : 21.0
Train_StdReturn : 3.6514837741851807
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.0
Actor Loss : 138.94668579101562
Train_EnvstepsSoFar : 37379
TimeSinceStart : 37.67044925689697
Done logging...



********** Iteration 37 ************

Collecting data for eval...
Eval_AverageReturn : 21.421052932739258
Eval_StdReturn : 3.1341209411621094
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.42105263157895
Train_AverageReturn : 20.440000534057617
Train_StdReturn : 3.4476659297943115
Train_MaxReturn : 28.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.44
Actor Loss : 137.06756591796875
Train_EnvstepsSoFar : 38401
TimeSinceStart : 38.50245499610901
Done logging...



********** Iteration 38 ************

Collecting data for eval...
Eval_AverageReturn : 21.63157844543457
Eval_StdReturn : 3.7305357456207275
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.63157894736842
Train_AverageReturn : 20.816326141357422
Train_StdReturn : 3.520630121231079
Train_MaxReturn : 29.0
Train_MinReturn : 16.0
Train_AverageEpLen : 20.816326530612244
Actor Loss : 124.9046630859375
Train_EnvstepsSoFar : 39421
TimeSinceStart : 39.34687161445618
Done logging...



********** Iteration 39 ************

Collecting data for eval...
Eval_AverageReturn : 21.157894134521484
Eval_StdReturn : 4.93391227722168
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.157894736842106
Train_AverageReturn : 22.266666412353516
Train_StdReturn : 4.0792155265808105
Train_MaxReturn : 30.0
Train_MinReturn : 16.0
Train_AverageEpLen : 22.266666666666666
Actor Loss : 126.09451293945312
Train_EnvstepsSoFar : 40423
TimeSinceStart : 40.542059898376465
Done logging...



********** Iteration 40 ************

Collecting data for eval...
Eval_AverageReturn : 21.842105865478516
Eval_StdReturn : 4.91253137588501
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.842105263157894
Train_AverageReturn : 21.375
Train_StdReturn : 4.585416316986084
Train_MaxReturn : 32.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.375
Actor Loss : 133.65184020996094
Train_EnvstepsSoFar : 41449
TimeSinceStart : 41.32375359535217
Done logging...



********** Iteration 41 ************

Collecting data for eval...
Eval_AverageReturn : 21.947368621826172
Eval_StdReturn : 4.109983444213867
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.94736842105263
Train_AverageReturn : 21.46808433532715
Train_StdReturn : 4.685201168060303
Train_MaxReturn : 32.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.46808510638298
Actor Loss : 122.08487701416016
Train_EnvstepsSoFar : 42458
TimeSinceStart : 42.11818194389343
Done logging...



********** Iteration 42 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 3.3674917221069336
Eval_MaxReturn : 26.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 20.31999969482422
Train_StdReturn : 3.240000009536743
Train_MaxReturn : 27.0
Train_MinReturn : 16.0
Train_AverageEpLen : 20.32
Actor Loss : 136.46405029296875
Train_EnvstepsSoFar : 43474
TimeSinceStart : 42.917211055755615
Done logging...



********** Iteration 43 ************

Collecting data for eval...
Eval_AverageReturn : 20.75
Eval_StdReturn : 3.41869854927063
Eval_MaxReturn : 26.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.75
Train_AverageReturn : 21.35416603088379
Train_StdReturn : 3.923696994781494
Train_MaxReturn : 30.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.354166666666668
Actor Loss : 131.30926513671875
Train_EnvstepsSoFar : 44499
TimeSinceStart : 44.667206048965454
Done logging...



********** Iteration 44 ************

Collecting data for eval...
Eval_AverageReturn : 21.894737243652344
Eval_StdReturn : 4.216443061828613
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.894736842105264
Train_AverageReturn : 20.714284896850586
Train_StdReturn : 3.8172543048858643
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.714285714285715
Actor Loss : 131.81793212890625
Train_EnvstepsSoFar : 45514
TimeSinceStart : 45.458789587020874
Done logging...



********** Iteration 45 ************

Collecting data for eval...
Eval_AverageReturn : 22.61111068725586
Eval_StdReturn : 3.713921070098877
Eval_MaxReturn : 30.0
Eval_MinReturn : 18.0
Eval_AverageEpLen : 22.61111111111111
Train_AverageReturn : 21.25
Train_StdReturn : 4.210601806640625
Train_MaxReturn : 31.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.25
Actor Loss : 107.25675201416016
Train_EnvstepsSoFar : 46534
TimeSinceStart : 46.23794150352478
Done logging...



********** Iteration 46 ************

Collecting data for eval...
Eval_AverageReturn : 21.0
Eval_StdReturn : 3.492849826812744
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.0
Train_AverageReturn : 21.7391300201416
Train_StdReturn : 4.265304088592529
Train_MaxReturn : 30.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.73913043478261
Actor Loss : 106.6455078125
Train_EnvstepsSoFar : 47534
TimeSinceStart : 47.69453167915344
Done logging...



********** Iteration 47 ************

Collecting data for eval...
Eval_AverageReturn : 21.36842155456543
Eval_StdReturn : 4.067981719970703
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.36842105263158
Train_AverageReturn : 21.14583396911621
Train_StdReturn : 4.010348796844482
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.145833333333332
Actor Loss : 109.92012023925781
Train_EnvstepsSoFar : 48549
TimeSinceStart : 48.46695137023926
Done logging...



********** Iteration 48 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 2.843852996826172
Eval_MaxReturn : 24.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 20.83333396911621
Train_StdReturn : 3.6016972064971924
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.833333333333332
Actor Loss : 116.49610900878906
Train_EnvstepsSoFar : 49549
TimeSinceStart : 49.25404977798462
Done logging...



********** Iteration 49 ************

Collecting data for eval...
Eval_AverageReturn : 20.850000381469727
Eval_StdReturn : 3.636963129043579
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.85
Train_AverageReturn : 20.9375
Train_StdReturn : 4.007317543029785
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.9375
Actor Loss : 99.82687377929688
Train_EnvstepsSoFar : 50554
TimeSinceStart : 50.056967973709106
Done logging...



********** Iteration 50 ************

Collecting data for eval...
Eval_AverageReturn : 20.049999237060547
Eval_StdReturn : 3.6942522525787354
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.05
Train_AverageReturn : 21.382978439331055
Train_StdReturn : 4.179754734039307
Train_MaxReturn : 31.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.382978723404257
Actor Loss : 109.76385498046875
Train_EnvstepsSoFar : 51559
TimeSinceStart : 50.82616710662842
Done logging...



********** Iteration 51 ************

Collecting data for eval...
Eval_AverageReturn : 21.473684310913086
Eval_StdReturn : 3.439223051071167
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.473684210526315
Train_AverageReturn : 21.29787254333496
Train_StdReturn : 4.301978588104248
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.29787234042553
Actor Loss : 91.70039367675781
Train_EnvstepsSoFar : 52560
TimeSinceStart : 51.61272168159485
Done logging...



********** Iteration 52 ************

Collecting data for eval...
Eval_AverageReturn : 21.105262756347656
Eval_StdReturn : 3.6547694206237793
Eval_MaxReturn : 27.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.105263157894736
Train_AverageReturn : 20.95833396911621
Train_StdReturn : 4.107707500457764
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.958333333333332
Actor Loss : 75.54137420654297
Train_EnvstepsSoFar : 53566
TimeSinceStart : 52.3801326751709
Done logging...



********** Iteration 53 ************

Collecting data for eval...
Eval_AverageReturn : 21.299999237060547
Eval_StdReturn : 3.822303056716919
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.3
Train_AverageReturn : 20.612245559692383
Train_StdReturn : 3.6634786128997803
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.612244897959183
Actor Loss : 77.67774200439453
Train_EnvstepsSoFar : 54576
TimeSinceStart : 53.40025758743286
Done logging...



********** Iteration 54 ************

Collecting data for eval...
Eval_AverageReturn : 21.894737243652344
Eval_StdReturn : 4.063894271850586
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.894736842105264
Train_AverageReturn : 20.5
Train_StdReturn : 3.8431758880615234
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.5
Actor Loss : 94.78964233398438
Train_EnvstepsSoFar : 55601
TimeSinceStart : 54.20303678512573
Done logging...



********** Iteration 55 ************

Collecting data for eval...
Eval_AverageReturn : 21.36842155456543
Eval_StdReturn : 2.9057207107543945
Eval_MaxReturn : 27.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.36842105263158
Train_AverageReturn : 21.4255313873291
Train_StdReturn : 3.9288601875305176
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.425531914893618
Actor Loss : 87.27234649658203
Train_EnvstepsSoFar : 56608
TimeSinceStart : 54.96242046356201
Done logging...



********** Iteration 56 ************

Collecting data for eval...
Eval_AverageReturn : 21.052631378173828
Eval_StdReturn : 3.6342475414276123
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.05263157894737
Train_AverageReturn : 20.53061294555664
Train_StdReturn : 4.290958881378174
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.53061224489796
Actor Loss : 127.6171646118164
Train_EnvstepsSoFar : 57614
TimeSinceStart : 55.72847104072571
Done logging...



********** Iteration 57 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 4.269367218017578
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 20.510204315185547
Train_StdReturn : 3.3081374168395996
Train_MaxReturn : 29.0
Train_MinReturn : 16.0
Train_AverageEpLen : 20.510204081632654
Actor Loss : 70.11760711669922
Train_EnvstepsSoFar : 58619
TimeSinceStart : 56.903279304504395
Done logging...



********** Iteration 58 ************

Collecting data for eval...
Eval_AverageReturn : 20.700000762939453
Eval_StdReturn : 3.648287296295166
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.7
Train_AverageReturn : 19.66666603088379
Train_StdReturn : 3.7503812313079834
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.666666666666668
Actor Loss : 80.4661865234375
Train_EnvstepsSoFar : 59622
TimeSinceStart : 57.66097903251648
Done logging...



********** Iteration 59 ************

Collecting data for eval...
Eval_AverageReturn : 19.136363983154297
Eval_StdReturn : 3.4810585975646973
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.136363636363637
Train_AverageReturn : 20.46938705444336
Train_StdReturn : 3.5289013385772705
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.46938775510204
Actor Loss : 68.2447509765625
Train_EnvstepsSoFar : 60625
TimeSinceStart : 58.40784311294556
Done logging...



********** Iteration 60 ************

Collecting data for eval...
Eval_AverageReturn : 21.210525512695312
Eval_StdReturn : 3.121722936630249
Eval_MaxReturn : 25.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.210526315789473
Train_AverageReturn : 21.0
Train_StdReturn : 4.262237071990967
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.0
Actor Loss : 79.02066040039062
Train_EnvstepsSoFar : 61633
TimeSinceStart : 59.500755310058594
Done logging...



********** Iteration 61 ************

Collecting data for eval...
Eval_AverageReturn : 21.473684310913086
Eval_StdReturn : 4.108635425567627
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.473684210526315
Train_AverageReturn : 20.97916603088379
Train_StdReturn : 3.986903429031372
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.979166666666668
Actor Loss : 61.30842208862305
Train_EnvstepsSoFar : 62640
TimeSinceStart : 60.244176626205444
Done logging...



********** Iteration 62 ************

Collecting data for eval...
Eval_AverageReturn : 22.105262756347656
Eval_StdReturn : 3.5227789878845215
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.105263157894736
Train_AverageReturn : 21.340425491333008
Train_StdReturn : 3.8772470951080322
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.340425531914892
Actor Loss : 63.38507843017578
Train_EnvstepsSoFar : 63643
TimeSinceStart : 61.04734826087952
Done logging...



********** Iteration 63 ************

Collecting data for eval...
Eval_AverageReturn : 20.299999237060547
Eval_StdReturn : 3.729611396789551
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.3
Train_AverageReturn : 19.764705657958984
Train_StdReturn : 3.6492719650268555
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.764705882352942
Actor Loss : 75.88924407958984
Train_EnvstepsSoFar : 64651
TimeSinceStart : 61.82912564277649
Done logging...



********** Iteration 64 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 2.5937423706054688
Eval_MaxReturn : 25.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 21.10416603088379
Train_StdReturn : 4.104060649871826
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.104166666666668
Actor Loss : 59.97811508178711
Train_EnvstepsSoFar : 65664
TimeSinceStart : 62.60086488723755
Done logging...



********** Iteration 65 ************

Collecting data for eval...
Eval_AverageReturn : 20.299999237060547
Eval_StdReturn : 4.255584716796875
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.3
Train_AverageReturn : 20.31999969482422
Train_StdReturn : 3.2950873374938965
Train_MaxReturn : 27.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.32
Actor Loss : 62.71186828613281
Train_EnvstepsSoFar : 66680
TimeSinceStart : 63.706191539764404
Done logging...



********** Iteration 66 ************

Collecting data for eval...
Eval_AverageReturn : 20.649999618530273
Eval_StdReturn : 4.077683448791504
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.65
Train_AverageReturn : 19.6862735748291
Train_StdReturn : 3.643367290496826
Train_MaxReturn : 28.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.686274509803923
Actor Loss : 67.77609252929688
Train_EnvstepsSoFar : 67684
TimeSinceStart : 64.48692846298218
Done logging...



********** Iteration 67 ************

Collecting data for eval...
Eval_AverageReturn : 22.83333396911621
Eval_StdReturn : 3.8477985858917236
Eval_MaxReturn : 32.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.833333333333332
Train_AverageReturn : 21.0
Train_StdReturn : 4.097763538360596
Train_MaxReturn : 31.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.0
Actor Loss : 57.30720520019531
Train_EnvstepsSoFar : 68692
TimeSinceStart : 65.24849581718445
Done logging...



********** Iteration 68 ************

Collecting data for eval...
Eval_AverageReturn : 20.799999237060547
Eval_StdReturn : 4.843552589416504
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.8
Train_AverageReturn : 21.16666603088379
Train_StdReturn : 4.3365373611450195
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.166666666666668
Actor Loss : 65.5124740600586
Train_EnvstepsSoFar : 69708
TimeSinceStart : 66.0172278881073
Done logging...



********** Iteration 69 ************

Collecting data for eval...
Eval_AverageReturn : 21.052631378173828
Eval_StdReturn : 3.939993381500244
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.05263157894737
Train_AverageReturn : 21.95652198791504
Train_StdReturn : 4.4230451583862305
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.956521739130434
Actor Loss : 52.042694091796875
Train_EnvstepsSoFar : 70718
TimeSinceStart : 66.79990196228027
Done logging...



********** Iteration 70 ************

Collecting data for eval...
Eval_AverageReturn : 19.428571701049805
Eval_StdReturn : 3.910564661026001
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.428571428571427
Train_AverageReturn : 20.59183692932129
Train_StdReturn : 3.6360909938812256
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.591836734693878
Actor Loss : 55.82225799560547
Train_EnvstepsSoFar : 71727
TimeSinceStart : 67.58095192909241
Done logging...



********** Iteration 71 ************

Collecting data for eval...
Eval_AverageReturn : 21.789474487304688
Eval_StdReturn : 3.301976203918457
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.789473684210527
Train_AverageReturn : 21.36170196533203
Train_StdReturn : 3.7497546672821045
Train_MaxReturn : 28.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.361702127659573
Actor Loss : 57.77637481689453
Train_EnvstepsSoFar : 72731
TimeSinceStart : 68.35013914108276
Done logging...



********** Iteration 72 ************

Collecting data for eval...
Eval_AverageReturn : 20.5
Eval_StdReturn : 3.9051249027252197
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.5
Train_AverageReturn : 20.91666603088379
Train_StdReturn : 4.4433159828186035
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.916666666666668
Actor Loss : 51.866539001464844
Train_EnvstepsSoFar : 73735
TimeSinceStart : 69.11865615844727
Done logging...



********** Iteration 73 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 3.1124749183654785
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 21.0
Train_StdReturn : 4.2328081130981445
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.0
Actor Loss : 71.52782440185547
Train_EnvstepsSoFar : 74743
TimeSinceStart : 69.90803456306458
Done logging...



********** Iteration 74 ************

Collecting data for eval...
Eval_AverageReturn : 20.049999237060547
Eval_StdReturn : 3.99343204498291
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.05
Train_AverageReturn : 20.87755012512207
Train_StdReturn : 3.9930176734924316
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.877551020408163
Actor Loss : 66.14497375488281
Train_EnvstepsSoFar : 75766
TimeSinceStart : 70.67580366134644
Done logging...



********** Iteration 75 ************

Collecting data for eval...
Eval_AverageReturn : 19.14285659790039
Eval_StdReturn : 3.3563828468322754
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 19.142857142857142
Train_AverageReturn : 21.04166603088379
Train_StdReturn : 3.7580931186676025
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.041666666666668
Actor Loss : 52.57646560668945
Train_EnvstepsSoFar : 76776
TimeSinceStart : 71.4440221786499
Done logging...



********** Iteration 76 ************

Collecting data for eval...
Eval_AverageReturn : 21.578947067260742
Eval_StdReturn : 3.5439465045928955
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.57894736842105
Train_AverageReturn : 20.34000015258789
Train_StdReturn : 3.787400007247925
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.34
Actor Loss : 58.193382263183594
Train_EnvstepsSoFar : 77793
TimeSinceStart : 72.23276329040527
Done logging...



********** Iteration 77 ************

Collecting data for eval...
Eval_AverageReturn : 20.5
Eval_StdReturn : 2.991655111312866
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.5
Train_AverageReturn : 20.4489803314209
Train_StdReturn : 3.5574655532836914
Train_MaxReturn : 28.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.448979591836736
Actor Loss : 66.79359436035156
Train_EnvstepsSoFar : 78795
TimeSinceStart : 73.00417304039001
Done logging...



********** Iteration 78 ************

Collecting data for eval...
Eval_AverageReturn : 20.5
Eval_StdReturn : 3.667424201965332
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.5
Train_AverageReturn : 20.428571701049805
Train_StdReturn : 4.135461330413818
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.428571428571427
Actor Loss : 61.2095947265625
Train_EnvstepsSoFar : 79796
TimeSinceStart : 73.77752780914307
Done logging...



********** Iteration 79 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 3.69224214553833
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 20.46938705444336
Train_StdReturn : 3.546208381652832
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.46938775510204
Actor Loss : 62.158958435058594
Train_EnvstepsSoFar : 80799
TimeSinceStart : 74.54085445404053
Done logging...



********** Iteration 80 ************

Collecting data for eval...
Eval_AverageReturn : 20.700000762939453
Eval_StdReturn : 3.21091890335083
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.7
Train_AverageReturn : 21.340425491333008
Train_StdReturn : 3.937147617340088
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.340425531914892
Actor Loss : 50.780052185058594
Train_EnvstepsSoFar : 81802
TimeSinceStart : 75.6581175327301
Done logging...



********** Iteration 81 ************

Collecting data for eval...
Eval_AverageReturn : 21.842105865478516
Eval_StdReturn : 5.546579360961914
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.842105263157894
Train_AverageReturn : 20.200000762939453
Train_StdReturn : 3.789458990097046
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.2
Actor Loss : 53.35529327392578
Train_EnvstepsSoFar : 82812
TimeSinceStart : 76.45552897453308
Done logging...



********** Iteration 82 ************

Collecting data for eval...
Eval_AverageReturn : 21.25
Eval_StdReturn : 4.2646803855896
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.25
Train_AverageReturn : 20.489795684814453
Train_StdReturn : 3.511627435684204
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.489795918367346
Actor Loss : 43.76508712768555
Train_EnvstepsSoFar : 83816
TimeSinceStart : 77.35884428024292
Done logging...



********** Iteration 83 ************

Collecting data for eval...
Eval_AverageReturn : 19.85714340209961
Eval_StdReturn : 3.5761873722076416
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.857142857142858
Train_AverageReturn : 20.571428298950195
Train_StdReturn : 3.7742414474487305
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.571428571428573
Actor Loss : 48.44740295410156
Train_EnvstepsSoFar : 84824
TimeSinceStart : 78.1373450756073
Done logging...



********** Iteration 84 ************

Collecting data for eval...
Eval_AverageReturn : 21.63157844543457
Eval_StdReturn : 4.46283483505249
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.63157894736842
Train_AverageReturn : 19.941177368164062
Train_StdReturn : 4.070033073425293
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.941176470588236
Actor Loss : 41.50048065185547
Train_EnvstepsSoFar : 85841
TimeSinceStart : 78.97500681877136
Done logging...



********** Iteration 85 ************

Collecting data for eval...
Eval_AverageReturn : 19.952381134033203
Eval_StdReturn : 3.7730393409729004
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.952380952380953
Train_AverageReturn : 20.219999313354492
Train_StdReturn : 3.62926983833313
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.22
Actor Loss : 36.918251037597656
Train_EnvstepsSoFar : 86852
TimeSinceStart : 79.71911835670471
Done logging...



********** Iteration 86 ************

Collecting data for eval...
Eval_AverageReturn : 21.894737243652344
Eval_StdReturn : 4.929980754852295
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.894736842105264
Train_AverageReturn : 20.1200008392334
Train_StdReturn : 4.092138767242432
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.12
Actor Loss : 59.139888763427734
Train_EnvstepsSoFar : 87858
TimeSinceStart : 80.47711491584778
Done logging...



********** Iteration 87 ************

Collecting data for eval...
Eval_AverageReturn : 19.85714340209961
Eval_StdReturn : 3.967555522918701
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.857142857142858
Train_AverageReturn : 20.3799991607666
Train_StdReturn : 4.728170871734619
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.38
Actor Loss : 102.76760864257812
Train_EnvstepsSoFar : 88877
TimeSinceStart : 81.2604501247406
Done logging...



********** Iteration 88 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 3.636963129043579
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 19.647058486938477
Train_StdReturn : 3.5303921699523926
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.647058823529413
Actor Loss : 36.36860656738281
Train_EnvstepsSoFar : 89879
TimeSinceStart : 82.03365588188171
Done logging...



********** Iteration 89 ************

Collecting data for eval...
Eval_AverageReturn : 21.789474487304688
Eval_StdReturn : 3.664609670639038
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.789473684210527
Train_AverageReturn : 21.913043975830078
Train_StdReturn : 4.297755241394043
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.91304347826087
Actor Loss : 39.566951751708984
Train_EnvstepsSoFar : 90887
TimeSinceStart : 83.2617084980011
Done logging...



********** Iteration 90 ************

Collecting data for eval...
Eval_AverageReturn : 20.649999618530273
Eval_StdReturn : 3.6779749393463135
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.65
Train_AverageReturn : 21.1875
Train_StdReturn : 2.697655200958252
Train_MaxReturn : 26.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.1875
Actor Loss : 36.190086364746094
Train_EnvstepsSoFar : 91904
TimeSinceStart : 84.04989504814148
Done logging...



********** Iteration 91 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 3.3087007999420166
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 19.69230842590332
Train_StdReturn : 4.176575660705566
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.692307692307693
Actor Loss : 46.037391662597656
Train_EnvstepsSoFar : 92928
TimeSinceStart : 84.82991814613342
Done logging...



********** Iteration 92 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 3.7851686477661133
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 20.280000686645508
Train_StdReturn : 4.2710185050964355
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.28
Actor Loss : 48.375003814697266
Train_EnvstepsSoFar : 93942
TimeSinceStart : 85.61114406585693
Done logging...



********** Iteration 93 ************

Collecting data for eval...
Eval_AverageReturn : 22.77777862548828
Eval_StdReturn : 4.170738697052002
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 22.77777777777778
Train_AverageReturn : 20.510204315185547
Train_StdReturn : 4.403720378875732
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.510204081632654
Actor Loss : 42.118900299072266
Train_EnvstepsSoFar : 94947
TimeSinceStart : 86.3866798877716
Done logging...



********** Iteration 94 ************

Collecting data for eval...
Eval_AverageReturn : 22.22222137451172
Eval_StdReturn : 4.184037685394287
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 22.22222222222222
Train_AverageReturn : 20.34000015258789
Train_StdReturn : 4.032914638519287
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.34
Actor Loss : 58.918212890625
Train_EnvstepsSoFar : 95964
TimeSinceStart : 87.15280938148499
Done logging...



********** Iteration 95 ************

Collecting data for eval...
Eval_AverageReturn : 21.3157901763916
Eval_StdReturn : 4.155562400817871
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.31578947368421
Train_AverageReturn : 20.459999084472656
Train_StdReturn : 4.3183794021606445
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.46
Actor Loss : 49.4716796875
Train_EnvstepsSoFar : 96987
TimeSinceStart : 88.37745714187622
Done logging...



********** Iteration 96 ************

Collecting data for eval...
Eval_AverageReturn : 22.38888931274414
Eval_StdReturn : 4.178501605987549
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 22.38888888888889
Train_AverageReturn : 20.079999923706055
Train_StdReturn : 3.3695106506347656
Train_MaxReturn : 27.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.08
Actor Loss : 51.865562438964844
Train_EnvstepsSoFar : 97991
TimeSinceStart : 89.1593759059906
Done logging...



********** Iteration 97 ************

Collecting data for eval...
Eval_AverageReturn : 18.727272033691406
Eval_StdReturn : 2.799055576324463
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 18.727272727272727
Train_AverageReturn : 21.08333396911621
Train_StdReturn : 4.009537220001221
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.083333333333332
Actor Loss : 48.04164505004883
Train_EnvstepsSoFar : 99003
TimeSinceStart : 89.91980385780334
Done logging...



********** Iteration 98 ************

Collecting data for eval...
Eval_AverageReturn : 19.904762268066406
Eval_StdReturn : 3.7910263538360596
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.904761904761905
Train_AverageReturn : 19.921567916870117
Train_StdReturn : 4.44946813583374
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.92156862745098
Actor Loss : 51.544124603271484
Train_EnvstepsSoFar : 100019
TimeSinceStart : 90.89673638343811
Done logging...



********** Iteration 99 ************

Collecting data for eval...
Eval_AverageReturn : 19.761905670166016
Eval_StdReturn : 3.4490132331848145
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.761904761904763
Train_AverageReturn : 21.3125
Train_StdReturn : 4.637511253356934
Train_MaxReturn : 32.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.3125
Actor Loss : 38.633384704589844
Train_EnvstepsSoFar : 101042
TimeSinceStart : 91.70206332206726
Done logging...



********** Iteration 100 ************

Collecting data for eval...
Eval_AverageReturn : 21.578947067260742
Eval_StdReturn : 3.8156988620758057
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.57894736842105
Train_AverageReturn : 21.20833396911621
Train_StdReturn : 4.0873703956604
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.208333333333332
Actor Loss : 36.111759185791016
Train_EnvstepsSoFar : 102060
TimeSinceStart : 92.49827098846436
Done logging...



********** Iteration 101 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 4.725198268890381
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 19.11320686340332
Train_StdReturn : 3.357112407684326
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.11320754716981
Actor Loss : 51.077938079833984
Train_EnvstepsSoFar : 103073
TimeSinceStart : 93.28573417663574
Done logging...



********** Iteration 102 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 3.8062448501586914
Eval_MaxReturn : 26.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 20.239999771118164
Train_StdReturn : 3.9977993965148926
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.24
Actor Loss : 38.96442413330078
Train_EnvstepsSoFar : 104085
TimeSinceStart : 94.07367825508118
Done logging...



********** Iteration 103 ************

Collecting data for eval...
Eval_AverageReturn : 20.75
Eval_StdReturn : 3.41869854927063
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.75
Train_AverageReturn : 20.020000457763672
Train_StdReturn : 3.9974491596221924
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.02
Actor Loss : 41.07419204711914
Train_EnvstepsSoFar : 105086
TimeSinceStart : 94.86029505729675
Done logging...



********** Iteration 104 ************

Collecting data for eval...
Eval_AverageReturn : 19.095237731933594
Eval_StdReturn : 3.544341564178467
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.095238095238095
Train_AverageReturn : 21.20833396911621
Train_StdReturn : 3.8781349658966064
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.208333333333332
Actor Loss : 28.20882797241211
Train_EnvstepsSoFar : 106104
TimeSinceStart : 95.86201524734497
Done logging...



********** Iteration 105 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 4.425776958465576
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 20.139999389648438
Train_StdReturn : 3.560955047607422
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.14
Actor Loss : 33.52975845336914
Train_EnvstepsSoFar : 107111
TimeSinceStart : 96.63469910621643
Done logging...



********** Iteration 106 ************

Collecting data for eval...
Eval_AverageReturn : 19.380952835083008
Eval_StdReturn : 4.029370307922363
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.38095238095238
Train_AverageReturn : 20.59183692932129
Train_StdReturn : 4.3888468742370605
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.591836734693878
Actor Loss : 34.285118103027344
Train_EnvstepsSoFar : 108120
TimeSinceStart : 97.4030749797821
Done logging...



********** Iteration 107 ************

Collecting data for eval...
Eval_AverageReturn : 21.63157844543457
Eval_StdReturn : 3.132352828979492
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.63157894736842
Train_AverageReturn : 20.020000457763672
Train_StdReturn : 3.8392186164855957
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.02
Actor Loss : 27.414222717285156
Train_EnvstepsSoFar : 109121
TimeSinceStart : 98.16297841072083
Done logging...



********** Iteration 108 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 3.979949712753296
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 21.869565963745117
Train_StdReturn : 4.057246208190918
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.869565217391305
Actor Loss : 19.343143463134766
Train_EnvstepsSoFar : 110127
TimeSinceStart : 99.01650857925415
Done logging...



********** Iteration 109 ************

Collecting data for eval...
Eval_AverageReturn : 19.85714340209961
Eval_StdReturn : 2.6418917179107666
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.857142857142858
Train_AverageReturn : 20.200000762939453
Train_StdReturn : 4.209513187408447
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.2
Actor Loss : 24.70519256591797
Train_EnvstepsSoFar : 111137
TimeSinceStart : 99.93967986106873
Done logging...



********** Iteration 110 ************

Collecting data for eval...
Eval_AverageReturn : 20.700000762939453
Eval_StdReturn : 4.026164531707764
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.7
Train_AverageReturn : 20.079999923706055
Train_StdReturn : 4.048901081085205
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.08
Actor Loss : 21.554718017578125
Train_EnvstepsSoFar : 112141
TimeSinceStart : 100.72347211837769
Done logging...



********** Iteration 111 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 3.953815221786499
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 21.5744686126709
Train_StdReturn : 4.423076152801514
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.574468085106382
Actor Loss : 15.5087251663208
Train_EnvstepsSoFar : 113155
TimeSinceStart : 101.48767137527466
Done logging...



********** Iteration 112 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 4.725198745727539
Eval_MaxReturn : 32.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 20.520000457763672
Train_StdReturn : 4.162883758544922
Train_MaxReturn : 28.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.52
Actor Loss : 20.928936004638672
Train_EnvstepsSoFar : 114181
TimeSinceStart : 102.66226482391357
Done logging...



********** Iteration 113 ************

Collecting data for eval...
Eval_AverageReturn : 21.263158798217773
Eval_StdReturn : 2.8254873752593994
Eval_MaxReturn : 26.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.263157894736842
Train_AverageReturn : 21.14583396911621
Train_StdReturn : 4.0465497970581055
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.145833333333332
Actor Loss : 11.217903137207031
Train_EnvstepsSoFar : 115196
TimeSinceStart : 103.7442696094513
Done logging...



********** Iteration 114 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 3.3087007999420166
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 18.759260177612305
Train_StdReturn : 2.987226963043213
Train_MaxReturn : 27.0
Train_MinReturn : 14.0
Train_AverageEpLen : 18.75925925925926
Actor Loss : 9.565298080444336
Train_EnvstepsSoFar : 116209
TimeSinceStart : 104.50699162483215
Done logging...



********** Iteration 115 ************

Collecting data for eval...
Eval_AverageReturn : 22.33333396911621
Eval_StdReturn : 4.594682693481445
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.333333333333332
Train_AverageReturn : 20.079999923706055
Train_StdReturn : 4.307389259338379
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.08
Actor Loss : 26.054855346679688
Train_EnvstepsSoFar : 117213
TimeSinceStart : 105.28529119491577
Done logging...



********** Iteration 116 ************

Collecting data for eval...
Eval_AverageReturn : 19.31818199157715
Eval_StdReturn : 3.5082547664642334
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.318181818181817
Train_AverageReturn : 19.80392074584961
Train_StdReturn : 3.778264284133911
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.80392156862745
Actor Loss : 44.83271026611328
Train_EnvstepsSoFar : 118223
TimeSinceStart : 106.05876064300537
Done logging...



********** Iteration 117 ************

Collecting data for eval...
Eval_AverageReturn : 21.736841201782227
Eval_StdReturn : 3.6969704627990723
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.736842105263158
Train_AverageReturn : 20.0
Train_StdReturn : 4.0199503898620605
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.0
Actor Loss : 13.846481323242188
Train_EnvstepsSoFar : 119223
TimeSinceStart : 106.82247829437256
Done logging...



********** Iteration 118 ************

Collecting data for eval...
Eval_AverageReturn : 21.0
Eval_StdReturn : 3.8987176418304443
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.0
Train_AverageReturn : 20.693878173828125
Train_StdReturn : 3.802276849746704
Train_MaxReturn : 28.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.693877551020407
Actor Loss : 9.5189208984375
Train_EnvstepsSoFar : 120237
TimeSinceStart : 107.59544324874878
Done logging...



********** Iteration 119 ************

Collecting data for eval...
Eval_AverageReturn : 20.100000381469727
Eval_StdReturn : 3.505709409713745
Eval_MaxReturn : 25.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.1
Train_AverageReturn : 20.260000228881836
Train_StdReturn : 4.607862949371338
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.26
Actor Loss : 42.56105422973633
Train_EnvstepsSoFar : 121250
TimeSinceStart : 108.35208940505981
Done logging...



********** Iteration 120 ************

Collecting data for eval...
Eval_AverageReturn : 19.809524536132812
Eval_StdReturn : 4.271935939788818
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.80952380952381
Train_AverageReturn : 20.139999389648438
Train_StdReturn : 3.4293441772460938
Train_MaxReturn : 27.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.14
Actor Loss : 13.408269882202148
Train_EnvstepsSoFar : 122257
TimeSinceStart : 109.10705065727234
Done logging...



********** Iteration 121 ************

Collecting data for eval...
Eval_AverageReturn : 20.450000762939453
Eval_StdReturn : 4.295055389404297
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.45
Train_AverageReturn : 20.100000381469727
Train_StdReturn : 4.4732537269592285
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.1
Actor Loss : 9.808280944824219
Train_EnvstepsSoFar : 123262
TimeSinceStart : 109.8587863445282
Done logging...



********** Iteration 122 ************

Collecting data for eval...
Eval_AverageReturn : 20.75
Eval_StdReturn : 4.035777568817139
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.75
Train_AverageReturn : 20.85714340209961
Train_StdReturn : 3.8332595825195312
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.857142857142858
Actor Loss : 16.469188690185547
Train_EnvstepsSoFar : 124284
TimeSinceStart : 110.63625502586365
Done logging...



********** Iteration 123 ************

Collecting data for eval...
Eval_AverageReturn : 21.350000381469727
Eval_StdReturn : 4.003436088562012
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.35
Train_AverageReturn : 20.1200008392334
Train_StdReturn : 3.9680728912353516
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.12
Actor Loss : 13.291544914245605
Train_EnvstepsSoFar : 125290
TimeSinceStart : 112.13765239715576
Done logging...



********** Iteration 124 ************

Collecting data for eval...
Eval_AverageReturn : 20.200000762939453
Eval_StdReturn : 3.4438352584838867
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.2
Train_AverageReturn : 20.53061294555664
Train_StdReturn : 3.823141098022461
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.53061224489796
Actor Loss : 15.693279266357422
Train_EnvstepsSoFar : 126296
TimeSinceStart : 113.67496109008789
Done logging...



********** Iteration 125 ************

Collecting data for eval...
Eval_AverageReturn : 20.049999237060547
Eval_StdReturn : 3.9556922912597656
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.05
Train_AverageReturn : 20.4489803314209
Train_StdReturn : 3.7146220207214355
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.448979591836736
Actor Loss : 8.21232795715332
Train_EnvstepsSoFar : 127298
TimeSinceStart : 114.92101263999939
Done logging...



********** Iteration 126 ************

Collecting data for eval...
Eval_AverageReturn : 20.850000381469727
Eval_StdReturn : 3.863612413406372
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.85
Train_AverageReturn : 19.823530197143555
Train_StdReturn : 3.771440029144287
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.823529411764707
Actor Loss : 16.726287841796875
Train_EnvstepsSoFar : 128309
TimeSinceStart : 116.40148949623108
Done logging...



********** Iteration 127 ************

Collecting data for eval...
Eval_AverageReturn : 20.049999237060547
Eval_StdReturn : 4.188973903656006
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.05
Train_AverageReturn : 20.612245559692383
Train_StdReturn : 4.241757392883301
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.612244897959183
Actor Loss : 51.566795349121094
Train_EnvstepsSoFar : 129319
TimeSinceStart : 117.78452634811401
Done logging...



********** Iteration 128 ************

Collecting data for eval...
Eval_AverageReturn : 21.3157901763916
Eval_StdReturn : 3.853264331817627
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.31578947368421
Train_AverageReturn : 20.89583396911621
Train_StdReturn : 4.574565410614014
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.895833333333332
Actor Loss : 18.32158851623535
Train_EnvstepsSoFar : 130322
TimeSinceStart : 118.74297642707825
Done logging...



********** Iteration 129 ************

Collecting data for eval...
Eval_AverageReturn : 20.14285659790039
Eval_StdReturn : 4.257046699523926
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.142857142857142
Train_AverageReturn : 20.693878173828125
Train_StdReturn : 4.590158462524414
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.693877551020407
Actor Loss : 19.10192108154297
Train_EnvstepsSoFar : 131336
TimeSinceStart : 120.2738025188446
Done logging...



********** Iteration 130 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 3.5972211360931396
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 21.22916603088379
Train_StdReturn : 4.402837753295898
Train_MaxReturn : 32.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.229166666666668
Actor Loss : 9.699216842651367
Train_EnvstepsSoFar : 132355
TimeSinceStart : 121.70460033416748
Done logging...



********** Iteration 131 ************

Collecting data for eval...
Eval_AverageReturn : 19.5238094329834
Eval_StdReturn : 3.403346300125122
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.523809523809526
Train_AverageReturn : 21.7608699798584
Train_StdReturn : 3.5764007568359375
Train_MaxReturn : 27.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.76086956521739
Actor Loss : 9.757861137390137
Train_EnvstepsSoFar : 133356
TimeSinceStart : 123.1864366531372
Done logging...



********** Iteration 132 ************

Collecting data for eval...
Eval_AverageReturn : 21.63157844543457
Eval_StdReturn : 3.786548614501953
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.63157894736842
Train_AverageReturn : 19.960784912109375
Train_StdReturn : 3.575300693511963
Train_MaxReturn : 28.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.96078431372549
Actor Loss : 11.032611846923828
Train_EnvstepsSoFar : 134374
TimeSinceStart : 124.57302856445312
Done logging...



********** Iteration 133 ************

Collecting data for eval...
Eval_AverageReturn : 21.473684310913086
Eval_StdReturn : 3.9784739017486572
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.473684210526315
Train_AverageReturn : 19.843137741088867
Train_StdReturn : 4.079468250274658
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.84313725490196
Actor Loss : 46.90169906616211
Train_EnvstepsSoFar : 135386
TimeSinceStart : 126.17369103431702
Done logging...



********** Iteration 134 ************

Collecting data for eval...
Eval_AverageReturn : 19.095237731933594
Eval_StdReturn : 3.890216827392578
Eval_MaxReturn : 26.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.095238095238095
Train_AverageReturn : 21.0
Train_StdReturn : 3.8944404125213623
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.0
Actor Loss : 12.529714584350586
Train_EnvstepsSoFar : 136394
TimeSinceStart : 127.03168177604675
Done logging...



********** Iteration 135 ************

Collecting data for eval...
Eval_AverageReturn : 19.952381134033203
Eval_StdReturn : 4.715487957000732
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.952380952380953
Train_AverageReturn : 20.83333396911621
Train_StdReturn : 3.543381690979004
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.833333333333332
Actor Loss : 13.270981788635254
Train_EnvstepsSoFar : 137394
TimeSinceStart : 128.1039595603943
Done logging...



********** Iteration 136 ************

Collecting data for eval...
Eval_AverageReturn : 20.799999237060547
Eval_StdReturn : 4.226109504699707
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.8
Train_AverageReturn : 20.020000457763672
Train_StdReturn : 4.106044292449951
Train_MaxReturn : 28.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.02
Actor Loss : 14.109819412231445
Train_EnvstepsSoFar : 138395
TimeSinceStart : 129.28388690948486
Done logging...



********** Iteration 137 ************

Collecting data for eval...
Eval_AverageReturn : 19.571428298950195
Eval_StdReturn : 4.042293548583984
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.571428571428573
Train_AverageReturn : 21.08333396911621
Train_StdReturn : 4.025094509124756
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.083333333333332
Actor Loss : 13.641877174377441
Train_EnvstepsSoFar : 139407
TimeSinceStart : 130.31892228126526
Done logging...



********** Iteration 138 ************

Collecting data for eval...
Eval_AverageReturn : 19.571428298950195
Eval_StdReturn : 3.606494665145874
Eval_MaxReturn : 26.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.571428571428573
Train_AverageReturn : 20.87755012512207
Train_StdReturn : 4.008321285247803
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.877551020408163
Actor Loss : 15.954885482788086
Train_EnvstepsSoFar : 140430
TimeSinceStart : 131.55311274528503
Done logging...



********** Iteration 139 ************

Collecting data for eval...
Eval_AverageReturn : 20.049999237060547
Eval_StdReturn : 4.128861904144287
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.05
Train_AverageReturn : 21.02083396911621
Train_StdReturn : 3.550173759460449
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.020833333333332
Actor Loss : 10.53697395324707
Train_EnvstepsSoFar : 141439
TimeSinceStart : 132.58895421028137
Done logging...



********** Iteration 140 ************

Collecting data for eval...
Eval_AverageReturn : 20.850000381469727
Eval_StdReturn : 3.811495780944824
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.85
Train_AverageReturn : 20.571428298950195
Train_StdReturn : 4.050699234008789
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.571428571428573
Actor Loss : 12.891107559204102
Train_EnvstepsSoFar : 142447
TimeSinceStart : 133.61523413658142
Done logging...



********** Iteration 141 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 4.114304542541504
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 20.360000610351562
Train_StdReturn : 4.131633758544922
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.36
Actor Loss : 12.633532524108887
Train_EnvstepsSoFar : 143465
TimeSinceStart : 135.02790665626526
Done logging...



********** Iteration 142 ************

Collecting data for eval...
Eval_AverageReturn : 17.826086044311523
Eval_StdReturn : 2.8384346961975098
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 17.82608695652174
Train_AverageReturn : 20.299999237060547
Train_StdReturn : 3.8170671463012695
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.3
Actor Loss : 12.274078369140625
Train_EnvstepsSoFar : 144480
TimeSinceStart : 136.05174040794373
Done logging...



********** Iteration 143 ************

Collecting data for eval...
Eval_AverageReturn : 21.6842098236084
Eval_StdReturn : 4.013826370239258
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.68421052631579
Train_AverageReturn : 19.921567916870117
Train_StdReturn : 4.153161525726318
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.92156862745098
Actor Loss : 7.225899696350098
Train_EnvstepsSoFar : 145496
TimeSinceStart : 137.32310843467712
Done logging...



********** Iteration 144 ************

Collecting data for eval...
Eval_AverageReturn : 19.952381134033203
Eval_StdReturn : 3.734984874725342
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.952380952380953
Train_AverageReturn : 19.882352828979492
Train_StdReturn : 4.236383438110352
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.88235294117647
Actor Loss : 8.235644340515137
Train_EnvstepsSoFar : 146510
TimeSinceStart : 138.72224473953247
Done logging...



********** Iteration 145 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 4.3405070304870605
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 21.340425491333008
Train_StdReturn : 3.969439744949341
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.340425531914892
Actor Loss : 6.908626556396484
Train_EnvstepsSoFar : 147513
TimeSinceStart : 139.7120976448059
Done logging...



********** Iteration 146 ************

Collecting data for eval...
Eval_AverageReturn : 20.5
Eval_StdReturn : 3.814446210861206
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.5
Train_AverageReturn : 20.020000457763672
Train_StdReturn : 3.865177869796753
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.02
Actor Loss : 5.857237339019775
Train_EnvstepsSoFar : 148514
TimeSinceStart : 141.07693576812744
Done logging...



********** Iteration 147 ************

Collecting data for eval...
Eval_AverageReturn : 20.200000762939453
Eval_StdReturn : 3.5298726558685303
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.2
Train_AverageReturn : 20.420000076293945
Train_StdReturn : 4.669432640075684
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.42
Actor Loss : 8.269204139709473
Train_EnvstepsSoFar : 149535
TimeSinceStart : 142.17121577262878
Done logging...



********** Iteration 148 ************

Collecting data for eval...
Eval_AverageReturn : 20.950000762939453
Eval_StdReturn : 4.510820388793945
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.95
Train_AverageReturn : 20.571428298950195
Train_StdReturn : 3.6421568393707275
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.571428571428573
Actor Loss : 2.844700336456299
Train_EnvstepsSoFar : 150543
TimeSinceStart : 143.3214681148529
Done logging...



********** Iteration 149 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 3.5139012336730957
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 21.10416603088379
Train_StdReturn : 4.459258079528809
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.104166666666668
Actor Loss : 14.781312942504883
Train_EnvstepsSoFar : 151556
TimeSinceStart : 144.7309648990631
Done logging...



********** Iteration 150 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 3.806546449661255
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 20.40816307067871
Train_StdReturn : 4.149837970733643
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.408163265306122
Actor Loss : 5.042989253997803
Train_EnvstepsSoFar : 152556
TimeSinceStart : 146.08142638206482
Done logging...



********** Iteration 151 ************

Collecting data for eval...
Eval_AverageReturn : 19.4761905670166
Eval_StdReturn : 3.141413688659668
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.476190476190474
Train_AverageReturn : 19.615385055541992
Train_StdReturn : 3.8687796592712402
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.615384615384617
Actor Loss : 3.974175453186035
Train_EnvstepsSoFar : 153576
TimeSinceStart : 147.14950132369995
Done logging...



********** Iteration 152 ************

Collecting data for eval...
Eval_AverageReturn : 21.263158798217773
Eval_StdReturn : 4.190742492675781
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.263157894736842
Train_AverageReturn : 21.553192138671875
Train_StdReturn : 4.135001182556152
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.5531914893617
Actor Loss : 8.623176574707031
Train_EnvstepsSoFar : 154589
TimeSinceStart : 148.51538562774658
Done logging...



********** Iteration 153 ************

Collecting data for eval...
Eval_AverageReturn : 19.380952835083008
Eval_StdReturn : 3.511561870574951
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.38095238095238
Train_AverageReturn : 19.075471878051758
Train_StdReturn : 3.6952240467071533
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.07547169811321
Actor Loss : 6.72584342956543
Train_EnvstepsSoFar : 155600
TimeSinceStart : 149.55591082572937
Done logging...



********** Iteration 154 ************

Collecting data for eval...
Eval_AverageReturn : 21.210525512695312
Eval_StdReturn : 4.548902988433838
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.210526315789473
Train_AverageReturn : 19.901960372924805
Train_StdReturn : 3.695545196533203
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.901960784313726
Actor Loss : 2.9762582778930664
Train_EnvstepsSoFar : 156615
TimeSinceStart : 150.52110290527344
Done logging...



********** Iteration 155 ************

Collecting data for eval...
Eval_AverageReturn : 20.200000762939453
Eval_StdReturn : 3.8807215690612793
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.2
Train_AverageReturn : 21.0625
Train_StdReturn : 4.740808010101318
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.0625
Actor Loss : 6.665508270263672
Train_EnvstepsSoFar : 157626
TimeSinceStart : 151.8244709968567
Done logging...



********** Iteration 156 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 4.477443218231201
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 19.72549057006836
Train_StdReturn : 3.9856529235839844
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.725490196078432
Actor Loss : 6.931884288787842
Train_EnvstepsSoFar : 158632
TimeSinceStart : 152.7861611843109
Done logging...



********** Iteration 157 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 3.7434749603271484
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 21.0625
Train_StdReturn : 3.436363458633423
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.0625
Actor Loss : 2.995169162750244
Train_EnvstepsSoFar : 159643
TimeSinceStart : 154.1182930469513
Done logging...



********** Iteration 158 ************

Collecting data for eval...
Eval_AverageReturn : 21.421052932739258
Eval_StdReturn : 4.4875946044921875
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.42105263157895
Train_AverageReturn : 21.125
Train_StdReturn : 3.8113045692443848
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.125
Actor Loss : 2.5032594203948975
Train_EnvstepsSoFar : 160657
TimeSinceStart : 155.1565864086151
Done logging...



********** Iteration 159 ************

Collecting data for eval...
Eval_AverageReturn : 21.100000381469727
Eval_StdReturn : 3.884584665298462
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.1
Train_AverageReturn : 19.72549057006836
Train_StdReturn : 4.279813289642334
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.725490196078432
Actor Loss : 3.4371564388275146
Train_EnvstepsSoFar : 161663
TimeSinceStart : 156.53814888000488
Done logging...



********** Iteration 160 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 4.452317237854004
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 19.72549057006836
Train_StdReturn : 4.419557094573975
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.725490196078432
Actor Loss : 4.991152763366699
Train_EnvstepsSoFar : 162669
TimeSinceStart : 157.7359538078308
Done logging...



********** Iteration 161 ************

Collecting data for eval...
Eval_AverageReturn : 22.55555534362793
Eval_StdReturn : 3.847397804260254
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.555555555555557
Train_AverageReturn : 20.18000030517578
Train_StdReturn : 4.554953575134277
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.18
Actor Loss : 3.0264031887054443
Train_EnvstepsSoFar : 163678
TimeSinceStart : 158.69385242462158
Done logging...



********** Iteration 162 ************

Collecting data for eval...
Eval_AverageReturn : 19.18181800842285
Eval_StdReturn : 4.1190948486328125
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.181818181818183
Train_AverageReturn : 20.816326141357422
Train_StdReturn : 3.9417879581451416
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.816326530612244
Actor Loss : 3.655045509338379
Train_EnvstepsSoFar : 164698
TimeSinceStart : 159.6242551803589
Done logging...



********** Iteration 163 ************

Collecting data for eval...
Eval_AverageReturn : 18.363636016845703
Eval_StdReturn : 3.1844143867492676
Eval_MaxReturn : 26.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 18.363636363636363
Train_AverageReturn : 20.67346954345703
Train_StdReturn : 4.082754611968994
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.6734693877551
Actor Loss : 4.392348289489746
Train_EnvstepsSoFar : 165711
TimeSinceStart : 160.56573295593262
Done logging...



********** Iteration 164 ************

Collecting data for eval...
Eval_AverageReturn : 19.571428298950195
Eval_StdReturn : 3.094871759414673
Eval_MaxReturn : 25.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.571428571428573
Train_AverageReturn : 20.67346954345703
Train_StdReturn : 4.892258644104004
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.6734693877551
Actor Loss : 4.113089561462402
Train_EnvstepsSoFar : 166724
TimeSinceStart : 161.8690378665924
Done logging...



********** Iteration 165 ************

Collecting data for eval...
Eval_AverageReturn : 20.299999237060547
Eval_StdReturn : 4.3829216957092285
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.3
Train_AverageReturn : 20.18000030517578
Train_StdReturn : 3.9632813930511475
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.18
Actor Loss : 4.192224502563477
Train_EnvstepsSoFar : 167733
TimeSinceStart : 162.8618779182434
Done logging...



********** Iteration 166 ************

Collecting data for eval...
Eval_AverageReturn : 20.75
Eval_StdReturn : 3.6176650524139404
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.75
Train_AverageReturn : 20.53061294555664
Train_StdReturn : 3.8761544227600098
Train_MaxReturn : 27.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.53061224489796
Actor Loss : 2.0687785148620605
Train_EnvstepsSoFar : 168739
TimeSinceStart : 164.24566221237183
Done logging...



********** Iteration 167 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 3.9293766021728516
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.83333396911621
Train_StdReturn : 3.8097097873687744
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.833333333333332
Actor Loss : 3.4499659538269043
Train_EnvstepsSoFar : 169739
TimeSinceStart : 165.12444186210632
Done logging...



********** Iteration 168 ************

Collecting data for eval...
Eval_AverageReturn : 22.0
Eval_StdReturn : 3.6992175579071045
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 22.0
Train_AverageReturn : 20.489795684814453
Train_StdReturn : 4.214273452758789
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.489795918367346
Actor Loss : 13.451040267944336
Train_EnvstepsSoFar : 170743
TimeSinceStart : 166.3828363418579
Done logging...



********** Iteration 169 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 4.328972339630127
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 21.16666603088379
Train_StdReturn : 4.28822660446167
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.166666666666668
Actor Loss : 3.020048141479492
Train_EnvstepsSoFar : 171759
TimeSinceStart : 167.89444637298584
Done logging...



********** Iteration 170 ************

Collecting data for eval...
Eval_AverageReturn : 21.052631378173828
Eval_StdReturn : 4.058437347412109
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.05263157894737
Train_AverageReturn : 20.67346954345703
Train_StdReturn : 3.2159533500671387
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.6734693877551
Actor Loss : 3.3685076236724854
Train_EnvstepsSoFar : 172772
TimeSinceStart : 168.9312722682953
Done logging...



********** Iteration 171 ************

Collecting data for eval...
Eval_AverageReturn : 20.049999237060547
Eval_StdReturn : 3.8009867668151855
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.05
Train_AverageReturn : 20.1200008392334
Train_StdReturn : 3.963029146194458
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.12
Actor Loss : 4.033961772918701
Train_EnvstepsSoFar : 173778
TimeSinceStart : 169.96522974967957
Done logging...



********** Iteration 172 ************

Collecting data for eval...
Eval_AverageReturn : 18.545454025268555
Eval_StdReturn : 3.4736316204071045
Eval_MaxReturn : 25.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 18.545454545454547
Train_AverageReturn : 19.882352828979492
Train_StdReturn : 3.7815189361572266
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.88235294117647
Actor Loss : 6.395336151123047
Train_EnvstepsSoFar : 174792
TimeSinceStart : 171.02794885635376
Done logging...



********** Iteration 173 ************

Collecting data for eval...
Eval_AverageReturn : 19.047618865966797
Eval_StdReturn : 3.3162829875946045
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.047619047619047
Train_AverageReturn : 20.755102157592773
Train_StdReturn : 4.172458648681641
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.755102040816325
Actor Loss : 4.164653778076172
Train_EnvstepsSoFar : 175809
TimeSinceStart : 172.00628209114075
Done logging...



********** Iteration 174 ************

Collecting data for eval...
Eval_AverageReturn : 20.14285659790039
Eval_StdReturn : 3.694084405899048
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.142857142857142
Train_AverageReturn : 20.795917510986328
Train_StdReturn : 3.779534339904785
Train_MaxReturn : 27.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.79591836734694
Actor Loss : 3.641862154006958
Train_EnvstepsSoFar : 176828
TimeSinceStart : 173.6304907798767
Done logging...



********** Iteration 175 ************

Collecting data for eval...
Eval_AverageReturn : 19.4761905670166
Eval_StdReturn : 4.181808948516846
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.476190476190474
Train_AverageReturn : 22.93181800842285
Train_StdReturn : 4.180027008056641
Train_MaxReturn : 30.0
Train_MinReturn : 16.0
Train_AverageEpLen : 22.931818181818183
Actor Loss : 4.201505661010742
Train_EnvstepsSoFar : 177837
TimeSinceStart : 174.6930832862854
Done logging...



********** Iteration 176 ************

Collecting data for eval...
Eval_AverageReturn : 18.772727966308594
Eval_StdReturn : 3.4236056804656982
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 18.772727272727273
Train_AverageReturn : 20.612245559692383
Train_StdReturn : 3.6856937408447266
Train_MaxReturn : 27.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.612244897959183
Actor Loss : 2.7155134677886963
Train_EnvstepsSoFar : 178847
TimeSinceStart : 175.74280309677124
Done logging...



********** Iteration 177 ************

Collecting data for eval...
Eval_AverageReturn : 20.285715103149414
Eval_StdReturn : 3.5070388317108154
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.285714285714285
Train_AverageReturn : 20.019607543945312
Train_StdReturn : 3.427056074142456
Train_MaxReturn : 28.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.019607843137255
Actor Loss : 3.4154748916625977
Train_EnvstepsSoFar : 179868
TimeSinceStart : 177.29676008224487
Done logging...



********** Iteration 178 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 4.07247257232666
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 20.83333396911621
Train_StdReturn : 4.422166347503662
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.833333333333332
Actor Loss : 4.014217853546143
Train_EnvstepsSoFar : 180868
TimeSinceStart : 178.81337237358093
Done logging...



********** Iteration 179 ************

Collecting data for eval...
Eval_AverageReturn : 21.210525512695312
Eval_StdReturn : 4.560458660125732
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.210526315789473
Train_AverageReturn : 20.53061294555664
Train_StdReturn : 4.06629753112793
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.53061224489796
Actor Loss : 4.256417274475098
Train_EnvstepsSoFar : 181874
TimeSinceStart : 180.33836674690247
Done logging...



********** Iteration 180 ************

Collecting data for eval...
Eval_AverageReturn : 21.736841201782227
Eval_StdReturn : 4.277752876281738
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.736842105263158
Train_AverageReturn : 20.299999237060547
Train_StdReturn : 4.148493766784668
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.3
Actor Loss : 3.964229106903076
Train_EnvstepsSoFar : 182889
TimeSinceStart : 181.77886843681335
Done logging...



********** Iteration 181 ************

Collecting data for eval...
Eval_AverageReturn : 21.473684310913086
Eval_StdReturn : 3.9652228355407715
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.473684210526315
Train_AverageReturn : 21.10416603088379
Train_StdReturn : 4.0989813804626465
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.104166666666668
Actor Loss : 2.7087035179138184
Train_EnvstepsSoFar : 183902
TimeSinceStart : 182.8044831752777
Done logging...



********** Iteration 182 ************

Collecting data for eval...
Eval_AverageReturn : 20.649999618530273
Eval_StdReturn : 4.430293083190918
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.65
Train_AverageReturn : 20.53061294555664
Train_StdReturn : 4.150741100311279
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.53061224489796
Actor Loss : 3.4291834831237793
Train_EnvstepsSoFar : 184908
TimeSinceStart : 184.0851125717163
Done logging...



********** Iteration 183 ************

Collecting data for eval...
Eval_AverageReturn : 22.210525512695312
Eval_StdReturn : 4.883688449859619
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 22.210526315789473
Train_AverageReturn : 19.784313201904297
Train_StdReturn : 3.727553606033325
Train_MaxReturn : 27.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.784313725490197
Actor Loss : 1.7722301483154297
Train_EnvstepsSoFar : 185917
TimeSinceStart : 185.27899479866028
Done logging...



********** Iteration 184 ************

Collecting data for eval...
Eval_AverageReturn : 19.14285659790039
Eval_StdReturn : 4.1321702003479
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.142857142857142
Train_AverageReturn : 20.260000228881836
Train_StdReturn : 3.8564751148223877
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.26
Actor Loss : 2.8192734718322754
Train_EnvstepsSoFar : 186930
TimeSinceStart : 186.63971519470215
Done logging...



********** Iteration 185 ************

Collecting data for eval...
Eval_AverageReturn : 20.700000762939453
Eval_StdReturn : 3.45108699798584
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.7
Train_AverageReturn : 19.980392456054688
Train_StdReturn : 3.982757806777954
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.980392156862745
Actor Loss : 1.8238005638122559
Train_EnvstepsSoFar : 187949
TimeSinceStart : 187.70625042915344
Done logging...



********** Iteration 186 ************

Collecting data for eval...
Eval_AverageReturn : 20.950000762939453
Eval_StdReturn : 3.8009862899780273
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.95
Train_AverageReturn : 19.764705657958984
Train_StdReturn : 4.066063404083252
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.764705882352942
Actor Loss : 2.8112266063690186
Train_EnvstepsSoFar : 188957
TimeSinceStart : 189.2450716495514
Done logging...



********** Iteration 187 ************

Collecting data for eval...
Eval_AverageReturn : 20.649999618530273
Eval_StdReturn : 3.609363079071045
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.65
Train_AverageReturn : 20.219999313354492
Train_StdReturn : 3.4945099353790283
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.22
Actor Loss : 1.5794284343719482
Train_EnvstepsSoFar : 189968
TimeSinceStart : 190.3498146533966
Done logging...



********** Iteration 188 ************

Collecting data for eval...
Eval_AverageReturn : 19.380952835083008
Eval_StdReturn : 4.498425006866455
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.38095238095238
Train_AverageReturn : 20.83333396911621
Train_StdReturn : 4.099457740783691
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.833333333333332
Actor Loss : 2.3040313720703125
Train_EnvstepsSoFar : 190968
TimeSinceStart : 191.87706422805786
Done logging...



********** Iteration 189 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 3.845451831817627
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 19.188678741455078
Train_StdReturn : 3.48612642288208
Train_MaxReturn : 27.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.18867924528302
Actor Loss : 1.528019905090332
Train_EnvstepsSoFar : 191985
TimeSinceStart : 192.91641521453857
Done logging...



********** Iteration 190 ************

Collecting data for eval...
Eval_AverageReturn : 21.210525512695312
Eval_StdReturn : 4.443551540374756
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.210526315789473
Train_AverageReturn : 20.428571701049805
Train_StdReturn : 4.3141913414001465
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.428571428571427
Actor Loss : 1.5755069255828857
Train_EnvstepsSoFar : 192986
TimeSinceStart : 194.35866022109985
Done logging...



********** Iteration 191 ************

Collecting data for eval...
Eval_AverageReturn : 21.578947067260742
Eval_StdReturn : 4.196687698364258
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.57894736842105
Train_AverageReturn : 20.280000686645508
Train_StdReturn : 4.303672790527344
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.28
Actor Loss : 8.781295776367188
Train_EnvstepsSoFar : 194000
TimeSinceStart : 195.7871904373169
Done logging...



********** Iteration 192 ************

Collecting data for eval...
Eval_AverageReturn : 21.526315689086914
Eval_StdReturn : 3.77482533454895
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.526315789473685
Train_AverageReturn : 20.299999237060547
Train_StdReturn : 3.7376465797424316
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.3
Actor Loss : 2.5930275917053223
Train_EnvstepsSoFar : 195015
TimeSinceStart : 197.3917236328125
Done logging...



********** Iteration 193 ************

Collecting data for eval...
Eval_AverageReturn : 20.700000762939453
Eval_StdReturn : 3.4655447006225586
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.7
Train_AverageReturn : 20.280000686645508
Train_StdReturn : 3.688034772872925
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.28
Actor Loss : 1.1104011535644531
Train_EnvstepsSoFar : 196029
TimeSinceStart : 198.44298887252808
Done logging...



********** Iteration 194 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 3.5972211360931396
Eval_MaxReturn : 26.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.440000534057617
Train_StdReturn : 4.114170551300049
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.44
Actor Loss : 2.4079647064208984
Train_EnvstepsSoFar : 197051
TimeSinceStart : 199.9038441181183
Done logging...



********** Iteration 195 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 4.350574493408203
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 19.823530197143555
Train_StdReturn : 3.5793845653533936
Train_MaxReturn : 28.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.823529411764707
Actor Loss : 1.9362070560455322
Train_EnvstepsSoFar : 198062
TimeSinceStart : 200.71745491027832
Done logging...



********** Iteration 196 ************

Collecting data for eval...
Eval_AverageReturn : 19.66666603088379
Eval_StdReturn : 3.6558279991149902
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.666666666666668
Train_AverageReturn : 20.3799991607666
Train_StdReturn : 4.321527481079102
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.38
Actor Loss : 1.1508071422576904
Train_EnvstepsSoFar : 199081
TimeSinceStart : 201.68394541740417
Done logging...



********** Iteration 197 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 4.352011203765869
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 20.0
Train_StdReturn : 3.9395432472229004
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.0
Actor Loss : 1.1365392208099365
Train_EnvstepsSoFar : 200081
TimeSinceStart : 202.50115323066711
Done logging...



********** Iteration 198 ************

Collecting data for eval...
Eval_AverageReturn : 19.285715103149414
Eval_StdReturn : 3.6402885913848877
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.285714285714285
Train_AverageReturn : 19.86274528503418
Train_StdReturn : 4.182219982147217
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.862745098039216
Actor Loss : 2.0362064838409424
Train_EnvstepsSoFar : 201094
TimeSinceStart : 203.3351912498474
Done logging...



********** Iteration 199 ************

Collecting data for eval...
Eval_AverageReturn : 21.526315689086914
Eval_StdReturn : 4.705746173858643
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.526315789473685
Train_AverageReturn : 20.4489803314209
Train_StdReturn : 4.125882625579834
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.448979591836736
Actor Loss : 2.513540029525757
Train_EnvstepsSoFar : 202096
TimeSinceStart : 204.2961356639862
Done logging...



********** Iteration 200 ************

Collecting data for eval...
Eval_AverageReturn : 21.36842155456543
Eval_StdReturn : 3.390552282333374
Eval_MaxReturn : 29.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 21.36842105263158
Train_AverageReturn : 19.627450942993164
Train_StdReturn : 4.476346492767334
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.627450980392158
Actor Loss : 6.88490104675293
Train_EnvstepsSoFar : 203097
TimeSinceStart : 205.13254475593567
Done logging...



********** Iteration 201 ************

Collecting data for eval...
Eval_AverageReturn : 19.095237731933594
Eval_StdReturn : 3.3224310874938965
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.095238095238095
Train_AverageReturn : 20.0
Train_StdReturn : 4.132795810699463
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.0
Actor Loss : 1.6222676038742065
Train_EnvstepsSoFar : 204097
TimeSinceStart : 205.96468591690063
Done logging...



********** Iteration 202 ************

Collecting data for eval...
Eval_AverageReturn : 20.799999237060547
Eval_StdReturn : 4.6540303230285645
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.8
Train_AverageReturn : 19.901960372924805
Train_StdReturn : 4.131442546844482
Train_MaxReturn : 27.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.901960784313726
Actor Loss : 4.271570682525635
Train_EnvstepsSoFar : 205112
TimeSinceStart : 206.8135061264038
Done logging...



********** Iteration 203 ************

Collecting data for eval...
Eval_AverageReturn : 21.789474487304688
Eval_StdReturn : 4.76366662979126
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.789473684210527
Train_AverageReturn : 19.538461685180664
Train_StdReturn : 4.007020473480225
Train_MaxReturn : 32.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.53846153846154
Actor Loss : 2.629091262817383
Train_EnvstepsSoFar : 206128
TimeSinceStart : 207.6290888786316
Done logging...



********** Iteration 204 ************

Collecting data for eval...
Eval_AverageReturn : 21.0
Eval_StdReturn : 3.5916569232940674
Eval_MaxReturn : 25.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.0
Train_AverageReturn : 21.913043975830078
Train_StdReturn : 4.2108869552612305
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.91304347826087
Actor Loss : 4.0863776206970215
Train_EnvstepsSoFar : 207136
TimeSinceStart : 208.45724296569824
Done logging...



********** Iteration 205 ************

Collecting data for eval...
Eval_AverageReturn : 21.210525512695312
Eval_StdReturn : 4.443551540374756
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.210526315789473
Train_AverageReturn : 20.632652282714844
Train_StdReturn : 3.905484676361084
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.632653061224488
Actor Loss : 1.0695637464523315
Train_EnvstepsSoFar : 208147
TimeSinceStart : 209.25789666175842
Done logging...



********** Iteration 206 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 3.6402885913848877
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 20.40816307067871
Train_StdReturn : 3.752106189727783
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.408163265306122
Actor Loss : 2.739292621612549
Train_EnvstepsSoFar : 209147
TimeSinceStart : 210.07653403282166
Done logging...



********** Iteration 207 ************

Collecting data for eval...
Eval_AverageReturn : 20.799999237060547
Eval_StdReturn : 3.9949967861175537
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.8
Train_AverageReturn : 20.239999771118164
Train_StdReturn : 4.0573883056640625
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.24
Actor Loss : 2.4206058979034424
Train_EnvstepsSoFar : 210159
TimeSinceStart : 210.88027381896973
Done logging...



********** Iteration 208 ************

Collecting data for eval...
Eval_AverageReturn : 21.210525512695312
Eval_StdReturn : 4.862086772918701
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.210526315789473
Train_AverageReturn : 19.745098114013672
Train_StdReturn : 3.777348041534424
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.745098039215687
Actor Loss : 2.1015286445617676
Train_EnvstepsSoFar : 211166
TimeSinceStart : 211.6854796409607
Done logging...



********** Iteration 209 ************

Collecting data for eval...
Eval_AverageReturn : 19.904762268066406
Eval_StdReturn : 3.938875675201416
Eval_MaxReturn : 26.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.904761904761905
Train_AverageReturn : 20.079999923706055
Train_StdReturn : 3.681521415710449
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.08
Actor Loss : 2.8224847316741943
Train_EnvstepsSoFar : 212170
TimeSinceStart : 212.5145263671875
Done logging...



********** Iteration 210 ************

Collecting data for eval...
Eval_AverageReturn : 20.100000381469727
Eval_StdReturn : 4.646503925323486
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.1
Train_AverageReturn : 20.83333396911621
Train_StdReturn : 4.038013935089111
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.833333333333332
Actor Loss : 2.9625954627990723
Train_EnvstepsSoFar : 213170
TimeSinceStart : 213.323561668396
Done logging...



********** Iteration 211 ************

Collecting data for eval...
Eval_AverageReturn : 18.363636016845703
Eval_StdReturn : 3.808429002761841
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 18.363636363636363
Train_AverageReturn : 19.075471878051758
Train_StdReturn : 3.5969011783599854
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.07547169811321
Actor Loss : 4.354822158813477
Train_EnvstepsSoFar : 214181
TimeSinceStart : 214.14970993995667
Done logging...



********** Iteration 212 ************

Collecting data for eval...
Eval_AverageReturn : 21.3157901763916
Eval_StdReturn : 4.205918788909912
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.31578947368421
Train_AverageReturn : 21.02083396911621
Train_StdReturn : 4.327670574188232
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.020833333333332
Actor Loss : 1.745105504989624
Train_EnvstepsSoFar : 215190
TimeSinceStart : 215.46691703796387
Done logging...



********** Iteration 213 ************

Collecting data for eval...
Eval_AverageReturn : 19.380952835083008
Eval_StdReturn : 3.3162827491760254
Eval_MaxReturn : 25.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.38095238095238
Train_AverageReturn : 20.100000381469727
Train_StdReturn : 3.8431756496429443
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.1
Actor Loss : 2.7043404579162598
Train_EnvstepsSoFar : 216195
TimeSinceStart : 216.29679560661316
Done logging...



********** Iteration 214 ************

Collecting data for eval...
Eval_AverageReturn : 20.75
Eval_StdReturn : 4.570284366607666
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.75
Train_AverageReturn : 20.775510787963867
Train_StdReturn : 4.367156505584717
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.775510204081634
Actor Loss : 4.298468112945557
Train_EnvstepsSoFar : 217213
TimeSinceStart : 217.1145532131195
Done logging...



********** Iteration 215 ************

Collecting data for eval...
Eval_AverageReturn : 22.27777862548828
Eval_StdReturn : 3.797741174697876
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.27777777777778
Train_AverageReturn : 21.29166603088379
Train_StdReturn : 4.061805248260498
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.291666666666668
Actor Loss : 0.7346025705337524
Train_EnvstepsSoFar : 218235
TimeSinceStart : 218.08740258216858
Done logging...



********** Iteration 216 ************

Collecting data for eval...
Eval_AverageReturn : 22.105262756347656
Eval_StdReturn : 4.011755466461182
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 22.105263157894736
Train_AverageReturn : 21.08333396911621
Train_StdReturn : 3.8342390060424805
Train_MaxReturn : 28.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.083333333333332
Actor Loss : 0.9171013832092285
Train_EnvstepsSoFar : 219247
TimeSinceStart : 219.01418685913086
Done logging...



********** Iteration 217 ************

Collecting data for eval...
Eval_AverageReturn : 20.75
Eval_StdReturn : 3.8713693618774414
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.75
Train_AverageReturn : 20.428571701049805
Train_StdReturn : 3.6421568393707275
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.428571428571427
Actor Loss : 1.9958598613739014
Train_EnvstepsSoFar : 220248
TimeSinceStart : 219.879727602005
Done logging...



********** Iteration 218 ************

Collecting data for eval...
Eval_AverageReturn : 21.3157901763916
Eval_StdReturn : 3.920964241027832
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.31578947368421
Train_AverageReturn : 20.693878173828125
Train_StdReturn : 4.238810062408447
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.693877551020407
Actor Loss : 15.903423309326172
Train_EnvstepsSoFar : 221262
TimeSinceStart : 221.32566142082214
Done logging...



********** Iteration 219 ************

Collecting data for eval...
Eval_AverageReturn : 20.700000762939453
Eval_StdReturn : 4.786438941955566
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.7
Train_AverageReturn : 20.360000610351562
Train_StdReturn : 4.255631923675537
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.36
Actor Loss : 4.867339134216309
Train_EnvstepsSoFar : 222280
TimeSinceStart : 222.15691566467285
Done logging...



********** Iteration 220 ************

Collecting data for eval...
Eval_AverageReturn : 20.200000762939453
Eval_StdReturn : 4.261455535888672
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.2
Train_AverageReturn : 19.86274528503418
Train_StdReturn : 3.564639091491699
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.862745098039216
Actor Loss : 2.4332053661346436
Train_EnvstepsSoFar : 223293
TimeSinceStart : 223.12749600410461
Done logging...



********** Iteration 221 ************

Collecting data for eval...
Eval_AverageReturn : 21.3157901763916
Eval_StdReturn : 4.389612674713135
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.31578947368421
Train_AverageReturn : 19.596153259277344
Train_StdReturn : 4.243817329406738
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.596153846153847
Actor Loss : 5.140234470367432
Train_EnvstepsSoFar : 224312
TimeSinceStart : 223.93964052200317
Done logging...



********** Iteration 222 ************

Collecting data for eval...
Eval_AverageReturn : 20.299999237060547
Eval_StdReturn : 3.861347198486328
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.3
Train_AverageReturn : 19.882352828979492
Train_StdReturn : 3.9933624267578125
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.88235294117647
Actor Loss : 5.168205261230469
Train_EnvstepsSoFar : 225326
TimeSinceStart : 224.9881672859192
Done logging...



********** Iteration 223 ************

Collecting data for eval...
Eval_AverageReturn : 21.052631378173828
Eval_StdReturn : 4.084291934967041
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.05263157894737
Train_AverageReturn : 20.360000610351562
Train_StdReturn : 4.236791133880615
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.36
Actor Loss : 3.736057758331299
Train_EnvstepsSoFar : 226344
TimeSinceStart : 225.79668283462524
Done logging...



********** Iteration 224 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 3.889408588409424
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 20.755102157592773
Train_StdReturn : 4.46085262298584
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.755102040816325
Actor Loss : 5.54842472076416
Train_EnvstepsSoFar : 227361
TimeSinceStart : 226.607426404953
Done logging...



********** Iteration 225 ************

Collecting data for eval...
Eval_AverageReturn : 22.72222137451172
Eval_StdReturn : 4.419723033905029
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 22.72222222222222
Train_AverageReturn : 20.34000015258789
Train_StdReturn : 4.806704044342041
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.34
Actor Loss : 2.8332271575927734
Train_EnvstepsSoFar : 228378
TimeSinceStart : 227.4186246395111
Done logging...



********** Iteration 226 ************

Collecting data for eval...
Eval_AverageReturn : 19.238094329833984
Eval_StdReturn : 3.099996328353882
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.238095238095237
Train_AverageReturn : 20.058822631835938
Train_StdReturn : 3.9178414344787598
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.058823529411764
Actor Loss : 4.601804256439209
Train_EnvstepsSoFar : 229401
TimeSinceStart : 228.22453355789185
Done logging...



********** Iteration 227 ************

Collecting data for eval...
Eval_AverageReturn : 21.526315689086914
Eval_StdReturn : 4.057072162628174
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.526315789473685
Train_AverageReturn : 21.27083396911621
Train_StdReturn : 3.7457733154296875
Train_MaxReturn : 28.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.270833333333332
Actor Loss : 3.314992904663086
Train_EnvstepsSoFar : 230422
TimeSinceStart : 229.05089783668518
Done logging...



********** Iteration 228 ************

Collecting data for eval...
Eval_AverageReturn : 20.200000762939453
Eval_StdReturn : 4.760252475738525
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.2
Train_AverageReturn : 21.14583396911621
Train_StdReturn : 4.358849048614502
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.145833333333332
Actor Loss : 3.401909828186035
Train_EnvstepsSoFar : 231437
TimeSinceStart : 230.3090271949768
Done logging...



********** Iteration 229 ************

Collecting data for eval...
Eval_AverageReturn : 19.761905670166016
Eval_StdReturn : 3.5976815223693848
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.761904761904763
Train_AverageReturn : 20.239999771118164
Train_StdReturn : 4.174014568328857
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.24
Actor Loss : 1.0359954833984375
Train_EnvstepsSoFar : 232449
TimeSinceStart : 231.56854915618896
Done logging...



********** Iteration 230 ************

Collecting data for eval...
Eval_AverageReturn : 19.190475463867188
Eval_StdReturn : 3.724041223526001
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.19047619047619
Train_AverageReturn : 20.18000030517578
Train_StdReturn : 4.546163082122803
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.18
Actor Loss : 2.3192355632781982
Train_EnvstepsSoFar : 233458
TimeSinceStart : 232.37526607513428
Done logging...



********** Iteration 231 ************

Collecting data for eval...
Eval_AverageReturn : 20.850000381469727
Eval_StdReturn : 3.5535194873809814
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.85
Train_AverageReturn : 20.420000076293945
Train_StdReturn : 3.8889071941375732
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.42
Actor Loss : 1.7280468940734863
Train_EnvstepsSoFar : 234479
TimeSinceStart : 233.9174726009369
Done logging...



********** Iteration 232 ************

Collecting data for eval...
Eval_AverageReturn : 20.100000381469727
Eval_StdReturn : 4.2649736404418945
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.1
Train_AverageReturn : 19.627450942993164
Train_StdReturn : 4.242459297180176
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.627450980392158
Actor Loss : 2.824942111968994
Train_EnvstepsSoFar : 235480
TimeSinceStart : 234.72821068763733
Done logging...



********** Iteration 233 ************

Collecting data for eval...
Eval_AverageReturn : 20.850000381469727
Eval_StdReturn : 3.9531631469726562
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.85
Train_AverageReturn : 20.020000457763672
Train_StdReturn : 3.936953067779541
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.02
Actor Loss : 2.0183820724487305
Train_EnvstepsSoFar : 236481
TimeSinceStart : 235.55473017692566
Done logging...



********** Iteration 234 ************

Collecting data for eval...
Eval_AverageReturn : 20.450000762939453
Eval_StdReturn : 2.6921181678771973
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.45
Train_AverageReturn : 20.489795684814453
Train_StdReturn : 3.714958429336548
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.489795918367346
Actor Loss : 1.5856983661651611
Train_EnvstepsSoFar : 237485
TimeSinceStart : 236.40866255760193
Done logging...



********** Iteration 235 ************

Collecting data for eval...
Eval_AverageReturn : 19.66666603088379
Eval_StdReturn : 3.707564115524292
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.666666666666668
Train_AverageReturn : 20.100000381469727
Train_StdReturn : 4.262628078460693
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.1
Actor Loss : 26.023664474487305
Train_EnvstepsSoFar : 238490
TimeSinceStart : 237.26189613342285
Done logging...



********** Iteration 236 ************

Collecting data for eval...
Eval_AverageReturn : 20.100000381469727
Eval_StdReturn : 3.9484171867370605
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.1
Train_AverageReturn : 20.428571701049805
Train_StdReturn : 3.8913824558258057
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.428571428571427
Actor Loss : 0.9177635908126831
Train_EnvstepsSoFar : 239491
TimeSinceStart : 238.08609747886658
Done logging...



********** Iteration 237 ************

Collecting data for eval...
Eval_AverageReturn : 20.190475463867188
Eval_StdReturn : 4.2607741355896
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.19047619047619
Train_AverageReturn : 18.574073791503906
Train_StdReturn : 3.2975969314575195
Train_MaxReturn : 27.0
Train_MinReturn : 14.0
Train_AverageEpLen : 18.574074074074073
Actor Loss : 1.0843931436538696
Train_EnvstepsSoFar : 240494
TimeSinceStart : 238.91515922546387
Done logging...



********** Iteration 238 ************

Collecting data for eval...
Eval_AverageReturn : 21.263158798217773
Eval_StdReturn : 4.654845714569092
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.263157894736842
Train_AverageReturn : 20.755102157592773
Train_StdReturn : 4.058403015136719
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.755102040816325
Actor Loss : 2.2160396575927734
Train_EnvstepsSoFar : 241511
TimeSinceStart : 240.0233199596405
Done logging...



********** Iteration 239 ************

Collecting data for eval...
Eval_AverageReturn : 21.052631378173828
Eval_StdReturn : 3.939993143081665
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.05263157894737
Train_AverageReturn : 20.85416603088379
Train_StdReturn : 3.696786642074585
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.854166666666668
Actor Loss : 1.624199390411377
Train_EnvstepsSoFar : 242512
TimeSinceStart : 240.82433819770813
Done logging...



********** Iteration 240 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 4.153010845184326
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 20.040000915527344
Train_StdReturn : 4.331096649169922
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.04
Actor Loss : 2.127720832824707
Train_EnvstepsSoFar : 243514
TimeSinceStart : 242.0750617980957
Done logging...



********** Iteration 241 ************

Collecting data for eval...
Eval_AverageReturn : 20.200000762939453
Eval_StdReturn : 3.8935842514038086
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.2
Train_AverageReturn : 20.875
Train_StdReturn : 4.702060699462891
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.875
Actor Loss : 6.245778560638428
Train_EnvstepsSoFar : 244516
TimeSinceStart : 242.9429099559784
Done logging...



********** Iteration 242 ************

Collecting data for eval...
Eval_AverageReturn : 19.14285659790039
Eval_StdReturn : 3.88263201713562
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.142857142857142
Train_AverageReturn : 20.875
Train_StdReturn : 3.778364896774292
Train_MaxReturn : 27.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.875
Actor Loss : 1.942549705505371
Train_EnvstepsSoFar : 245518
TimeSinceStart : 243.75511598587036
Done logging...



********** Iteration 243 ************

Collecting data for eval...
Eval_AverageReturn : 21.842105865478516
Eval_StdReturn : 3.9371798038482666
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.842105263157894
Train_AverageReturn : 20.612245559692383
Train_StdReturn : 3.8693792819976807
Train_MaxReturn : 28.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.612244897959183
Actor Loss : 2.009911060333252
Train_EnvstepsSoFar : 246528
TimeSinceStart : 244.5979528427124
Done logging...



********** Iteration 244 ************

Collecting data for eval...
Eval_AverageReturn : 20.450000762939453
Eval_StdReturn : 3.4420199394226074
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.45
Train_AverageReturn : 19.538461685180664
Train_StdReturn : 3.382429361343384
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.53846153846154
Actor Loss : 2.636988401412964
Train_EnvstepsSoFar : 247544
TimeSinceStart : 245.6753225326538
Done logging...



********** Iteration 245 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 4.466262340545654
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 20.795917510986328
Train_StdReturn : 4.0956902503967285
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.79591836734694
Actor Loss : 2.0543720722198486
Train_EnvstepsSoFar : 248563
TimeSinceStart : 246.5242259502411
Done logging...



********** Iteration 246 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 3.2905166149139404
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 20.459999084472656
Train_StdReturn : 3.453751802444458
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.46
Actor Loss : 1.8282266855239868
Train_EnvstepsSoFar : 249586
TimeSinceStart : 247.39596819877625
Done logging...



********** Iteration 247 ************

Collecting data for eval...
Eval_AverageReturn : 21.049999237060547
Eval_StdReturn : 3.99343204498291
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.05
Train_AverageReturn : 19.823530197143555
Train_StdReturn : 4.236655235290527
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.823529411764707
Actor Loss : 2.349728584289551
Train_EnvstepsSoFar : 250597
TimeSinceStart : 248.30090522766113
Done logging...



********** Iteration 248 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 3.8562610149383545
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 21.04166603088379
Train_StdReturn : 4.163123607635498
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.041666666666668
Actor Loss : 2.203265428543091
Train_EnvstepsSoFar : 251607
TimeSinceStart : 249.42090272903442
Done logging...



********** Iteration 249 ************

Collecting data for eval...
Eval_AverageReturn : 18.727272033691406
Eval_StdReturn : 3.5570905208587646
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 18.727272727272727
Train_AverageReturn : 20.200000762939453
Train_StdReturn : 4.308131694793701
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.2
Actor Loss : 3.0366806983947754
Train_EnvstepsSoFar : 252617
TimeSinceStart : 251.14499187469482
Done logging...



********** Iteration 250 ************

Collecting data for eval...
Eval_AverageReturn : 18.954545974731445
Eval_StdReturn : 3.5480759143829346
Eval_MaxReturn : 25.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 18.954545454545453
Train_AverageReturn : 19.647058486938477
Train_StdReturn : 4.148344993591309
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.647058823529413
Actor Loss : 3.425450086593628
Train_EnvstepsSoFar : 253619
TimeSinceStart : 252.25483679771423
Done logging...



********** Iteration 251 ************

Collecting data for eval...
Eval_AverageReturn : 19.809524536132812
Eval_StdReturn : 4.5734124183654785
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.80952380952381
Train_AverageReturn : 20.428571701049805
Train_StdReturn : 4.184519290924072
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.428571428571427
Actor Loss : 3.317765474319458
Train_EnvstepsSoFar : 254620
TimeSinceStart : 253.36130237579346
Done logging...



********** Iteration 252 ************

Collecting data for eval...
Eval_AverageReturn : 20.649999618530273
Eval_StdReturn : 3.718534469604492
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.65
Train_AverageReturn : 19.6862735748291
Train_StdReturn : 3.7389848232269287
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.686274509803923
Actor Loss : 1.401209831237793
Train_EnvstepsSoFar : 255624
TimeSinceStart : 254.91809701919556
Done logging...



********** Iteration 253 ************

Collecting data for eval...
Eval_AverageReturn : 18.954545974731445
Eval_StdReturn : 3.444063186645508
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 18.954545454545453
Train_AverageReturn : 20.280000686645508
Train_StdReturn : 4.039999961853027
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.28
Actor Loss : 1.3298070430755615
Train_EnvstepsSoFar : 256638
TimeSinceStart : 255.74126386642456
Done logging...



********** Iteration 254 ************

Collecting data for eval...
Eval_AverageReturn : 20.700000762939453
Eval_StdReturn : 5.129327774047852
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.7
Train_AverageReturn : 19.823530197143555
Train_StdReturn : 3.5352890491485596
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.823529411764707
Actor Loss : 3.52591609954834
Train_EnvstepsSoFar : 257649
TimeSinceStart : 256.5599830150604
Done logging...



********** Iteration 255 ************

Collecting data for eval...
Eval_AverageReturn : 19.285715103149414
Eval_StdReturn : 3.6008312702178955
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.285714285714285
Train_AverageReturn : 21.14583396911621
Train_StdReturn : 4.267071723937988
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.145833333333332
Actor Loss : 1.092361569404602
Train_EnvstepsSoFar : 258664
TimeSinceStart : 257.4530289173126
Done logging...



********** Iteration 256 ************

Collecting data for eval...
Eval_AverageReturn : 19.136363983154297
Eval_StdReturn : 3.4548444747924805
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.136363636363637
Train_AverageReturn : 20.73469352722168
Train_StdReturn : 4.139286994934082
Train_MaxReturn : 32.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.73469387755102
Actor Loss : 5.38266134262085
Train_EnvstepsSoFar : 259680
TimeSinceStart : 258.9631428718567
Done logging...



********** Iteration 257 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 4.222262382507324
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 21.84782600402832
Train_StdReturn : 4.889951705932617
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.847826086956523
Actor Loss : 2.081456422805786
Train_EnvstepsSoFar : 260685
TimeSinceStart : 259.78287410736084
Done logging...



********** Iteration 258 ************

Collecting data for eval...
Eval_AverageReturn : 21.052631378173828
Eval_StdReturn : 3.817875862121582
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.05263157894737
Train_AverageReturn : 20.079999923706055
Train_StdReturn : 3.559999942779541
Train_MaxReturn : 28.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.08
Actor Loss : 0.9849276542663574
Train_EnvstepsSoFar : 261689
TimeSinceStart : 261.4803237915039
Done logging...



********** Iteration 259 ************

Collecting data for eval...
Eval_AverageReturn : 20.700000762939453
Eval_StdReturn : 4.627094268798828
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.7
Train_AverageReturn : 20.91666603088379
Train_StdReturn : 4.4433159828186035
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.916666666666668
Actor Loss : 2.514389991760254
Train_EnvstepsSoFar : 262693
TimeSinceStart : 262.3073306083679
Done logging...



********** Iteration 260 ************

Collecting data for eval...
Eval_AverageReturn : 22.105262756347656
Eval_StdReturn : 4.6554412841796875
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 22.105263157894736
Train_AverageReturn : 19.288461685180664
Train_StdReturn : 4.244165897369385
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.28846153846154
Actor Loss : 2.4723410606384277
Train_EnvstepsSoFar : 263696
TimeSinceStart : 263.1334140300751
Done logging...



********** Iteration 261 ************

Collecting data for eval...
Eval_AverageReturn : 18.863636016845703
Eval_StdReturn : 3.781479597091675
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 18.863636363636363
Train_AverageReturn : 20.260000228881836
Train_StdReturn : 4.107602596282959
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.26
Actor Loss : 1.8980939388275146
Train_EnvstepsSoFar : 264709
TimeSinceStart : 264.88700914382935
Done logging...



********** Iteration 262 ************

Collecting data for eval...
Eval_AverageReturn : 18.636363983154297
Eval_StdReturn : 3.1122260093688965
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 18.636363636363637
Train_AverageReturn : 20.5510196685791
Train_StdReturn : 4.281241416931152
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.551020408163264
Actor Loss : 2.1401028633117676
Train_EnvstepsSoFar : 265716
TimeSinceStart : 265.97664523124695
Done logging...



********** Iteration 263 ************

Collecting data for eval...
Eval_AverageReturn : 18.409090042114258
Eval_StdReturn : 4.4072160720825195
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 18.40909090909091
Train_AverageReturn : 20.15999984741211
Train_StdReturn : 3.523407220840454
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.16
Actor Loss : 0.6428942680358887
Train_EnvstepsSoFar : 266724
TimeSinceStart : 266.80033230781555
Done logging...



********** Iteration 264 ************

Collecting data for eval...
Eval_AverageReturn : 19.85714340209961
Eval_StdReturn : 3.45426869392395
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.857142857142858
Train_AverageReturn : 20.73469352722168
Train_StdReturn : 3.8744349479675293
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.73469387755102
Actor Loss : 1.7264149188995361
Train_EnvstepsSoFar : 267740
TimeSinceStart : 267.6352849006653
Done logging...



********** Iteration 265 ************

Collecting data for eval...
Eval_AverageReturn : 19.66666603088379
Eval_StdReturn : 3.7458972930908203
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.666666666666668
Train_AverageReturn : 21.76595687866211
Train_StdReturn : 4.137080669403076
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.76595744680851
Actor Loss : 1.1511532068252563
Train_EnvstepsSoFar : 268763
TimeSinceStart : 268.5629231929779
Done logging...



********** Iteration 266 ************

Collecting data for eval...
Eval_AverageReturn : 19.619047164916992
Eval_StdReturn : 3.4430909156799316
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.61904761904762
Train_AverageReturn : 20.571428298950195
Train_StdReturn : 4.213680267333984
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.571428571428573
Actor Loss : 3.321030616760254
Train_EnvstepsSoFar : 269771
TimeSinceStart : 270.31956911087036
Done logging...



********** Iteration 267 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 3.5205905437469482
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 20.40816307067871
Train_StdReturn : 4.0351433753967285
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.408163265306122
Actor Loss : 0.5785517692565918
Train_EnvstepsSoFar : 270771
TimeSinceStart : 271.19320130348206
Done logging...



********** Iteration 268 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 3.7613162994384766
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 21.46808433532715
Train_StdReturn : 4.584205627441406
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.46808510638298
Actor Loss : 1.054753303527832
Train_EnvstepsSoFar : 271780
TimeSinceStart : 272.07584524154663
Done logging...



********** Iteration 269 ************

Collecting data for eval...
Eval_AverageReturn : 20.100000381469727
Eval_StdReturn : 3.726928949356079
Eval_MaxReturn : 26.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.1
Train_AverageReturn : 20.139999389648438
Train_StdReturn : 4.1905131340026855
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.14
Actor Loss : 1.1562796831130981
Train_EnvstepsSoFar : 272787
TimeSinceStart : 272.8968243598938
Done logging...



********** Iteration 270 ************

Collecting data for eval...
Eval_AverageReturn : 21.299999237060547
Eval_StdReturn : 4.702126979827881
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.3
Train_AverageReturn : 20.4489803314209
Train_StdReturn : 3.7091243267059326
Train_MaxReturn : 28.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.448979591836736
Actor Loss : 0.9296528100967407
Train_EnvstepsSoFar : 273789
TimeSinceStart : 273.726699590683
Done logging...



********** Iteration 271 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 4.684815883636475
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 19.80392074584961
Train_StdReturn : 4.053657531738281
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.80392156862745
Actor Loss : 1.4530073404312134
Train_EnvstepsSoFar : 274799
TimeSinceStart : 274.6131639480591
Done logging...



********** Iteration 272 ************

Collecting data for eval...
Eval_AverageReturn : 20.649999618530273
Eval_StdReturn : 3.0866646766662598
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.65
Train_AverageReturn : 20.510204315185547
Train_StdReturn : 4.734253883361816
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.510204081632654
Actor Loss : 1.6652400493621826
Train_EnvstepsSoFar : 275804
TimeSinceStart : 275.5247120857239
Done logging...



********** Iteration 273 ************

Collecting data for eval...
Eval_AverageReturn : 21.789474487304688
Eval_StdReturn : 4.502384185791016
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.789473684210527
Train_AverageReturn : 19.882352828979492
Train_StdReturn : 3.404996633529663
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.88235294117647
Actor Loss : 1.1088886260986328
Train_EnvstepsSoFar : 276818
TimeSinceStart : 276.62248969078064
Done logging...



********** Iteration 274 ************

Collecting data for eval...
Eval_AverageReturn : 21.842105865478516
Eval_StdReturn : 3.9505252838134766
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.842105263157894
Train_AverageReturn : 20.83333396911621
Train_StdReturn : 4.179978847503662
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.833333333333332
Actor Loss : 0.6287572383880615
Train_EnvstepsSoFar : 277818
TimeSinceStart : 277.4585688114166
Done logging...



********** Iteration 275 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 4.104570388793945
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 20.040000915527344
Train_StdReturn : 3.7997894287109375
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.04
Actor Loss : 0.9300740957260132
Train_EnvstepsSoFar : 278820
TimeSinceStart : 278.27964878082275
Done logging...



********** Iteration 276 ************

Collecting data for eval...
Eval_AverageReturn : 18.18181800842285
Eval_StdReturn : 3.651106595993042
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 18.181818181818183
Train_AverageReturn : 19.6862735748291
Train_StdReturn : 3.691485643386841
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.686274509803923
Actor Loss : 0.8596858978271484
Train_EnvstepsSoFar : 279824
TimeSinceStart : 279.12536215782166
Done logging...



********** Iteration 277 ************

Collecting data for eval...
Eval_AverageReturn : 21.421052932739258
Eval_StdReturn : 3.897580862045288
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.42105263157895
Train_AverageReturn : 21.46808433532715
Train_StdReturn : 3.8858776092529297
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.46808510638298
Actor Loss : 0.8692029714584351
Train_EnvstepsSoFar : 280833
TimeSinceStart : 280.37564063072205
Done logging...



********** Iteration 278 ************

Collecting data for eval...
Eval_AverageReturn : 20.649999618530273
Eval_StdReturn : 4.407663822174072
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.65
Train_AverageReturn : 20.440000534057617
Train_StdReturn : 3.8113512992858887
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.44
Actor Loss : 0.8101568222045898
Train_EnvstepsSoFar : 281855
TimeSinceStart : 281.24006628990173
Done logging...



********** Iteration 279 ************

Collecting data for eval...
Eval_AverageReturn : 19.809524536132812
Eval_StdReturn : 3.7112319469451904
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.80952380952381
Train_AverageReturn : 19.80392074584961
Train_StdReturn : 4.428161144256592
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.80392156862745
Actor Loss : 1.0068720579147339
Train_EnvstepsSoFar : 282865
TimeSinceStart : 282.07572174072266
Done logging...



********** Iteration 280 ************

Collecting data for eval...
Eval_AverageReturn : 19.5238094329834
Eval_StdReturn : 4.193181037902832
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.523809523809526
Train_AverageReturn : 20.9375
Train_StdReturn : 3.837350845336914
Train_MaxReturn : 28.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.9375
Actor Loss : 0.6745309829711914
Train_EnvstepsSoFar : 283870
TimeSinceStart : 282.90550565719604
Done logging...



********** Iteration 281 ************

Collecting data for eval...
Eval_AverageReturn : 22.22222137451172
Eval_StdReturn : 3.2413225173950195
Eval_MaxReturn : 28.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 22.22222222222222
Train_AverageReturn : 20.91666603088379
Train_StdReturn : 4.004337787628174
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.916666666666668
Actor Loss : 0.8160712718963623
Train_EnvstepsSoFar : 284874
TimeSinceStart : 283.7294976711273
Done logging...



********** Iteration 282 ************

Collecting data for eval...
Eval_AverageReturn : 21.473684310913086
Eval_StdReturn : 4.108635425567627
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.473684210526315
Train_AverageReturn : 20.816326141357422
Train_StdReturn : 4.207250595092773
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.816326530612244
Actor Loss : 1.2461451292037964
Train_EnvstepsSoFar : 285894
TimeSinceStart : 284.5634546279907
Done logging...



********** Iteration 283 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 3.4478254318237305
Eval_MaxReturn : 26.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 20.020000457763672
Train_StdReturn : 3.7442753314971924
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.02
Actor Loss : 0.9670295715332031
Train_EnvstepsSoFar : 286895
TimeSinceStart : 285.37977170944214
Done logging...



********** Iteration 284 ************

Collecting data for eval...
Eval_AverageReturn : 21.157894134521484
Eval_StdReturn : 4.944567680358887
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.157894736842106
Train_AverageReturn : 20.85714340209961
Train_StdReturn : 4.417036056518555
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.857142857142858
Actor Loss : 1.3473315238952637
Train_EnvstepsSoFar : 287917
TimeSinceStart : 286.21665120124817
Done logging...



********** Iteration 285 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 4.328971862792969
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.039215087890625
Train_StdReturn : 3.6886725425720215
Train_MaxReturn : 27.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.03921568627451
Actor Loss : 0.7266496419906616
Train_EnvstepsSoFar : 288939
TimeSinceStart : 287.0555820465088
Done logging...



********** Iteration 286 ************

Collecting data for eval...
Eval_AverageReturn : 19.31818199157715
Eval_StdReturn : 3.697497606277466
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.318181818181817
Train_AverageReturn : 20.95833396911621
Train_StdReturn : 4.222747325897217
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.958333333333332
Actor Loss : 2.51179838180542
Train_EnvstepsSoFar : 289945
TimeSinceStart : 287.8885428905487
Done logging...



********** Iteration 287 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 2.7454354763031006
Eval_MaxReturn : 26.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 20.1200008392334
Train_StdReturn : 4.003198623657227
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.12
Actor Loss : 0.44356468319892883
Train_EnvstepsSoFar : 290951
TimeSinceStart : 288.720112323761
Done logging...



********** Iteration 288 ************

Collecting data for eval...
Eval_AverageReturn : 21.36842155456543
Eval_StdReturn : 4.486359596252441
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.36842105263158
Train_AverageReturn : 20.15999984741211
Train_StdReturn : 3.722149610519409
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.16
Actor Loss : 1.539096474647522
Train_EnvstepsSoFar : 291959
TimeSinceStart : 289.5393793582916
Done logging...



********** Iteration 289 ************

Collecting data for eval...
Eval_AverageReturn : 20.649999618530273
Eval_StdReturn : 4.186585903167725
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.65
Train_AverageReturn : 20.91666603088379
Train_StdReturn : 4.39143705368042
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.916666666666668
Actor Loss : 1.1839104890823364
Train_EnvstepsSoFar : 292963
TimeSinceStart : 290.36185359954834
Done logging...



********** Iteration 290 ************

Collecting data for eval...
Eval_AverageReturn : 19.190475463867188
Eval_StdReturn : 3.659548044204712
Eval_MaxReturn : 25.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.19047619047619
Train_AverageReturn : 18.814815521240234
Train_StdReturn : 3.432276487350464
Train_MaxReturn : 27.0
Train_MinReturn : 14.0
Train_AverageEpLen : 18.814814814814813
Actor Loss : 0.8852167129516602
Train_EnvstepsSoFar : 293979
TimeSinceStart : 291.2127845287323
Done logging...



********** Iteration 291 ************

Collecting data for eval...
Eval_AverageReturn : 22.210525512695312
Eval_StdReturn : 4.212499618530273
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 22.210526315789473
Train_AverageReturn : 19.921567916870117
Train_StdReturn : 3.6667191982269287
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.92156862745098
Actor Loss : 0.5540727376937866
Train_EnvstepsSoFar : 294995
TimeSinceStart : 292.0887098312378
Done logging...



********** Iteration 292 ************

Collecting data for eval...
Eval_AverageReturn : 21.210525512695312
Eval_StdReturn : 4.046816825866699
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.210526315789473
Train_AverageReturn : 20.239999771118164
Train_StdReturn : 4.111252784729004
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.24
Actor Loss : 0.4655855894088745
Train_EnvstepsSoFar : 296007
TimeSinceStart : 293.0803573131561
Done logging...



********** Iteration 293 ************

Collecting data for eval...
Eval_AverageReturn : 21.842105865478516
Eval_StdReturn : 4.016585826873779
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.842105263157894
Train_AverageReturn : 20.46938705444336
Train_StdReturn : 4.081326484680176
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.46938775510204
Actor Loss : 1.1340750455856323
Train_EnvstepsSoFar : 297010
TimeSinceStart : 293.9077413082123
Done logging...



********** Iteration 294 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 3.4985711574554443
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 19.843137741088867
Train_StdReturn : 4.0842719078063965
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.84313725490196
Actor Loss : 0.9514479637145996
Train_EnvstepsSoFar : 298022
TimeSinceStart : 294.72636222839355
Done logging...



********** Iteration 295 ************

Collecting data for eval...
Eval_AverageReturn : 19.904762268066406
Eval_StdReturn : 3.3933372497558594
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.904761904761905
Train_AverageReturn : 21.489360809326172
Train_StdReturn : 4.49052095413208
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.48936170212766
Actor Loss : 0.9531347751617432
Train_EnvstepsSoFar : 299032
TimeSinceStart : 295.55804896354675
Done logging...



********** Iteration 296 ************

Collecting data for eval...
Eval_AverageReturn : 19.619047164916992
Eval_StdReturn : 3.734984874725342
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.61904761904762
Train_AverageReturn : 19.843137741088867
Train_StdReturn : 4.491266250610352
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.84313725490196
Actor Loss : 1.1136471033096313
Train_EnvstepsSoFar : 300044
TimeSinceStart : 296.3834128379822
Done logging...



********** Iteration 297 ************

Collecting data for eval...
Eval_AverageReturn : 20.950000762939453
Eval_StdReturn : 4.663421630859375
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.95
Train_AverageReturn : 20.653060913085938
Train_StdReturn : 4.108482837677002
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.653061224489797
Actor Loss : 2.423715353012085
Train_EnvstepsSoFar : 301056
TimeSinceStart : 297.2249891757965
Done logging...



********** Iteration 298 ************

Collecting data for eval...
Eval_AverageReturn : 19.14285659790039
Eval_StdReturn : 3.8456618785858154
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.142857142857142
Train_AverageReturn : 20.875
Train_StdReturn : 3.7562448978424072
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.875
Actor Loss : 1.4274433851242065
Train_EnvstepsSoFar : 302058
TimeSinceStart : 298.0313169956207
Done logging...



********** Iteration 299 ************

Collecting data for eval...
Eval_AverageReturn : 19.5238094329834
Eval_StdReturn : 3.607123374938965
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.523809523809526
Train_AverageReturn : 19.245283126831055
Train_StdReturn : 4.0136823654174805
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.245283018867923
Actor Loss : 8.004523277282715
Train_EnvstepsSoFar : 303078
TimeSinceStart : 298.8611042499542
Done logging...



********** Iteration 300 ************

Collecting data for eval...
Eval_AverageReturn : 21.63157844543457
Eval_StdReturn : 3.012439489364624
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.63157894736842
Train_AverageReturn : 19.784313201904297
Train_StdReturn : 3.7849738597869873
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.784313725490197
Actor Loss : 2.2504019737243652
Train_EnvstepsSoFar : 304087
TimeSinceStart : 300.5988829135895
Done logging...



********** Iteration 301 ************

Collecting data for eval...
Eval_AverageReturn : 21.578947067260742
Eval_StdReturn : 3.717890977859497
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.57894736842105
Train_AverageReturn : 20.755102157592773
Train_StdReturn : 3.66188645362854
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.755102040816325
Actor Loss : 0.7027971744537354
Train_EnvstepsSoFar : 305104
TimeSinceStart : 301.4288260936737
Done logging...



********** Iteration 302 ************

Collecting data for eval...
Eval_AverageReturn : 22.27777862548828
Eval_StdReturn : 4.953176021575928
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 22.27777777777778
Train_AverageReturn : 19.60784339904785
Train_StdReturn : 4.106801509857178
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.607843137254903
Actor Loss : 10.55095100402832
Train_EnvstepsSoFar : 306104
TimeSinceStart : 302.24996852874756
Done logging...



********** Iteration 303 ************

Collecting data for eval...
Eval_AverageReturn : 18.5
Eval_StdReturn : 3.473928928375244
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 18.5
Train_AverageReturn : 20.875
Train_StdReturn : 3.9928321838378906
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.875
Actor Loss : 1.0466876029968262
Train_EnvstepsSoFar : 307106
TimeSinceStart : 303.0649492740631
Done logging...



********** Iteration 304 ************

Collecting data for eval...
Eval_AverageReturn : 19.571428298950195
Eval_StdReturn : 4.552042007446289
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.571428571428573
Train_AverageReturn : 20.510204315185547
Train_StdReturn : 3.6372363567352295
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.510204081632654
Actor Loss : 1.3764748573303223
Train_EnvstepsSoFar : 308111
TimeSinceStart : 303.89354395866394
Done logging...



********** Iteration 305 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 3.320768117904663
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 19.150943756103516
Train_StdReturn : 3.47169828414917
Train_MaxReturn : 26.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.150943396226417
Actor Loss : 1.5409152507781982
Train_EnvstepsSoFar : 309126
TimeSinceStart : 304.71164059638977
Done logging...



********** Iteration 306 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 3.0310888290405273
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 20.100000381469727
Train_StdReturn : 4.153311729431152
Train_MaxReturn : 27.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.1
Actor Loss : 1.3840866088867188
Train_EnvstepsSoFar : 310131
TimeSinceStart : 305.52646350860596
Done logging...



********** Iteration 307 ************

Collecting data for eval...
Eval_AverageReturn : 19.428571701049805
Eval_StdReturn : 3.811903953552246
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.428571428571427
Train_AverageReturn : 20.693878173828125
Train_StdReturn : 4.041640758514404
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.693877551020407
Actor Loss : 2.600397825241089
Train_EnvstepsSoFar : 311145
TimeSinceStart : 306.3455157279968
Done logging...



********** Iteration 308 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 4.288064956665039
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 22.0
Train_StdReturn : 4.19108772277832
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 22.0
Actor Loss : 9.312233924865723
Train_EnvstepsSoFar : 312157
TimeSinceStart : 307.49745059013367
Done logging...



********** Iteration 309 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 3.3401291370391846
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 20.020000457763672
Train_StdReturn : 3.813082695007324
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.02
Actor Loss : 1.8329765796661377
Train_EnvstepsSoFar : 313158
TimeSinceStart : 308.3249034881592
Done logging...



********** Iteration 310 ************

Collecting data for eval...
Eval_AverageReturn : 19.0
Eval_StdReturn : 4.210376739501953
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.0
Train_AverageReturn : 20.46938705444336
Train_StdReturn : 4.086324214935303
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.46938775510204
Actor Loss : 1.3979161977767944
Train_EnvstepsSoFar : 314161
TimeSinceStart : 309.1520745754242
Done logging...



********** Iteration 311 ************

Collecting data for eval...
Eval_AverageReturn : 20.049999237060547
Eval_StdReturn : 4.224630355834961
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.05
Train_AverageReturn : 21.319149017333984
Train_StdReturn : 4.400707721710205
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.319148936170212
Actor Loss : 3.355937957763672
Train_EnvstepsSoFar : 315163
TimeSinceStart : 309.9732925891876
Done logging...



********** Iteration 312 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 4.164132595062256
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 19.11320686340332
Train_StdReturn : 3.694260835647583
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.11320754716981
Actor Loss : 1.0214276313781738
Train_EnvstepsSoFar : 316176
TimeSinceStart : 311.71678042411804
Done logging...



********** Iteration 313 ************

Collecting data for eval...
Eval_AverageReturn : 20.200000762939453
Eval_StdReturn : 3.31058931350708
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.2
Train_AverageReturn : 20.95833396911621
Train_StdReturn : 4.025742053985596
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.958333333333332
Actor Loss : 2.5339651107788086
Train_EnvstepsSoFar : 317182
TimeSinceStart : 313.1123535633087
Done logging...



********** Iteration 314 ************

Collecting data for eval...
Eval_AverageReturn : 20.799999237060547
Eval_StdReturn : 3.695943832397461
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.8
Train_AverageReturn : 20.219999313354492
Train_StdReturn : 4.177511215209961
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.22
Actor Loss : 0.9946928024291992
Train_EnvstepsSoFar : 318193
TimeSinceStart : 314.0927610397339
Done logging...



********** Iteration 315 ************

Collecting data for eval...
Eval_AverageReturn : 21.526315689086914
Eval_StdReturn : 4.452892780303955
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.526315789473685
Train_AverageReturn : 20.219999313354492
Train_StdReturn : 4.1679253578186035
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.22
Actor Loss : 1.243387222290039
Train_EnvstepsSoFar : 319204
TimeSinceStart : 314.92194652557373
Done logging...



********** Iteration 316 ************

Collecting data for eval...
Eval_AverageReturn : 19.619047164916992
Eval_StdReturn : 3.4706411361694336
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.61904761904762
Train_AverageReturn : 19.5
Train_StdReturn : 3.4278273582458496
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.5
Actor Loss : 0.6600539684295654
Train_EnvstepsSoFar : 320218
TimeSinceStart : 315.73236536979675
Done logging...



********** Iteration 317 ************

Collecting data for eval...
Eval_AverageReturn : 20.950000762939453
Eval_StdReturn : 4.043204307556152
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.95
Train_AverageReturn : 20.31999969482422
Train_StdReturn : 4.206851482391357
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.32
Actor Loss : 1.0850684642791748
Train_EnvstepsSoFar : 321234
TimeSinceStart : 316.5676896572113
Done logging...



********** Iteration 318 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 5.003998279571533
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.139999389648438
Train_StdReturn : 3.873034954071045
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.14
Actor Loss : 0.9757816195487976
Train_EnvstepsSoFar : 322241
TimeSinceStart : 317.3915982246399
Done logging...



********** Iteration 319 ************

Collecting data for eval...
Eval_AverageReturn : 19.809524536132812
Eval_StdReturn : 4.227112770080566
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.80952380952381
Train_AverageReturn : 19.384614944458008
Train_StdReturn : 3.7782466411590576
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.384615384615383
Actor Loss : 1.0850675106048584
Train_EnvstepsSoFar : 323249
TimeSinceStart : 318.2346816062927
Done logging...



********** Iteration 320 ************

Collecting data for eval...
Eval_AverageReturn : 22.27777862548828
Eval_StdReturn : 4.699947357177734
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 22.27777777777778
Train_AverageReturn : 20.200000762939453
Train_StdReturn : 3.7416574954986572
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.2
Actor Loss : 0.5244754552841187
Train_EnvstepsSoFar : 324259
TimeSinceStart : 319.0499885082245
Done logging...



********** Iteration 321 ************

Collecting data for eval...
Eval_AverageReturn : 21.36842155456543
Eval_StdReturn : 4.11940860748291
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.36842105263158
Train_AverageReturn : 20.714284896850586
Train_StdReturn : 4.328359127044678
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.714285714285715
Actor Loss : 3.078468084335327
Train_EnvstepsSoFar : 325274
TimeSinceStart : 319.8818337917328
Done logging...



********** Iteration 322 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 3.194382905960083
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 20.5510196685791
Train_StdReturn : 3.747441053390503
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.551020408163264
Actor Loss : 1.1804763078689575
Train_EnvstepsSoFar : 326281
TimeSinceStart : 320.70154571533203
Done logging...



********** Iteration 323 ************

Collecting data for eval...
Eval_AverageReturn : 21.157894134521484
Eval_StdReturn : 4.016585826873779
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.157894736842106
Train_AverageReturn : 21.95652198791504
Train_StdReturn : 4.587111473083496
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.956521739130434
Actor Loss : 1.471325159072876
Train_EnvstepsSoFar : 327291
TimeSinceStart : 321.52946043014526
Done logging...



********** Iteration 324 ************

Collecting data for eval...
Eval_AverageReturn : 21.578947067260742
Eval_StdReturn : 3.9777777194976807
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.57894736842105
Train_AverageReturn : 20.040000915527344
Train_StdReturn : 4.014772891998291
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.04
Actor Loss : 2.388456344604492
Train_EnvstepsSoFar : 328293
TimeSinceStart : 322.3516728878021
Done logging...



********** Iteration 325 ************

Collecting data for eval...
Eval_AverageReturn : 21.200000762939453
Eval_StdReturn : 3.310588836669922
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.2
Train_AverageReturn : 20.1200008392334
Train_StdReturn : 3.1409554481506348
Train_MaxReturn : 26.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.12
Actor Loss : 0.4404942989349365
Train_EnvstepsSoFar : 329299
TimeSinceStart : 323.19461011886597
Done logging...



********** Iteration 326 ************

Collecting data for eval...
Eval_AverageReturn : 20.0
Eval_StdReturn : 3.7416574954986572
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.0
Train_AverageReturn : 19.5
Train_StdReturn : 3.963778257369995
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.5
Actor Loss : 0.7889792919158936
Train_EnvstepsSoFar : 330313
TimeSinceStart : 324.038964509964
Done logging...



********** Iteration 327 ************

Collecting data for eval...
Eval_AverageReturn : 21.894737243652344
Eval_StdReturn : 3.7260780334472656
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.894736842105264
Train_AverageReturn : 20.97916603088379
Train_StdReturn : 4.095167636871338
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.979166666666668
Actor Loss : 1.6108123064041138
Train_EnvstepsSoFar : 331320
TimeSinceStart : 324.96006441116333
Done logging...



********** Iteration 328 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 2.9133315086364746
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 20.755102157592773
Train_StdReturn : 4.259589672088623
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.755102040816325
Actor Loss : 1.4342856407165527
Train_EnvstepsSoFar : 332337
TimeSinceStart : 325.79531478881836
Done logging...



********** Iteration 329 ************

Collecting data for eval...
Eval_AverageReturn : 20.299999237060547
Eval_StdReturn : 3.796050548553467
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.3
Train_AverageReturn : 20.399999618530273
Train_StdReturn : 4.108527660369873
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.4
Actor Loss : 7.715043067932129
Train_EnvstepsSoFar : 333357
TimeSinceStart : 327.545529127121
Done logging...



********** Iteration 330 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 4.329838275909424
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 20.100000381469727
Train_StdReturn : 3.4190640449523926
Train_MaxReturn : 27.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.1
Actor Loss : 0.6372590065002441
Train_EnvstepsSoFar : 334362
TimeSinceStart : 328.3620557785034
Done logging...



********** Iteration 331 ************

Collecting data for eval...
Eval_AverageReturn : 20.75
Eval_StdReturn : 4.097255229949951
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.75
Train_AverageReturn : 20.67346954345703
Train_StdReturn : 4.348998069763184
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.6734693877551
Actor Loss : 1.3190722465515137
Train_EnvstepsSoFar : 335375
TimeSinceStart : 329.2101151943207
Done logging...



********** Iteration 332 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 3.8781440258026123
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 20.100000381469727
Train_StdReturn : 4.167733192443848
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.1
Actor Loss : 0.5872026681900024
Train_EnvstepsSoFar : 336380
TimeSinceStart : 330.038241147995
Done logging...



********** Iteration 333 ************

Collecting data for eval...
Eval_AverageReturn : 22.22222137451172
Eval_StdReturn : 4.184037685394287
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.22222222222222
Train_AverageReturn : 19.941177368164062
Train_StdReturn : 4.504515647888184
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.941176470588236
Actor Loss : 4.017760753631592
Train_EnvstepsSoFar : 337397
TimeSinceStart : 330.94125962257385
Done logging...



********** Iteration 334 ************

Collecting data for eval...
Eval_AverageReturn : 19.33333396911621
Eval_StdReturn : 3.9681270122528076
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.333333333333332
Train_AverageReturn : 21.382978439331055
Train_StdReturn : 4.1336870193481445
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.382978723404257
Actor Loss : 1.6226794719696045
Train_EnvstepsSoFar : 338402
TimeSinceStart : 332.17396450042725
Done logging...



********** Iteration 335 ************

Collecting data for eval...
Eval_AverageReturn : 20.649999618530273
Eval_StdReturn : 3.9531633853912354
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.65
Train_AverageReturn : 20.489795684814453
Train_StdReturn : 4.300557613372803
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.489795918367346
Actor Loss : 1.6356360912322998
Train_EnvstepsSoFar : 339406
TimeSinceStart : 333.2794568538666
Done logging...



********** Iteration 336 ************

Collecting data for eval...
Eval_AverageReturn : 22.36842155456543
Eval_StdReturn : 3.7305355072021484
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.36842105263158
Train_AverageReturn : 21.02083396911621
Train_StdReturn : 4.566588878631592
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.020833333333332
Actor Loss : 1.0946438312530518
Train_EnvstepsSoFar : 340415
TimeSinceStart : 334.29194617271423
Done logging...



********** Iteration 337 ************

Collecting data for eval...
Eval_AverageReturn : 21.157894134521484
Eval_StdReturn : 3.7171459197998047
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.157894736842106
Train_AverageReturn : 21.33333396911621
Train_StdReturn : 4.124789237976074
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.333333333333332
Actor Loss : 1.1349067687988281
Train_EnvstepsSoFar : 341439
TimeSinceStart : 335.12694931030273
Done logging...



********** Iteration 338 ************

Collecting data for eval...
Eval_AverageReturn : 20.200000762939453
Eval_StdReturn : 3.9949967861175537
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.2
Train_AverageReturn : 21.14583396911621
Train_StdReturn : 3.8405163288116455
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.145833333333332
Actor Loss : 0.9906986355781555
Train_EnvstepsSoFar : 342454
TimeSinceStart : 335.96609473228455
Done logging...



********** Iteration 339 ************

Collecting data for eval...
Eval_AverageReturn : 21.63157844543457
Eval_StdReturn : 3.8554203510284424
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.63157894736842
Train_AverageReturn : 20.299999237060547
Train_StdReturn : 4.1916584968566895
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.3
Actor Loss : 1.3330169916152954
Train_EnvstepsSoFar : 343469
TimeSinceStart : 337.8082392215729
Done logging...



********** Iteration 340 ************

Collecting data for eval...
Eval_AverageReturn : 21.049999237060547
Eval_StdReturn : 4.7167253494262695
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.05
Train_AverageReturn : 19.843137741088867
Train_StdReturn : 4.239739894866943
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.84313725490196
Actor Loss : 2.2032086849212646
Train_EnvstepsSoFar : 344481
TimeSinceStart : 338.9287986755371
Done logging...



********** Iteration 341 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 3.7067506313323975
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 21.489360809326172
Train_StdReturn : 3.808570146560669
Train_MaxReturn : 28.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.48936170212766
Actor Loss : 0.697493314743042
Train_EnvstepsSoFar : 345491
TimeSinceStart : 339.95264077186584
Done logging...



********** Iteration 342 ************

Collecting data for eval...
Eval_AverageReturn : 22.36842155456543
Eval_StdReturn : 4.294556140899658
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 22.36842105263158
Train_AverageReturn : 19.647058486938477
Train_StdReturn : 3.5248336791992188
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.647058823529413
Actor Loss : 2.0206003189086914
Train_EnvstepsSoFar : 346493
TimeSinceStart : 340.798654794693
Done logging...



********** Iteration 343 ************

Collecting data for eval...
Eval_AverageReturn : 19.952381134033203
Eval_StdReturn : 3.9698410034179688
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.952380952380953
Train_AverageReturn : 22.22222137451172
Train_StdReturn : 4.755763530731201
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 22.22222222222222
Actor Loss : 2.1100001335144043
Train_EnvstepsSoFar : 347493
TimeSinceStart : 341.7180161476135
Done logging...



********** Iteration 344 ************

Collecting data for eval...
Eval_AverageReturn : 19.090909957885742
Eval_StdReturn : 3.918593406677246
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.09090909090909
Train_AverageReturn : 20.428571701049805
Train_StdReturn : 4.11071252822876
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.428571428571427
Actor Loss : 1.6411097049713135
Train_EnvstepsSoFar : 348494
TimeSinceStart : 342.68394899368286
Done logging...



********** Iteration 345 ************

Collecting data for eval...
Eval_AverageReturn : 19.095237731933594
Eval_StdReturn : 3.1305673122406006
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.095238095238095
Train_AverageReturn : 19.921567916870117
Train_StdReturn : 4.264965057373047
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.92156862745098
Actor Loss : 0.9929636716842651
Train_EnvstepsSoFar : 349510
TimeSinceStart : 343.5103952884674
Done logging...



********** Iteration 346 ************

Collecting data for eval...
Eval_AverageReturn : 21.0
Eval_StdReturn : 4.098780155181885
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.0
Train_AverageReturn : 20.46938705444336
Train_StdReturn : 4.0863237380981445
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.46938775510204
Actor Loss : 1.2151997089385986
Train_EnvstepsSoFar : 350513
TimeSinceStart : 344.37389874458313
Done logging...



********** Iteration 347 ************

Collecting data for eval...
Eval_AverageReturn : 19.809524536132812
Eval_StdReturn : 3.095604658126831
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.80952380952381
Train_AverageReturn : 21.617021560668945
Train_StdReturn : 3.9494311809539795
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.617021276595743
Actor Loss : 0.5424172878265381
Train_EnvstepsSoFar : 351529
TimeSinceStart : 345.3384597301483
Done logging...



********** Iteration 348 ************

Collecting data for eval...
Eval_AverageReturn : 21.3157901763916
Eval_StdReturn : 4.5312089920043945
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.31578947368421
Train_AverageReturn : 19.882352828979492
Train_StdReturn : 3.7134997844696045
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.88235294117647
Actor Loss : 1.719757318496704
Train_EnvstepsSoFar : 352543
TimeSinceStart : 346.70046162605286
Done logging...



********** Iteration 349 ************

Collecting data for eval...
Eval_AverageReturn : 20.350000381469727
Eval_StdReturn : 4.077683448791504
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.35
Train_AverageReturn : 20.219999313354492
Train_StdReturn : 3.360297441482544
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.22
Actor Loss : 0.49443456530570984
Train_EnvstepsSoFar : 353554
TimeSinceStart : 347.60510325431824
Done logging...



********** Iteration 350 ************

Collecting data for eval...
Eval_AverageReturn : 19.904762268066406
Eval_StdReturn : 2.926150321960449
Eval_MaxReturn : 25.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 19.904761904761905
Train_AverageReturn : 19.615385055541992
Train_StdReturn : 3.3920371532440186
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.615384615384617
Actor Loss : 1.133697748184204
Train_EnvstepsSoFar : 354574
TimeSinceStart : 348.80359292030334
Done logging...



********** Iteration 351 ************

Collecting data for eval...
Eval_AverageReturn : 21.3157901763916
Eval_StdReturn : 4.823763847351074
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.31578947368421
Train_AverageReturn : 20.239999771118164
Train_StdReturn : 3.870710611343384
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.24
Actor Loss : 0.5808020830154419
Train_EnvstepsSoFar : 355586
TimeSinceStart : 349.61173605918884
Done logging...



********** Iteration 352 ************

Collecting data for eval...
Eval_AverageReturn : 21.473684310913086
Eval_StdReturn : 4.14688777923584
Eval_MaxReturn : 31.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 21.473684210526315
Train_AverageReturn : 20.239999771118164
Train_StdReturn : 4.268770217895508
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.24
Actor Loss : 0.4877582788467407
Train_EnvstepsSoFar : 356598
TimeSinceStart : 350.4256308078766
Done logging...



********** Iteration 353 ************

Collecting data for eval...
Eval_AverageReturn : 20.100000381469727
Eval_StdReturn : 3.5199434757232666
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.1
Train_AverageReturn : 20.299999237060547
Train_StdReturn : 4.070626735687256
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.3
Actor Loss : 0.3160167932510376
Train_EnvstepsSoFar : 357613
TimeSinceStart : 351.2378544807434
Done logging...



********** Iteration 354 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 4.641928672790527
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 21.89130401611328
Train_StdReturn : 4.569407939910889
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.891304347826086
Actor Loss : 1.0031335353851318
Train_EnvstepsSoFar : 358620
TimeSinceStart : 352.0639705657959
Done logging...



********** Iteration 355 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 2.850877046585083
Eval_MaxReturn : 26.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 19.519229888916016
Train_StdReturn : 3.543631076812744
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.51923076923077
Actor Loss : 1.6144381761550903
Train_EnvstepsSoFar : 359635
TimeSinceStart : 352.90925669670105
Done logging...



********** Iteration 356 ************

Collecting data for eval...
Eval_AverageReturn : 19.904762268066406
Eval_StdReturn : 3.998865842819214
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.904761904761905
Train_AverageReturn : 20.079999923706055
Train_StdReturn : 4.274763107299805
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.08
Actor Loss : 0.7499755024909973
Train_EnvstepsSoFar : 360639
TimeSinceStart : 353.90570282936096
Done logging...



********** Iteration 357 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 4.576843738555908
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 20.200000762939453
Train_StdReturn : 4.0249223709106445
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.2
Actor Loss : 0.39272773265838623
Train_EnvstepsSoFar : 361649
TimeSinceStart : 354.9557807445526
Done logging...



********** Iteration 358 ************

Collecting data for eval...
Eval_AverageReturn : 19.285715103149414
Eval_StdReturn : 3.410667657852173
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.285714285714285
Train_AverageReturn : 21.76595687866211
Train_StdReturn : 4.048707485198975
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.76595744680851
Actor Loss : 0.6800686717033386
Train_EnvstepsSoFar : 362672
TimeSinceStart : 355.79354214668274
Done logging...



********** Iteration 359 ************

Collecting data for eval...
Eval_AverageReturn : 19.66666603088379
Eval_StdReturn : 3.8214097023010254
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.666666666666668
Train_AverageReturn : 20.714284896850586
Train_StdReturn : 3.763411283493042
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.714285714285715
Actor Loss : 0.3967212736606598
Train_EnvstepsSoFar : 363687
TimeSinceStart : 356.68752336502075
Done logging...



********** Iteration 360 ************

Collecting data for eval...
Eval_AverageReturn : 21.149999618530273
Eval_StdReturn : 3.785168409347534
Eval_MaxReturn : 27.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.15
Train_AverageReturn : 20.3799991607666
Train_StdReturn : 4.647106647491455
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.38
Actor Loss : 0.9515377283096313
Train_EnvstepsSoFar : 364706
TimeSinceStart : 357.5087311267853
Done logging...



********** Iteration 361 ************

Collecting data for eval...
Eval_AverageReturn : 19.571428298950195
Eval_StdReturn : 3.3032658100128174
Eval_MaxReturn : 26.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 19.571428571428573
Train_AverageReturn : 20.428571701049805
Train_StdReturn : 4.407785415649414
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.428571428571427
Actor Loss : 0.6149970889091492
Train_EnvstepsSoFar : 365707
TimeSinceStart : 358.3201587200165
Done logging...



********** Iteration 362 ************

Collecting data for eval...
Eval_AverageReturn : 20.75
Eval_StdReturn : 4.322904109954834
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.75
Train_AverageReturn : 20.9375
Train_StdReturn : 3.7215938568115234
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.9375
Actor Loss : 1.4198501110076904
Train_EnvstepsSoFar : 366712
TimeSinceStart : 359.7462453842163
Done logging...



********** Iteration 363 ************

Collecting data for eval...
Eval_AverageReturn : 21.789474487304688
Eval_StdReturn : 5.615569591522217
Eval_MaxReturn : 32.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.789473684210527
Train_AverageReturn : 20.95833396911621
Train_StdReturn : 3.8995635509490967
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.958333333333332
Actor Loss : 0.7821189761161804
Train_EnvstepsSoFar : 367718
TimeSinceStart : 361.33467864990234
Done logging...



********** Iteration 364 ************

Collecting data for eval...
Eval_AverageReturn : 19.047618865966797
Eval_StdReturn : 3.848019599914551
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.047619047619047
Train_AverageReturn : 20.059999465942383
Train_StdReturn : 3.9568166732788086
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.06
Actor Loss : 0.9836046695709229
Train_EnvstepsSoFar : 368721
TimeSinceStart : 362.3500361442566
Done logging...



********** Iteration 365 ************

Collecting data for eval...
Eval_AverageReturn : 19.33333396911621
Eval_StdReturn : 3.06024169921875
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.333333333333332
Train_AverageReturn : 20.73469352722168
Train_StdReturn : 3.4862735271453857
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.73469387755102
Actor Loss : 3.080650806427002
Train_EnvstepsSoFar : 369737
TimeSinceStart : 363.69478845596313
Done logging...



********** Iteration 366 ************

Collecting data for eval...
Eval_AverageReturn : 20.238094329833984
Eval_StdReturn : 3.8656580448150635
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.238095238095237
Train_AverageReturn : 20.34000015258789
Train_StdReturn : 4.259624481201172
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.34
Actor Loss : 0.9027990698814392
Train_EnvstepsSoFar : 370754
TimeSinceStart : 364.6443486213684
Done logging...



********** Iteration 367 ************

Collecting data for eval...
Eval_AverageReturn : 19.809524536132812
Eval_StdReturn : 3.672537088394165
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.80952380952381
Train_AverageReturn : 19.80392074584961
Train_StdReturn : 3.9158780574798584
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.80392156862745
Actor Loss : 1.0775028467178345
Train_EnvstepsSoFar : 371764
TimeSinceStart : 365.48380422592163
Done logging...



********** Iteration 368 ************

Collecting data for eval...
Eval_AverageReturn : 22.3157901763916
Eval_StdReturn : 4.389612674713135
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 22.31578947368421
Train_AverageReturn : 19.30769157409668
Train_StdReturn : 3.603088617324829
Train_MaxReturn : 27.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.307692307692307
Actor Loss : 0.3889981508255005
Train_EnvstepsSoFar : 372768
TimeSinceStart : 366.3139531612396
Done logging...



********** Iteration 369 ************

Collecting data for eval...
Eval_AverageReturn : 20.649999618530273
Eval_StdReturn : 4.126439094543457
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.65
Train_AverageReturn : 20.510204315185547
Train_StdReturn : 3.8232505321502686
Train_MaxReturn : 27.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.510204081632654
Actor Loss : 0.42384544014930725
Train_EnvstepsSoFar : 373773
TimeSinceStart : 367.1270396709442
Done logging...



********** Iteration 370 ************

Collecting data for eval...
Eval_AverageReturn : 19.428571701049805
Eval_StdReturn : 4.112367630004883
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.428571428571427
Train_AverageReturn : 20.714284896850586
Train_StdReturn : 4.295227527618408
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.714285714285715
Actor Loss : 0.4983223080635071
Train_EnvstepsSoFar : 374788
TimeSinceStart : 368.10873460769653
Done logging...



********** Iteration 371 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 3.8765318393707275
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 20.755102157592773
Train_StdReturn : 3.678568124771118
Train_MaxReturn : 27.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.755102040816325
Actor Loss : 0.6610196828842163
Train_EnvstepsSoFar : 375805
TimeSinceStart : 369.25749111175537
Done logging...



********** Iteration 372 ************

Collecting data for eval...
Eval_AverageReturn : 21.736841201782227
Eval_StdReturn : 4.203283309936523
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.736842105263158
Train_AverageReturn : 21.84782600402832
Train_StdReturn : 4.096485137939453
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.847826086956523
Actor Loss : 1.7769663333892822
Train_EnvstepsSoFar : 376810
TimeSinceStart : 370.084112405777
Done logging...



********** Iteration 373 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 4.974686145782471
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 21.53191566467285
Train_StdReturn : 4.067782402038574
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.53191489361702
Actor Loss : 1.8377492427825928
Train_EnvstepsSoFar : 377822
TimeSinceStart : 370.8858938217163
Done logging...



********** Iteration 374 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 3.054095506668091
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 20.40816307067871
Train_StdReturn : 4.2326154708862305
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.408163265306122
Actor Loss : 2.800194263458252
Train_EnvstepsSoFar : 378822
TimeSinceStart : 371.6983141899109
Done logging...



********** Iteration 375 ************

Collecting data for eval...
Eval_AverageReturn : 21.157894134521484
Eval_StdReturn : 4.439809799194336
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.157894736842106
Train_AverageReturn : 21.4255313873291
Train_StdReturn : 4.836671352386475
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.425531914893618
Actor Loss : 1.2705353498458862
Train_EnvstepsSoFar : 379829
TimeSinceStart : 372.4974875450134
Done logging...



********** Iteration 376 ************

Collecting data for eval...
Eval_AverageReturn : 21.63157844543457
Eval_StdReturn : 2.959561347961426
Eval_MaxReturn : 27.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.63157894736842
Train_AverageReturn : 20.632652282714844
Train_StdReturn : 4.094266414642334
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.632653061224488
Actor Loss : 0.7775097489356995
Train_EnvstepsSoFar : 380840
TimeSinceStart : 374.02978014945984
Done logging...



********** Iteration 377 ************

Collecting data for eval...
Eval_AverageReturn : 20.0
Eval_StdReturn : 4.1747541427612305
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.0
Train_AverageReturn : 20.795917510986328
Train_StdReturn : 4.5038743019104
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.79591836734694
Actor Loss : 1.9385414123535156
Train_EnvstepsSoFar : 381859
TimeSinceStart : 375.28975439071655
Done logging...



********** Iteration 378 ************

Collecting data for eval...
Eval_AverageReturn : 19.380952835083008
Eval_StdReturn : 2.999622106552124
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.38095238095238
Train_AverageReturn : 19.764705657958984
Train_StdReturn : 4.114003658294678
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.764705882352942
Actor Loss : 0.5485764741897583
Train_EnvstepsSoFar : 382867
TimeSinceStart : 376.0973250865936
Done logging...



********** Iteration 379 ************

Collecting data for eval...
Eval_AverageReturn : 18.590909957885742
Eval_StdReturn : 2.7905538082122803
Eval_MaxReturn : 23.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 18.59090909090909
Train_AverageReturn : 20.299999237060547
Train_StdReturn : 3.5846898555755615
Train_MaxReturn : 27.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.3
Actor Loss : 1.777437686920166
Train_EnvstepsSoFar : 383882
TimeSinceStart : 376.94424653053284
Done logging...



********** Iteration 380 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 3.832427501678467
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 19.941177368164062
Train_StdReturn : 3.1274356842041016
Train_MaxReturn : 27.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.941176470588236
Actor Loss : 0.9884018898010254
Train_EnvstepsSoFar : 384899
TimeSinceStart : 377.7759301662445
Done logging...



********** Iteration 381 ************

Collecting data for eval...
Eval_AverageReturn : 21.200000762939453
Eval_StdReturn : 3.529872417449951
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.2
Train_AverageReturn : 20.714284896850586
Train_StdReturn : 3.8808794021606445
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.714285714285715
Actor Loss : 0.6455588340759277
Train_EnvstepsSoFar : 385914
TimeSinceStart : 378.77489042282104
Done logging...



********** Iteration 382 ************

Collecting data for eval...
Eval_AverageReturn : 22.27777862548828
Eval_StdReturn : 3.955383777618408
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.27777777777778
Train_AverageReturn : 20.079999923706055
Train_StdReturn : 4.014174461364746
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.08
Actor Loss : 0.7506846189498901
Train_EnvstepsSoFar : 386918
TimeSinceStart : 379.5997202396393
Done logging...



********** Iteration 383 ************

Collecting data for eval...
Eval_AverageReturn : 20.799999237060547
Eval_StdReturn : 4.237924098968506
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.8
Train_AverageReturn : 19.6862735748291
Train_StdReturn : 4.447912693023682
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.686274509803923
Actor Loss : 1.0142451524734497
Train_EnvstepsSoFar : 387922
TimeSinceStart : 380.88949036598206
Done logging...



********** Iteration 384 ************

Collecting data for eval...
Eval_AverageReturn : 21.210525512695312
Eval_StdReturn : 4.395918369293213
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.210526315789473
Train_AverageReturn : 19.823530197143555
Train_StdReturn : 3.914307117462158
Train_MaxReturn : 27.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.823529411764707
Actor Loss : 0.4645964503288269
Train_EnvstepsSoFar : 388933
TimeSinceStart : 381.8479573726654
Done logging...



********** Iteration 385 ************

Collecting data for eval...
Eval_AverageReturn : 21.526315689086914
Eval_StdReturn : 4.672071933746338
Eval_MaxReturn : 32.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.526315789473685
Train_AverageReturn : 19.673076629638672
Train_StdReturn : 3.8115267753601074
Train_MaxReturn : 28.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.673076923076923
Actor Loss : 0.5975338220596313
Train_EnvstepsSoFar : 389956
TimeSinceStart : 382.6729335784912
Done logging...



********** Iteration 386 ************

Collecting data for eval...
Eval_AverageReturn : 19.809524536132812
Eval_StdReturn : 3.593897819519043
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.80952380952381
Train_AverageReturn : 21.340425491333008
Train_StdReturn : 4.2590413093566895
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.340425531914892
Actor Loss : 0.7554949522018433
Train_EnvstepsSoFar : 390959
TimeSinceStart : 383.66954469680786
Done logging...



********** Iteration 387 ************

Collecting data for eval...
Eval_AverageReturn : 19.619047164916992
Eval_StdReturn : 3.7730395793914795
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.61904761904762
Train_AverageReturn : 18.88679313659668
Train_StdReturn : 3.7800889015197754
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 18.88679245283019
Actor Loss : 0.985952615737915
Train_EnvstepsSoFar : 391960
TimeSinceStart : 384.47629380226135
Done logging...



********** Iteration 388 ************

Collecting data for eval...
Eval_AverageReturn : 20.850000381469727
Eval_StdReturn : 4.396305084228516
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.85
Train_AverageReturn : 20.40816307067871
Train_StdReturn : 4.3795366287231445
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.408163265306122
Actor Loss : 1.7731530666351318
Train_EnvstepsSoFar : 392960
TimeSinceStart : 385.42010974884033
Done logging...



********** Iteration 389 ************

Collecting data for eval...
Eval_AverageReturn : 20.450000762939453
Eval_StdReturn : 4.5549421310424805
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.45
Train_AverageReturn : 20.139999389648438
Train_StdReturn : 3.888495922088623
Train_MaxReturn : 27.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.14
Actor Loss : 0.526350736618042
Train_EnvstepsSoFar : 393967
TimeSinceStart : 386.2496819496155
Done logging...



********** Iteration 390 ************

Collecting data for eval...
Eval_AverageReturn : 20.200000762939453
Eval_StdReturn : 4.0323686599731445
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.2
Train_AverageReturn : 21.125
Train_StdReturn : 4.679854869842529
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.125
Actor Loss : 1.7568947076797485
Train_EnvstepsSoFar : 394981
TimeSinceStart : 387.04025197029114
Done logging...



********** Iteration 391 ************

Collecting data for eval...
Eval_AverageReturn : 20.950000762939453
Eval_StdReturn : 3.4420197010040283
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.95
Train_AverageReturn : 20.040000915527344
Train_StdReturn : 4.171138763427734
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.04
Actor Loss : 1.9759191274642944
Train_EnvstepsSoFar : 395983
TimeSinceStart : 387.9999358654022
Done logging...



********** Iteration 392 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 3.589916467666626
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 20.3799991607666
Train_StdReturn : 4.5951714515686035
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.38
Actor Loss : 1.0778429508209229
Train_EnvstepsSoFar : 397002
TimeSinceStart : 389.16101121902466
Done logging...



********** Iteration 393 ************

Collecting data for eval...
Eval_AverageReturn : 19.761905670166016
Eval_StdReturn : 3.336733102798462
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.761904761904763
Train_AverageReturn : 21.36170196533203
Train_StdReturn : 4.488403797149658
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.361702127659573
Actor Loss : 2.069551944732666
Train_EnvstepsSoFar : 398006
TimeSinceStart : 389.9771749973297
Done logging...



********** Iteration 394 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 5.112729072570801
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.1200008392334
Train_StdReturn : 4.434591293334961
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.12
Actor Loss : 0.7924612760543823
Train_EnvstepsSoFar : 399012
TimeSinceStart : 390.9790778160095
Done logging...



********** Iteration 395 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 3.395217180252075
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 20.97916603088379
Train_StdReturn : 4.05426549911499
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.979166666666668
Actor Loss : 1.2749334573745728
Train_EnvstepsSoFar : 400019
TimeSinceStart : 391.8068151473999
Done logging...



********** Iteration 396 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 4.972675323486328
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 20.200000762939453
Train_StdReturn : 4.431704044342041
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.2
Actor Loss : 1.5249375104904175
Train_EnvstepsSoFar : 401029
TimeSinceStart : 392.61578822135925
Done logging...



********** Iteration 397 ************

Collecting data for eval...
Eval_AverageReturn : 19.4761905670166
Eval_StdReturn : 4.019228458404541
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.476190476190474
Train_AverageReturn : 21.510639190673828
Train_StdReturn : 3.5060577392578125
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.51063829787234
Actor Loss : 0.9676555395126343
Train_EnvstepsSoFar : 402040
TimeSinceStart : 393.42834758758545
Done logging...



********** Iteration 398 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 3.2310988903045654
Eval_MaxReturn : 27.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 21.53191566467285
Train_StdReturn : 4.251913547515869
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.53191489361702
Actor Loss : 0.7172176241874695
Train_EnvstepsSoFar : 403052
TimeSinceStart : 394.2484014034271
Done logging...



********** Iteration 399 ************

Collecting data for eval...
Eval_AverageReturn : 19.380952835083008
Eval_StdReturn : 3.046874761581421
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.38095238095238
Train_AverageReturn : 20.260000228881836
Train_StdReturn : 4.0733771324157715
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.26
Actor Loss : 1.1727652549743652
Train_EnvstepsSoFar : 404065
TimeSinceStart : 395.0676736831665
Done logging...



********** Iteration 400 ************

Collecting data for eval...
Eval_AverageReturn : 21.6842098236084
Eval_StdReturn : 4.588918209075928
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.68421052631579
Train_AverageReturn : 20.632652282714844
Train_StdReturn : 4.35043478012085
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.632653061224488
Actor Loss : 0.7992952466011047
Train_EnvstepsSoFar : 405076
TimeSinceStart : 395.88966035842896
Done logging...



********** Iteration 401 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 4.1521077156066895
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.260000228881836
Train_StdReturn : 3.8460888862609863
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.26
Actor Loss : 0.8623683452606201
Train_EnvstepsSoFar : 406089
TimeSinceStart : 396.73372077941895
Done logging...



********** Iteration 402 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 4.872371196746826
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 20.239999771118164
Train_StdReturn : 3.234563112258911
Train_MaxReturn : 26.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.24
Actor Loss : 1.0969197750091553
Train_EnvstepsSoFar : 407101
TimeSinceStart : 397.9818060398102
Done logging...



********** Iteration 403 ************

Collecting data for eval...
Eval_AverageReturn : 19.619047164916992
Eval_StdReturn : 4.236757278442383
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.61904761904762
Train_AverageReturn : 21.20833396911621
Train_StdReturn : 4.153102874755859
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.208333333333332
Actor Loss : 0.4763161838054657
Train_EnvstepsSoFar : 408119
TimeSinceStart : 399.3379747867584
Done logging...



********** Iteration 404 ************

Collecting data for eval...
Eval_AverageReturn : 21.100000381469727
Eval_StdReturn : 4.011234283447266
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.1
Train_AverageReturn : 21.1875
Train_StdReturn : 4.371576309204102
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.1875
Actor Loss : 3.3952114582061768
Train_EnvstepsSoFar : 409136
TimeSinceStart : 400.1827006340027
Done logging...



********** Iteration 405 ************

Collecting data for eval...
Eval_AverageReturn : 20.299999237060547
Eval_StdReturn : 3.9635844230651855
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.3
Train_AverageReturn : 19.647058486938477
Train_StdReturn : 4.167208671569824
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.647058823529413
Actor Loss : 0.629785418510437
Train_EnvstepsSoFar : 410138
TimeSinceStart : 400.9818305969238
Done logging...



********** Iteration 406 ************

Collecting data for eval...
Eval_AverageReturn : 18.727272033691406
Eval_StdReturn : 4.255283355712891
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 18.727272727272727
Train_AverageReturn : 20.73469352722168
Train_StdReturn : 4.507479190826416
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.73469387755102
Actor Loss : 0.7487341165542603
Train_EnvstepsSoFar : 411154
TimeSinceStart : 401.81681299209595
Done logging...



********** Iteration 407 ************

Collecting data for eval...
Eval_AverageReturn : 19.045454025268555
Eval_StdReturn : 3.84326171875
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.045454545454547
Train_AverageReturn : 20.139999389648438
Train_StdReturn : 4.395497798919678
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.14
Actor Loss : 0.7070720195770264
Train_EnvstepsSoFar : 412161
TimeSinceStart : 402.6334500312805
Done logging...



********** Iteration 408 ************

Collecting data for eval...
Eval_AverageReturn : 20.299999237060547
Eval_StdReturn : 4.561797618865967
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.3
Train_AverageReturn : 20.571428298950195
Train_StdReturn : 4.379917144775391
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.571428571428573
Actor Loss : 1.0525676012039185
Train_EnvstepsSoFar : 413169
TimeSinceStart : 403.97474575042725
Done logging...



********** Iteration 409 ************

Collecting data for eval...
Eval_AverageReturn : 21.0
Eval_StdReturn : 4.857983112335205
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.0
Train_AverageReturn : 20.97916603088379
Train_StdReturn : 4.845486164093018
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.979166666666668
Actor Loss : 1.504554033279419
Train_EnvstepsSoFar : 414176
TimeSinceStart : 404.7984092235565
Done logging...



********** Iteration 410 ************

Collecting data for eval...
Eval_AverageReturn : 20.200000762939453
Eval_StdReturn : 4.3197221755981445
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.2
Train_AverageReturn : 21.404254913330078
Train_StdReturn : 4.555378437042236
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.404255319148938
Actor Loss : 0.9039274454116821
Train_EnvstepsSoFar : 415182
TimeSinceStart : 406.0116214752197
Done logging...



********** Iteration 411 ************

Collecting data for eval...
Eval_AverageReturn : 19.428571701049805
Eval_StdReturn : 3.125493049621582
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.428571428571427
Train_AverageReturn : 20.3799991607666
Train_StdReturn : 4.117717742919922
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.38
Actor Loss : 1.3634567260742188
Train_EnvstepsSoFar : 416201
TimeSinceStart : 406.87269043922424
Done logging...



********** Iteration 412 ************

Collecting data for eval...
Eval_AverageReturn : 20.700000762939453
Eval_StdReturn : 4.51774263381958
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.7
Train_AverageReturn : 20.020000457763672
Train_StdReturn : 3.849623203277588
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.02
Actor Loss : 0.37813496589660645
Train_EnvstepsSoFar : 417202
TimeSinceStart : 407.68510603904724
Done logging...



********** Iteration 413 ************

Collecting data for eval...
Eval_AverageReturn : 21.36842155456543
Eval_StdReturn : 4.042023181915283
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.36842105263158
Train_AverageReturn : 20.9375
Train_StdReturn : 4.007317543029785
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.9375
Actor Loss : 0.6890888214111328
Train_EnvstepsSoFar : 418207
TimeSinceStart : 409.1496431827545
Done logging...



********** Iteration 414 ************

Collecting data for eval...
Eval_AverageReturn : 21.578947067260742
Eval_StdReturn : 4.6033830642700195
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.57894736842105
Train_AverageReturn : 20.510204315185547
Train_StdReturn : 4.116281509399414
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.510204081632654
Actor Loss : 0.5860018134117126
Train_EnvstepsSoFar : 419212
TimeSinceStart : 410.43074131011963
Done logging...



********** Iteration 415 ************

Collecting data for eval...
Eval_AverageReturn : 20.049999237060547
Eval_StdReturn : 3.9430317878723145
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.05
Train_AverageReturn : 20.34000015258789
Train_StdReturn : 4.2549262046813965
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.34
Actor Loss : 1.1019498109817505
Train_EnvstepsSoFar : 420229
TimeSinceStart : 411.77690744400024
Done logging...



********** Iteration 416 ************

Collecting data for eval...
Eval_AverageReturn : 22.5
Eval_StdReturn : 3.8477988243103027
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 22.5
Train_AverageReturn : 20.15999984741211
Train_StdReturn : 4.566662311553955
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.16
Actor Loss : 2.4963700771331787
Train_EnvstepsSoFar : 421237
TimeSinceStart : 412.75566601753235
Done logging...



********** Iteration 417 ************

Collecting data for eval...
Eval_AverageReturn : 21.578947067260742
Eval_StdReturn : 4.55742073059082
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.57894736842105
Train_AverageReturn : 20.83333396911621
Train_StdReturn : 3.906902551651001
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.833333333333332
Actor Loss : 0.5234664678573608
Train_EnvstepsSoFar : 422237
TimeSinceStart : 413.762971162796
Done logging...



********** Iteration 418 ************

Collecting data for eval...
Eval_AverageReturn : 22.33333396911621
Eval_StdReturn : 3.901566505432129
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 22.333333333333332
Train_AverageReturn : 20.5510196685791
Train_StdReturn : 3.3628294467926025
Train_MaxReturn : 27.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.551020408163264
Actor Loss : 1.1921207904815674
Train_EnvstepsSoFar : 423244
TimeSinceStart : 415.22437739372253
Done logging...



********** Iteration 419 ************

Collecting data for eval...
Eval_AverageReturn : 21.052631378173828
Eval_StdReturn : 3.845348596572876
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.05263157894737
Train_AverageReturn : 20.85714340209961
Train_StdReturn : 4.065785884857178
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.857142857142858
Actor Loss : 0.7804158329963684
Train_EnvstepsSoFar : 424266
TimeSinceStart : 416.18452286720276
Done logging...



********** Iteration 420 ************

Collecting data for eval...
Eval_AverageReturn : 21.052631378173828
Eval_StdReturn : 3.619736433029175
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.05263157894737
Train_AverageReturn : 19.44230842590332
Train_StdReturn : 4.417680740356445
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.442307692307693
Actor Loss : 0.7671352624893188
Train_EnvstepsSoFar : 425277
TimeSinceStart : 416.99067878723145
Done logging...



********** Iteration 421 ************

Collecting data for eval...
Eval_AverageReturn : 21.947368621826172
Eval_StdReturn : 5.433557510375977
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.94736842105263
Train_AverageReturn : 20.67346954345703
Train_StdReturn : 4.2348785400390625
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.6734693877551
Actor Loss : 0.9180955290794373
Train_EnvstepsSoFar : 426290
TimeSinceStart : 418.047913312912
Done logging...



********** Iteration 422 ************

Collecting data for eval...
Eval_AverageReturn : 20.75
Eval_StdReturn : 4.133702754974365
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.75
Train_AverageReturn : 20.91666603088379
Train_StdReturn : 4.531525135040283
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.916666666666668
Actor Loss : 0.7986849546432495
Train_EnvstepsSoFar : 427294
TimeSinceStart : 419.17311668395996
Done logging...



********** Iteration 423 ************

Collecting data for eval...
Eval_AverageReturn : 19.095237731933594
Eval_StdReturn : 3.7531542778015137
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.095238095238095
Train_AverageReturn : 20.510204315185547
Train_StdReturn : 3.6316211223602295
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.510204081632654
Actor Loss : 0.2722732424736023
Train_EnvstepsSoFar : 428299
TimeSinceStart : 419.9720821380615
Done logging...



********** Iteration 424 ************

Collecting data for eval...
Eval_AverageReturn : 21.736841201782227
Eval_StdReturn : 4.810537815093994
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.736842105263158
Train_AverageReturn : 20.59183692932129
Train_StdReturn : 3.7575414180755615
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.591836734693878
Actor Loss : 1.4518336057662964
Train_EnvstepsSoFar : 429308
TimeSinceStart : 420.7896656990051
Done logging...



********** Iteration 425 ************

Collecting data for eval...
Eval_AverageReturn : 20.200000762939453
Eval_StdReturn : 4.331281661987305
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.2
Train_AverageReturn : 19.745098114013672
Train_StdReturn : 4.1484375
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.745098039215687
Actor Loss : 0.8273106217384338
Train_EnvstepsSoFar : 430315
TimeSinceStart : 421.59678411483765
Done logging...



********** Iteration 426 ************

Collecting data for eval...
Eval_AverageReturn : 21.578947067260742
Eval_StdReturn : 4.499307155609131
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.57894736842105
Train_AverageReturn : 20.653060913085938
Train_StdReturn : 4.048436164855957
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.653061224489797
Actor Loss : 1.041426181793213
Train_EnvstepsSoFar : 431327
TimeSinceStart : 422.98598408699036
Done logging...



********** Iteration 427 ************

Collecting data for eval...
Eval_AverageReturn : 19.761905670166016
Eval_StdReturn : 3.8533196449279785
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.761904761904763
Train_AverageReturn : 19.901960372924805
Train_StdReturn : 3.2434239387512207
Train_MaxReturn : 32.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.901960784313726
Actor Loss : 3.743551015853882
Train_EnvstepsSoFar : 432342
TimeSinceStart : 423.8348214626312
Done logging...



********** Iteration 428 ************

Collecting data for eval...
Eval_AverageReturn : 19.571428298950195
Eval_StdReturn : 3.5666635036468506
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.571428571428573
Train_AverageReturn : 21.404254913330078
Train_StdReturn : 3.7961885929107666
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.404255319148938
Actor Loss : 1.568666696548462
Train_EnvstepsSoFar : 433348
TimeSinceStart : 424.6655066013336
Done logging...



********** Iteration 429 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 3.8522722721099854
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 20.89583396911621
Train_StdReturn : 4.144472122192383
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.895833333333332
Actor Loss : 0.8194293975830078
Train_EnvstepsSoFar : 434351
TimeSinceStart : 425.4820773601532
Done logging...



********** Iteration 430 ************

Collecting data for eval...
Eval_AverageReturn : 19.952381134033203
Eval_StdReturn : 3.9818179607391357
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.952380952380953
Train_AverageReturn : 20.612245559692383
Train_StdReturn : 3.9008965492248535
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.612244897959183
Actor Loss : 0.5328289866447449
Train_EnvstepsSoFar : 435361
TimeSinceStart : 426.3034830093384
Done logging...



********** Iteration 431 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 3.718534469604492
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 19.538461685180664
Train_StdReturn : 3.3994429111480713
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.53846153846154
Actor Loss : 0.6304019689559937
Train_EnvstepsSoFar : 436377
TimeSinceStart : 427.347669839859
Done logging...



********** Iteration 432 ************

Collecting data for eval...
Eval_AverageReturn : 20.950000762939453
Eval_StdReturn : 4.295055389404297
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.95
Train_AverageReturn : 21.02083396911621
Train_StdReturn : 3.8594558238983154
Train_MaxReturn : 27.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.020833333333332
Actor Loss : 0.48281151056289673
Train_EnvstepsSoFar : 437386
TimeSinceStart : 428.59243988990784
Done logging...



********** Iteration 433 ************

Collecting data for eval...
Eval_AverageReturn : 21.105262756347656
Eval_StdReturn : 4.166214466094971
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.105263157894736
Train_AverageReturn : 20.428571701049805
Train_StdReturn : 4.030496120452881
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.428571428571427
Actor Loss : 1.2329500913619995
Train_EnvstepsSoFar : 438387
TimeSinceStart : 429.40326714515686
Done logging...



********** Iteration 434 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 4.043204307556152
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 20.571428298950195
Train_StdReturn : 4.323641777038574
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.571428571428573
Actor Loss : 1.3055369853973389
Train_EnvstepsSoFar : 439395
TimeSinceStart : 430.23465514183044
Done logging...



********** Iteration 435 ************

Collecting data for eval...
Eval_AverageReturn : 21.36842155456543
Eval_StdReturn : 4.7039794921875
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.36842105263158
Train_AverageReturn : 20.653060913085938
Train_StdReturn : 3.920386552810669
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.653061224489797
Actor Loss : 0.5560827255249023
Train_EnvstepsSoFar : 440407
TimeSinceStart : 431.54339694976807
Done logging...



********** Iteration 436 ************

Collecting data for eval...
Eval_AverageReturn : 21.157894134521484
Eval_StdReturn : 3.4832403659820557
Eval_MaxReturn : 31.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 21.157894736842106
Train_AverageReturn : 19.843137741088867
Train_StdReturn : 3.544520854949951
Train_MaxReturn : 28.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.84313725490196
Actor Loss : 0.35550254583358765
Train_EnvstepsSoFar : 441419
TimeSinceStart : 432.4108474254608
Done logging...



********** Iteration 437 ************

Collecting data for eval...
Eval_AverageReturn : 20.0
Eval_StdReturn : 3.4364986419677734
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.0
Train_AverageReturn : 20.714284896850586
Train_StdReturn : 4.237827777862549
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.714285714285715
Actor Loss : 2.2791740894317627
Train_EnvstepsSoFar : 442434
TimeSinceStart : 433.2860345840454
Done logging...



********** Iteration 438 ************

Collecting data for eval...
Eval_AverageReturn : 20.0
Eval_StdReturn : 4.1747541427612305
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.0
Train_AverageReturn : 19.480770111083984
Train_StdReturn : 3.4333789348602295
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.48076923076923
Actor Loss : 0.5850768089294434
Train_EnvstepsSoFar : 443447
TimeSinceStart : 434.4170002937317
Done logging...



********** Iteration 439 ************

Collecting data for eval...
Eval_AverageReturn : 21.526315689086914
Eval_StdReturn : 4.77238130569458
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.526315789473685
Train_AverageReturn : 21.489360809326172
Train_StdReturn : 4.447673797607422
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.48936170212766
Actor Loss : 0.7613130211830139
Train_EnvstepsSoFar : 444457
TimeSinceStart : 435.43563532829285
Done logging...



********** Iteration 440 ************

Collecting data for eval...
Eval_AverageReturn : 22.22222137451172
Eval_StdReturn : 3.895232915878296
Eval_MaxReturn : 30.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 22.22222222222222
Train_AverageReturn : 19.843137741088867
Train_StdReturn : 3.6265499591827393
Train_MaxReturn : 26.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.84313725490196
Actor Loss : 0.7439446449279785
Train_EnvstepsSoFar : 445469
TimeSinceStart : 436.489994764328
Done logging...



********** Iteration 441 ************

Collecting data for eval...
Eval_AverageReturn : 22.83333396911621
Eval_StdReturn : 3.3040380477905273
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.833333333333332
Train_AverageReturn : 20.479999542236328
Train_StdReturn : 3.8483242988586426
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.48
Actor Loss : 0.32429367303848267
Train_EnvstepsSoFar : 446493
TimeSinceStart : 437.6055061817169
Done logging...



********** Iteration 442 ************

Collecting data for eval...
Eval_AverageReturn : 20.049999237060547
Eval_StdReturn : 3.3834152221679688
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.05
Train_AverageReturn : 20.020000457763672
Train_StdReturn : 4.370308876037598
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.02
Actor Loss : 1.1581414937973022
Train_EnvstepsSoFar : 447494
TimeSinceStart : 438.45246624946594
Done logging...



********** Iteration 443 ************

Collecting data for eval...
Eval_AverageReturn : 21.736841201782227
Eval_StdReturn : 3.8776297569274902
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.736842105263158
Train_AverageReturn : 21.08333396911621
Train_StdReturn : 3.695906162261963
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.083333333333332
Actor Loss : 0.46313267946243286
Train_EnvstepsSoFar : 448506
TimeSinceStart : 439.2885367870331
Done logging...



********** Iteration 444 ************

Collecting data for eval...
Eval_AverageReturn : 19.33333396911621
Eval_StdReturn : 3.0131986141204834
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.333333333333332
Train_AverageReturn : 21.020408630371094
Train_StdReturn : 4.488033294677734
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.020408163265305
Actor Loss : 1.5708333253860474
Train_EnvstepsSoFar : 449536
TimeSinceStart : 440.1459970474243
Done logging...



********** Iteration 445 ************

Collecting data for eval...
Eval_AverageReturn : 19.14285659790039
Eval_StdReturn : 3.2991442680358887
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.142857142857142
Train_AverageReturn : 21.02083396911621
Train_StdReturn : 3.777618408203125
Train_MaxReturn : 27.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.020833333333332
Actor Loss : 0.6705330014228821
Train_EnvstepsSoFar : 450545
TimeSinceStart : 441.21273159980774
Done logging...



********** Iteration 446 ************

Collecting data for eval...
Eval_AverageReturn : 20.200000762939453
Eval_StdReturn : 4.47883939743042
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.2
Train_AverageReturn : 19.423076629638672
Train_StdReturn : 3.9968552589416504
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.423076923076923
Actor Loss : 0.48990681767463684
Train_EnvstepsSoFar : 451555
TimeSinceStart : 442.03431701660156
Done logging...



********** Iteration 447 ************

Collecting data for eval...
Eval_AverageReturn : 19.66666603088379
Eval_StdReturn : 4.4113850593566895
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.666666666666668
Train_AverageReturn : 20.571428298950195
Train_StdReturn : 4.4216532707214355
Train_MaxReturn : 32.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.571428571428573
Actor Loss : 0.6883931159973145
Train_EnvstepsSoFar : 452563
TimeSinceStart : 442.87393403053284
Done logging...



********** Iteration 448 ************

Collecting data for eval...
Eval_AverageReturn : 20.047618865966797
Eval_StdReturn : 3.9698410034179688
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.047619047619047
Train_AverageReturn : 20.280000686645508
Train_StdReturn : 4.181100368499756
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.28
Actor Loss : 1.0419855117797852
Train_EnvstepsSoFar : 453577
TimeSinceStart : 443.7053847312927
Done logging...



********** Iteration 449 ************

Collecting data for eval...
Eval_AverageReturn : 21.473684310913086
Eval_StdReturn : 3.377454996109009
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.473684210526315
Train_AverageReturn : 21.10416603088379
Train_StdReturn : 3.483530282974243
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.104166666666668
Actor Loss : 0.4238537549972534
Train_EnvstepsSoFar : 454590
TimeSinceStart : 444.58037400245667
Done logging...



********** Iteration 450 ************

Collecting data for eval...
Eval_AverageReturn : 20.450000762939453
Eval_StdReturn : 4.576843738555908
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.45
Train_AverageReturn : 20.73469352722168
Train_StdReturn : 4.212593078613281
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.73469387755102
Actor Loss : 0.6926496028900146
Train_EnvstepsSoFar : 455606
TimeSinceStart : 445.4188416004181
Done logging...



********** Iteration 451 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 4.072775363922119
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 20.95833396911621
Train_StdReturn : 4.791304111480713
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.958333333333332
Actor Loss : 0.3975113034248352
Train_EnvstepsSoFar : 456612
TimeSinceStart : 446.2530598640442
Done logging...



********** Iteration 452 ************

Collecting data for eval...
Eval_AverageReturn : 20.850000381469727
Eval_StdReturn : 4.315958499908447
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.85
Train_AverageReturn : 20.139999389648438
Train_StdReturn : 4.204806804656982
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.14
Actor Loss : 0.8144410848617554
Train_EnvstepsSoFar : 457619
TimeSinceStart : 447.08198070526123
Done logging...



********** Iteration 453 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 4.223742485046387
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 20.1200008392334
Train_StdReturn : 3.5532519817352295
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.12
Actor Loss : 0.2581132650375366
Train_EnvstepsSoFar : 458625
TimeSinceStart : 447.910915851593
Done logging...



********** Iteration 454 ************

Collecting data for eval...
Eval_AverageReturn : 19.190475463867188
Eval_StdReturn : 4.0546159744262695
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.19047619047619
Train_AverageReturn : 19.823530197143555
Train_StdReturn : 4.222748279571533
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.823529411764707
Actor Loss : 0.6094774603843689
Train_EnvstepsSoFar : 459636
TimeSinceStart : 448.73846077919006
Done logging...



********** Iteration 455 ************

Collecting data for eval...
Eval_AverageReturn : 20.649999618530273
Eval_StdReturn : 3.9657909870147705
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.65
Train_AverageReturn : 21.95652198791504
Train_StdReturn : 4.568115234375
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.956521739130434
Actor Loss : 1.1225723028182983
Train_EnvstepsSoFar : 460646
TimeSinceStart : 450.44036078453064
Done logging...



********** Iteration 456 ************

Collecting data for eval...
Eval_AverageReturn : 20.200000762939453
Eval_StdReturn : 3.325657844543457
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.2
Train_AverageReturn : 20.039215087890625
Train_StdReturn : 3.900531768798828
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.03921568627451
Actor Loss : 0.5106579661369324
Train_EnvstepsSoFar : 461668
TimeSinceStart : 451.43436670303345
Done logging...



********** Iteration 457 ************

Collecting data for eval...
Eval_AverageReturn : 19.0
Eval_StdReturn : 3.0
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.0
Train_AverageReturn : 19.960784912109375
Train_StdReturn : 4.038835048675537
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.96078431372549
Actor Loss : 0.5505160093307495
Train_EnvstepsSoFar : 462686
TimeSinceStart : 452.4577007293701
Done logging...



********** Iteration 458 ************

Collecting data for eval...
Eval_AverageReturn : 21.210525512695312
Eval_StdReturn : 3.6212668418884277
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.210526315789473
Train_AverageReturn : 20.0
Train_StdReturn : 3.5777087211608887
Train_MaxReturn : 28.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.0
Actor Loss : 0.5401316285133362
Train_EnvstepsSoFar : 463686
TimeSinceStart : 453.4845185279846
Done logging...



********** Iteration 459 ************

Collecting data for eval...
Eval_AverageReturn : 20.350000381469727
Eval_StdReturn : 3.4824562072753906
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.35
Train_AverageReturn : 20.775510787963867
Train_StdReturn : 3.759425163269043
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.775510204081634
Actor Loss : 0.659114420413971
Train_EnvstepsSoFar : 464704
TimeSinceStart : 454.3413212299347
Done logging...



********** Iteration 460 ************

Collecting data for eval...
Eval_AverageReturn : 21.049999237060547
Eval_StdReturn : 4.554942607879639
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.05
Train_AverageReturn : 20.875
Train_StdReturn : 3.833106756210327
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.875
Actor Loss : 0.4524856209754944
Train_EnvstepsSoFar : 465706
TimeSinceStart : 455.9370234012604
Done logging...



********** Iteration 461 ************

Collecting data for eval...
Eval_AverageReturn : 20.5
Eval_StdReturn : 3.748332977294922
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.5
Train_AverageReturn : 20.360000610351562
Train_StdReturn : 3.968677282333374
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.36
Actor Loss : 0.9282834529876709
Train_EnvstepsSoFar : 466724
TimeSinceStart : 456.77908730506897
Done logging...



********** Iteration 462 ************

Collecting data for eval...
Eval_AverageReturn : 20.299999237060547
Eval_StdReturn : 3.6207735538482666
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.3
Train_AverageReturn : 19.882352828979492
Train_StdReturn : 3.9190189838409424
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.88235294117647
Actor Loss : 0.3893547058105469
Train_EnvstepsSoFar : 467738
TimeSinceStart : 457.8826496601105
Done logging...



********** Iteration 463 ************

Collecting data for eval...
Eval_AverageReturn : 20.299999237060547
Eval_StdReturn : 4.659399032592773
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.3
Train_AverageReturn : 20.280000686645508
Train_StdReturn : 3.6662790775299072
Train_MaxReturn : 27.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.28
Actor Loss : 0.8543546199798584
Train_EnvstepsSoFar : 468752
TimeSinceStart : 458.83407187461853
Done logging...



********** Iteration 464 ************

Collecting data for eval...
Eval_AverageReturn : 21.25
Eval_StdReturn : 3.645202398300171
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.25
Train_AverageReturn : 21.36170196533203
Train_StdReturn : 4.224677085876465
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.361702127659573
Actor Loss : 0.9545080065727234
Train_EnvstepsSoFar : 469756
TimeSinceStart : 459.8807089328766
Done logging...



********** Iteration 465 ************

Collecting data for eval...
Eval_AverageReturn : 21.210525512695312
Eval_StdReturn : 3.833082437515259
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.210526315789473
Train_AverageReturn : 20.3799991607666
Train_StdReturn : 3.90328049659729
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.38
Actor Loss : 0.6081156134605408
Train_EnvstepsSoFar : 470775
TimeSinceStart : 460.7996199131012
Done logging...



********** Iteration 466 ************

Collecting data for eval...
Eval_AverageReturn : 20.700000762939453
Eval_StdReturn : 4.733920097351074
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.7
Train_AverageReturn : 20.9375
Train_StdReturn : 3.9338607788085938
Train_MaxReturn : 28.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.9375
Actor Loss : 0.3057531416416168
Train_EnvstepsSoFar : 471780
TimeSinceStart : 461.6106376647949
Done logging...



********** Iteration 467 ************

Collecting data for eval...
Eval_AverageReturn : 19.33333396911621
Eval_StdReturn : 3.563483238220215
Eval_MaxReturn : 26.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.333333333333332
Train_AverageReturn : 20.775510787963867
Train_StdReturn : 3.9551842212677
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.775510204081634
Actor Loss : 0.7818673849105835
Train_EnvstepsSoFar : 472798
TimeSinceStart : 462.44196939468384
Done logging...



********** Iteration 468 ************

Collecting data for eval...
Eval_AverageReturn : 19.33333396911621
Eval_StdReturn : 4.389742851257324
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.333333333333332
Train_AverageReturn : 20.95833396911621
Train_StdReturn : 3.8511812686920166
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.958333333333332
Actor Loss : 1.0314161777496338
Train_EnvstepsSoFar : 473804
TimeSinceStart : 463.62110209465027
Done logging...



********** Iteration 469 ************

Collecting data for eval...
Eval_AverageReturn : 19.0
Eval_StdReturn : 2.9232609272003174
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.0
Train_AverageReturn : 20.18000030517578
Train_StdReturn : 4.155429840087891
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.18
Actor Loss : 0.30335357785224915
Train_EnvstepsSoFar : 474813
TimeSinceStart : 464.4780752658844
Done logging...



********** Iteration 470 ************

Collecting data for eval...
Eval_AverageReturn : 21.894737243652344
Eval_StdReturn : 4.140871524810791
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.894736842105264
Train_AverageReturn : 21.340425491333008
Train_StdReturn : 3.8772470951080322
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.340425531914892
Actor Loss : 0.2715577483177185
Train_EnvstepsSoFar : 475816
TimeSinceStart : 465.46999311447144
Done logging...



********** Iteration 471 ************

Collecting data for eval...
Eval_AverageReturn : 20.049999237060547
Eval_StdReturn : 3.556332588195801
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.05
Train_AverageReturn : 21.510639190673828
Train_StdReturn : 4.924417495727539
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.51063829787234
Actor Loss : 1.5453109741210938
Train_EnvstepsSoFar : 476827
TimeSinceStart : 466.7021596431732
Done logging...



********** Iteration 472 ************

Collecting data for eval...
Eval_AverageReturn : 19.761905670166016
Eval_StdReturn : 3.3933374881744385
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.761904761904763
Train_AverageReturn : 20.4489803314209
Train_StdReturn : 3.896944046020508
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.448979591836736
Actor Loss : 0.458381712436676
Train_EnvstepsSoFar : 477829
TimeSinceStart : 467.5302062034607
Done logging...



********** Iteration 473 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 4.430875301361084
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 20.73469352722168
Train_StdReturn : 4.104629039764404
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.73469387755102
Actor Loss : 1.1969965696334839
Train_EnvstepsSoFar : 478845
TimeSinceStart : 468.55938482284546
Done logging...



********** Iteration 474 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 4.02988862991333
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.693878173828125
Train_StdReturn : 3.632079839706421
Train_MaxReturn : 28.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.693877551020407
Actor Loss : 0.3465239405632019
Train_EnvstepsSoFar : 479859
TimeSinceStart : 469.599294424057
Done logging...



********** Iteration 475 ************

Collecting data for eval...
Eval_AverageReturn : 21.473684310913086
Eval_StdReturn : 3.871195077896118
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.473684210526315
Train_AverageReturn : 19.730770111083984
Train_StdReturn : 3.908154249191284
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.73076923076923
Actor Loss : 0.2568995952606201
Train_EnvstepsSoFar : 480885
TimeSinceStart : 471.1968686580658
Done logging...



********** Iteration 476 ************

Collecting data for eval...
Eval_AverageReturn : 21.789474487304688
Eval_StdReturn : 4.162222385406494
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.789473684210527
Train_AverageReturn : 20.360000610351562
Train_StdReturn : 3.993795156478882
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.36
Actor Loss : 0.5615919232368469
Train_EnvstepsSoFar : 481903
TimeSinceStart : 472.87296962738037
Done logging...



********** Iteration 477 ************

Collecting data for eval...
Eval_AverageReturn : 20.0
Eval_StdReturn : 3.3015148639678955
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.0
Train_AverageReturn : 20.59183692932129
Train_StdReturn : 3.9842464923858643
Train_MaxReturn : 28.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.591836734693878
Actor Loss : 0.6410374641418457
Train_EnvstepsSoFar : 482912
TimeSinceStart : 473.71000838279724
Done logging...



********** Iteration 478 ************

Collecting data for eval...
Eval_AverageReturn : 21.210525512695312
Eval_StdReturn : 3.928022623062134
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.210526315789473
Train_AverageReturn : 20.53061294555664
Train_StdReturn : 4.431344985961914
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.53061224489796
Actor Loss : 0.3191866874694824
Train_EnvstepsSoFar : 483918
TimeSinceStart : 474.554883480072
Done logging...



********** Iteration 479 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 3.5070388317108154
Eval_MaxReturn : 26.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 20.360000610351562
Train_StdReturn : 3.9737136363983154
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.36
Actor Loss : 0.4314501881599426
Train_EnvstepsSoFar : 484936
TimeSinceStart : 475.4064440727234
Done logging...



********** Iteration 480 ************

Collecting data for eval...
Eval_AverageReturn : 20.047618865966797
Eval_StdReturn : 3.9937591552734375
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.047619047619047
Train_AverageReturn : 20.510204315185547
Train_StdReturn : 4.5897955894470215
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.510204081632654
Actor Loss : 0.44858524203300476
Train_EnvstepsSoFar : 485941
TimeSinceStart : 476.25849175453186
Done logging...



********** Iteration 481 ************

Collecting data for eval...
Eval_AverageReturn : 21.049999237060547
Eval_StdReturn : 4.521891117095947
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.05
Train_AverageReturn : 20.1200008392334
Train_StdReturn : 3.586865186691284
Train_MaxReturn : 28.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.12
Actor Loss : 0.37602412700653076
Train_EnvstepsSoFar : 486947
TimeSinceStart : 477.1094443798065
Done logging...



********** Iteration 482 ************

Collecting data for eval...
Eval_AverageReturn : 19.85714340209961
Eval_StdReturn : 3.9070839881896973
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.857142857142858
Train_AverageReturn : 19.66666603088379
Train_StdReturn : 3.606457471847534
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.666666666666668
Actor Loss : 0.7575137615203857
Train_EnvstepsSoFar : 487950
TimeSinceStart : 478.84546303749084
Done logging...



********** Iteration 483 ************

Collecting data for eval...
Eval_AverageReturn : 21.157894134521484
Eval_StdReturn : 3.73127818107605
Eval_MaxReturn : 27.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.157894736842106
Train_AverageReturn : 20.34000015258789
Train_StdReturn : 3.6965391635894775
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.34
Actor Loss : 0.4679097533226013
Train_EnvstepsSoFar : 488967
TimeSinceStart : 479.69682002067566
Done logging...



********** Iteration 484 ************

Collecting data for eval...
Eval_AverageReturn : 20.049999237060547
Eval_StdReturn : 3.8009867668151855
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.05
Train_AverageReturn : 19.66666603088379
Train_StdReturn : 4.318980693817139
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.666666666666668
Actor Loss : 0.7410268783569336
Train_EnvstepsSoFar : 489970
TimeSinceStart : 480.54586362838745
Done logging...



********** Iteration 485 ************

Collecting data for eval...
Eval_AverageReturn : 19.4761905670166
Eval_StdReturn : 3.4999186992645264
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.476190476190474
Train_AverageReturn : 20.0
Train_StdReturn : 4.4721360206604
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.0
Actor Loss : 0.5628734827041626
Train_EnvstepsSoFar : 490990
TimeSinceStart : 481.3814158439636
Done logging...



********** Iteration 486 ************

Collecting data for eval...
Eval_AverageReturn : 21.052631378173828
Eval_StdReturn : 4.999722957611084
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.05263157894737
Train_AverageReturn : 20.200000762939453
Train_StdReturn : 4.252058506011963
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.2
Actor Loss : 0.29309767484664917
Train_EnvstepsSoFar : 492000
TimeSinceStart : 482.22230315208435
Done logging...



********** Iteration 487 ************

Collecting data for eval...
Eval_AverageReturn : 20.299999237060547
Eval_StdReturn : 3.7828562259674072
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.3
Train_AverageReturn : 21.25
Train_StdReturn : 3.7721567153930664
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.25
Actor Loss : 0.9082096219062805
Train_EnvstepsSoFar : 493020
TimeSinceStart : 483.4212074279785
Done logging...



********** Iteration 488 ************

Collecting data for eval...
Eval_AverageReturn : 21.210525512695312
Eval_StdReturn : 4.6631693840026855
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.210526315789473
Train_AverageReturn : 20.440000534057617
Train_StdReturn : 4.035641193389893
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.44
Actor Loss : 0.3297397196292877
Train_EnvstepsSoFar : 494042
TimeSinceStart : 484.2415075302124
Done logging...



********** Iteration 489 ************

Collecting data for eval...
Eval_AverageReturn : 18.863636016845703
Eval_StdReturn : 3.583997964859009
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 18.863636363636363
Train_AverageReturn : 20.360000610351562
Train_StdReturn : 3.876905918121338
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.36
Actor Loss : 0.3409310579299927
Train_EnvstepsSoFar : 495060
TimeSinceStart : 485.0697946548462
Done logging...



********** Iteration 490 ************

Collecting data for eval...
Eval_AverageReturn : 23.05555534362793
Eval_StdReturn : 3.535097360610962
Eval_MaxReturn : 30.0
Eval_MinReturn : 18.0
Eval_AverageEpLen : 23.055555555555557
Train_AverageReturn : 21.382978439331055
Train_StdReturn : 4.46524715423584
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.382978723404257
Actor Loss : 2.6568942070007324
Train_EnvstepsSoFar : 496065
TimeSinceStart : 486.4844796657562
Done logging...



********** Iteration 491 ************

Collecting data for eval...
Eval_AverageReturn : 19.4761905670166
Eval_StdReturn : 3.995462417602539
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.476190476190474
Train_AverageReturn : 20.15999984741211
Train_StdReturn : 4.095655918121338
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.16
Actor Loss : 0.3622870445251465
Train_EnvstepsSoFar : 497073
TimeSinceStart : 487.4971969127655
Done logging...



********** Iteration 492 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 3.9658405780792236
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 19.037734985351562
Train_StdReturn : 3.1560800075531006
Train_MaxReturn : 27.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.037735849056602
Actor Loss : 0.3242030143737793
Train_EnvstepsSoFar : 498082
TimeSinceStart : 488.50105834007263
Done logging...



********** Iteration 493 ************

Collecting data for eval...
Eval_AverageReturn : 21.149999618530273
Eval_StdReturn : 3.4391133785247803
Eval_MaxReturn : 30.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 21.15
Train_AverageReturn : 19.230770111083984
Train_StdReturn : 3.3317551612854004
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.23076923076923
Actor Loss : 0.5413501262664795
Train_EnvstepsSoFar : 499082
TimeSinceStart : 489.32791209220886
Done logging...



********** Iteration 494 ************

Collecting data for eval...
Eval_AverageReturn : 21.157894134521484
Eval_StdReturn : 4.068662643432617
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.157894736842106
Train_AverageReturn : 20.875
Train_StdReturn : 4.23096227645874
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.875
Actor Loss : 0.6233769655227661
Train_EnvstepsSoFar : 500084
TimeSinceStart : 490.1382987499237
Done logging...



********** Iteration 495 ************

Collecting data for eval...
Eval_AverageReturn : 21.157894134521484
Eval_StdReturn : 4.094452381134033
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.157894736842106
Train_AverageReturn : 20.91666603088379
Train_StdReturn : 4.236907958984375
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.916666666666668
Actor Loss : 0.8580585718154907
Train_EnvstepsSoFar : 501088
TimeSinceStart : 490.9447798728943
Done logging...



********** Iteration 496 ************

Collecting data for eval...
Eval_AverageReturn : 19.380952835083008
Eval_StdReturn : 3.8726906776428223
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.38095238095238
Train_AverageReturn : 19.80392074584961
Train_StdReturn : 3.5920369625091553
Train_MaxReturn : 27.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.80392156862745
Actor Loss : 0.7845107913017273
Train_EnvstepsSoFar : 502098
TimeSinceStart : 491.73841285705566
Done logging...



********** Iteration 497 ************

Collecting data for eval...
Eval_AverageReturn : 21.526315689086914
Eval_StdReturn : 3.9784739017486572
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.526315789473685
Train_AverageReturn : 20.612245559692383
Train_StdReturn : 4.164065361022949
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.612244897959183
Actor Loss : 0.4524279832839966
Train_EnvstepsSoFar : 503108
TimeSinceStart : 492.6382236480713
Done logging...



********** Iteration 498 ************

Collecting data for eval...
Eval_AverageReturn : 21.049999237060547
Eval_StdReturn : 4.153010845184326
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.05
Train_AverageReturn : 20.139999389648438
Train_StdReturn : 3.8471288681030273
Train_MaxReturn : 32.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.14
Actor Loss : 0.7342307567596436
Train_EnvstepsSoFar : 504115
TimeSinceStart : 493.45253133773804
Done logging...



********** Iteration 499 ************

Collecting data for eval...
Eval_AverageReturn : 20.450000762939453
Eval_StdReturn : 4.24823522567749
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.45
Train_AverageReturn : 20.020000457763672
Train_StdReturn : 4.558464527130127
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.02
Actor Loss : 0.7139993906021118
Train_EnvstepsSoFar : 505116
TimeSinceStart : 494.26368737220764
Done logging...


########################
logging outputs to  /home/jaehyun-jeong/UCBerkeley_cs285/hw2/cs285/scripts/../../data/q2_pg_cartpole_na_CartPole-v0_17-08-2024_01-18-36
########################
Using GPU id 0
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/envs/registration.py:593: UserWarning: [33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.[0m
  logger.warn(
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/core.py:317: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(

********** Iteration 0 ************
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):

Collecting data for eval...
Eval_AverageReturn : 9.159090995788574
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/tensorboardX/summary.py:153: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
  scalar = float(scalar)
Eval_StdReturn : 0.7670244574546814
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.159090909090908
Train_AverageReturn : 40.47999954223633
Train_StdReturn : 18.461029052734375
Train_MaxReturn : 103.0
Train_MinReturn : 20.0
Train_AverageEpLen : 40.48
Actor Loss : -0.10866165161132812
Train_EnvstepsSoFar : 1012
TimeSinceStart : 1.003892183303833
Initial_DataCollection_AverageReturn : 40.47999954223633
Done logging...



********** Iteration 1 ************

Collecting data for eval...
Eval_AverageReturn : 23.0
Eval_StdReturn : 4.6666669845581055
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 23.0
Train_AverageReturn : 9.45283031463623
Train_StdReturn : 0.8141677975654602
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.452830188679245
Actor Loss : 7.326473236083984
Train_EnvstepsSoFar : 2014
TimeSinceStart : 2.029723882675171
Done logging...



********** Iteration 2 ************

Collecting data for eval...
Eval_AverageReturn : 47.77777862548828
Eval_StdReturn : 17.093063354492188
Eval_MaxReturn : 91.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 47.77777777777778
Train_AverageReturn : 22.311111450195312
Train_StdReturn : 4.081515312194824
Train_MaxReturn : 32.0
Train_MinReturn : 16.0
Train_AverageEpLen : 22.31111111111111
Actor Loss : 0.624786376953125
Train_EnvstepsSoFar : 3018
TimeSinceStart : 2.784942150115967
Done logging...



********** Iteration 3 ************

Collecting data for eval...
Eval_AverageReturn : 67.16666412353516
Eval_StdReturn : 9.9568510055542
Eval_MaxReturn : 81.0
Eval_MinReturn : 53.0
Eval_AverageEpLen : 67.16666666666667
Train_AverageReturn : 50.75
Train_StdReturn : 16.561628341674805
Train_MaxReturn : 106.0
Train_MinReturn : 33.0
Train_AverageEpLen : 50.75
Actor Loss : 0.32571983337402344
Train_EnvstepsSoFar : 4033
TimeSinceStart : 3.566544771194458
Done logging...



********** Iteration 4 ************

Collecting data for eval...
Eval_AverageReturn : 64.57142639160156
Eval_StdReturn : 18.00680160522461
Eval_MaxReturn : 98.0
Eval_MinReturn : 47.0
Eval_AverageEpLen : 64.57142857142857
Train_AverageReturn : 76.5
Train_StdReturn : 20.236988067626953
Train_MaxReturn : 122.0
Train_MinReturn : 49.0
Train_AverageEpLen : 76.5
Actor Loss : 0.16032028198242188
Train_EnvstepsSoFar : 5104
TimeSinceStart : 4.379718065261841
Done logging...



********** Iteration 5 ************

Collecting data for eval...
Eval_AverageReturn : 50.875
Eval_StdReturn : 21.268741607666016
Eval_MaxReturn : 94.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 50.875
Train_AverageReturn : 53.68421173095703
Train_StdReturn : 20.073686599731445
Train_MaxReturn : 104.0
Train_MinReturn : 37.0
Train_AverageEpLen : 53.68421052631579
Actor Loss : 0.23760414123535156
Train_EnvstepsSoFar : 6124
TimeSinceStart : 5.14414381980896
Done logging...



********** Iteration 6 ************

Collecting data for eval...
Eval_AverageReturn : 43.79999923706055
Eval_StdReturn : 15.138031005859375
Eval_MaxReturn : 79.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 43.8
Train_AverageReturn : 44.30434799194336
Train_StdReturn : 13.867179870605469
Train_MaxReturn : 84.0
Train_MinReturn : 31.0
Train_AverageEpLen : 44.30434782608695
Actor Loss : 0.5210018157958984
Train_EnvstepsSoFar : 7143
TimeSinceStart : 5.930238485336304
Done logging...



********** Iteration 7 ************

Collecting data for eval...
Eval_AverageReturn : 39.09090805053711
Eval_StdReturn : 8.753747940063477
Eval_MaxReturn : 60.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 39.09090909090909
Train_AverageReturn : 39.46154022216797
Train_StdReturn : 9.434921264648438
Train_MaxReturn : 55.0
Train_MinReturn : 26.0
Train_AverageEpLen : 39.46153846153846
Actor Loss : 0.9091720581054688
Train_EnvstepsSoFar : 8169
TimeSinceStart : 6.733264446258545
Done logging...



********** Iteration 8 ************

Collecting data for eval...
Eval_AverageReturn : 37.727272033691406
Eval_StdReturn : 5.894387245178223
Eval_MaxReturn : 50.0
Eval_MinReturn : 26.0
Eval_AverageEpLen : 37.72727272727273
Train_AverageReturn : 36.28571319580078
Train_StdReturn : 7.855194568634033
Train_MaxReturn : 60.0
Train_MinReturn : 25.0
Train_AverageEpLen : 36.285714285714285
Actor Loss : 0.5850238800048828
Train_EnvstepsSoFar : 9185
TimeSinceStart : 7.888713359832764
Done logging...



********** Iteration 9 ************

Collecting data for eval...
Eval_AverageReturn : 33.58333206176758
Eval_StdReturn : 5.589548587799072
Eval_MaxReturn : 47.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 33.583333333333336
Train_AverageReturn : 37.33333206176758
Train_StdReturn : 6.036923408508301
Train_MaxReturn : 50.0
Train_MinReturn : 25.0
Train_AverageEpLen : 37.333333333333336
Actor Loss : 1.1372947692871094
Train_EnvstepsSoFar : 10193
TimeSinceStart : 8.646972417831421
Done logging...



********** Iteration 10 ************

Collecting data for eval...
Eval_AverageReturn : 33.75
Eval_StdReturn : 6.8693156242370605
Eval_MaxReturn : 46.0
Eval_MinReturn : 26.0
Eval_AverageEpLen : 33.75
Train_AverageReturn : 36.07143020629883
Train_StdReturn : 6.496859550476074
Train_MaxReturn : 54.0
Train_MinReturn : 27.0
Train_AverageEpLen : 36.07142857142857
Actor Loss : 1.2937240600585938
Train_EnvstepsSoFar : 11203
TimeSinceStart : 9.933026790618896
Done logging...



********** Iteration 11 ************

Collecting data for eval...
Eval_AverageReturn : 43.400001525878906
Eval_StdReturn : 14.143549919128418
Eval_MaxReturn : 68.0
Eval_MinReturn : 26.0
Eval_AverageEpLen : 43.4
Train_AverageReturn : 36.10714340209961
Train_StdReturn : 6.9864115715026855
Train_MaxReturn : 49.0
Train_MinReturn : 25.0
Train_AverageEpLen : 36.107142857142854
Actor Loss : 1.1575336456298828
Train_EnvstepsSoFar : 12214
TimeSinceStart : 10.71997880935669
Done logging...



********** Iteration 12 ************

Collecting data for eval...
Eval_AverageReturn : 46.22222137451172
Eval_StdReturn : 14.890547752380371
Eval_MaxReturn : 72.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 46.22222222222222
Train_AverageReturn : 39.61538314819336
Train_StdReturn : 9.278083801269531
Train_MaxReturn : 58.0
Train_MinReturn : 26.0
Train_AverageEpLen : 39.61538461538461
Actor Loss : 1.116098403930664
Train_EnvstepsSoFar : 13244
TimeSinceStart : 11.517243385314941
Done logging...



********** Iteration 13 ************

Collecting data for eval...
Eval_AverageReturn : 50.75
Eval_StdReturn : 19.511215209960938
Eval_MaxReturn : 86.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 50.75
Train_AverageReturn : 46.09090805053711
Train_StdReturn : 11.758590698242188
Train_MaxReturn : 66.0
Train_MinReturn : 30.0
Train_AverageEpLen : 46.09090909090909
Actor Loss : 1.8634223937988281
Train_EnvstepsSoFar : 14258
TimeSinceStart : 13.22493052482605
Done logging...



********** Iteration 14 ************

Collecting data for eval...
Eval_AverageReturn : 46.0
Eval_StdReturn : 17.89475440979004
Eval_MaxReturn : 87.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 46.0
Train_AverageReturn : 50.95000076293945
Train_StdReturn : 20.50238037109375
Train_MaxReturn : 104.0
Train_MinReturn : 29.0
Train_AverageEpLen : 50.95
Actor Loss : 1.2119140625
Train_EnvstepsSoFar : 15277
TimeSinceStart : 13.995322465896606
Done logging...



********** Iteration 15 ************

Collecting data for eval...
Eval_AverageReturn : 47.66666793823242
Eval_StdReturn : 11.105554580688477
Eval_MaxReturn : 73.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 47.666666666666664
Train_AverageReturn : 52.78947448730469
Train_StdReturn : 23.61216926574707
Train_MaxReturn : 112.0
Train_MinReturn : 32.0
Train_AverageEpLen : 52.78947368421053
Actor Loss : -0.3631172180175781
Train_EnvstepsSoFar : 16280
TimeSinceStart : 14.75572943687439
Done logging...



********** Iteration 16 ************

Collecting data for eval...
Eval_AverageReturn : 55.375
Eval_StdReturn : 12.21615219116211
Eval_MaxReturn : 75.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 55.375
Train_AverageReturn : 54.26315689086914
Train_StdReturn : 21.908523559570312
Train_MaxReturn : 107.0
Train_MinReturn : 37.0
Train_AverageEpLen : 54.26315789473684
Actor Loss : -1.8506908416748047
Train_EnvstepsSoFar : 17311
TimeSinceStart : 15.696866989135742
Done logging...



********** Iteration 17 ************

Collecting data for eval...
Eval_AverageReturn : 50.625
Eval_StdReturn : 9.054522514343262
Eval_MaxReturn : 65.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 50.625
Train_AverageReturn : 48.238094329833984
Train_StdReturn : 11.669678688049316
Train_MaxReturn : 75.0
Train_MinReturn : 34.0
Train_AverageEpLen : 48.23809523809524
Actor Loss : -1.6954936981201172
Train_EnvstepsSoFar : 18324
TimeSinceStart : 16.97690439224243
Done logging...



********** Iteration 18 ************

Collecting data for eval...
Eval_AverageReturn : 42.099998474121094
Eval_StdReturn : 12.429400444030762
Eval_MaxReturn : 71.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 42.1
Train_AverageReturn : 49.33333206176758
Train_StdReturn : 14.340529441833496
Train_MaxReturn : 94.0
Train_MinReturn : 33.0
Train_AverageEpLen : 49.333333333333336
Actor Loss : -2.2052106857299805
Train_EnvstepsSoFar : 19360
TimeSinceStart : 17.770472288131714
Done logging...



********** Iteration 19 ************

Collecting data for eval...
Eval_AverageReturn : 58.75
Eval_StdReturn : 31.9951171875
Eval_MaxReturn : 122.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 58.75
Train_AverageReturn : 53.52631759643555
Train_StdReturn : 32.71144485473633
Train_MaxReturn : 162.0
Train_MinReturn : 29.0
Train_AverageEpLen : 53.526315789473685
Actor Loss : -0.23936939239501953
Train_EnvstepsSoFar : 20377
TimeSinceStart : 18.586094617843628
Done logging...



********** Iteration 20 ************

Collecting data for eval...
Eval_AverageReturn : 66.83333587646484
Eval_StdReturn : 34.299739837646484
Eval_MaxReturn : 106.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 66.83333333333333
Train_AverageReturn : 45.39130401611328
Train_StdReturn : 18.858142852783203
Train_MaxReturn : 108.0
Train_MinReturn : 26.0
Train_AverageEpLen : 45.391304347826086
Actor Loss : -1.2664661407470703
Train_EnvstepsSoFar : 21421
TimeSinceStart : 19.358031511306763
Done logging...



********** Iteration 21 ************

Collecting data for eval...
Eval_AverageReturn : 53.75
Eval_StdReturn : 20.80714988708496
Eval_MaxReturn : 85.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 53.75
Train_AverageReturn : 50.45454406738281
Train_StdReturn : 23.092161178588867
Train_MaxReturn : 112.0
Train_MinReturn : 25.0
Train_AverageEpLen : 50.45454545454545
Actor Loss : -0.4312763214111328
Train_EnvstepsSoFar : 22531
TimeSinceStart : 20.17364001274109
Done logging...



********** Iteration 22 ************

Collecting data for eval...
Eval_AverageReturn : 72.66666412353516
Eval_StdReturn : 26.322782516479492
Eval_MaxReturn : 123.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 72.66666666666667
Train_AverageReturn : 43.565216064453125
Train_StdReturn : 14.980643272399902
Train_MaxReturn : 86.0
Train_MinReturn : 25.0
Train_AverageEpLen : 43.56521739130435
Actor Loss : -0.03565216064453125
Train_EnvstepsSoFar : 23533
TimeSinceStart : 20.939824104309082
Done logging...



********** Iteration 23 ************

Collecting data for eval...
Eval_AverageReturn : 51.0
Eval_StdReturn : 32.973472595214844
Eval_MaxReturn : 117.0
Eval_MinReturn : 26.0
Eval_AverageEpLen : 51.0
Train_AverageReturn : 37.14814758300781
Train_StdReturn : 10.229599952697754
Train_MaxReturn : 62.0
Train_MinReturn : 26.0
Train_AverageEpLen : 37.148148148148145
Actor Loss : -1.1949615478515625
Train_EnvstepsSoFar : 24536
TimeSinceStart : 21.71102738380432
Done logging...



********** Iteration 24 ************

Collecting data for eval...
Eval_AverageReturn : 73.57142639160156
Eval_StdReturn : 33.767513275146484
Eval_MaxReturn : 135.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 73.57142857142857
Train_AverageReturn : 57.05555725097656
Train_StdReturn : 33.85011291503906
Train_MaxReturn : 146.0
Train_MinReturn : 25.0
Train_AverageEpLen : 57.05555555555556
Actor Loss : -2.5509214401245117
Train_EnvstepsSoFar : 25563
TimeSinceStart : 22.528602123260498
Done logging...



********** Iteration 25 ************

Collecting data for eval...
Eval_AverageReturn : 60.42856979370117
Eval_StdReturn : 24.835786819458008
Eval_MaxReturn : 105.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 60.42857142857143
Train_AverageReturn : 41.36000061035156
Train_StdReturn : 19.170560836791992
Train_MaxReturn : 124.0
Train_MinReturn : 25.0
Train_AverageEpLen : 41.36
Actor Loss : -3.092959403991699
Train_EnvstepsSoFar : 26597
TimeSinceStart : 23.311376333236694
Done logging...



********** Iteration 26 ************

Collecting data for eval...
Eval_AverageReturn : 57.85714340209961
Eval_StdReturn : 22.49716567993164
Eval_MaxReturn : 101.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 57.857142857142854
Train_AverageReturn : 52.894737243652344
Train_StdReturn : 23.99538230895996
Train_MaxReturn : 104.0
Train_MinReturn : 25.0
Train_AverageEpLen : 52.89473684210526
Actor Loss : -4.479460716247559
Train_EnvstepsSoFar : 27602
TimeSinceStart : 24.063058137893677
Done logging...



********** Iteration 27 ************

Collecting data for eval...
Eval_AverageReturn : 43.29999923706055
Eval_StdReturn : 15.316984176635742
Eval_MaxReturn : 77.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 43.3
Train_AverageReturn : 43.69565200805664
Train_StdReturn : 15.916725158691406
Train_MaxReturn : 80.0
Train_MinReturn : 27.0
Train_AverageEpLen : 43.69565217391305
Actor Loss : -6.1387481689453125
Train_EnvstepsSoFar : 28607
TimeSinceStart : 24.826996564865112
Done logging...



********** Iteration 28 ************

Collecting data for eval...
Eval_AverageReturn : 39.3636360168457
Eval_StdReturn : 11.475449562072754
Eval_MaxReturn : 67.0
Eval_MinReturn : 26.0
Eval_AverageEpLen : 39.36363636363637
Train_AverageReturn : 46.09090805053711
Train_StdReturn : 15.721755027770996
Train_MaxReturn : 84.0
Train_MinReturn : 28.0
Train_AverageEpLen : 46.09090909090909
Actor Loss : -6.257808685302734
Train_EnvstepsSoFar : 29621
TimeSinceStart : 26.01324462890625
Done logging...



********** Iteration 29 ************

Collecting data for eval...
Eval_AverageReturn : 42.400001525878906
Eval_StdReturn : 12.563438415527344
Eval_MaxReturn : 71.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 42.4
Train_AverageReturn : 46.772727966308594
Train_StdReturn : 18.340049743652344
Train_MaxReturn : 101.0
Train_MinReturn : 27.0
Train_AverageEpLen : 46.77272727272727
Actor Loss : -5.720203399658203
Train_EnvstepsSoFar : 30650
TimeSinceStart : 26.794907093048096
Done logging...



********** Iteration 30 ************

Collecting data for eval...
Eval_AverageReturn : 45.66666793823242
Eval_StdReturn : 19.573225021362305
Eval_MaxReturn : 87.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 45.666666666666664
Train_AverageReturn : 41.70833206176758
Train_StdReturn : 13.07184886932373
Train_MaxReturn : 76.0
Train_MinReturn : 27.0
Train_AverageEpLen : 41.708333333333336
Actor Loss : -4.295967102050781
Train_EnvstepsSoFar : 31651
TimeSinceStart : 27.538838863372803
Done logging...



********** Iteration 31 ************

Collecting data for eval...
Eval_AverageReturn : 40.900001525878906
Eval_StdReturn : 12.668464660644531
Eval_MaxReturn : 75.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 40.9
Train_AverageReturn : 43.16666793823242
Train_StdReturn : 20.00763702392578
Train_MaxReturn : 128.0
Train_MinReturn : 27.0
Train_AverageEpLen : 43.166666666666664
Actor Loss : -8.164565086364746
Train_EnvstepsSoFar : 32687
TimeSinceStart : 28.92245101928711
Done logging...



********** Iteration 32 ************

Collecting data for eval...
Eval_AverageReturn : 46.77777862548828
Eval_StdReturn : 11.57370376586914
Eval_MaxReturn : 66.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 46.77777777777778
Train_AverageReturn : 40.31999969482422
Train_StdReturn : 15.486044883728027
Train_MaxReturn : 96.0
Train_MinReturn : 25.0
Train_AverageEpLen : 40.32
Actor Loss : -9.409834861755371
Train_EnvstepsSoFar : 33695
TimeSinceStart : 29.679531574249268
Done logging...



********** Iteration 33 ************

Collecting data for eval...
Eval_AverageReturn : 57.25
Eval_StdReturn : 16.114822387695312
Eval_MaxReturn : 93.0
Eval_MinReturn : 40.0
Eval_AverageEpLen : 57.25
Train_AverageReturn : 44.60869598388672
Train_StdReturn : 16.66221809387207
Train_MaxReturn : 102.0
Train_MinReturn : 29.0
Train_AverageEpLen : 44.608695652173914
Actor Loss : -7.236944198608398
Train_EnvstepsSoFar : 34721
TimeSinceStart : 30.455418586730957
Done logging...



********** Iteration 34 ************

Collecting data for eval...
Eval_AverageReturn : 60.71428680419922
Eval_StdReturn : 15.709089279174805
Eval_MaxReturn : 97.0
Eval_MinReturn : 50.0
Eval_AverageEpLen : 60.714285714285715
Train_AverageReturn : 59.882354736328125
Train_StdReturn : 14.887351036071777
Train_MaxReturn : 85.0
Train_MinReturn : 42.0
Train_AverageEpLen : 59.88235294117647
Actor Loss : -3.7972183227539062
Train_EnvstepsSoFar : 35739
TimeSinceStart : 31.233317852020264
Done logging...



********** Iteration 35 ************

Collecting data for eval...
Eval_AverageReturn : 50.0
Eval_StdReturn : 10.828204154968262
Eval_MaxReturn : 67.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 50.0
Train_AverageReturn : 53.3684196472168
Train_StdReturn : 19.945215225219727
Train_MaxReturn : 118.0
Train_MinReturn : 32.0
Train_AverageEpLen : 53.36842105263158
Actor Loss : 9.896425247192383
Train_EnvstepsSoFar : 36753
TimeSinceStart : 31.99324607849121
Done logging...



********** Iteration 36 ************

Collecting data for eval...
Eval_AverageReturn : 50.75
Eval_StdReturn : 14.694811820983887
Eval_MaxReturn : 76.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 50.75
Train_AverageReturn : 50.04999923706055
Train_StdReturn : 14.0587158203125
Train_MaxReturn : 77.0
Train_MinReturn : 30.0
Train_AverageEpLen : 50.05
Actor Loss : 5.8123016357421875
Train_EnvstepsSoFar : 37754
TimeSinceStart : 32.759705781936646
Done logging...



********** Iteration 37 ************

Collecting data for eval...
Eval_AverageReturn : 51.0
Eval_StdReturn : 20.105968475341797
Eval_MaxReturn : 85.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 51.0
Train_AverageReturn : 48.14285659790039
Train_StdReturn : 22.10426902770996
Train_MaxReturn : 114.0
Train_MinReturn : 30.0
Train_AverageEpLen : 48.142857142857146
Actor Loss : 12.731300354003906
Train_EnvstepsSoFar : 38765
TimeSinceStart : 34.47415208816528
Done logging...



********** Iteration 38 ************

Collecting data for eval...
Eval_AverageReturn : 56.5
Eval_StdReturn : 16.874536514282227
Eval_MaxReturn : 86.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 56.5
Train_AverageReturn : 51.79999923706055
Train_StdReturn : 28.310070037841797
Train_MaxReturn : 151.0
Train_MinReturn : 30.0
Train_AverageEpLen : 51.8
Actor Loss : 8.34878158569336
Train_EnvstepsSoFar : 39801
TimeSinceStart : 36.245070695877075
Done logging...



********** Iteration 39 ************

Collecting data for eval...
Eval_AverageReturn : 52.375
Eval_StdReturn : 11.455757141113281
Eval_MaxReturn : 78.0
Eval_MinReturn : 39.0
Eval_AverageEpLen : 52.375
Train_AverageReturn : 51.849998474121094
Train_StdReturn : 18.070072174072266
Train_MaxReturn : 97.0
Train_MinReturn : 34.0
Train_AverageEpLen : 51.85
Actor Loss : 10.164315223693848
Train_EnvstepsSoFar : 40838
TimeSinceStart : 37.017897605895996
Done logging...



********** Iteration 40 ************

Collecting data for eval...
Eval_AverageReturn : 50.125
Eval_StdReturn : 22.552370071411133
Eval_MaxReturn : 106.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 50.125
Train_AverageReturn : 47.181819915771484
Train_StdReturn : 11.633167266845703
Train_MaxReturn : 70.0
Train_MinReturn : 30.0
Train_AverageEpLen : 47.18181818181818
Actor Loss : 8.093246459960938
Train_EnvstepsSoFar : 41876
TimeSinceStart : 38.092997789382935
Done logging...



********** Iteration 41 ************

Collecting data for eval...
Eval_AverageReturn : 58.0
Eval_StdReturn : 25.105491638183594
Eval_MaxReturn : 94.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 58.0
Train_AverageReturn : 50.599998474121094
Train_StdReturn : 10.575443267822266
Train_MaxReturn : 72.0
Train_MinReturn : 36.0
Train_AverageEpLen : 50.6
Actor Loss : -0.36175537109375
Train_EnvstepsSoFar : 42888
TimeSinceStart : 38.85089993476868
Done logging...



********** Iteration 42 ************

Collecting data for eval...
Eval_AverageReturn : 49.44444274902344
Eval_StdReturn : 11.767291069030762
Eval_MaxReturn : 66.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 49.44444444444444
Train_AverageReturn : 51.45000076293945
Train_StdReturn : 11.235992431640625
Train_MaxReturn : 80.0
Train_MinReturn : 31.0
Train_AverageEpLen : 51.45
Actor Loss : 0.943202018737793
Train_EnvstepsSoFar : 43917
TimeSinceStart : 39.64271879196167
Done logging...



********** Iteration 43 ************

Collecting data for eval...
Eval_AverageReturn : 50.75
Eval_StdReturn : 12.04937744140625
Eval_MaxReturn : 71.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 50.75
Train_AverageReturn : 44.173912048339844
Train_StdReturn : 9.00556468963623
Train_MaxReturn : 69.0
Train_MinReturn : 34.0
Train_AverageEpLen : 44.17391304347826
Actor Loss : 1.155029296875
Train_EnvstepsSoFar : 44933
TimeSinceStart : 40.3971152305603
Done logging...



********** Iteration 44 ************

Collecting data for eval...
Eval_AverageReturn : 57.0
Eval_StdReturn : 22.24859619140625
Eval_MaxReturn : 92.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 57.0
Train_AverageReturn : 58.73684310913086
Train_StdReturn : 32.60261917114258
Train_MaxReturn : 149.0
Train_MinReturn : 30.0
Train_AverageEpLen : 58.73684210526316
Actor Loss : 0.5816879272460938
Train_EnvstepsSoFar : 46049
TimeSinceStart : 41.94361591339111
Done logging...



********** Iteration 45 ************

Collecting data for eval...
Eval_AverageReturn : 46.55555725097656
Eval_StdReturn : 9.967848777770996
Eval_MaxReturn : 63.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 46.55555555555556
Train_AverageReturn : 53.45000076293945
Train_StdReturn : 16.27413558959961
Train_MaxReturn : 94.0
Train_MinReturn : 31.0
Train_AverageEpLen : 53.45
Actor Loss : -7.256153106689453
Train_EnvstepsSoFar : 47118
TimeSinceStart : 42.73706078529358
Done logging...



********** Iteration 46 ************

Collecting data for eval...
Eval_AverageReturn : 51.75
Eval_StdReturn : 8.347904205322266
Eval_MaxReturn : 62.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 51.75
Train_AverageReturn : 45.08695602416992
Train_StdReturn : 12.991344451904297
Train_MaxReturn : 82.0
Train_MinReturn : 31.0
Train_AverageEpLen : 45.08695652173913
Actor Loss : -4.6540374755859375
Train_EnvstepsSoFar : 48155
TimeSinceStart : 43.49808883666992
Done logging...



********** Iteration 47 ************

Collecting data for eval...
Eval_AverageReturn : 54.25
Eval_StdReturn : 11.776565551757812
Eval_MaxReturn : 82.0
Eval_MinReturn : 42.0
Eval_AverageEpLen : 54.25
Train_AverageReturn : 67.06666564941406
Train_StdReturn : 19.41980743408203
Train_MaxReturn : 121.0
Train_MinReturn : 34.0
Train_AverageEpLen : 67.06666666666666
Actor Loss : -0.322265625
Train_EnvstepsSoFar : 49161
TimeSinceStart : 44.264856815338135
Done logging...



********** Iteration 48 ************

Collecting data for eval...
Eval_AverageReturn : 67.66666412353516
Eval_StdReturn : 21.638442993164062
Eval_MaxReturn : 91.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 67.66666666666667
Train_AverageReturn : 69.86666870117188
Train_StdReturn : 12.18669605255127
Train_MaxReturn : 91.0
Train_MinReturn : 46.0
Train_AverageEpLen : 69.86666666666666
Actor Loss : 0.8379364013671875
Train_EnvstepsSoFar : 50209
TimeSinceStart : 45.18741250038147
Done logging...



********** Iteration 49 ************

Collecting data for eval...
Eval_AverageReturn : 45.0
Eval_StdReturn : 11.680943489074707
Eval_MaxReturn : 68.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 45.0
Train_AverageReturn : 51.900001525878906
Train_StdReturn : 14.2684965133667
Train_MaxReturn : 87.0
Train_MinReturn : 34.0
Train_AverageEpLen : 51.9
Actor Loss : -6.642345428466797
Train_EnvstepsSoFar : 51247
TimeSinceStart : 45.94113636016846
Done logging...



********** Iteration 50 ************

Collecting data for eval...
Eval_AverageReturn : 63.0
Eval_StdReturn : 34.98571014404297
Eval_MaxReturn : 140.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 63.0
Train_AverageReturn : 49.095237731933594
Train_StdReturn : 18.368982315063477
Train_MaxReturn : 92.0
Train_MinReturn : 30.0
Train_AverageEpLen : 49.095238095238095
Actor Loss : -7.824301719665527
Train_EnvstepsSoFar : 52278
TimeSinceStart : 46.7374746799469
Done logging...



********** Iteration 51 ************

Collecting data for eval...
Eval_AverageReturn : 50.625
Eval_StdReturn : 21.753950119018555
Eval_MaxReturn : 99.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 50.625
Train_AverageReturn : 50.20000076293945
Train_StdReturn : 19.236942291259766
Train_MaxReturn : 93.0
Train_MinReturn : 30.0
Train_AverageEpLen : 50.2
Actor Loss : -3.985595703125
Train_EnvstepsSoFar : 53282
TimeSinceStart : 47.49104046821594
Done logging...



********** Iteration 52 ************

Collecting data for eval...
Eval_AverageReturn : 40.70000076293945
Eval_StdReturn : 14.4502592086792
Eval_MaxReturn : 82.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 40.7
Train_AverageReturn : 53.842105865478516
Train_StdReturn : 24.112157821655273
Train_MaxReturn : 109.0
Train_MinReturn : 29.0
Train_AverageEpLen : 53.8421052631579
Actor Loss : -3.8712081909179688
Train_EnvstepsSoFar : 54305
TimeSinceStart : 48.25046730041504
Done logging...



********** Iteration 53 ************

Collecting data for eval...
Eval_AverageReturn : 51.25
Eval_StdReturn : 5.952940464019775
Eval_MaxReturn : 64.0
Eval_MinReturn : 43.0
Eval_AverageEpLen : 51.25
Train_AverageReturn : 52.04999923706055
Train_StdReturn : 20.57784080505371
Train_MaxReturn : 108.0
Train_MinReturn : 31.0
Train_AverageEpLen : 52.05
Actor Loss : -6.574234962463379
Train_EnvstepsSoFar : 55346
TimeSinceStart : 49.01716470718384
Done logging...



********** Iteration 54 ************

Collecting data for eval...
Eval_AverageReturn : 55.125
Eval_StdReturn : 12.712567329406738
Eval_MaxReturn : 77.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 55.125
Train_AverageReturn : 47.3636360168457
Train_StdReturn : 9.271390914916992
Train_MaxReturn : 69.0
Train_MinReturn : 34.0
Train_AverageEpLen : 47.36363636363637
Actor Loss : -5.25346565246582
Train_EnvstepsSoFar : 56388
TimeSinceStart : 49.80518841743469
Done logging...



********** Iteration 55 ************

Collecting data for eval...
Eval_AverageReturn : 63.28571319580078
Eval_StdReturn : 9.793792724609375
Eval_MaxReturn : 76.0
Eval_MinReturn : 50.0
Eval_AverageEpLen : 63.285714285714285
Train_AverageReturn : 53.94736862182617
Train_StdReturn : 16.021282196044922
Train_MaxReturn : 88.0
Train_MinReturn : 36.0
Train_AverageEpLen : 53.94736842105263
Actor Loss : -11.642424583435059
Train_EnvstepsSoFar : 57413
TimeSinceStart : 50.58468961715698
Done logging...



********** Iteration 56 ************

Collecting data for eval...
Eval_AverageReturn : 55.625
Eval_StdReturn : 11.279821395874023
Eval_MaxReturn : 78.0
Eval_MinReturn : 39.0
Eval_AverageEpLen : 55.625
Train_AverageReturn : 58.82352828979492
Train_StdReturn : 14.3782320022583
Train_MaxReturn : 108.0
Train_MinReturn : 41.0
Train_AverageEpLen : 58.8235294117647
Actor Loss : -7.510329723358154
Train_EnvstepsSoFar : 58413
TimeSinceStart : 52.28597974777222
Done logging...



********** Iteration 57 ************

Collecting data for eval...
Eval_AverageReturn : 67.5
Eval_StdReturn : 15.152007102966309
Eval_MaxReturn : 89.0
Eval_MinReturn : 47.0
Eval_AverageEpLen : 67.5
Train_AverageReturn : 65.76470947265625
Train_StdReturn : 24.443283081054688
Train_MaxReturn : 135.0
Train_MinReturn : 40.0
Train_AverageEpLen : 65.76470588235294
Actor Loss : 2.0961380004882812
Train_EnvstepsSoFar : 59531
TimeSinceStart : 53.08547616004944
Done logging...



********** Iteration 58 ************

Collecting data for eval...
Eval_AverageReturn : 101.25
Eval_StdReturn : 25.143339157104492
Eval_MaxReturn : 123.0
Eval_MinReturn : 61.0
Eval_AverageEpLen : 101.25
Train_AverageReturn : 67.13333129882812
Train_StdReturn : 19.43833351135254
Train_MaxReturn : 108.0
Train_MinReturn : 39.0
Train_AverageEpLen : 67.13333333333334
Actor Loss : -6.227160453796387
Train_EnvstepsSoFar : 60538
TimeSinceStart : 53.83679556846619
Done logging...



********** Iteration 59 ************

Collecting data for eval...
Eval_AverageReturn : 63.42856979370117
Eval_StdReturn : 8.243736267089844
Eval_MaxReturn : 76.0
Eval_MinReturn : 53.0
Eval_AverageEpLen : 63.42857142857143
Train_AverageReturn : 57.61111068725586
Train_StdReturn : 10.144177436828613
Train_MaxReturn : 74.0
Train_MinReturn : 41.0
Train_AverageEpLen : 57.611111111111114
Actor Loss : 4.563835144042969
Train_EnvstepsSoFar : 61575
TimeSinceStart : 54.60592985153198
Done logging...



********** Iteration 60 ************

Collecting data for eval...
Eval_AverageReturn : 76.33333587646484
Eval_StdReturn : 22.521595001220703
Eval_MaxReturn : 109.0
Eval_MinReturn : 45.0
Eval_AverageEpLen : 76.33333333333333
Train_AverageReturn : 72.0
Train_StdReturn : 19.045059204101562
Train_MaxReturn : 102.0
Train_MinReturn : 40.0
Train_AverageEpLen : 72.0
Actor Loss : 8.525825500488281
Train_EnvstepsSoFar : 62583
TimeSinceStart : 55.37053990364075
Done logging...



********** Iteration 61 ************

Collecting data for eval...
Eval_AverageReturn : 75.33333587646484
Eval_StdReturn : 17.26911163330078
Eval_MaxReturn : 100.0
Eval_MinReturn : 45.0
Eval_AverageEpLen : 75.33333333333333
Train_AverageReturn : 84.38461303710938
Train_StdReturn : 26.467798233032227
Train_MaxReturn : 135.0
Train_MinReturn : 45.0
Train_AverageEpLen : 84.38461538461539
Actor Loss : 9.074546813964844
Train_EnvstepsSoFar : 63680
TimeSinceStart : 56.18686032295227
Done logging...



********** Iteration 62 ************

Collecting data for eval...
Eval_AverageReturn : 76.5
Eval_StdReturn : 25.604360580444336
Eval_MaxReturn : 121.0
Eval_MinReturn : 45.0
Eval_AverageEpLen : 76.5
Train_AverageReturn : 92.83333587646484
Train_StdReturn : 27.865251541137695
Train_MaxReturn : 136.0
Train_MinReturn : 49.0
Train_AverageEpLen : 92.83333333333333
Actor Loss : -0.20238208770751953
Train_EnvstepsSoFar : 64794
TimeSinceStart : 57.014458894729614
Done logging...



********** Iteration 63 ************

Collecting data for eval...
Eval_AverageReturn : 80.80000305175781
Eval_StdReturn : 4.621687889099121
Eval_MaxReturn : 86.0
Eval_MinReturn : 74.0
Eval_AverageEpLen : 80.8
Train_AverageReturn : 78.42857360839844
Train_StdReturn : 23.163131713867188
Train_MaxReturn : 134.0
Train_MinReturn : 53.0
Train_AverageEpLen : 78.42857142857143
Actor Loss : -4.495859146118164
Train_EnvstepsSoFar : 65892
TimeSinceStart : 57.818103313446045
Done logging...



********** Iteration 64 ************

Collecting data for eval...
Eval_AverageReturn : 67.0
Eval_StdReturn : 17.078250885009766
Eval_MaxReturn : 94.0
Eval_MinReturn : 47.0
Eval_AverageEpLen : 67.0
Train_AverageReturn : 78.07142639160156
Train_StdReturn : 24.308917999267578
Train_MaxReturn : 129.0
Train_MinReturn : 50.0
Train_AverageEpLen : 78.07142857142857
Actor Loss : 11.156997680664062
Train_EnvstepsSoFar : 66985
TimeSinceStart : 58.593103885650635
Done logging...



********** Iteration 65 ************

Collecting data for eval...
Eval_AverageReturn : 63.85714340209961
Eval_StdReturn : 17.739614486694336
Eval_MaxReturn : 102.0
Eval_MinReturn : 45.0
Eval_AverageEpLen : 63.857142857142854
Train_AverageReturn : 82.15384674072266
Train_StdReturn : 27.10335350036621
Train_MaxReturn : 161.0
Train_MinReturn : 43.0
Train_AverageEpLen : 82.15384615384616
Actor Loss : -1.9263057708740234
Train_EnvstepsSoFar : 68053
TimeSinceStart : 59.396748065948486
Done logging...



********** Iteration 66 ************

Collecting data for eval...
Eval_AverageReturn : 82.4000015258789
Eval_StdReturn : 26.363611221313477
Eval_MaxReturn : 133.0
Eval_MinReturn : 61.0
Eval_AverageEpLen : 82.4
Train_AverageReturn : 71.78571319580078
Train_StdReturn : 18.19803237915039
Train_MaxReturn : 118.0
Train_MinReturn : 47.0
Train_AverageEpLen : 71.78571428571429
Actor Loss : 1.5185273885726929
Train_EnvstepsSoFar : 69058
TimeSinceStart : 60.13738298416138
Done logging...



********** Iteration 67 ************

Collecting data for eval...
Eval_AverageReturn : 88.19999694824219
Eval_StdReturn : 16.998823165893555
Eval_MaxReturn : 116.0
Eval_MinReturn : 68.0
Eval_AverageEpLen : 88.2
Train_AverageReturn : 71.0
Train_StdReturn : 20.373186111450195
Train_MaxReturn : 117.0
Train_MinReturn : 45.0
Train_AverageEpLen : 71.0
Actor Loss : 10.504440307617188
Train_EnvstepsSoFar : 70123
TimeSinceStart : 60.93768239021301
Done logging...



********** Iteration 68 ************

Collecting data for eval...
Eval_AverageReturn : 73.66666412353516
Eval_StdReturn : 7.930251598358154
Eval_MaxReturn : 86.0
Eval_MinReturn : 66.0
Eval_AverageEpLen : 73.66666666666667
Train_AverageReturn : 83.33333587646484
Train_StdReturn : 31.433351516723633
Train_MaxReturn : 151.0
Train_MinReturn : 49.0
Train_AverageEpLen : 83.33333333333333
Actor Loss : 5.561443328857422
Train_EnvstepsSoFar : 71123
TimeSinceStart : 61.7085177898407
Done logging...



********** Iteration 69 ************

Collecting data for eval...
Eval_AverageReturn : 60.71428680419922
Eval_StdReturn : 12.032269477844238
Eval_MaxReturn : 84.0
Eval_MinReturn : 47.0
Eval_AverageEpLen : 60.714285714285715
Train_AverageReturn : 78.38461303710938
Train_StdReturn : 18.18933868408203
Train_MaxReturn : 112.0
Train_MinReturn : 43.0
Train_AverageEpLen : 78.38461538461539
Actor Loss : 0.9857921600341797
Train_EnvstepsSoFar : 72142
TimeSinceStart : 62.47559714317322
Done logging...



********** Iteration 70 ************

Collecting data for eval...
Eval_AverageReturn : 72.33333587646484
Eval_StdReturn : 16.839107513427734
Eval_MaxReturn : 102.0
Eval_MinReturn : 52.0
Eval_AverageEpLen : 72.33333333333333
Train_AverageReturn : 70.86666870117188
Train_StdReturn : 22.066162109375
Train_MaxReturn : 120.0
Train_MinReturn : 41.0
Train_AverageEpLen : 70.86666666666666
Actor Loss : 1.1154274940490723
Train_EnvstepsSoFar : 73205
TimeSinceStart : 63.27532243728638
Done logging...



********** Iteration 71 ************

Collecting data for eval...
Eval_AverageReturn : 78.16666412353516
Eval_StdReturn : 17.496824264526367
Eval_MaxReturn : 115.0
Eval_MinReturn : 63.0
Eval_AverageEpLen : 78.16666666666667
Train_AverageReturn : 73.71428680419922
Train_StdReturn : 21.726970672607422
Train_MaxReturn : 110.0
Train_MinReturn : 39.0
Train_AverageEpLen : 73.71428571428571
Actor Loss : 3.0236196517944336
Train_EnvstepsSoFar : 74237
TimeSinceStart : 64.07099103927612
Done logging...



********** Iteration 72 ************

Collecting data for eval...
Eval_AverageReturn : 78.66666412353516
Eval_StdReturn : 9.049247741699219
Eval_MaxReturn : 95.0
Eval_MinReturn : 68.0
Eval_AverageEpLen : 78.66666666666667
Train_AverageReturn : 64.64705657958984
Train_StdReturn : 16.34172248840332
Train_MaxReturn : 104.0
Train_MinReturn : 44.0
Train_AverageEpLen : 64.6470588235294
Actor Loss : -10.897525787353516
Train_EnvstepsSoFar : 75336
TimeSinceStart : 64.92374610900879
Done logging...



********** Iteration 73 ************

Collecting data for eval...
Eval_AverageReturn : 87.5999984741211
Eval_StdReturn : 14.037093162536621
Eval_MaxReturn : 109.0
Eval_MinReturn : 66.0
Eval_AverageEpLen : 87.6
Train_AverageReturn : 73.0
Train_StdReturn : 15.057034492492676
Train_MaxReturn : 106.0
Train_MinReturn : 52.0
Train_AverageEpLen : 73.0
Actor Loss : 11.554547309875488
Train_EnvstepsSoFar : 76358
TimeSinceStart : 65.72291851043701
Done logging...



********** Iteration 74 ************

Collecting data for eval...
Eval_AverageReturn : 97.19999694824219
Eval_StdReturn : 16.975276947021484
Eval_MaxReturn : 123.0
Eval_MinReturn : 78.0
Eval_AverageEpLen : 97.2
Train_AverageReturn : 88.91666412353516
Train_StdReturn : 29.161785125732422
Train_MaxReturn : 163.0
Train_MinReturn : 50.0
Train_AverageEpLen : 88.91666666666667
Actor Loss : -0.6953010559082031
Train_EnvstepsSoFar : 77425
TimeSinceStart : 66.54379296302795
Done logging...



********** Iteration 75 ************

Collecting data for eval...
Eval_AverageReturn : 95.80000305175781
Eval_StdReturn : 32.578521728515625
Eval_MaxReturn : 155.0
Eval_MinReturn : 59.0
Eval_AverageEpLen : 95.8
Train_AverageReturn : 92.54545593261719
Train_StdReturn : 25.627981185913086
Train_MaxReturn : 160.0
Train_MinReturn : 59.0
Train_AverageEpLen : 92.54545454545455
Actor Loss : -9.310508728027344
Train_EnvstepsSoFar : 78443
TimeSinceStart : 67.32442951202393
Done logging...



********** Iteration 76 ************

Collecting data for eval...
Eval_AverageReturn : 105.25
Eval_StdReturn : 25.81060791015625
Eval_MaxReturn : 133.0
Eval_MinReturn : 69.0
Eval_AverageEpLen : 105.25
Train_AverageReturn : 81.30769348144531
Train_StdReturn : 16.35841178894043
Train_MaxReturn : 122.0
Train_MinReturn : 61.0
Train_AverageEpLen : 81.3076923076923
Actor Loss : 6.345932960510254
Train_EnvstepsSoFar : 79500
TimeSinceStart : 68.10920310020447
Done logging...



********** Iteration 77 ************

Collecting data for eval...
Eval_AverageReturn : 92.0
Eval_StdReturn : 25.408658981323242
Eval_MaxReturn : 128.0
Eval_MinReturn : 61.0
Eval_AverageEpLen : 92.0
Train_AverageReturn : 84.83333587646484
Train_StdReturn : 28.398454666137695
Train_MaxReturn : 141.0
Train_MinReturn : 51.0
Train_AverageEpLen : 84.83333333333333
Actor Loss : 0.2911226749420166
Train_EnvstepsSoFar : 80518
TimeSinceStart : 68.90717101097107
Done logging...



********** Iteration 78 ************

Collecting data for eval...
Eval_AverageReturn : 70.66666412353516
Eval_StdReturn : 16.28564453125
Eval_MaxReturn : 98.0
Eval_MinReturn : 50.0
Eval_AverageEpLen : 70.66666666666667
Train_AverageReturn : 87.91666412353516
Train_StdReturn : 30.239208221435547
Train_MaxReturn : 145.0
Train_MinReturn : 50.0
Train_AverageEpLen : 87.91666666666667
Actor Loss : 3.234280586242676
Train_EnvstepsSoFar : 81573
TimeSinceStart : 69.68929433822632
Done logging...



********** Iteration 79 ************

Collecting data for eval...
Eval_AverageReturn : 101.25
Eval_StdReturn : 29.617351531982422
Eval_MaxReturn : 137.0
Eval_MinReturn : 71.0
Eval_AverageEpLen : 101.25
Train_AverageReturn : 90.5
Train_StdReturn : 25.044960021972656
Train_MaxReturn : 137.0
Train_MinReturn : 59.0
Train_AverageEpLen : 90.5
Actor Loss : -4.324408531188965
Train_EnvstepsSoFar : 82659
TimeSinceStart : 70.48317575454712
Done logging...



********** Iteration 80 ************

Collecting data for eval...
Eval_AverageReturn : 88.80000305175781
Eval_StdReturn : 23.60847282409668
Eval_MaxReturn : 125.0
Eval_MinReturn : 53.0
Eval_AverageEpLen : 88.8
Train_AverageReturn : 102.69999694824219
Train_StdReturn : 41.66305160522461
Train_MaxReturn : 200.0
Train_MinReturn : 54.0
Train_AverageEpLen : 102.7
Actor Loss : -15.24769401550293
Train_EnvstepsSoFar : 83686
TimeSinceStart : 71.24949789047241
Done logging...



********** Iteration 81 ************

Collecting data for eval...
Eval_AverageReturn : 112.0
Eval_StdReturn : 34.47462844848633
Eval_MaxReturn : 170.0
Eval_MinReturn : 85.0
Eval_AverageEpLen : 112.0
Train_AverageReturn : 74.64286041259766
Train_StdReturn : 11.461782455444336
Train_MaxReturn : 94.0
Train_MinReturn : 57.0
Train_AverageEpLen : 74.64285714285714
Actor Loss : -6.157399654388428
Train_EnvstepsSoFar : 84731
TimeSinceStart : 72.05021500587463
Done logging...



********** Iteration 82 ************

Collecting data for eval...
Eval_AverageReturn : 89.4000015258789
Eval_StdReturn : 15.173661231994629
Eval_MaxReturn : 112.0
Eval_MinReturn : 68.0
Eval_AverageEpLen : 89.4
Train_AverageReturn : 94.63636016845703
Train_StdReturn : 20.645370483398438
Train_MaxReturn : 146.0
Train_MinReturn : 67.0
Train_AverageEpLen : 94.63636363636364
Actor Loss : 2.6479949951171875
Train_EnvstepsSoFar : 85772
TimeSinceStart : 72.82668089866638
Done logging...



********** Iteration 83 ************

Collecting data for eval...
Eval_AverageReturn : 114.25
Eval_StdReturn : 21.00446319580078
Eval_MaxReturn : 144.0
Eval_MinReturn : 93.0
Eval_AverageEpLen : 114.25
Train_AverageReturn : 109.80000305175781
Train_StdReturn : 16.933990478515625
Train_MaxReturn : 151.0
Train_MinReturn : 90.0
Train_AverageEpLen : 109.8
Actor Loss : 5.72920036315918
Train_EnvstepsSoFar : 86870
TimeSinceStart : 73.6370005607605
Done logging...



********** Iteration 84 ************

Collecting data for eval...
Eval_AverageReturn : 84.19999694824219
Eval_StdReturn : 22.094343185424805
Eval_MaxReturn : 125.0
Eval_MinReturn : 62.0
Eval_AverageEpLen : 84.2
Train_AverageReturn : 90.33333587646484
Train_StdReturn : 21.688451766967773
Train_MaxReturn : 129.0
Train_MinReturn : 63.0
Train_AverageEpLen : 90.33333333333333
Actor Loss : 0.855219841003418
Train_EnvstepsSoFar : 87954
TimeSinceStart : 74.42368149757385
Done logging...



********** Iteration 85 ************

Collecting data for eval...
Eval_AverageReturn : 133.3333282470703
Eval_StdReturn : 44.439720153808594
Eval_MaxReturn : 195.0
Eval_MinReturn : 92.0
Eval_AverageEpLen : 133.33333333333334
Train_AverageReturn : 91.63636016845703
Train_StdReturn : 19.905563354492188
Train_MaxReturn : 122.0
Train_MinReturn : 59.0
Train_AverageEpLen : 91.63636363636364
Actor Loss : 3.337045192718506
Train_EnvstepsSoFar : 88962
TimeSinceStart : 75.1785614490509
Done logging...



********** Iteration 86 ************

Collecting data for eval...
Eval_AverageReturn : 102.25
Eval_StdReturn : 37.022796630859375
Eval_MaxReturn : 153.0
Eval_MinReturn : 63.0
Eval_AverageEpLen : 102.25
Train_AverageReturn : 112.88888549804688
Train_StdReturn : 22.536115646362305
Train_MaxReturn : 143.0
Train_MinReturn : 71.0
Train_AverageEpLen : 112.88888888888889
Actor Loss : -0.009023666381835938
Train_EnvstepsSoFar : 89978
TimeSinceStart : 75.9430091381073
Done logging...



********** Iteration 87 ************

Collecting data for eval...
Eval_AverageReturn : 96.5999984741211
Eval_StdReturn : 10.5185546875
Eval_MaxReturn : 117.0
Eval_MinReturn : 87.0
Eval_AverageEpLen : 96.6
Train_AverageReturn : 96.81818389892578
Train_StdReturn : 20.292490005493164
Train_MaxReturn : 125.0
Train_MinReturn : 59.0
Train_AverageEpLen : 96.81818181818181
Actor Loss : 7.605403900146484
Train_EnvstepsSoFar : 91043
TimeSinceStart : 76.75205779075623
Done logging...



********** Iteration 88 ************

Collecting data for eval...
Eval_AverageReturn : 93.4000015258789
Eval_StdReturn : 26.325653076171875
Eval_MaxReturn : 141.0
Eval_MinReturn : 62.0
Eval_AverageEpLen : 93.4
Train_AverageReturn : 100.19999694824219
Train_StdReturn : 25.051145553588867
Train_MaxReturn : 158.0
Train_MinReturn : 58.0
Train_AverageEpLen : 100.2
Actor Loss : -12.433829307556152
Train_EnvstepsSoFar : 92045
TimeSinceStart : 77.52522230148315
Done logging...



********** Iteration 89 ************

Collecting data for eval...
Eval_AverageReturn : 95.80000305175781
Eval_StdReturn : 10.796295166015625
Eval_MaxReturn : 112.0
Eval_MinReturn : 79.0
Eval_AverageEpLen : 95.8
Train_AverageReturn : 110.5999984741211
Train_StdReturn : 27.742385864257812
Train_MaxReturn : 154.0
Train_MinReturn : 65.0
Train_AverageEpLen : 110.6
Actor Loss : 2.4488840103149414
Train_EnvstepsSoFar : 93151
TimeSinceStart : 78.37293934822083
Done logging...



********** Iteration 90 ************

Collecting data for eval...
Eval_AverageReturn : 90.5999984741211
Eval_StdReturn : 17.071613311767578
Eval_MaxReturn : 109.0
Eval_MinReturn : 62.0
Eval_AverageEpLen : 90.6
Train_AverageReturn : 117.22222137451172
Train_StdReturn : 22.802425384521484
Train_MaxReturn : 161.0
Train_MinReturn : 79.0
Train_AverageEpLen : 117.22222222222223
Actor Loss : 3.596254348754883
Train_EnvstepsSoFar : 94206
TimeSinceStart : 79.1809298992157
Done logging...



********** Iteration 91 ************

Collecting data for eval...
Eval_AverageReturn : 109.0
Eval_StdReturn : 15.378556251525879
Eval_MaxReturn : 135.0
Eval_MinReturn : 95.0
Eval_AverageEpLen : 109.0
Train_AverageReturn : 114.11111450195312
Train_StdReturn : 34.271610260009766
Train_MaxReturn : 200.0
Train_MinReturn : 75.0
Train_AverageEpLen : 114.11111111111111
Actor Loss : -6.804121494293213
Train_EnvstepsSoFar : 95233
TimeSinceStart : 79.96744632720947
Done logging...



********** Iteration 92 ************

Collecting data for eval...
Eval_AverageReturn : 130.25
Eval_StdReturn : 36.7924919128418
Eval_MaxReturn : 165.0
Eval_MinReturn : 77.0
Eval_AverageEpLen : 130.25
Train_AverageReturn : 100.9000015258789
Train_StdReturn : 16.531484603881836
Train_MaxReturn : 134.0
Train_MinReturn : 83.0
Train_AverageEpLen : 100.9
Actor Loss : -1.0654096603393555
Train_EnvstepsSoFar : 96242
TimeSinceStart : 80.7734842300415
Done logging...



********** Iteration 93 ************

Collecting data for eval...
Eval_AverageReturn : 147.3333282470703
Eval_StdReturn : 38.508296966552734
Eval_MaxReturn : 200.0
Eval_MinReturn : 109.0
Eval_AverageEpLen : 147.33333333333334
Train_AverageReturn : 113.77777862548828
Train_StdReturn : 28.224409103393555
Train_MaxReturn : 181.0
Train_MinReturn : 83.0
Train_AverageEpLen : 113.77777777777777
Actor Loss : 5.080417633056641
Train_EnvstepsSoFar : 97266
TimeSinceStart : 81.57116079330444
Done logging...



********** Iteration 94 ************

Collecting data for eval...
Eval_AverageReturn : 97.80000305175781
Eval_StdReturn : 18.508377075195312
Eval_MaxReturn : 130.0
Eval_MinReturn : 76.0
Eval_AverageEpLen : 97.8
Train_AverageReturn : 128.0
Train_StdReturn : 21.0
Train_MaxReturn : 161.0
Train_MinReturn : 102.0
Train_AverageEpLen : 128.0
Actor Loss : 4.294164657592773
Train_EnvstepsSoFar : 98290
TimeSinceStart : 82.36032128334045
Done logging...



********** Iteration 95 ************

Collecting data for eval...
Eval_AverageReturn : 97.19999694824219
Eval_StdReturn : 6.615134239196777
Eval_MaxReturn : 106.0
Eval_MinReturn : 86.0
Eval_AverageEpLen : 97.2
Train_AverageReturn : 92.54545593261719
Train_StdReturn : 19.602243423461914
Train_MaxReturn : 132.0
Train_MinReturn : 69.0
Train_AverageEpLen : 92.54545454545455
Actor Loss : -1.7183828353881836
Train_EnvstepsSoFar : 99308
TimeSinceStart : 83.1663179397583
Done logging...



********** Iteration 96 ************

Collecting data for eval...
Eval_AverageReturn : 109.5
Eval_StdReturn : 36.36962890625
Eval_MaxReturn : 171.0
Eval_MinReturn : 77.0
Eval_AverageEpLen : 109.5
Train_AverageReturn : 119.22222137451172
Train_StdReturn : 34.70119094848633
Train_MaxReturn : 180.0
Train_MinReturn : 80.0
Train_AverageEpLen : 119.22222222222223
Actor Loss : 1.363981008529663
Train_EnvstepsSoFar : 100381
TimeSinceStart : 83.95872473716736
Done logging...



********** Iteration 97 ************

Collecting data for eval...
Eval_AverageReturn : 108.0
Eval_StdReturn : 53.230628967285156
Eval_MaxReturn : 200.0
Eval_MinReturn : 74.0
Eval_AverageEpLen : 108.0
Train_AverageReturn : 113.22222137451172
Train_StdReturn : 29.442138671875
Train_MaxReturn : 166.0
Train_MinReturn : 60.0
Train_AverageEpLen : 113.22222222222223
Actor Loss : 3.225637912750244
Train_EnvstepsSoFar : 101400
TimeSinceStart : 84.72848844528198
Done logging...



********** Iteration 98 ************

Collecting data for eval...
Eval_AverageReturn : 122.25
Eval_StdReturn : 16.40693473815918
Eval_MaxReturn : 141.0
Eval_MinReturn : 96.0
Eval_AverageEpLen : 122.25
Train_AverageReturn : 110.0
Train_StdReturn : 37.90250778198242
Train_MaxReturn : 200.0
Train_MinReturn : 60.0
Train_AverageEpLen : 110.0
Actor Loss : -0.12859153747558594
Train_EnvstepsSoFar : 102500
TimeSinceStart : 85.56468915939331
Done logging...



********** Iteration 99 ************

Collecting data for eval...
Eval_AverageReturn : 147.6666717529297
Eval_StdReturn : 29.261274337768555
Eval_MaxReturn : 186.0
Eval_MinReturn : 115.0
Eval_AverageEpLen : 147.66666666666666
Train_AverageReturn : 128.25
Train_StdReturn : 30.605350494384766
Train_MaxReturn : 175.0
Train_MinReturn : 89.0
Train_AverageEpLen : 128.25
Actor Loss : 0.02017498016357422
Train_EnvstepsSoFar : 103526
TimeSinceStart : 86.34764575958252
Done logging...



********** Iteration 100 ************

Collecting data for eval...
Eval_AverageReturn : 110.5
Eval_StdReturn : 19.371370315551758
Eval_MaxReturn : 134.0
Eval_MinReturn : 81.0
Eval_AverageEpLen : 110.5
Train_AverageReturn : 125.625
Train_StdReturn : 27.635744094848633
Train_MaxReturn : 160.0
Train_MinReturn : 69.0
Train_AverageEpLen : 125.625
Actor Loss : -1.4901866912841797
Train_EnvstepsSoFar : 104531
TimeSinceStart : 87.11822867393494
Done logging...



********** Iteration 101 ************

Collecting data for eval...
Eval_AverageReturn : 127.5
Eval_StdReturn : 6.8007354736328125
Eval_MaxReturn : 138.0
Eval_MinReturn : 121.0
Eval_AverageEpLen : 127.5
Train_AverageReturn : 146.57142639160156
Train_StdReturn : 28.609973907470703
Train_MaxReturn : 200.0
Train_MinReturn : 108.0
Train_AverageEpLen : 146.57142857142858
Actor Loss : 8.274094581604004
Train_EnvstepsSoFar : 105557
TimeSinceStart : 87.93097805976868
Done logging...



********** Iteration 102 ************

Collecting data for eval...
Eval_AverageReturn : 152.0
Eval_StdReturn : 44.89988708496094
Eval_MaxReturn : 200.0
Eval_MinReturn : 92.0
Eval_AverageEpLen : 152.0
Train_AverageReturn : 144.42857360839844
Train_StdReturn : 21.986080169677734
Train_MaxReturn : 173.0
Train_MinReturn : 101.0
Train_AverageEpLen : 144.42857142857142
Actor Loss : 0.47630977630615234
Train_EnvstepsSoFar : 106568
TimeSinceStart : 88.71358323097229
Done logging...



********** Iteration 103 ************

Collecting data for eval...
Eval_AverageReturn : 135.0
Eval_StdReturn : 30.364452362060547
Eval_MaxReturn : 157.0
Eval_MinReturn : 83.0
Eval_AverageEpLen : 135.0
Train_AverageReturn : 143.57142639160156
Train_StdReturn : 29.7746639251709
Train_MaxReturn : 192.0
Train_MinReturn : 95.0
Train_AverageEpLen : 143.57142857142858
Actor Loss : -12.164806365966797
Train_EnvstepsSoFar : 107573
TimeSinceStart : 89.52187514305115
Done logging...



********** Iteration 104 ************

Collecting data for eval...
Eval_AverageReturn : 139.0
Eval_StdReturn : 34.48188018798828
Eval_MaxReturn : 176.0
Eval_MinReturn : 84.0
Eval_AverageEpLen : 139.0
Train_AverageReturn : 139.25
Train_StdReturn : 34.81648254394531
Train_MaxReturn : 200.0
Train_MinReturn : 95.0
Train_AverageEpLen : 139.25
Actor Loss : -2.561626434326172
Train_EnvstepsSoFar : 108687
TimeSinceStart : 90.39558005332947
Done logging...



********** Iteration 105 ************

Collecting data for eval...
Eval_AverageReturn : 134.0
Eval_StdReturn : 11.224971771240234
Eval_MaxReturn : 149.0
Eval_MinReturn : 122.0
Eval_AverageEpLen : 134.0
Train_AverageReturn : 131.75
Train_StdReturn : 30.764225006103516
Train_MaxReturn : 174.0
Train_MinReturn : 84.0
Train_AverageEpLen : 131.75
Actor Loss : -0.2671337127685547
Train_EnvstepsSoFar : 109741
TimeSinceStart : 91.16383385658264
Done logging...



********** Iteration 106 ************

Collecting data for eval...
Eval_AverageReturn : 161.3333282470703
Eval_StdReturn : 29.04402732849121
Eval_MaxReturn : 200.0
Eval_MinReturn : 130.0
Eval_AverageEpLen : 161.33333333333334
Train_AverageReturn : 150.2857208251953
Train_StdReturn : 13.832820892333984
Train_MaxReturn : 172.0
Train_MinReturn : 130.0
Train_AverageEpLen : 150.28571428571428
Actor Loss : -2.276665449142456
Train_EnvstepsSoFar : 110793
TimeSinceStart : 91.97452926635742
Done logging...



********** Iteration 107 ************

Collecting data for eval...
Eval_AverageReturn : 102.0
Eval_StdReturn : 20.57911491394043
Eval_MaxReturn : 132.0
Eval_MinReturn : 74.0
Eval_AverageEpLen : 102.0
Train_AverageReturn : 146.42857360839844
Train_StdReturn : 29.095197677612305
Train_MaxReturn : 200.0
Train_MinReturn : 107.0
Train_AverageEpLen : 146.42857142857142
Actor Loss : -6.820504188537598
Train_EnvstepsSoFar : 111818
TimeSinceStart : 92.7197630405426
Done logging...



********** Iteration 108 ************

Collecting data for eval...
Eval_AverageReturn : 134.75
Eval_StdReturn : 21.075756072998047
Eval_MaxReturn : 157.0
Eval_MinReturn : 109.0
Eval_AverageEpLen : 134.75
Train_AverageReturn : 145.625
Train_StdReturn : 38.91958999633789
Train_MaxReturn : 200.0
Train_MinReturn : 100.0
Train_AverageEpLen : 145.625
Actor Loss : -2.238858222961426
Train_EnvstepsSoFar : 112983
TimeSinceStart : 93.9193983078003
Done logging...



********** Iteration 109 ************

Collecting data for eval...
Eval_AverageReturn : 143.3333282470703
Eval_StdReturn : 16.99673080444336
Eval_MaxReturn : 160.0
Eval_MinReturn : 120.0
Eval_AverageEpLen : 143.33333333333334
Train_AverageReturn : 151.14285278320312
Train_StdReturn : 38.12921142578125
Train_MaxReturn : 193.0
Train_MinReturn : 78.0
Train_AverageEpLen : 151.14285714285714
Actor Loss : -11.175512313842773
Train_EnvstepsSoFar : 114041
TimeSinceStart : 94.70251488685608
Done logging...



********** Iteration 110 ************

Collecting data for eval...
Eval_AverageReturn : 182.0
Eval_StdReturn : 17.107501983642578
Eval_MaxReturn : 200.0
Eval_MinReturn : 159.0
Eval_AverageEpLen : 182.0
Train_AverageReturn : 149.7142791748047
Train_StdReturn : 25.57741355895996
Train_MaxReturn : 183.0
Train_MinReturn : 107.0
Train_AverageEpLen : 149.71428571428572
Actor Loss : 2.0582666397094727
Train_EnvstepsSoFar : 115089
TimeSinceStart : 95.52619504928589
Done logging...



********** Iteration 111 ************

Collecting data for eval...
Eval_AverageReturn : 150.0
Eval_StdReturn : 20.510160446166992
Eval_MaxReturn : 179.0
Eval_MinReturn : 135.0
Eval_AverageEpLen : 150.0
Train_AverageReturn : 152.85714721679688
Train_StdReturn : 25.63161277770996
Train_MaxReturn : 200.0
Train_MinReturn : 125.0
Train_AverageEpLen : 152.85714285714286
Actor Loss : -3.3943357467651367
Train_EnvstepsSoFar : 116159
TimeSinceStart : 96.33570075035095
Done logging...



********** Iteration 112 ************

Collecting data for eval...
Eval_AverageReturn : 138.6666717529297
Eval_StdReturn : 12.283684730529785
Eval_MaxReturn : 156.0
Eval_MinReturn : 129.0
Eval_AverageEpLen : 138.66666666666666
Train_AverageReturn : 178.5
Train_StdReturn : 17.308475494384766
Train_MaxReturn : 200.0
Train_MinReturn : 160.0
Train_AverageEpLen : 178.5
Actor Loss : 6.208078384399414
Train_EnvstepsSoFar : 117230
TimeSinceStart : 97.10952425003052
Done logging...



********** Iteration 113 ************

Collecting data for eval...
Eval_AverageReturn : 171.3333282470703
Eval_StdReturn : 20.3360652923584
Eval_MaxReturn : 200.0
Eval_MinReturn : 155.0
Eval_AverageEpLen : 171.33333333333334
Train_AverageReturn : 173.1666717529297
Train_StdReturn : 20.456594467163086
Train_MaxReturn : 200.0
Train_MinReturn : 144.0
Train_AverageEpLen : 173.16666666666666
Actor Loss : 0.45902401208877563
Train_EnvstepsSoFar : 118269
TimeSinceStart : 97.91672539710999
Done logging...



********** Iteration 114 ************

Collecting data for eval...
Eval_AverageReturn : 162.3333282470703
Eval_StdReturn : 17.613126754760742
Eval_MaxReturn : 187.0
Eval_MinReturn : 147.0
Eval_AverageEpLen : 162.33333333333334
Train_AverageReturn : 167.6666717529297
Train_StdReturn : 22.201101303100586
Train_MaxReturn : 200.0
Train_MinReturn : 128.0
Train_AverageEpLen : 167.66666666666666
Actor Loss : -2.7762885093688965
Train_EnvstepsSoFar : 119275
TimeSinceStart : 98.69878697395325
Done logging...



********** Iteration 115 ************

Collecting data for eval...
Eval_AverageReturn : 153.6666717529297
Eval_StdReturn : 8.259674072265625
Eval_MaxReturn : 160.0
Eval_MinReturn : 142.0
Eval_AverageEpLen : 153.66666666666666
Train_AverageReturn : 174.1666717529297
Train_StdReturn : 24.922657012939453
Train_MaxReturn : 200.0
Train_MinReturn : 129.0
Train_AverageEpLen : 174.16666666666666
Actor Loss : -6.4761857986450195
Train_EnvstepsSoFar : 120320
TimeSinceStart : 99.48968553543091
Done logging...



********** Iteration 116 ************

Collecting data for eval...
Eval_AverageReturn : 172.3333282470703
Eval_StdReturn : 19.601587295532227
Eval_MaxReturn : 200.0
Eval_MinReturn : 157.0
Eval_AverageEpLen : 172.33333333333334
Train_AverageReturn : 163.57142639160156
Train_StdReturn : 28.654876708984375
Train_MaxReturn : 200.0
Train_MinReturn : 132.0
Train_AverageEpLen : 163.57142857142858
Actor Loss : -2.1327719688415527
Train_EnvstepsSoFar : 121465
TimeSinceStart : 100.36899542808533
Done logging...



********** Iteration 117 ************

Collecting data for eval...
Eval_AverageReturn : 189.3333282470703
Eval_StdReturn : 12.364825248718262
Eval_MaxReturn : 200.0
Eval_MinReturn : 172.0
Eval_AverageEpLen : 189.33333333333334
Train_AverageReturn : 153.14285278320312
Train_StdReturn : 23.691038131713867
Train_MaxReturn : 200.0
Train_MinReturn : 126.0
Train_AverageEpLen : 153.14285714285714
Actor Loss : -8.620975494384766
Train_EnvstepsSoFar : 122537
TimeSinceStart : 101.22565388679504
Done logging...



********** Iteration 118 ************

Collecting data for eval...
Eval_AverageReturn : 163.6666717529297
Eval_StdReturn : 12.498888969421387
Eval_MaxReturn : 181.0
Eval_MinReturn : 152.0
Eval_AverageEpLen : 163.66666666666666
Train_AverageReturn : 171.0
Train_StdReturn : 29.09589958190918
Train_MaxReturn : 200.0
Train_MinReturn : 127.0
Train_AverageEpLen : 171.0
Actor Loss : -0.219376802444458
Train_EnvstepsSoFar : 123734
TimeSinceStart : 102.12641763687134
Done logging...



********** Iteration 119 ************

Collecting data for eval...
Eval_AverageReturn : 179.6666717529297
Eval_StdReturn : 22.06555938720703
Eval_MaxReturn : 200.0
Eval_MinReturn : 149.0
Eval_AverageEpLen : 179.66666666666666
Train_AverageReturn : 164.42857360839844
Train_StdReturn : 20.700979232788086
Train_MaxReturn : 200.0
Train_MinReturn : 127.0
Train_AverageEpLen : 164.42857142857142
Actor Loss : -12.276371955871582
Train_EnvstepsSoFar : 124885
TimeSinceStart : 103.01959824562073
Done logging...



********** Iteration 120 ************

Collecting data for eval...
Eval_AverageReturn : 184.0
Eval_StdReturn : 11.775681495666504
Eval_MaxReturn : 200.0
Eval_MinReturn : 172.0
Eval_AverageEpLen : 184.0
Train_AverageReturn : 175.3333282470703
Train_StdReturn : 26.749868392944336
Train_MaxReturn : 200.0
Train_MinReturn : 138.0
Train_AverageEpLen : 175.33333333333334
Actor Loss : 1.9990286827087402
Train_EnvstepsSoFar : 125937
TimeSinceStart : 104.8665235042572
Done logging...



********** Iteration 121 ************

Collecting data for eval...
Eval_AverageReturn : 158.3333282470703
Eval_StdReturn : 26.246692657470703
Eval_MaxReturn : 195.0
Eval_MinReturn : 135.0
Eval_AverageEpLen : 158.33333333333334
Train_AverageReturn : 159.85714721679688
Train_StdReturn : 18.999462127685547
Train_MaxReturn : 183.0
Train_MinReturn : 128.0
Train_AverageEpLen : 159.85714285714286
Actor Loss : -2.0620276927948
Train_EnvstepsSoFar : 127056
TimeSinceStart : 105.71983575820923
Done logging...



********** Iteration 122 ************

Collecting data for eval...
Eval_AverageReturn : 158.3333282470703
Eval_StdReturn : 26.96087646484375
Eval_MaxReturn : 192.0
Eval_MinReturn : 126.0
Eval_AverageEpLen : 158.33333333333334
Train_AverageReturn : 172.8333282470703
Train_StdReturn : 33.358741760253906
Train_MaxReturn : 200.0
Train_MinReturn : 113.0
Train_AverageEpLen : 172.83333333333334
Actor Loss : 1.6768460273742676
Train_EnvstepsSoFar : 128093
TimeSinceStart : 106.52115297317505
Done logging...



********** Iteration 123 ************

Collecting data for eval...
Eval_AverageReturn : 179.6666717529297
Eval_StdReturn : 17.632041931152344
Eval_MaxReturn : 200.0
Eval_MinReturn : 157.0
Eval_AverageEpLen : 179.66666666666666
Train_AverageReturn : 178.1666717529297
Train_StdReturn : 23.3553466796875
Train_MaxReturn : 200.0
Train_MinReturn : 140.0
Train_AverageEpLen : 178.16666666666666
Actor Loss : -5.4779205322265625
Train_EnvstepsSoFar : 129162
TimeSinceStart : 107.3650164604187
Done logging...



********** Iteration 124 ************

Collecting data for eval...
Eval_AverageReturn : 158.6666717529297
Eval_StdReturn : 27.47524070739746
Eval_MaxReturn : 197.0
Eval_MinReturn : 134.0
Eval_AverageEpLen : 158.66666666666666
Train_AverageReturn : 188.0
Train_StdReturn : 18.574174880981445
Train_MaxReturn : 200.0
Train_MinReturn : 149.0
Train_AverageEpLen : 188.0
Actor Loss : 1.3923664093017578
Train_EnvstepsSoFar : 130290
TimeSinceStart : 108.20075416564941
Done logging...



********** Iteration 125 ************

Collecting data for eval...
Eval_AverageReturn : 181.6666717529297
Eval_StdReturn : 11.897712707519531
Eval_MaxReturn : 198.0
Eval_MinReturn : 170.0
Eval_AverageEpLen : 181.66666666666666
Train_AverageReturn : 185.1666717529297
Train_StdReturn : 17.667451858520508
Train_MaxReturn : 200.0
Train_MinReturn : 155.0
Train_AverageEpLen : 185.16666666666666
Actor Loss : -5.504636764526367
Train_EnvstepsSoFar : 131401
TimeSinceStart : 109.07701849937439
Done logging...



********** Iteration 126 ************

Collecting data for eval...
Eval_AverageReturn : 161.3333282470703
Eval_StdReturn : 19.669490814208984
Eval_MaxReturn : 189.0
Eval_MinReturn : 145.0
Eval_AverageEpLen : 161.33333333333334
Train_AverageReturn : 175.5
Train_StdReturn : 19.64476203918457
Train_MaxReturn : 200.0
Train_MinReturn : 147.0
Train_AverageEpLen : 175.5
Actor Loss : -6.457629203796387
Train_EnvstepsSoFar : 132454
TimeSinceStart : 109.89970088005066
Done logging...



********** Iteration 127 ************

Collecting data for eval...
Eval_AverageReturn : 168.3333282470703
Eval_StdReturn : 15.151090621948242
Eval_MaxReturn : 186.0
Eval_MinReturn : 149.0
Eval_AverageEpLen : 168.33333333333334
Train_AverageReturn : 171.6666717529297
Train_StdReturn : 29.71344757080078
Train_MaxReturn : 200.0
Train_MinReturn : 128.0
Train_AverageEpLen : 171.66666666666666
Actor Loss : -7.329193115234375
Train_EnvstepsSoFar : 133484
TimeSinceStart : 110.71126580238342
Done logging...



********** Iteration 128 ************

Collecting data for eval...
Eval_AverageReturn : 171.6666717529297
Eval_StdReturn : 22.12590217590332
Eval_MaxReturn : 200.0
Eval_MinReturn : 146.0
Eval_AverageEpLen : 171.66666666666666
Train_AverageReturn : 162.2857208251953
Train_StdReturn : 25.93240737915039
Train_MaxReturn : 200.0
Train_MinReturn : 133.0
Train_AverageEpLen : 162.28571428571428
Actor Loss : -13.515918731689453
Train_EnvstepsSoFar : 134620
TimeSinceStart : 111.59799551963806
Done logging...



********** Iteration 129 ************

Collecting data for eval...
Eval_AverageReturn : 167.0
Eval_StdReturn : 24.124675750732422
Eval_MaxReturn : 200.0
Eval_MinReturn : 143.0
Eval_AverageEpLen : 167.0
Train_AverageReturn : 175.0
Train_StdReturn : 28.746013641357422
Train_MaxReturn : 200.0
Train_MinReturn : 116.0
Train_AverageEpLen : 175.0
Actor Loss : -7.495415687561035
Train_EnvstepsSoFar : 135670
TimeSinceStart : 112.42459106445312
Done logging...



********** Iteration 130 ************

Collecting data for eval...
Eval_AverageReturn : 151.0
Eval_StdReturn : 10.424330711364746
Eval_MaxReturn : 165.0
Eval_MinReturn : 140.0
Eval_AverageEpLen : 151.0
Train_AverageReturn : 167.42857360839844
Train_StdReturn : 31.572399139404297
Train_MaxReturn : 200.0
Train_MinReturn : 109.0
Train_AverageEpLen : 167.42857142857142
Actor Loss : -2.3693583011627197
Train_EnvstepsSoFar : 136842
TimeSinceStart : 113.26687026023865
Done logging...



********** Iteration 131 ************

Collecting data for eval...
Eval_AverageReturn : 152.3333282470703
Eval_StdReturn : 19.601587295532227
Eval_MaxReturn : 176.0
Eval_MinReturn : 128.0
Eval_AverageEpLen : 152.33333333333334
Train_AverageReturn : 174.3333282470703
Train_StdReturn : 17.88543701171875
Train_MaxReturn : 200.0
Train_MinReturn : 154.0
Train_AverageEpLen : 174.33333333333334
Actor Loss : -0.7801170349121094
Train_EnvstepsSoFar : 137888
TimeSinceStart : 114.05566096305847
Done logging...



********** Iteration 132 ************

Collecting data for eval...
Eval_AverageReturn : 146.0
Eval_StdReturn : 21.21320343017578
Eval_MaxReturn : 161.0
Eval_MinReturn : 116.0
Eval_AverageEpLen : 146.0
Train_AverageReturn : 172.5
Train_StdReturn : 39.13119125366211
Train_MaxReturn : 200.0
Train_MinReturn : 110.0
Train_AverageEpLen : 172.5
Actor Loss : -17.09592056274414
Train_EnvstepsSoFar : 138923
TimeSinceStart : 114.8317334651947
Done logging...



********** Iteration 133 ************

Collecting data for eval...
Eval_AverageReturn : 169.6666717529297
Eval_StdReturn : 21.638442993164062
Eval_MaxReturn : 200.0
Eval_MinReturn : 151.0
Eval_AverageEpLen : 169.66666666666666
Train_AverageReturn : 178.0
Train_StdReturn : 23.151674270629883
Train_MaxReturn : 200.0
Train_MinReturn : 146.0
Train_AverageEpLen : 178.0
Actor Loss : -20.721641540527344
Train_EnvstepsSoFar : 139991
TimeSinceStart : 115.6693663597107
Done logging...



********** Iteration 134 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 175.3333282470703
Train_StdReturn : 31.972209930419922
Train_MaxReturn : 200.0
Train_MinReturn : 122.0
Train_AverageEpLen : 175.33333333333334
Actor Loss : -35.47407531738281
Train_EnvstepsSoFar : 141043
TimeSinceStart : 116.4575788974762
Done logging...



********** Iteration 135 ************

Collecting data for eval...
Eval_AverageReturn : 187.3333282470703
Eval_StdReturn : 13.888444900512695
Eval_MaxReturn : 200.0
Eval_MinReturn : 168.0
Eval_AverageEpLen : 187.33333333333334
Train_AverageReturn : 169.0
Train_StdReturn : 26.677082061767578
Train_MaxReturn : 200.0
Train_MinReturn : 120.0
Train_AverageEpLen : 169.0
Actor Loss : -22.543657302856445
Train_EnvstepsSoFar : 142057
TimeSinceStart : 117.2977991104126
Done logging...



********** Iteration 136 ************

Collecting data for eval...
Eval_AverageReturn : 147.3333282470703
Eval_StdReturn : 27.341461181640625
Eval_MaxReturn : 186.0
Eval_MinReturn : 128.0
Eval_AverageEpLen : 147.33333333333334
Train_AverageReturn : 160.7142791748047
Train_StdReturn : 26.342330932617188
Train_MaxReturn : 200.0
Train_MinReturn : 123.0
Train_AverageEpLen : 160.71428571428572
Actor Loss : -14.259771347045898
Train_EnvstepsSoFar : 143182
TimeSinceStart : 118.13485050201416
Done logging...



********** Iteration 137 ************

Collecting data for eval...
Eval_AverageReturn : 111.0
Eval_StdReturn : 51.0343017578125
Eval_MaxReturn : 194.0
Eval_MinReturn : 69.0
Eval_AverageEpLen : 111.0
Train_AverageReturn : 136.0
Train_StdReturn : 40.59556579589844
Train_MaxReturn : 200.0
Train_MinReturn : 77.0
Train_AverageEpLen : 136.0
Actor Loss : -18.65412139892578
Train_EnvstepsSoFar : 144270
TimeSinceStart : 118.95422005653381
Done logging...



********** Iteration 138 ************

Collecting data for eval...
Eval_AverageReturn : 90.4000015258789
Eval_StdReturn : 15.34405517578125
Eval_MaxReturn : 111.0
Eval_MinReturn : 64.0
Eval_AverageEpLen : 90.4
Train_AverageReturn : 106.5
Train_StdReturn : 31.62672996520996
Train_MaxReturn : 169.0
Train_MinReturn : 77.0
Train_AverageEpLen : 106.5
Actor Loss : -18.12392234802246
Train_EnvstepsSoFar : 145335
TimeSinceStart : 119.7554395198822
Done logging...



********** Iteration 139 ************

Collecting data for eval...
Eval_AverageReturn : 67.0
Eval_StdReturn : 13.759844779968262
Eval_MaxReturn : 91.0
Eval_MinReturn : 45.0
Eval_AverageEpLen : 67.0
Train_AverageReturn : 82.38461303710938
Train_StdReturn : 23.866741180419922
Train_MaxReturn : 142.0
Train_MinReturn : 54.0
Train_AverageEpLen : 82.38461538461539
Actor Loss : -19.375141143798828
Train_EnvstepsSoFar : 146406
TimeSinceStart : 120.53522658348083
Done logging...



********** Iteration 140 ************

Collecting data for eval...
Eval_AverageReturn : 72.83333587646484
Eval_StdReturn : 30.710567474365234
Eval_MaxReturn : 125.0
Eval_MinReturn : 44.0
Eval_AverageEpLen : 72.83333333333333
Train_AverageReturn : 71.13333129882812
Train_StdReturn : 24.245594024658203
Train_MaxReturn : 133.0
Train_MinReturn : 47.0
Train_AverageEpLen : 71.13333333333334
Actor Loss : -22.901103973388672
Train_EnvstepsSoFar : 147473
TimeSinceStart : 121.35437297821045
Done logging...



********** Iteration 141 ************

Collecting data for eval...
Eval_AverageReturn : 72.83333587646484
Eval_StdReturn : 24.848987579345703
Eval_MaxReturn : 120.0
Eval_MinReturn : 40.0
Eval_AverageEpLen : 72.83333333333333
Train_AverageReturn : 65.0
Train_StdReturn : 20.00937271118164
Train_MaxReturn : 116.0
Train_MinReturn : 40.0
Train_AverageEpLen : 65.0
Actor Loss : -19.834630966186523
Train_EnvstepsSoFar : 148513
TimeSinceStart : 122.11397433280945
Done logging...



********** Iteration 142 ************

Collecting data for eval...
Eval_AverageReturn : 57.14285659790039
Eval_StdReturn : 14.024759292602539
Eval_MaxReturn : 82.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 57.142857142857146
Train_AverageReturn : 68.5625
Train_StdReturn : 25.019914627075195
Train_MaxReturn : 127.0
Train_MinReturn : 38.0
Train_AverageEpLen : 68.5625
Actor Loss : -31.649606704711914
Train_EnvstepsSoFar : 149610
TimeSinceStart : 122.92615365982056
Done logging...



********** Iteration 143 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 63.875
Train_StdReturn : 23.406396865844727
Train_MaxReturn : 130.0
Train_MinReturn : 41.0
Train_AverageEpLen : 63.875
Actor Loss : -32.94329071044922
Train_EnvstepsSoFar : 150632
TimeSinceStart : 123.6819679737091
Done logging...



********** Iteration 144 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 196.1666717529297
Train_StdReturn : 8.57159423828125
Train_MaxReturn : 200.0
Train_MinReturn : 177.0
Train_AverageEpLen : 196.16666666666666
Actor Loss : -5.633632659912109
Train_EnvstepsSoFar : 151809
TimeSinceStart : 124.50251317024231
Done logging...



********** Iteration 145 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 199.0
Train_StdReturn : 2.2360680103302
Train_MaxReturn : 200.0
Train_MinReturn : 194.0
Train_AverageEpLen : 199.0
Actor Loss : 0.9632863998413086
Train_EnvstepsSoFar : 153003
TimeSinceStart : 125.36170697212219
Done logging...



********** Iteration 146 ************

Collecting data for eval...
Eval_AverageReturn : 183.3333282470703
Eval_StdReturn : 11.897712707519531
Eval_MaxReturn : 200.0
Eval_MinReturn : 173.0
Eval_AverageEpLen : 183.33333333333334
Train_AverageReturn : 191.6666717529297
Train_StdReturn : 11.085525512695312
Train_MaxReturn : 200.0
Train_MinReturn : 169.0
Train_AverageEpLen : 191.66666666666666
Actor Loss : -2.2346906661987305
Train_EnvstepsSoFar : 154153
TimeSinceStart : 126.20564365386963
Done logging...



********** Iteration 147 ************

Collecting data for eval...
Eval_AverageReturn : 149.3333282470703
Eval_StdReturn : 40.077701568603516
Eval_MaxReturn : 200.0
Eval_MinReturn : 102.0
Eval_AverageEpLen : 149.33333333333334
Train_AverageReturn : 178.0
Train_StdReturn : 11.73314380645752
Train_MaxReturn : 198.0
Train_MinReturn : 158.0
Train_AverageEpLen : 178.0
Actor Loss : 4.340343475341797
Train_EnvstepsSoFar : 155221
TimeSinceStart : 126.97001266479492
Done logging...



********** Iteration 148 ************

Collecting data for eval...
Eval_AverageReturn : 158.3333282470703
Eval_StdReturn : 11.085526466369629
Eval_MaxReturn : 174.0
Eval_MinReturn : 150.0
Eval_AverageEpLen : 158.33333333333334
Train_AverageReturn : 163.0
Train_StdReturn : 21.494184494018555
Train_MaxReturn : 200.0
Train_MinReturn : 123.0
Train_AverageEpLen : 163.0
Actor Loss : 3.032660961151123
Train_EnvstepsSoFar : 156362
TimeSinceStart : 127.80551266670227
Done logging...



********** Iteration 149 ************

Collecting data for eval...
Eval_AverageReturn : 145.6666717529297
Eval_StdReturn : 4.71404504776001
Eval_MaxReturn : 149.0
Eval_MinReturn : 139.0
Eval_AverageEpLen : 145.66666666666666
Train_AverageReturn : 153.2857208251953
Train_StdReturn : 15.52614688873291
Train_MaxReturn : 164.0
Train_MinReturn : 116.0
Train_AverageEpLen : 153.28571428571428
Actor Loss : -0.9684453010559082
Train_EnvstepsSoFar : 157435
TimeSinceStart : 128.56368207931519
Done logging...



********** Iteration 150 ************

Collecting data for eval...
Eval_AverageReturn : 134.0
Eval_StdReturn : 16.990192413330078
Eval_MaxReturn : 147.0
Eval_MinReturn : 110.0
Eval_AverageEpLen : 134.0
Train_AverageReturn : 146.0
Train_StdReturn : 14.716365814208984
Train_MaxReturn : 159.0
Train_MinReturn : 113.0
Train_AverageEpLen : 146.0
Actor Loss : -0.6676101684570312
Train_EnvstepsSoFar : 158457
TimeSinceStart : 129.27587628364563
Done logging...



********** Iteration 151 ************

Collecting data for eval...
Eval_AverageReturn : 108.25
Eval_StdReturn : 17.412281036376953
Eval_MaxReturn : 136.0
Eval_MinReturn : 92.0
Eval_AverageEpLen : 108.25
Train_AverageReturn : 140.375
Train_StdReturn : 22.186355590820312
Train_MaxReturn : 166.0
Train_MinReturn : 98.0
Train_AverageEpLen : 140.375
Actor Loss : 1.6284637451171875
Train_EnvstepsSoFar : 159580
TimeSinceStart : 130.05559730529785
Done logging...



********** Iteration 152 ************

Collecting data for eval...
Eval_AverageReturn : 88.5999984741211
Eval_StdReturn : 27.251420974731445
Eval_MaxReturn : 143.0
Eval_MinReturn : 73.0
Eval_AverageEpLen : 88.6
Train_AverageReturn : 124.11111450195312
Train_StdReturn : 24.551280975341797
Train_MaxReturn : 153.0
Train_MinReturn : 84.0
Train_AverageEpLen : 124.11111111111111
Actor Loss : 1.0071029663085938
Train_EnvstepsSoFar : 160697
TimeSinceStart : 130.84964108467102
Done logging...



********** Iteration 153 ************

Collecting data for eval...
Eval_AverageReturn : 68.83333587646484
Eval_StdReturn : 3.670452833175659
Eval_MaxReturn : 73.0
Eval_MinReturn : 63.0
Eval_AverageEpLen : 68.83333333333333
Train_AverageReturn : 91.7272720336914
Train_StdReturn : 21.821969985961914
Train_MaxReturn : 138.0
Train_MinReturn : 74.0
Train_AverageEpLen : 91.72727272727273
Actor Loss : 0.5104589462280273
Train_EnvstepsSoFar : 161706
TimeSinceStart : 131.91763877868652
Done logging...



********** Iteration 154 ************

Collecting data for eval...
Eval_AverageReturn : 70.66666412353516
Eval_StdReturn : 26.60618019104004
Eval_MaxReturn : 130.0
Eval_MinReturn : 56.0
Eval_AverageEpLen : 70.66666666666667
Train_AverageReturn : 76.5
Train_StdReturn : 20.130821228027344
Train_MaxReturn : 127.0
Train_MinReturn : 62.0
Train_AverageEpLen : 76.5
Actor Loss : -1.744950532913208
Train_EnvstepsSoFar : 162777
TimeSinceStart : 132.66352534294128
Done logging...



********** Iteration 155 ************

Collecting data for eval...
Eval_AverageReturn : 23.705883026123047
Eval_StdReturn : 2.3705224990844727
Eval_MaxReturn : 28.0
Eval_MinReturn : 20.0
Eval_AverageEpLen : 23.705882352941178
Train_AverageReturn : 58.94117736816406
Train_StdReturn : 2.8381972312927246
Train_MaxReturn : 65.0
Train_MinReturn : 54.0
Train_AverageEpLen : 58.94117647058823
Actor Loss : -2.174358367919922
Train_EnvstepsSoFar : 163779
TimeSinceStart : 133.3697419166565
Done logging...



********** Iteration 156 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7564398050308228
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 22.33333396911621
Train_StdReturn : 2.7888667583465576
Train_MaxReturn : 27.0
Train_MinReturn : 18.0
Train_AverageEpLen : 22.333333333333332
Actor Loss : 2.2547683715820312
Train_EnvstepsSoFar : 164784
TimeSinceStart : 134.50872325897217
Done logging...



********** Iteration 157 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.6619732975959778
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 9.383177757263184
Train_StdReturn : 0.6787132024765015
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.383177570093459
Actor Loss : -1.6225662231445312
Train_EnvstepsSoFar : 165788
TimeSinceStart : 135.22341299057007
Done logging...



********** Iteration 158 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.8624393939971924
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.287036895751953
Train_StdReturn : 0.7582988739013672
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.287037037037036
Actor Loss : -3.4315567016601562
Train_EnvstepsSoFar : 166791
TimeSinceStart : 135.941237449646
Done logging...



********** Iteration 159 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.5846421122550964
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.229357719421387
Train_StdReturn : 0.6990561485290527
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.229357798165138
Actor Loss : -3.985177993774414
Train_EnvstepsSoFar : 167797
TimeSinceStart : 136.66180086135864
Done logging...



********** Iteration 160 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.6922268271446228
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.314814567565918
Train_StdReturn : 0.7283689379692078
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.314814814814815
Actor Loss : -3.3519887924194336
Train_EnvstepsSoFar : 168803
TimeSinceStart : 137.38289403915405
Done logging...



********** Iteration 161 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.8035884499549866
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.324073791503906
Train_StdReturn : 0.8369776010513306
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.324074074074074
Actor Loss : -5.410275459289551
Train_EnvstepsSoFar : 169810
TimeSinceStart : 138.09382820129395
Done logging...



********** Iteration 162 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.7885949611663818
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 9.5
Train_StdReturn : 0.7800580859184265
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.5
Actor Loss : -4.6872406005859375
Train_EnvstepsSoFar : 170817
TimeSinceStart : 138.82324409484863
Done logging...



********** Iteration 163 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.6863486170768738
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.411214828491211
Train_StdReturn : 0.7356511950492859
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.411214953271028
Actor Loss : -5.238091945648193
Train_EnvstepsSoFar : 171824
TimeSinceStart : 139.56294894218445
Done logging...



********** Iteration 164 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.8222171664237976
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.392523765563965
Train_StdReturn : 0.7457919716835022
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392523364485982
Actor Loss : -6.393451690673828
Train_EnvstepsSoFar : 172829
TimeSinceStart : 140.29466342926025
Done logging...



********** Iteration 165 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.6827868819236755
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.30555534362793
Train_StdReturn : 0.7510281801223755
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.305555555555555
Actor Loss : -10.019792556762695
Train_EnvstepsSoFar : 173834
TimeSinceStart : 141.01605129241943
Done logging...



********** Iteration 166 ************

Collecting data for eval...
Eval_AverageReturn : 22.66666603088379
Eval_StdReturn : 7.681146144866943
Eval_MaxReturn : 30.0
Eval_MinReturn : 10.0
Eval_AverageEpLen : 22.666666666666668
Train_AverageReturn : 9.383177757263184
Train_StdReturn : 0.7568362951278687
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.383177570093459
Actor Loss : -13.871684074401855
Train_EnvstepsSoFar : 174838
TimeSinceStart : 141.88290095329285
Done logging...



********** Iteration 167 ************

Collecting data for eval...
Eval_AverageReturn : 38.0
Eval_StdReturn : 4.512608528137207
Eval_MaxReturn : 48.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 38.0
Train_AverageReturn : 26.102563858032227
Train_StdReturn : 4.253474712371826
Train_MaxReturn : 32.0
Train_MinReturn : 10.0
Train_AverageEpLen : 26.102564102564102
Actor Loss : 5.606355667114258
Train_EnvstepsSoFar : 175856
TimeSinceStart : 142.6370210647583
Done logging...



********** Iteration 168 ************

Collecting data for eval...
Eval_AverageReturn : 46.55555725097656
Eval_StdReturn : 6.3789777755737305
Eval_MaxReturn : 58.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 46.55555555555556
Train_AverageReturn : 40.15999984741211
Train_StdReturn : 3.8645052909851074
Train_MaxReturn : 47.0
Train_MinReturn : 33.0
Train_AverageEpLen : 40.16
Actor Loss : 0.44664764404296875
Train_EnvstepsSoFar : 176860
TimeSinceStart : 143.36751461029053
Done logging...



********** Iteration 169 ************

Collecting data for eval...
Eval_AverageReturn : 58.71428680419922
Eval_StdReturn : 6.2498979568481445
Eval_MaxReturn : 65.0
Eval_MinReturn : 48.0
Eval_AverageEpLen : 58.714285714285715
Train_AverageReturn : 49.095237731933594
Train_StdReturn : 5.236363410949707
Train_MaxReturn : 60.0
Train_MinReturn : 40.0
Train_AverageEpLen : 49.095238095238095
Actor Loss : 1.416900634765625
Train_EnvstepsSoFar : 177891
TimeSinceStart : 144.09885334968567
Done logging...



********** Iteration 170 ************

Collecting data for eval...
Eval_AverageReturn : 71.5
Eval_StdReturn : 19.371370315551758
Eval_MaxReturn : 111.0
Eval_MinReturn : 54.0
Eval_AverageEpLen : 71.5
Train_AverageReturn : 56.66666793823242
Train_StdReturn : 10.33870792388916
Train_MaxReturn : 77.0
Train_MinReturn : 43.0
Train_AverageEpLen : 56.666666666666664
Actor Loss : 3.156209945678711
Train_EnvstepsSoFar : 178911
TimeSinceStart : 145.06807732582092
Done logging...



********** Iteration 171 ************

Collecting data for eval...
Eval_AverageReturn : 95.19999694824219
Eval_StdReturn : 13.05986213684082
Eval_MaxReturn : 115.0
Eval_MinReturn : 79.0
Eval_AverageEpLen : 95.2
Train_AverageReturn : 71.64286041259766
Train_StdReturn : 14.215721130371094
Train_MaxReturn : 102.0
Train_MinReturn : 51.0
Train_AverageEpLen : 71.64285714285714
Actor Loss : 4.36296272277832
Train_EnvstepsSoFar : 179914
TimeSinceStart : 145.8239245414734
Done logging...



********** Iteration 172 ************

Collecting data for eval...
Eval_AverageReturn : 159.6666717529297
Eval_StdReturn : 57.039947509765625
Eval_MaxReturn : 200.0
Eval_MinReturn : 79.0
Eval_AverageEpLen : 159.66666666666666
Train_AverageReturn : 104.69999694824219
Train_StdReturn : 19.804292678833008
Train_MaxReturn : 135.0
Train_MinReturn : 71.0
Train_AverageEpLen : 104.7
Actor Loss : 5.494344234466553
Train_EnvstepsSoFar : 180961
TimeSinceStart : 146.59430861473083
Done logging...



********** Iteration 173 ************

Collecting data for eval...
Eval_AverageReturn : 177.3333282470703
Eval_StdReturn : 16.213848114013672
Eval_MaxReturn : 200.0
Eval_MinReturn : 163.0
Eval_AverageEpLen : 177.33333333333334
Train_AverageReturn : 182.8333282470703
Train_StdReturn : 38.385833740234375
Train_MaxReturn : 200.0
Train_MinReturn : 97.0
Train_AverageEpLen : 182.83333333333334
Actor Loss : 30.5440673828125
Train_EnvstepsSoFar : 182058
TimeSinceStart : 147.41728472709656
Done logging...



********** Iteration 174 ************

Collecting data for eval...
Eval_AverageReturn : 197.0
Eval_StdReturn : 4.242640495300293
Eval_MaxReturn : 200.0
Eval_MinReturn : 191.0
Eval_AverageEpLen : 197.0
Train_AverageReturn : 160.42857360839844
Train_StdReturn : 45.74418640136719
Train_MaxReturn : 200.0
Train_MinReturn : 78.0
Train_AverageEpLen : 160.42857142857142
Actor Loss : 48.055885314941406
Train_EnvstepsSoFar : 183181
TimeSinceStart : 148.2755856513977
Done logging...



********** Iteration 175 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 195.6666717529297
Train_StdReturn : 4.678555965423584
Train_MaxReturn : 200.0
Train_MinReturn : 188.0
Train_AverageEpLen : 195.66666666666666
Actor Loss : -46.770660400390625
Train_EnvstepsSoFar : 184355
TimeSinceStart : 149.07370686531067
Done logging...



********** Iteration 176 ************

Collecting data for eval...
Eval_AverageReturn : 140.0
Eval_StdReturn : 9.416297912597656
Eval_MaxReturn : 152.0
Eval_MinReturn : 129.0
Eval_AverageEpLen : 140.0
Train_AverageReturn : 175.8333282470703
Train_StdReturn : 19.514240264892578
Train_MaxReturn : 200.0
Train_MinReturn : 150.0
Train_AverageEpLen : 175.83333333333334
Actor Loss : -46.64236068725586
Train_EnvstepsSoFar : 185410
TimeSinceStart : 149.81821203231812
Done logging...



********** Iteration 177 ************

Collecting data for eval...
Eval_AverageReturn : 142.6666717529297
Eval_StdReturn : 14.636332511901855
Eval_MaxReturn : 154.0
Eval_MinReturn : 122.0
Eval_AverageEpLen : 142.66666666666666
Train_AverageReturn : 160.42857360839844
Train_StdReturn : 17.879413604736328
Train_MaxReturn : 188.0
Train_MinReturn : 142.0
Train_AverageEpLen : 160.42857142857142
Actor Loss : -33.56669998168945
Train_EnvstepsSoFar : 186533
TimeSinceStart : 150.59975266456604
Done logging...



********** Iteration 178 ************

Collecting data for eval...
Eval_AverageReturn : 119.75
Eval_StdReturn : 5.804093360900879
Eval_MaxReturn : 126.0
Eval_MinReturn : 113.0
Eval_AverageEpLen : 119.75
Train_AverageReturn : 149.57142639160156
Train_StdReturn : 21.539710998535156
Train_MaxReturn : 200.0
Train_MinReturn : 134.0
Train_AverageEpLen : 149.57142857142858
Actor Loss : -48.31006622314453
Train_EnvstepsSoFar : 187580
TimeSinceStart : 151.36803364753723
Done logging...



********** Iteration 179 ************

Collecting data for eval...
Eval_AverageReturn : 103.75
Eval_StdReturn : 6.759253025054932
Eval_MaxReturn : 111.0
Eval_MinReturn : 94.0
Eval_AverageEpLen : 103.75
Train_AverageReturn : 126.125
Train_StdReturn : 17.18602180480957
Train_MaxReturn : 165.0
Train_MinReturn : 104.0
Train_AverageEpLen : 126.125
Actor Loss : -25.974220275878906
Train_EnvstepsSoFar : 188589
TimeSinceStart : 152.08937644958496
Done logging...



********** Iteration 180 ************

Collecting data for eval...
Eval_AverageReturn : 100.5
Eval_StdReturn : 9.630680084228516
Eval_MaxReturn : 113.0
Eval_MinReturn : 87.0
Eval_AverageEpLen : 100.5
Train_AverageReturn : 114.66666412353516
Train_StdReturn : 27.39018440246582
Train_MaxReturn : 172.0
Train_MinReturn : 88.0
Train_AverageEpLen : 114.66666666666667
Actor Loss : -52.112125396728516
Train_EnvstepsSoFar : 189621
TimeSinceStart : 153.2817611694336
Done logging...



********** Iteration 181 ************

Collecting data for eval...
Eval_AverageReturn : 114.25
Eval_StdReturn : 42.02603530883789
Eval_MaxReturn : 184.0
Eval_MinReturn : 74.0
Eval_AverageEpLen : 114.25
Train_AverageReturn : 106.63636016845703
Train_StdReturn : 25.467529296875
Train_MaxReturn : 175.0
Train_MinReturn : 79.0
Train_AverageEpLen : 106.63636363636364
Actor Loss : -46.0226936340332
Train_EnvstepsSoFar : 190794
TimeSinceStart : 154.10821151733398
Done logging...



********** Iteration 182 ************

Collecting data for eval...
Eval_AverageReturn : 92.0
Eval_StdReturn : 24.730546951293945
Eval_MaxReturn : 138.0
Eval_MinReturn : 64.0
Eval_AverageEpLen : 92.0
Train_AverageReturn : 91.09091186523438
Train_StdReturn : 27.786373138427734
Train_MaxReturn : 172.0
Train_MinReturn : 69.0
Train_AverageEpLen : 91.0909090909091
Actor Loss : -50.9151611328125
Train_EnvstepsSoFar : 191796
TimeSinceStart : 154.84705352783203
Done logging...



********** Iteration 183 ************

Collecting data for eval...
Eval_AverageReturn : 112.75
Eval_StdReturn : 53.03006362915039
Eval_MaxReturn : 200.0
Eval_MinReturn : 57.0
Eval_AverageEpLen : 112.75
Train_AverageReturn : 94.63636016845703
Train_StdReturn : 37.368614196777344
Train_MaxReturn : 188.0
Train_MinReturn : 63.0
Train_AverageEpLen : 94.63636363636364
Actor Loss : -79.69052124023438
Train_EnvstepsSoFar : 192837
TimeSinceStart : 155.60335564613342
Done logging...



********** Iteration 184 ************

Collecting data for eval...
Eval_AverageReturn : 93.83333587646484
Eval_StdReturn : 51.48921203613281
Eval_MaxReturn : 200.0
Eval_MinReturn : 49.0
Eval_AverageEpLen : 93.83333333333333
Train_AverageReturn : 82.23076629638672
Train_StdReturn : 30.298906326293945
Train_MaxReturn : 172.0
Train_MinReturn : 50.0
Train_AverageEpLen : 82.23076923076923
Actor Loss : -61.82301712036133
Train_EnvstepsSoFar : 193906
TimeSinceStart : 156.447336435318
Done logging...



********** Iteration 185 ************

Collecting data for eval...
Eval_AverageReturn : 153.0
Eval_StdReturn : 66.4680404663086
Eval_MaxReturn : 200.0
Eval_MinReturn : 59.0
Eval_AverageEpLen : 153.0
Train_AverageReturn : 119.77777862548828
Train_StdReturn : 55.679195404052734
Train_MaxReturn : 200.0
Train_MinReturn : 50.0
Train_AverageEpLen : 119.77777777777777
Actor Loss : -21.46520233154297
Train_EnvstepsSoFar : 194984
TimeSinceStart : 157.23270082473755
Done logging...



********** Iteration 186 ************

Collecting data for eval...
Eval_AverageReturn : 146.0
Eval_StdReturn : 39.63163757324219
Eval_MaxReturn : 200.0
Eval_MinReturn : 106.0
Eval_AverageEpLen : 146.0
Train_AverageReturn : 146.7142791748047
Train_StdReturn : 61.81011199951172
Train_MaxReturn : 200.0
Train_MinReturn : 63.0
Train_AverageEpLen : 146.71428571428572
Actor Loss : 7.965794563293457
Train_EnvstepsSoFar : 196011
TimeSinceStart : 157.99348163604736
Done logging...



********** Iteration 187 ************

Collecting data for eval...
Eval_AverageReturn : 87.4000015258789
Eval_StdReturn : 26.627803802490234
Eval_MaxReturn : 132.0
Eval_MinReturn : 52.0
Eval_AverageEpLen : 87.4
Train_AverageReturn : 141.875
Train_StdReturn : 57.12144470214844
Train_MaxReturn : 200.0
Train_MinReturn : 63.0
Train_AverageEpLen : 141.875
Actor Loss : 17.36532211303711
Train_EnvstepsSoFar : 197146
TimeSinceStart : 158.80593919754028
Done logging...



********** Iteration 188 ************

Collecting data for eval...
Eval_AverageReturn : 89.66666412353516
Eval_StdReturn : 28.66860580444336
Eval_MaxReturn : 143.0
Eval_MinReturn : 64.0
Eval_AverageEpLen : 89.66666666666667
Train_AverageReturn : 92.18181610107422
Train_StdReturn : 42.98798751831055
Train_MaxReturn : 200.0
Train_MinReturn : 49.0
Train_AverageEpLen : 92.18181818181819
Actor Loss : 21.186317443847656
Train_EnvstepsSoFar : 198160
TimeSinceStart : 159.60400581359863
Done logging...



********** Iteration 189 ************

Collecting data for eval...
Eval_AverageReturn : 69.66666412353516
Eval_StdReturn : 26.278425216674805
Eval_MaxReturn : 123.0
Eval_MinReturn : 48.0
Eval_AverageEpLen : 69.66666666666667
Train_AverageReturn : 67.66666412353516
Train_StdReturn : 18.703535079956055
Train_MaxReturn : 113.0
Train_MinReturn : 44.0
Train_AverageEpLen : 67.66666666666667
Actor Loss : -23.7423095703125
Train_EnvstepsSoFar : 199175
TimeSinceStart : 160.3390212059021
Done logging...



********** Iteration 190 ************

Collecting data for eval...
Eval_AverageReturn : 52.125
Eval_StdReturn : 9.333240509033203
Eval_MaxReturn : 72.0
Eval_MinReturn : 41.0
Eval_AverageEpLen : 52.125
Train_AverageReturn : 84.33333587646484
Train_StdReturn : 23.661970138549805
Train_MaxReturn : 121.0
Train_MinReturn : 48.0
Train_AverageEpLen : 84.33333333333333
Actor Loss : -15.336162567138672
Train_EnvstepsSoFar : 200187
TimeSinceStart : 161.08244013786316
Done logging...



********** Iteration 191 ************

Collecting data for eval...
Eval_AverageReturn : 67.16666412353516
Eval_StdReturn : 27.799379348754883
Eval_MaxReturn : 126.0
Eval_MinReturn : 42.0
Eval_AverageEpLen : 67.16666666666667
Train_AverageReturn : 68.5999984741211
Train_StdReturn : 39.84770965576172
Train_MaxReturn : 200.0
Train_MinReturn : 42.0
Train_AverageEpLen : 68.6
Actor Loss : -43.144676208496094
Train_EnvstepsSoFar : 201216
TimeSinceStart : 161.81818556785583
Done logging...



********** Iteration 192 ************

Collecting data for eval...
Eval_AverageReturn : 58.42856979370117
Eval_StdReturn : 13.916661262512207
Eval_MaxReturn : 84.0
Eval_MinReturn : 41.0
Eval_AverageEpLen : 58.42857142857143
Train_AverageReturn : 63.75
Train_StdReturn : 19.524023056030273
Train_MaxReturn : 107.0
Train_MinReturn : 40.0
Train_AverageEpLen : 63.75
Actor Loss : -34.718994140625
Train_EnvstepsSoFar : 202236
TimeSinceStart : 162.55702924728394
Done logging...



********** Iteration 193 ************

Collecting data for eval...
Eval_AverageReturn : 57.125
Eval_StdReturn : 22.32956314086914
Eval_MaxReturn : 112.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 57.125
Train_AverageReturn : 63.9375
Train_StdReturn : 20.422012329101562
Train_MaxReturn : 110.0
Train_MinReturn : 38.0
Train_AverageEpLen : 63.9375
Actor Loss : -49.03398513793945
Train_EnvstepsSoFar : 203259
TimeSinceStart : 163.31313633918762
Done logging...



********** Iteration 194 ************

Collecting data for eval...
Eval_AverageReturn : 57.85714340209961
Eval_StdReturn : 10.789260864257812
Eval_MaxReturn : 71.0
Eval_MinReturn : 40.0
Eval_AverageEpLen : 57.857142857142854
Train_AverageReturn : 58.82352828979492
Train_StdReturn : 14.459824562072754
Train_MaxReturn : 94.0
Train_MinReturn : 34.0
Train_AverageEpLen : 58.8235294117647
Actor Loss : -39.272220611572266
Train_EnvstepsSoFar : 204259
TimeSinceStart : 164.04134011268616
Done logging...



********** Iteration 195 ************

Collecting data for eval...
Eval_AverageReturn : 49.77777862548828
Eval_StdReturn : 16.20547103881836
Eval_MaxReturn : 77.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 49.77777777777778
Train_AverageReturn : 61.35293960571289
Train_StdReturn : 31.737789154052734
Train_MaxReturn : 152.0
Train_MinReturn : 34.0
Train_AverageEpLen : 61.35294117647059
Actor Loss : -65.29505920410156
Train_EnvstepsSoFar : 205302
TimeSinceStart : 164.8143355846405
Done logging...



********** Iteration 196 ************

Collecting data for eval...
Eval_AverageReturn : 79.16666412353516
Eval_StdReturn : 36.23265838623047
Eval_MaxReturn : 140.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 79.16666666666667
Train_AverageReturn : 64.8125
Train_StdReturn : 25.11030387878418
Train_MaxReturn : 112.0
Train_MinReturn : 33.0
Train_AverageEpLen : 64.8125
Actor Loss : -62.82712173461914
Train_EnvstepsSoFar : 206339
TimeSinceStart : 165.58710527420044
Done logging...



********** Iteration 197 ************

Collecting data for eval...
Eval_AverageReturn : 111.80000305175781
Eval_StdReturn : 65.14108276367188
Eval_MaxReturn : 200.0
Eval_MinReturn : 46.0
Eval_AverageEpLen : 111.8
Train_AverageReturn : 70.13333129882812
Train_StdReturn : 31.497865676879883
Train_MaxReturn : 148.0
Train_MinReturn : 39.0
Train_AverageEpLen : 70.13333333333334
Actor Loss : -69.82157897949219
Train_EnvstepsSoFar : 207391
TimeSinceStart : 166.83034801483154
Done logging...



********** Iteration 198 ************

Collecting data for eval...
Eval_AverageReturn : 151.0
Eval_StdReturn : 13.638181686401367
Eval_MaxReturn : 166.0
Eval_MinReturn : 133.0
Eval_AverageEpLen : 151.0
Train_AverageReturn : 125.77777862548828
Train_StdReturn : 49.881587982177734
Train_MaxReturn : 200.0
Train_MinReturn : 54.0
Train_AverageEpLen : 125.77777777777777
Actor Loss : -16.007854461669922
Train_EnvstepsSoFar : 208523
TimeSinceStart : 167.62414646148682
Done logging...



********** Iteration 199 ************

Collecting data for eval...
Eval_AverageReturn : 167.0
Eval_StdReturn : 39.8078727722168
Eval_MaxReturn : 200.0
Eval_MinReturn : 111.0
Eval_AverageEpLen : 167.0
Train_AverageReturn : 173.1666717529297
Train_StdReturn : 28.322057723999023
Train_MaxReturn : 200.0
Train_MinReturn : 128.0
Train_AverageEpLen : 173.16666666666666
Actor Loss : -48.35956954956055
Train_EnvstepsSoFar : 209562
TimeSinceStart : 168.41036915779114
Done logging...



********** Iteration 200 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 199.6666717529297
Train_StdReturn : 0.745356023311615
Train_MaxReturn : 200.0
Train_MinReturn : 198.0
Train_AverageEpLen : 199.66666666666666
Actor Loss : -26.41229820251465
Train_EnvstepsSoFar : 210760
TimeSinceStart : 169.2148997783661
Done logging...



********** Iteration 201 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 194.0
Train_StdReturn : 8.793937683105469
Train_MaxReturn : 200.0
Train_MinReturn : 178.0
Train_AverageEpLen : 194.0
Actor Loss : -73.88973999023438
Train_EnvstepsSoFar : 211924
TimeSinceStart : 170.01589274406433
Done logging...



********** Iteration 202 ************
/home/jaehyun-jeong/UCBerkeley_cs285/hw2/cs285/agents/pg_agent.py:155: RuntimeWarning: invalid value encountered in divide
  advantages = (advantages - np.mean(advantages)) / np.std(advantages)

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.6632566452026367
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 212924
TimeSinceStart : 170.75798344612122
Done logging...



********** Iteration 203 ************

Collecting data for eval...
Eval_AverageReturn : 9.227272987365723
Eval_StdReturn : 0.7027102112770081
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.227272727272727
Train_AverageReturn : 9.324073791503906
Train_StdReturn : 0.7677372097969055
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.324074074074074
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 213931
TimeSinceStart : 171.49836468696594
Done logging...



********** Iteration 204 ************

Collecting data for eval...
Eval_AverageReturn : 9.181818008422852
Eval_StdReturn : 0.7767276167869568
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.181818181818182
Train_AverageReturn : 9.383177757263184
Train_StdReturn : 0.6787132024765015
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.383177570093459
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 214935
TimeSinceStart : 172.23427820205688
Done logging...



********** Iteration 205 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.772392988204956
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.314814567565918
Train_StdReturn : 0.7283689379692078
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.314814814814815
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 215941
TimeSinceStart : 172.96217942237854
Done logging...



********** Iteration 206 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.647831916809082
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.392523765563965
Train_StdReturn : 0.7071993947029114
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392523364485982
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 216946
TimeSinceStart : 173.6796064376831
Done logging...



********** Iteration 207 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.6249716281890869
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 9.333333015441895
Train_StdReturn : 0.8050764203071594
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.333333333333334
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 217954
TimeSinceStart : 174.83167934417725
Done logging...



********** Iteration 208 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.7423856258392334
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.40186882019043
Train_StdReturn : 0.8522627353668213
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.401869158878505
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 218960
TimeSinceStart : 175.5543372631073
Done logging...



********** Iteration 209 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.7228032350540161
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.462264060974121
Train_StdReturn : 0.6753689050674438
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.462264150943396
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 219963
TimeSinceStart : 176.71223783493042
Done logging...



********** Iteration 210 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.7635560631752014
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.7643008828163147
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 220964
TimeSinceStart : 177.43829369544983
Done logging...



********** Iteration 211 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7061500549316406
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.429906845092773
Train_StdReturn : 0.7502292394638062
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.429906542056075
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 221973
TimeSinceStart : 178.15527415275574
Done logging...



********** Iteration 212 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.7622767090797424
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 9.462264060974121
Train_StdReturn : 0.7545400261878967
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.462264150943396
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 222976
TimeSinceStart : 178.88748693466187
Done logging...



********** Iteration 213 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.6970134377479553
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 9.277777671813965
Train_StdReturn : 0.7179359793663025
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.277777777777779
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 223978
TimeSinceStart : 179.62252616882324
Done logging...



********** Iteration 214 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.8928536176681519
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.392523765563965
Train_StdReturn : 0.7331535816192627
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392523364485982
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 224983
TimeSinceStart : 180.3622705936432
Done logging...



********** Iteration 215 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.77938312292099
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.333333015441895
Train_StdReturn : 0.6938886642456055
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.333333333333334
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 225991
TimeSinceStart : 181.09213995933533
Done logging...



********** Iteration 216 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.8076165318489075
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.220183372497559
Train_StdReturn : 0.7085040211677551
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.220183486238533
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 226996
TimeSinceStart : 181.8336865901947
Done logging...



********** Iteration 217 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.8136211633682251
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7900375127792358
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 227998
TimeSinceStart : 182.55173468589783
Done logging...



********** Iteration 218 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.8720155358314514
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.433961868286133
Train_StdReturn : 0.7650240063667297
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.433962264150944
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 228998
TimeSinceStart : 183.28092074394226
Done logging...



********** Iteration 219 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.630056619644165
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.324073791503906
Train_StdReturn : 0.8695327043533325
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.324074074074074
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 230005
TimeSinceStart : 184.02769780158997
Done logging...



********** Iteration 220 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.8076165318489075
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.324073791503906
Train_StdReturn : 0.7914907336235046
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.324074074074074
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 231012
TimeSinceStart : 184.76311993598938
Done logging...



********** Iteration 221 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7865830063819885
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.30555534362793
Train_StdReturn : 0.7752937078475952
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.305555555555555
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 232017
TimeSinceStart : 185.4892418384552
Done logging...



********** Iteration 222 ************

Collecting data for eval...
Eval_AverageReturn : 9.159090995788574
Eval_StdReturn : 0.7670244574546814
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.159090909090908
Train_AverageReturn : 9.392523765563965
Train_StdReturn : 0.6663753986358643
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392523364485982
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 233022
TimeSinceStart : 186.24043989181519
Done logging...



********** Iteration 223 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.6898789405822754
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.7519736289978027
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 234023
TimeSinceStart : 186.96582341194153
Done logging...



********** Iteration 224 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.6922268271446228
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.259259223937988
Train_StdReturn : 0.762189507484436
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.25925925925926
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 235023
TimeSinceStart : 187.7047348022461
Done logging...



********** Iteration 225 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.6478319764137268
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.296296119689941
Train_StdReturn : 0.7608384490013123
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.296296296296296
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 236027
TimeSinceStart : 188.44169116020203
Done logging...



********** Iteration 226 ************

Collecting data for eval...
Eval_AverageReturn : 9.227272987365723
Eval_StdReturn : 0.7938295006752014
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.227272727272727
Train_AverageReturn : 9.333333015441895
Train_StdReturn : 0.6938886046409607
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.333333333333334
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 237035
TimeSinceStart : 189.1788091659546
Done logging...



********** Iteration 227 ************

Collecting data for eval...
Eval_AverageReturn : 9.534883499145508
Eval_StdReturn : 0.6231517195701599
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.534883720930232
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.7643009424209595
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 238036
TimeSinceStart : 189.91898608207703
Done logging...



********** Iteration 228 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7692015767097473
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.411214828491211
Train_StdReturn : 0.7606351375579834
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.411214953271028
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 239043
TimeSinceStart : 190.6539225578308
Done logging...



********** Iteration 229 ************

Collecting data for eval...
Eval_AverageReturn : 9.136363983154297
Eval_StdReturn : 0.8684078454971313
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.136363636363637
Train_AverageReturn : 9.392523765563965
Train_StdReturn : 0.6663753986358643
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392523364485982
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 240048
TimeSinceStart : 191.37429070472717
Done logging...



********** Iteration 230 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 0.7604151964187622
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 9.277777671813965
Train_StdReturn : 0.7049209475517273
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.277777777777779
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 241050
TimeSinceStart : 192.1112928390503
Done logging...



********** Iteration 231 ************

Collecting data for eval...
Eval_AverageReturn : 9.511628150939941
Eval_StdReturn : 0.6240189671516418
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.511627906976743
Train_AverageReturn : 9.345794677734375
Train_StdReturn : 0.7117546200752258
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.345794392523365
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 242050
TimeSinceStart : 192.8542137145996
Done logging...



********** Iteration 232 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7061500549316406
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.21100902557373
Train_StdReturn : 0.7428359985351562
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.211009174311927
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 243054
TimeSinceStart : 193.5755467414856
Done logging...



********** Iteration 233 ************

Collecting data for eval...
Eval_AverageReturn : 9.181818008422852
Eval_StdReturn : 0.7468944191932678
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.181818181818182
Train_AverageReturn : 9.392523765563965
Train_StdReturn : 0.8620449900627136
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392523364485982
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 244059
TimeSinceStart : 194.30663084983826
Done logging...



********** Iteration 234 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.5992603898048401
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.383177757263184
Train_StdReturn : 0.7443853616714478
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.383177570093459
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 245063
TimeSinceStart : 195.03273177146912
Done logging...



********** Iteration 235 ************

Collecting data for eval...
Eval_AverageReturn : 9.136363983154297
Eval_StdReturn : 0.7565143704414368
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.136363636363637
Train_AverageReturn : 9.373831748962402
Train_StdReturn : 0.8262443542480469
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.373831775700934
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 246066
TimeSinceStart : 196.05185389518738
Done logging...



********** Iteration 236 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7250445485115051
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.345794677734375
Train_StdReturn : 0.7983956933021545
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.345794392523365
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 247066
TimeSinceStart : 197.06038975715637
Done logging...



********** Iteration 237 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.7324658036231995
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.429906845092773
Train_StdReturn : 0.698625385761261
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.429906542056075
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 248075
TimeSinceStart : 197.78540563583374
Done logging...



********** Iteration 238 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.8551058173179626
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.287036895751953
Train_StdReturn : 0.7704126834869385
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.287037037037036
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 249078
TimeSinceStart : 198.50020456314087
Done logging...



********** Iteration 239 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.7886430025100708
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.6449275612831116
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 250079
TimeSinceStart : 199.20270562171936
Done logging...



********** Iteration 240 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7865830063819885
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.373831748962402
Train_StdReturn : 0.7553344964981079
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.373831775700934
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 251082
TimeSinceStart : 199.91330647468567
Done logging...



********** Iteration 241 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.6999961137771606
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.471697807312012
Train_StdReturn : 0.7673472166061401
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.471698113207546
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 252086
TimeSinceStart : 200.61928486824036
Done logging...



********** Iteration 242 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.6152909994125366
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.247706413269043
Train_StdReturn : 0.7560879588127136
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.247706422018348
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 253094
TimeSinceStart : 201.32881546020508
Done logging...



********** Iteration 243 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.6970133781433105
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 9.342592239379883
Train_StdReturn : 0.7348726391792297
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.342592592592593
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 254103
TimeSinceStart : 202.03461050987244
Done logging...



********** Iteration 244 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.787956953048706
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.277777671813965
Train_StdReturn : 0.730719268321991
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.277777777777779
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 255105
TimeSinceStart : 202.759215593338
Done logging...



********** Iteration 245 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.889819860458374
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.5
Train_StdReturn : 0.7678688764572144
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.5
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 256112
TimeSinceStart : 203.4749574661255
Done logging...



********** Iteration 246 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.8391450047492981
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.49056625366211
Train_StdReturn : 0.7169811129570007
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.49056603773585
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 257118
TimeSinceStart : 204.1825065612793
Done logging...



********** Iteration 247 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.7114911079406738
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.383177757263184
Train_StdReturn : 0.7568362355232239
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.383177570093459
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 258122
TimeSinceStart : 204.88438272476196
Done logging...



********** Iteration 248 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.642803430557251
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.383177757263184
Train_StdReturn : 0.7690856456756592
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.383177570093459
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 259126
TimeSinceStart : 205.9739854335785
Done logging...



********** Iteration 249 ************

Collecting data for eval...
Eval_AverageReturn : 9.159090995788574
Eval_StdReturn : 0.8241574764251709
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.159090909090908
Train_AverageReturn : 9.333333015441895
Train_StdReturn : 0.7328280806541443
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.333333333333334
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 260134
TimeSinceStart : 206.690509557724
Done logging...



********** Iteration 250 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.8080177307128906
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.45283031463623
Train_StdReturn : 0.7906538248062134
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.452830188679245
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 261136
TimeSinceStart : 207.85802030563354
Done logging...



********** Iteration 251 ************

Collecting data for eval...
Eval_AverageReturn : 9.295454978942871
Eval_StdReturn : 0.7561728954315186
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.295454545454545
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.673286497592926
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 262137
TimeSinceStart : 208.56606149673462
Done logging...



********** Iteration 252 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.747810959815979
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.49056625366211
Train_StdReturn : 0.7037001848220825
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.49056603773585
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 263143
TimeSinceStart : 209.26956939697266
Done logging...



********** Iteration 253 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.6922268271446228
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.383177757263184
Train_StdReturn : 0.718836784362793
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.383177570093459
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 264147
TimeSinceStart : 209.98583459854126
Done logging...



********** Iteration 254 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7564398050308228
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.373831748962402
Train_StdReturn : 0.6907041668891907
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.373831775700934
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 265150
TimeSinceStart : 210.70233035087585
Done logging...



********** Iteration 255 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.6519927978515625
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.30555534362793
Train_StdReturn : 0.7510281801223755
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.305555555555555
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 266155
TimeSinceStart : 211.40882658958435
Done logging...



********** Iteration 256 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.6784005165100098
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.30555534362793
Train_StdReturn : 0.7988224029541016
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.305555555555555
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 267160
TimeSinceStart : 212.1173312664032
Done logging...



********** Iteration 257 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.8076165318489075
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.296296119689941
Train_StdReturn : 0.7104935646057129
Train_MaxReturn : 10.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.296296296296296
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 268164
TimeSinceStart : 213.0966718196869
Done logging...



********** Iteration 258 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.6231517195701599
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.314814567565918
Train_StdReturn : 0.7893755435943604
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.314814814814815
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 269170
TimeSinceStart : 213.80856347084045
Done logging...



********** Iteration 259 ************

Collecting data for eval...
Eval_AverageReturn : 9.511628150939941
Eval_StdReturn : 0.6602357029914856
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.511627906976743
Train_AverageReturn : 9.268518447875977
Train_StdReturn : 0.7528523206710815
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.268518518518519
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 270171
TimeSinceStart : 214.52520155906677
Done logging...



********** Iteration 260 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.6659451127052307
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.40186882019043
Train_StdReturn : 0.8412253260612488
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.401869158878505
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 271177
TimeSinceStart : 215.24378561973572
Done logging...



********** Iteration 261 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.6784005165100098
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.345794677734375
Train_StdReturn : 0.6985005140304565
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.345794392523365
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 272177
TimeSinceStart : 215.97640705108643
Done logging...



********** Iteration 262 ************

Collecting data for eval...
Eval_AverageReturn : 9.159090995788574
Eval_StdReturn : 0.6375800371170044
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.159090909090908
Train_AverageReturn : 9.287036895751953
Train_StdReturn : 0.7459883689880371
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.287037037037036
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 273180
TimeSinceStart : 216.7252480983734
Done logging...



********** Iteration 263 ************

Collecting data for eval...
Eval_AverageReturn : 9.090909004211426
Eval_StdReturn : 0.7633116245269775
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.090909090909092
Train_AverageReturn : 9.342592239379883
Train_StdReturn : 0.6960476040840149
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.342592592592593
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 274189
TimeSinceStart : 217.44643211364746
Done logging...



********** Iteration 264 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 0.5832118391990662
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 9.247706413269043
Train_StdReturn : 0.7438551187515259
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.247706422018348
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 275197
TimeSinceStart : 218.19362926483154
Done logging...



********** Iteration 265 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.77938312292099
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.7004983425140381
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 276198
TimeSinceStart : 218.92300605773926
Done logging...



********** Iteration 266 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.747810959815979
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.373831748962402
Train_StdReturn : 0.7428584098815918
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.373831775700934
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 277201
TimeSinceStart : 219.63780665397644
Done logging...



********** Iteration 267 ************

Collecting data for eval...
Eval_AverageReturn : 9.511628150939941
Eval_StdReturn : 0.788642942905426
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.511627906976743
Train_AverageReturn : 9.383177757263184
Train_StdReturn : 0.7568362951278687
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.383177570093459
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 278205
TimeSinceStart : 220.35300850868225
Done logging...



********** Iteration 268 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.8356716632843018
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.314814567565918
Train_StdReturn : 0.753364622592926
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.314814814814815
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 279211
TimeSinceStart : 221.09331059455872
Done logging...



********** Iteration 269 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.7478109002113342
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.523809432983398
Train_StdReturn : 0.7939682006835938
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.523809523809524
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 280211
TimeSinceStart : 221.82500576972961
Done logging...



********** Iteration 270 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.7635560035705566
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.433961868286133
Train_StdReturn : 0.7525914311408997
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.433962264150944
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 281211
TimeSinceStart : 222.5424988269806
Done logging...



********** Iteration 271 ************

Collecting data for eval...
Eval_AverageReturn : 9.090909004211426
Eval_StdReturn : 0.8207031488418579
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.090909090909092
Train_AverageReturn : 9.373831748962402
Train_StdReturn : 0.704105019569397
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.373831775700934
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 282214
TimeSinceStart : 223.26792001724243
Done logging...



********** Iteration 272 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.6568149328231812
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7023661136627197
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 283216
TimeSinceStart : 223.98566794395447
Done logging...



********** Iteration 273 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.7324658632278442
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.268518447875977
Train_StdReturn : 0.7770609259605408
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.268518518518519
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 284217
TimeSinceStart : 224.70386481285095
Done logging...



********** Iteration 274 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.6898789405822754
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.50943374633789
Train_StdReturn : 0.6763564944267273
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.50943396226415
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 285225
TimeSinceStart : 225.42636919021606
Done logging...



********** Iteration 275 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.738349199295044
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.345794677734375
Train_StdReturn : 0.8100168108940125
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.345794392523365
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 286225
TimeSinceStart : 226.14868783950806
Done logging...



********** Iteration 276 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7250445485115051
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.333333015441895
Train_StdReturn : 0.8050764799118042
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.333333333333334
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 287233
TimeSinceStart : 227.11767053604126
Done logging...



********** Iteration 277 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.6945666670799255
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.40186882019043
Train_StdReturn : 0.7470792531967163
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.401869158878505
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 288239
TimeSinceStart : 227.84703660011292
Done logging...



********** Iteration 278 ************

Collecting data for eval...
Eval_AverageReturn : 9.227272987365723
Eval_StdReturn : 0.7027102112770081
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.227272727272727
Train_AverageReturn : 9.383177757263184
Train_StdReturn : 0.7317225933074951
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.383177570093459
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 289243
TimeSinceStart : 228.63842248916626
Done logging...



********** Iteration 279 ************

Collecting data for eval...
Eval_AverageReturn : 9.204545021057129
Eval_StdReturn : 0.6934612393379211
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.204545454545455
Train_AverageReturn : 9.392523765563965
Train_StdReturn : 0.6938583254814148
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392523364485982
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 290248
TimeSinceStart : 229.35071444511414
Done logging...



********** Iteration 280 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.7741076946258545
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.481132507324219
Train_StdReturn : 0.7167949080467224
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.481132075471699
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 291253
TimeSinceStart : 230.06975984573364
Done logging...



********** Iteration 281 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.5919963121414185
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.287036895751953
Train_StdReturn : 0.6945679187774658
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.287037037037036
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 292256
TimeSinceStart : 230.7815248966217
Done logging...



********** Iteration 282 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.7478108406066895
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.314814567565918
Train_StdReturn : 0.7409721612930298
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.314814814814815
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 293262
TimeSinceStart : 231.4855010509491
Done logging...



********** Iteration 283 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.8320252895355225
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.21100902557373
Train_StdReturn : 0.8358196020126343
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.211009174311927
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 294266
TimeSinceStart : 232.20441150665283
Done logging...



********** Iteration 284 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.8012773990631104
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.751973569393158
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 295267
TimeSinceStart : 232.9186658859253
Done logging...



********** Iteration 285 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.738349199295044
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.277777671813965
Train_StdReturn : 0.7797593474388123
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.277777777777779
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 296269
TimeSinceStart : 233.640310049057
Done logging...



********** Iteration 286 ************

Collecting data for eval...
Eval_AverageReturn : 9.088889122009277
Eval_StdReturn : 0.6607142686843872
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.088888888888889
Train_AverageReturn : 9.383177757263184
Train_StdReturn : 0.6923461556434631
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.383177570093459
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 297273
TimeSinceStart : 234.3788800239563
Done logging...



********** Iteration 287 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.6152909994125366
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.333333015441895
Train_StdReturn : 0.7453559041023254
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.333333333333334
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 298281
TimeSinceStart : 235.54811096191406
Done logging...



********** Iteration 288 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.6263307929039001
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.342592239379883
Train_StdReturn : 0.7596544623374939
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.342592592592593
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 299290
TimeSinceStart : 236.28785371780396
Done logging...



********** Iteration 289 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.77938312292099
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.373831748962402
Train_StdReturn : 0.8148546814918518
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.373831775700934
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 300293
TimeSinceStart : 237.0211682319641
Done logging...



********** Iteration 290 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.5846421122550964
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.324073791503906
Train_StdReturn : 0.6642832159996033
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.324074074074074
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 301300
TimeSinceStart : 237.95998525619507
Done logging...



********** Iteration 291 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.716037392616272
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.433961868286133
Train_StdReturn : 0.7270887494087219
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.433962264150944
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 302300
TimeSinceStart : 238.6923749446869
Done logging...



********** Iteration 292 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.716037392616272
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.433961868286133
Train_StdReturn : 0.8243793845176697
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.433962264150944
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 303300
TimeSinceStart : 239.42441320419312
Done logging...



********** Iteration 293 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.6214134693145752
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.411214828491211
Train_StdReturn : 0.7228354215621948
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.411214953271028
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 304307
TimeSinceStart : 240.15235424041748
Done logging...



********** Iteration 294 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.7228032350540161
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.44339656829834
Train_StdReturn : 0.7533596158027649
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.443396226415095
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 305308
TimeSinceStart : 240.88993644714355
Done logging...



********** Iteration 295 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.6659451127052307
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.411214828491211
Train_StdReturn : 0.696496844291687
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.411214953271028
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 306315
TimeSinceStart : 241.61870884895325
Done logging...



********** Iteration 296 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.83591628074646
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.324073791503906
Train_StdReturn : 0.7432249784469604
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.324074074074074
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 307322
TimeSinceStart : 242.33426117897034
Done logging...



********** Iteration 297 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.6898789405822754
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.324073791503906
Train_StdReturn : 0.6915990710258484
Train_MaxReturn : 10.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.324074074074074
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 308329
TimeSinceStart : 243.06522369384766
Done logging...



********** Iteration 298 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.8012773990631104
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.751973569393158
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 309330
TimeSinceStart : 243.781391620636
Done logging...



********** Iteration 299 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.6784669756889343
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 9.373831748962402
Train_StdReturn : 0.7915838360786438
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.373831775700934
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 310333
TimeSinceStart : 244.51414155960083
Done logging...



********** Iteration 300 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.6300565600395203
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.259259223937988
Train_StdReturn : 0.7978021502494812
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.25925925925926
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 311333
TimeSinceStart : 245.25653553009033
Done logging...



********** Iteration 301 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.7845175862312317
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.220183372497559
Train_StdReturn : 0.7585330605506897
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.220183486238533
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 312338
TimeSinceStart : 245.99238085746765
Done logging...



********** Iteration 302 ************

Collecting data for eval...
Eval_AverageReturn : 9.136363983154297
Eval_StdReturn : 0.7258508801460266
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.136363636363637
Train_AverageReturn : 9.392523765563965
Train_StdReturn : 0.720293402671814
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392523364485982
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 313343
TimeSinceStart : 246.73845982551575
Done logging...



********** Iteration 303 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.605544924736023
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.40186882019043
Train_StdReturn : 0.8412253260612488
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.401869158878505
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 314349
TimeSinceStart : 247.90905714035034
Done logging...



********** Iteration 304 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.8632888197898865
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.183485984802246
Train_StdReturn : 0.7800862789154053
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.18348623853211
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 315350
TimeSinceStart : 248.64114236831665
Done logging...



********** Iteration 305 ************

Collecting data for eval...
Eval_AverageReturn : 9.227272987365723
Eval_StdReturn : 0.7938294410705566
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.227272727272727
Train_AverageReturn : 9.314814567565918
Train_StdReturn : 0.7409721612930298
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.314814814814815
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 316356
TimeSinceStart : 249.39817190170288
Done logging...



********** Iteration 306 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7692016363143921
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.471697807312012
Train_StdReturn : 0.7164844274520874
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.471698113207546
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 317360
TimeSinceStart : 250.1168041229248
Done logging...



********** Iteration 307 ************

Collecting data for eval...
Eval_AverageReturn : 9.181818008422852
Eval_StdReturn : 0.6833316683769226
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.181818181818182
Train_AverageReturn : 9.40186882019043
Train_StdReturn : 0.7344629168510437
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.401869158878505
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 318366
TimeSinceStart : 250.83256936073303
Done logging...



********** Iteration 308 ************

Collecting data for eval...
Eval_AverageReturn : 9.204545021057129
Eval_StdReturn : 0.7561729550361633
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.204545454545455
Train_AverageReturn : 9.40186882019043
Train_StdReturn : 0.6678157448768616
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.401869158878505
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 319372
TimeSinceStart : 251.5770173072815
Done logging...



********** Iteration 309 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.7160373330116272
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.411214828491211
Train_StdReturn : 0.7228354215621948
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.411214953271028
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 320379
TimeSinceStart : 252.3269350528717
Done logging...



********** Iteration 310 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.8417191505432129
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.471697807312012
Train_StdReturn : 0.779544472694397
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.471698113207546
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 321383
TimeSinceStart : 253.08174967765808
Done logging...



********** Iteration 311 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.6898789405822754
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.287036895751953
Train_StdReturn : 0.7459883689880371
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.287037037037036
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 322386
TimeSinceStart : 253.82337069511414
Done logging...



********** Iteration 312 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.9284867644309998
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.420560836791992
Train_StdReturn : 0.723922073841095
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.42056074766355
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 323394
TimeSinceStart : 254.74176740646362
Done logging...



********** Iteration 313 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.6945666670799255
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.45283031463623
Train_StdReturn : 0.646209180355072
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.452830188679245
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 324396
TimeSinceStart : 255.47111654281616
Done logging...



********** Iteration 314 ************

Collecting data for eval...
Eval_AverageReturn : 9.295454978942871
Eval_StdReturn : 0.6598741412162781
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.295454545454545
Train_AverageReturn : 9.345794677734375
Train_StdReturn : 0.6849900484085083
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.345794392523365
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 325396
TimeSinceStart : 256.2165424823761
Done logging...



********** Iteration 315 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.5919963121414185
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.345794677734375
Train_StdReturn : 0.8214735388755798
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.345794392523365
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 326396
TimeSinceStart : 257.17489552497864
Done logging...



********** Iteration 316 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.8664156198501587
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.287036895751953
Train_StdReturn : 0.7077733278274536
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.287037037037036
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 327399
TimeSinceStart : 257.9172387123108
Done logging...



********** Iteration 317 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.7514182925224304
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7023661136627197
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 328401
TimeSinceStart : 258.66894936561584
Done logging...



********** Iteration 318 ************

Collecting data for eval...
Eval_AverageReturn : 9.511628150939941
Eval_StdReturn : 0.7272788882255554
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.511627906976743
Train_AverageReturn : 9.40186882019043
Train_StdReturn : 0.7085567116737366
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.401869158878505
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 329407
TimeSinceStart : 259.6953718662262
Done logging...



********** Iteration 319 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 0.5832118391990662
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 9.345794677734375
Train_StdReturn : 0.7624703049659729
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.345794392523365
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 330407
TimeSinceStart : 260.45019721984863
Done logging...



********** Iteration 320 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.889819860458374
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.373831748962402
Train_StdReturn : 0.8033034801483154
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.373831775700934
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 331410
TimeSinceStart : 261.20893383026123
Done logging...



********** Iteration 321 ************

Collecting data for eval...
Eval_AverageReturn : 9.204545021057129
Eval_StdReturn : 0.7561729550361633
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.204545454545455
Train_AverageReturn : 9.314814567565918
Train_StdReturn : 0.7533646821975708
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.314814814814815
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 332416
TimeSinceStart : 261.97662568092346
Done logging...



********** Iteration 322 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.8109578490257263
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.268518447875977
Train_StdReturn : 0.7528523802757263
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.268518518518519
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 333417
TimeSinceStart : 262.71441197395325
Done logging...



********** Iteration 323 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.5856368541717529
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 9.481132507324219
Train_StdReturn : 0.7426511645317078
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.481132075471699
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 334422
TimeSinceStart : 263.43948912620544
Done logging...



********** Iteration 324 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.9136250019073486
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.373831748962402
Train_StdReturn : 0.7428584098815918
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.373831775700934
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 335425
TimeSinceStart : 264.1695146560669
Done logging...



********** Iteration 325 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 0.540848433971405
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7537137866020203
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 336427
TimeSinceStart : 265.0815169811249
Done logging...



********** Iteration 326 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.6784005165100098
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.40186882019043
Train_StdReturn : 0.7716933488845825
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.401869158878505
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 337433
TimeSinceStart : 265.99577045440674
Done logging...



********** Iteration 327 ************

Collecting data for eval...
Eval_AverageReturn : 9.318181991577148
Eval_StdReturn : 0.8194434642791748
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.318181818181818
Train_AverageReturn : 9.411214828491211
Train_StdReturn : 0.6829468011856079
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.411214953271028
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 338440
TimeSinceStart : 266.9277558326721
Done logging...



********** Iteration 328 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.6602357029914856
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.411214828491211
Train_StdReturn : 0.7228354215621948
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.411214953271028
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 339447
TimeSinceStart : 268.39701104164124
Done logging...



********** Iteration 329 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.798863410949707
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.229357719421387
Train_StdReturn : 0.7971627116203308
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.229357798165138
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 340453
TimeSinceStart : 269.46457076072693
Done logging...



********** Iteration 330 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.738349199295044
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.373831748962402
Train_StdReturn : 0.7301691174507141
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.373831775700934
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 341456
TimeSinceStart : 270.48988914489746
Done logging...



********** Iteration 331 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.7186995148658752
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.296296119689941
Train_StdReturn : 0.7485697269439697
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.296296296296296
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 342460
TimeSinceStart : 271.62425422668457
Done logging...



********** Iteration 332 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.6780176162719727
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.373831748962402
Train_StdReturn : 0.8033034801483154
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.373831775700934
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 343463
TimeSinceStart : 272.88075065612793
Done logging...



********** Iteration 333 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.6827868819236755
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.268518447875977
Train_StdReturn : 0.7150042653083801
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.268518518518519
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 344464
TimeSinceStart : 274.23079085350037
Done logging...



********** Iteration 334 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.6553024649620056
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.776432454586029
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 345465
TimeSinceStart : 275.15357851982117
Done logging...



********** Iteration 335 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7061500549316406
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7412104606628418
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 346467
TimeSinceStart : 276.07815623283386
Done logging...



********** Iteration 336 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.6424160599708557
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 9.383177757263184
Train_StdReturn : 0.7317225933074951
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.383177570093459
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 347471
TimeSinceStart : 277.33007860183716
Done logging...



********** Iteration 337 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.8012773990631104
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.30555534362793
Train_StdReturn : 0.7988224625587463
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.305555555555555
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 348476
TimeSinceStart : 278.3572316169739
Done logging...



********** Iteration 338 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.7434589266777039
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.345794677734375
Train_StdReturn : 0.711754560470581
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.345794392523365
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 349476
TimeSinceStart : 279.70406794548035
Done logging...



********** Iteration 339 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.7845175862312317
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.45283031463623
Train_StdReturn : 0.7285559773445129
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.452830188679245
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 350478
TimeSinceStart : 281.0326302051544
Done logging...



********** Iteration 340 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.6263307929039001
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.373831748962402
Train_StdReturn : 0.7301691174507141
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.373831775700934
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 351481
TimeSinceStart : 281.94002509117126
Done logging...



********** Iteration 341 ************

Collecting data for eval...
Eval_AverageReturn : 9.113636016845703
Eval_StdReturn : 0.6472286581993103
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.113636363636363
Train_AverageReturn : 9.324073791503906
Train_StdReturn : 0.7797044515609741
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.324074074074074
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 352488
TimeSinceStart : 282.8487446308136
Done logging...



********** Iteration 342 ************

Collecting data for eval...
Eval_AverageReturn : 9.04444408416748
Eval_StdReturn : 0.84210205078125
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.044444444444444
Train_AverageReturn : 9.324073791503906
Train_StdReturn : 0.7555804252624512
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.324074074074074
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 353495
TimeSinceStart : 283.779709815979
Done logging...



********** Iteration 343 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.793428897857666
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.392523765563965
Train_StdReturn : 0.7943375110626221
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392523364485982
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 354500
TimeSinceStart : 284.6838028430939
Done logging...



********** Iteration 344 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.6187969446182251
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.296296119689941
Train_StdReturn : 0.7485697269439697
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.296296296296296
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 355504
TimeSinceStart : 285.97176241874695
Done logging...



********** Iteration 345 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.5992603898048401
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.314814567565918
Train_StdReturn : 0.753364622592926
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.314814814814815
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 356510
TimeSinceStart : 286.728590965271
Done logging...



********** Iteration 346 ************

Collecting data for eval...
Eval_AverageReturn : 9.159090995788574
Eval_StdReturn : 0.8241574764251709
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.159090909090908
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.7394407987594604
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 357511
TimeSinceStart : 287.6550829410553
Done logging...



********** Iteration 347 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.8109579086303711
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.287036895751953
Train_StdReturn : 0.6945679187774658
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.287037037037036
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 358514
TimeSinceStart : 288.5415074825287
Done logging...



********** Iteration 348 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.6898789405822754
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.256880760192871
Train_StdReturn : 0.7590876817703247
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.256880733944953
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 359523
TimeSinceStart : 289.2731258869171
Done logging...



********** Iteration 349 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.829156219959259
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.333333015441895
Train_StdReturn : 0.8713547587394714
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.333333333333334
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 360531
TimeSinceStart : 290.0249137878418
Done logging...



********** Iteration 350 ************

Collecting data for eval...
Eval_AverageReturn : 9.642857551574707
Eval_StdReturn : 0.7502833604812622
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.642857142857142
Train_AverageReturn : 9.383177757263184
Train_StdReturn : 0.7443853616714478
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.383177570093459
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 361535
TimeSinceStart : 290.76458191871643
Done logging...



********** Iteration 351 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.7272788286209106
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.40186882019043
Train_StdReturn : 0.7085567116737366
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.401869158878505
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 362541
TimeSinceStart : 291.4961938858032
Done logging...



********** Iteration 352 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.6577737927436829
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7284924983978271
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 363543
TimeSinceStart : 292.2188048362732
Done logging...



********** Iteration 353 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.8436444997787476
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.518867492675781
Train_StdReturn : 0.7167949676513672
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.518867924528301
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 364552
TimeSinceStart : 292.9477276802063
Done logging...



********** Iteration 354 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.8632888197898865
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.277777671813965
Train_StdReturn : 0.8480187058448792
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.277777777777779
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 365554
TimeSinceStart : 294.09124660491943
Done logging...



********** Iteration 355 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.719804048538208
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7660130858421326
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 366556
TimeSinceStart : 295.00325751304626
Done logging...



********** Iteration 356 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.6577737927436829
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.324073791503906
Train_StdReturn : 0.755580484867096
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.324074074074074
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 367563
TimeSinceStart : 295.90792894363403
Done logging...



********** Iteration 357 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.5827890038490295
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.345794677734375
Train_StdReturn : 0.6849900484085083
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.345794392523365
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 368563
TimeSinceStart : 296.81926918029785
Done logging...



********** Iteration 358 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.738349199295044
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.776432454586029
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 369564
TimeSinceStart : 298.1333348751068
Done logging...



********** Iteration 359 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.7324658036231995
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.8117402195930481
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 370565
TimeSinceStart : 298.9611568450928
Done logging...



********** Iteration 360 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.747810959815979
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.40186882019043
Train_StdReturn : 0.7344629168510437
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.401869158878505
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 371571
TimeSinceStart : 299.8834459781647
Done logging...



********** Iteration 361 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.6898789405822754
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.49056625366211
Train_StdReturn : 0.7554241418838501
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.49056603773585
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 372577
TimeSinceStart : 301.22909474372864
Done logging...



********** Iteration 362 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.6152909994125366
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7660130858421326
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 373579
TimeSinceStart : 302.1206634044647
Done logging...



********** Iteration 363 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.6827868819236755
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.420560836791992
Train_StdReturn : 0.7738407254219055
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.42056074766355
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 374587
TimeSinceStart : 303.02876377105713
Done logging...



********** Iteration 364 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.787956953048706
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.314814567565918
Train_StdReturn : 0.7409721612930298
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.314814814814815
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 375593
TimeSinceStart : 304.3684706687927
Done logging...



********** Iteration 365 ************

Collecting data for eval...
Eval_AverageReturn : 9.619047164916992
Eval_StdReturn : 0.6529194712638855
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.619047619047619
Train_AverageReturn : 9.30555534362793
Train_StdReturn : 0.7871459722518921
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.305555555555555
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 376598
TimeSinceStart : 305.20174956321716
Done logging...



********** Iteration 366 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.7741076946258545
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.30555534362793
Train_StdReturn : 0.7510281801223755
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.305555555555555
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 377603
TimeSinceStart : 305.9225494861603
Done logging...



********** Iteration 367 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.672410786151886
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.552380561828613
Train_StdReturn : 0.6758550405502319
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.552380952380952
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 378606
TimeSinceStart : 306.6448175907135
Done logging...



********** Iteration 368 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.793428897857666
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.7137153148651123
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 379607
TimeSinceStart : 307.3606152534485
Done logging...



********** Iteration 369 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.6659451723098755
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.373831748962402
Train_StdReturn : 0.6770381331443787
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.373831775700934
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 380610
TimeSinceStart : 308.0898377895355
Done logging...



********** Iteration 370 ************

Collecting data for eval...
Eval_AverageReturn : 9.159090995788574
Eval_StdReturn : 0.6375800371170044
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.159090909090908
Train_AverageReturn : 9.268518447875977
Train_StdReturn : 0.7019348740577698
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.268518518518519
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 381611
TimeSinceStart : 308.8219118118286
Done logging...



********** Iteration 371 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7692016363143921
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.433961868286133
Train_StdReturn : 0.7772578001022339
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.433962264150944
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 382611
TimeSinceStart : 309.9964118003845
Done logging...



********** Iteration 372 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.7315376996994019
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.471697807312012
Train_StdReturn : 0.7031941413879395
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.471698113207546
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 383615
TimeSinceStart : 310.739132642746
Done logging...



********** Iteration 373 ************

Collecting data for eval...
Eval_AverageReturn : 9.090909004211426
Eval_StdReturn : 0.7329325079917908
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.090909090909092
Train_AverageReturn : 9.238532066345215
Train_StdReturn : 0.7406800985336304
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.238532110091743
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 384622
TimeSinceStart : 311.471999168396
Done logging...



********** Iteration 374 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.754291832447052
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.314814567565918
Train_StdReturn : 0.7409721612930298
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.314814814814815
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 385628
TimeSinceStart : 312.21132159233093
Done logging...



********** Iteration 375 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.7514183521270752
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.411214828491211
Train_StdReturn : 0.7966432571411133
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.411214953271028
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 386635
TimeSinceStart : 312.94530606269836
Done logging...



********** Iteration 376 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.6937876343727112
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.287036895751953
Train_StdReturn : 0.7207368016242981
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.287037037037036
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 387638
TimeSinceStart : 313.6773519515991
Done logging...



********** Iteration 377 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.8222171664237976
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.324073791503906
Train_StdReturn : 0.7048601508140564
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.324074074074074
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 388645
TimeSinceStart : 314.4137079715729
Done logging...



********** Iteration 378 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.8182304501533508
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 9.49056625366211
Train_StdReturn : 0.7428308725357056
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.49056603773585
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 389651
TimeSinceStart : 315.15964913368225
Done logging...



********** Iteration 379 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.7585816383361816
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.383177757263184
Train_StdReturn : 0.7568362951278687
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.383177570093459
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 390655
TimeSinceStart : 315.9015488624573
Done logging...



********** Iteration 380 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.8076164722442627
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.462264060974121
Train_StdReturn : 0.7669411301612854
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.462264150943396
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 391658
TimeSinceStart : 316.65681290626526
Done logging...



********** Iteration 381 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.6424160599708557
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 9.373831748962402
Train_StdReturn : 0.7172554731369019
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.373831775700934
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 392661
TimeSinceStart : 317.3950836658478
Done logging...



********** Iteration 382 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.7514182925224304
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.462264060974121
Train_StdReturn : 0.7160494923591614
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.462264150943396
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 393664
TimeSinceStart : 318.1382703781128
Done logging...



********** Iteration 383 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.8551058769226074
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.471697807312012
Train_StdReturn : 0.6617237329483032
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.471698113207546
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 394668
TimeSinceStart : 318.88383054733276
Done logging...



********** Iteration 384 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.8012773990631104
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7537137866020203
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 395670
TimeSinceStart : 319.60639548301697
Done logging...



********** Iteration 385 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.816938042640686
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7900375127792358
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 396672
TimeSinceStart : 320.33561992645264
Done logging...



********** Iteration 386 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.7434589266777039
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.481132507324219
Train_StdReturn : 0.7035105228424072
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.481132075471699
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 397677
TimeSinceStart : 321.07484436035156
Done logging...



********** Iteration 387 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7564398050308228
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.342592239379883
Train_StdReturn : 0.7348726391792297
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.342592592592593
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 398686
TimeSinceStart : 321.94958090782166
Done logging...



********** Iteration 388 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.7741076946258545
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.247706413269043
Train_StdReturn : 0.7799783945083618
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.247706422018348
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 399694
TimeSinceStart : 322.86761355400085
Done logging...



********** Iteration 389 ************

Collecting data for eval...
Eval_AverageReturn : 9.295454978942871
Eval_StdReturn : 0.6934611797332764
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.295454545454545
Train_AverageReturn : 9.247706413269043
Train_StdReturn : 0.7560879588127136
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.247706422018348
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 400702
TimeSinceStart : 323.59659481048584
Done logging...



********** Iteration 390 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.8109579086303711
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.287036895751953
Train_StdReturn : 0.8056619763374329
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.287037037037036
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 401705
TimeSinceStart : 324.32442712783813
Done logging...



********** Iteration 391 ************

Collecting data for eval...
Eval_AverageReturn : 9.204545021057129
Eval_StdReturn : 0.8140679597854614
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.204545454545455
Train_AverageReturn : 9.462264060974121
Train_StdReturn : 0.7669411301612854
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.462264150943396
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 402708
TimeSinceStart : 325.0630006790161
Done logging...



********** Iteration 392 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.716037392616272
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.411214828491211
Train_StdReturn : 0.696496844291687
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.411214953271028
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 403715
TimeSinceStart : 325.8041398525238
Done logging...



********** Iteration 393 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.8274626135826111
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.7266919016838074
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 404716
TimeSinceStart : 326.72980427742004
Done logging...



********** Iteration 394 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7865830063819885
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.277777671813965
Train_StdReturn : 0.8258927464485168
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.277777777777779
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 405718
TimeSinceStart : 327.4571692943573
Done logging...



********** Iteration 395 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.7934289574623108
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.145454406738281
Train_StdReturn : 0.711418092250824
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.145454545454545
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 406724
TimeSinceStart : 328.2054901123047
Done logging...



********** Iteration 396 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.793428897857666
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.324073791503906
Train_StdReturn : 0.7432249784469604
Train_MaxReturn : 10.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.324074074074074
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 407731
TimeSinceStart : 328.97845005989075
Done logging...



********** Iteration 397 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.672410786151886
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.174311637878418
Train_StdReturn : 0.7274945974349976
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.174311926605505
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 408731
TimeSinceStart : 330.3152365684509
Done logging...



********** Iteration 398 ************

Collecting data for eval...
Eval_AverageReturn : 9.136363983154297
Eval_StdReturn : 0.7258508801460266
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.136363636363637
Train_AverageReturn : 9.259259223937988
Train_StdReturn : 0.7374929189682007
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.25925925925926
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 409731
TimeSinceStart : 331.2589371204376
Done logging...



********** Iteration 399 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.7423856258392334
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.30555534362793
Train_StdReturn : 0.7130832076072693
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.305555555555555
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 410736
TimeSinceStart : 332.52958726882935
Done logging...



********** Iteration 400 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.77938312292099
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.7394407987594604
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 411737
TimeSinceStart : 333.8946895599365
Done logging...



********** Iteration 401 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7061500549316406
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.40186882019043
Train_StdReturn : 0.7837104797363281
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.401869158878505
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 412743
TimeSinceStart : 335.2477424144745
Done logging...



********** Iteration 402 ************

Collecting data for eval...
Eval_AverageReturn : 9.181818008422852
Eval_StdReturn : 0.7767276167869568
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.181818181818182
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7660130858421326
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 413745
TimeSinceStart : 336.7509181499481
Done logging...



********** Iteration 403 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7564398050308228
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.342592239379883
Train_StdReturn : 0.7092254757881165
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.342592592592593
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 414754
TimeSinceStart : 338.06356930732727
Done logging...



********** Iteration 404 ************

Collecting data for eval...
Eval_AverageReturn : 9.113636016845703
Eval_StdReturn : 0.8316442966461182
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.113636363636363
Train_AverageReturn : 9.324073791503906
Train_StdReturn : 0.7914907336235046
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.324074074074074
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 415761
TimeSinceStart : 338.80821919441223
Done logging...



********** Iteration 405 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.8136211633682251
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.296296119689941
Train_StdReturn : 0.7848007678985596
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.296296296296296
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 416765
TimeSinceStart : 339.53006291389465
Done logging...



********** Iteration 406 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.8035884499549866
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.345794677734375
Train_StdReturn : 0.6280485987663269
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.345794392523365
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 417765
TimeSinceStart : 340.26023411750793
Done logging...



********** Iteration 407 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 0.8206517696380615
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7023661136627197
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 418767
TimeSinceStart : 340.97477316856384
Done logging...



********** Iteration 408 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.772392988204956
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.30555534362793
Train_StdReturn : 0.7259519100189209
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.305555555555555
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 419772
TimeSinceStart : 341.6969196796417
Done logging...



********** Iteration 409 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.7114911079406738
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.433961868286133
Train_StdReturn : 0.7139958143234253
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.433962264150944
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 420772
TimeSinceStart : 342.4298417568207
Done logging...



********** Iteration 410 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.83591628074646
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.392523765563965
Train_StdReturn : 0.7704471349716187
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392523364485982
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 421777
TimeSinceStart : 343.15971970558167
Done logging...



********** Iteration 411 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.7496556043624878
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.383177757263184
Train_StdReturn : 0.7811430096626282
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.383177570093459
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 422781
TimeSinceStart : 343.9031300544739
Done logging...



********** Iteration 412 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.7782883644104004
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.183485984802246
Train_StdReturn : 0.8032633066177368
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.18348623853211
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 423782
TimeSinceStart : 345.07368993759155
Done logging...



********** Iteration 413 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.716037392616272
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.383177757263184
Train_StdReturn : 0.7930169105529785
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.383177570093459
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 424786
TimeSinceStart : 345.82948088645935
Done logging...



********** Iteration 414 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.7741076946258545
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.429906845092773
Train_StdReturn : 0.6713377237319946
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.429906542056075
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 425795
TimeSinceStart : 346.5667850971222
Done logging...



********** Iteration 415 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7988634705543518
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.345794677734375
Train_StdReturn : 0.7624702453613281
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.345794392523365
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 426795
TimeSinceStart : 347.2985689640045
Done logging...



********** Iteration 416 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.672410786151886
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.21100902557373
Train_StdReturn : 0.7790065407752991
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.211009174311927
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 427799
TimeSinceStart : 348.03781914711
Done logging...



********** Iteration 417 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.7845175862312317
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.345794677734375
Train_StdReturn : 0.7501128315925598
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.345794392523365
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 428799
TimeSinceStart : 348.7556347846985
Done logging...



********** Iteration 418 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7564398050308228
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.333333015441895
Train_StdReturn : 0.7328280806541443
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.333333333333334
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 429807
TimeSinceStart : 349.68265557289124
Done logging...



********** Iteration 419 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.7111130952835083
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.268518447875977
Train_StdReturn : 0.7650524377822876
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.268518518518519
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 430808
TimeSinceStart : 350.4219105243683
Done logging...



********** Iteration 420 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.6602357625961304
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.238532066345215
Train_StdReturn : 0.7650517821311951
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.238532110091743
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 431815
TimeSinceStart : 351.16248512268066
Done logging...



********** Iteration 421 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.6187969446182251
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.392523765563965
Train_StdReturn : 0.8511344790458679
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392523364485982
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 432820
TimeSinceStart : 351.87915539741516
Done logging...



********** Iteration 422 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.7782883644104004
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.40186882019043
Train_StdReturn : 0.8187044262886047
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.401869158878505
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 433826
TimeSinceStart : 352.6317398548126
Done logging...



********** Iteration 423 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.6922268271446228
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.345794677734375
Train_StdReturn : 0.7746305465698242
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.345794392523365
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 434826
TimeSinceStart : 353.54715871810913
Done logging...



********** Iteration 424 ************

Collecting data for eval...
Eval_AverageReturn : 9.181818008422852
Eval_StdReturn : 0.6492207646369934
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.181818181818182
Train_AverageReturn : 9.314814567565918
Train_StdReturn : 0.7775572538375854
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.314814814814815
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 435832
TimeSinceStart : 354.3939392566681
Done logging...



********** Iteration 425 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.6108802556991577
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7781180143356323
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 436834
TimeSinceStart : 355.2194619178772
Done logging...



********** Iteration 426 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.83591628074646
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.333333015441895
Train_StdReturn : 0.8277590870857239
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.333333333333334
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 437842
TimeSinceStart : 356.3872284889221
Done logging...



********** Iteration 427 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.6519927978515625
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.8001440763473511
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 438843
TimeSinceStart : 357.12374114990234
Done logging...



********** Iteration 428 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.6568149328231812
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 9.392523765563965
Train_StdReturn : 0.680255651473999
Train_MaxReturn : 10.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392523364485982
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 439848
TimeSinceStart : 357.8540804386139
Done logging...



********** Iteration 429 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7250445485115051
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.296296119689941
Train_StdReturn : 0.7965116500854492
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.296296296296296
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 440852
TimeSinceStart : 358.6106688976288
Done logging...



********** Iteration 430 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.6827868819236755
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.433961868286133
Train_StdReturn : 0.8357447385787964
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.433962264150944
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 441852
TimeSinceStart : 359.36573576927185
Done logging...



********** Iteration 431 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.6632566452026367
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.287036895751953
Train_StdReturn : 0.6945679187774658
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.287037037037036
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 442855
TimeSinceStart : 360.1063506603241
Done logging...



********** Iteration 432 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.7434589266777039
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.259259223937988
Train_StdReturn : 0.7119401693344116
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.25925925925926
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 443855
TimeSinceStart : 360.8513967990875
Done logging...



********** Iteration 433 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.816938042640686
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.342592239379883
Train_StdReturn : 0.6826153993606567
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.342592592592593
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 444864
TimeSinceStart : 361.5989110469818
Done logging...



********** Iteration 434 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.6619732975959778
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.7266919016838074
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 445865
TimeSinceStart : 362.7736313343048
Done logging...



********** Iteration 435 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.6152909994125366
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.44339656829834
Train_StdReturn : 0.6879034042358398
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.443396226415095
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 446866
TimeSinceStart : 363.5232834815979
Done logging...



********** Iteration 436 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.6999961137771606
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.481132507324219
Train_StdReturn : 0.7298375368118286
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.481132075471699
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 447871
TimeSinceStart : 364.24573945999146
Done logging...



********** Iteration 437 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.6999961137771606
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.471697807312012
Train_StdReturn : 0.7295327186584473
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.471698113207546
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 448875
TimeSinceStart : 364.98786759376526
Done logging...



********** Iteration 438 ************

Collecting data for eval...
Eval_AverageReturn : 9.159090995788574
Eval_StdReturn : 0.8241574764251709
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.159090909090908
Train_AverageReturn : 9.481132507324219
Train_StdReturn : 0.6899703741073608
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.481132075471699
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 449880
TimeSinceStart : 365.7508804798126
Done logging...



********** Iteration 439 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.8156129717826843
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7023661136627197
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 450882
TimeSinceStart : 366.49981331825256
Done logging...



********** Iteration 440 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.8595218062400818
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.333333015441895
Train_StdReturn : 0.7328280806541443
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.333333333333334
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 451890
TimeSinceStart : 367.68978548049927
Done logging...



********** Iteration 441 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.659416139125824
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.44339656829834
Train_StdReturn : 0.7533596158027649
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.443396226415095
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 452891
TimeSinceStart : 368.4455797672272
Done logging...



********** Iteration 442 ************

Collecting data for eval...
Eval_AverageReturn : 9.295454978942871
Eval_StdReturn : 0.7254949808120728
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.295454545454545
Train_AverageReturn : 9.324073791503906
Train_StdReturn : 0.8031039834022522
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.324074074074074
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 453898
TimeSinceStart : 369.199392080307
Done logging...



********** Iteration 443 ************

Collecting data for eval...
Eval_AverageReturn : 9.227272987365723
Eval_StdReturn : 0.764663815498352
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.227272727272727
Train_AverageReturn : 9.392523765563965
Train_StdReturn : 0.7071993350982666
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392523364485982
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 454903
TimeSinceStart : 369.9504792690277
Done logging...



********** Iteration 444 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.787956953048706
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.287036895751953
Train_StdReturn : 0.7704126834869385
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.287037037037036
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 455906
TimeSinceStart : 371.1104574203491
Done logging...



********** Iteration 445 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.8076164722442627
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.268518447875977
Train_StdReturn : 0.7404513359069824
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.268518518518519
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 456907
TimeSinceStart : 371.86265993118286
Done logging...



********** Iteration 446 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.8076165318489075
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.411214828491211
Train_StdReturn : 0.7606351375579834
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.411214953271028
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 457914
TimeSinceStart : 372.60948038101196
Done logging...



********** Iteration 447 ************

Collecting data for eval...
Eval_AverageReturn : 9.227272987365723
Eval_StdReturn : 0.7343406081199646
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.227272727272727
Train_AverageReturn : 9.420560836791992
Train_StdReturn : 0.7858251333236694
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.42056074766355
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 458922
TimeSinceStart : 373.3698010444641
Done logging...



********** Iteration 448 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.6827868223190308
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.392523765563965
Train_StdReturn : 0.7331535220146179
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392523364485982
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 459927
TimeSinceStart : 374.14449644088745
Done logging...



********** Iteration 449 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.7114911079406738
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.21100902557373
Train_StdReturn : 0.7428359985351562
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.211009174311927
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 460931
TimeSinceStart : 374.89099740982056
Done logging...



********** Iteration 450 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.6519927978515625
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7537137866020203
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 461933
TimeSinceStart : 375.64472556114197
Done logging...



********** Iteration 451 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.5846421122550964
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.45283031463623
Train_StdReturn : 0.7285559773445129
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.452830188679245
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 462935
TimeSinceStart : 376.4104497432709
Done logging...



********** Iteration 452 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.8136211633682251
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.7266919016838074
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 463936
TimeSinceStart : 377.15950298309326
Done logging...



********** Iteration 453 ************

Collecting data for eval...
Eval_AverageReturn : 9.181818008422852
Eval_StdReturn : 0.7468944191932678
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.181818181818182
Train_AverageReturn : 9.342592239379883
Train_StdReturn : 0.6960476040840149
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.342592592592593
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 464945
TimeSinceStart : 377.90898537635803
Done logging...



********** Iteration 454 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.6922268271446228
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.373831748962402
Train_StdReturn : 0.7676078081130981
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.373831775700934
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 465948
TimeSinceStart : 379.09258008003235
Done logging...



********** Iteration 455 ************

Collecting data for eval...
Eval_AverageReturn : 9.295454978942871
Eval_StdReturn : 0.6598741412162781
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.295454545454545
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.6889314651489258
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 466950
TimeSinceStart : 379.83542704582214
Done logging...



********** Iteration 456 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.7228032350540161
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.44339656829834
Train_StdReturn : 0.8018867373466492
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.443396226415095
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 467951
TimeSinceStart : 380.57181429862976
Done logging...



********** Iteration 457 ************

Collecting data for eval...
Eval_AverageReturn : 9.113636016845703
Eval_StdReturn : 0.7451634407043457
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.113636363636363
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.675229549407959
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 468953
TimeSinceStart : 381.4384026527405
Done logging...



********** Iteration 458 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.8035885095596313
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.277777671813965
Train_StdReturn : 0.6916610598564148
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.277777777777779
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 469955
TimeSinceStart : 382.1837637424469
Done logging...



********** Iteration 459 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.726534903049469
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.392523765563965
Train_StdReturn : 0.7582197785377502
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392523364485982
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 470960
TimeSinceStart : 382.9302818775177
Done logging...



********** Iteration 460 ************

Collecting data for eval...
Eval_AverageReturn : 9.136363983154297
Eval_StdReturn : 0.8418299555778503
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.136363636363637
Train_AverageReturn : 9.287036895751953
Train_StdReturn : 0.7077733278274536
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.287037037037036
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 471963
TimeSinceStart : 383.6519968509674
Done logging...



********** Iteration 461 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.8109579086303711
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.533333778381348
Train_StdReturn : 0.7311655879020691
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.533333333333333
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 472964
TimeSinceStart : 384.3905346393585
Done logging...



********** Iteration 462 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.7228032350540161
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.7394407987594604
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 473965
TimeSinceStart : 385.1596863269806
Done logging...



********** Iteration 463 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.7272788286209106
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.383177757263184
Train_StdReturn : 0.7930169105529785
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.383177570093459
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 474969
TimeSinceStart : 385.8959095478058
Done logging...



********** Iteration 464 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.8551058769226074
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.277777671813965
Train_StdReturn : 0.7432827353477478
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.277777777777779
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 475971
TimeSinceStart : 386.61816358566284
Done logging...



********** Iteration 465 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.6863486170768738
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.5
Train_StdReturn : 0.690228283405304
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.5
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 476978
TimeSinceStart : 387.3664267063141
Done logging...



********** Iteration 466 ************

Collecting data for eval...
Eval_AverageReturn : 9.295454978942871
Eval_StdReturn : 0.6934611797332764
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.295454545454545
Train_AverageReturn : 9.287036895751953
Train_StdReturn : 0.7207368016242981
Train_MaxReturn : 10.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.287037037037036
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 477981
TimeSinceStart : 388.1021535396576
Done logging...



********** Iteration 467 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.7160373330116272
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.751973569393158
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 478982
TimeSinceStart : 388.84764766693115
Done logging...



********** Iteration 468 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.7496556043624878
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.411214828491211
Train_StdReturn : 0.7356511950492859
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.411214953271028
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 479989
TimeSinceStart : 389.5978739261627
Done logging...



********** Iteration 469 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.7324658036231995
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7284924983978271
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 480991
TimeSinceStart : 390.33003759384155
Done logging...



********** Iteration 470 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.8035884499549866
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.259259223937988
Train_StdReturn : 0.7499428391456604
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.25925925925926
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 481991
TimeSinceStart : 391.0668683052063
Done logging...



********** Iteration 471 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.7782883644104004
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.247706413269043
Train_StdReturn : 0.7916532754898071
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.247706422018348
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 482999
TimeSinceStart : 391.81447649002075
Done logging...



********** Iteration 472 ************

Collecting data for eval...
Eval_AverageReturn : 9.181818008422852
Eval_StdReturn : 0.8600403666496277
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.181818181818182
Train_AverageReturn : 9.392523765563965
Train_StdReturn : 0.8175299763679504
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392523364485982
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 484004
TimeSinceStart : 392.54621934890747
Done logging...



********** Iteration 473 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.754291832447052
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.45283031463623
Train_StdReturn : 0.7664187550544739
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.452830188679245
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 485006
TimeSinceStart : 393.27459597587585
Done logging...



********** Iteration 474 ************

Collecting data for eval...
Eval_AverageReturn : 9.204545021057129
Eval_StdReturn : 0.8140679597854614
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.204545454545455
Train_AverageReturn : 9.259259223937988
Train_StdReturn : 0.7119401693344116
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.25925925925926
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 486006
TimeSinceStart : 393.98838210105896
Done logging...



********** Iteration 475 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.636886715888977
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.324073791503906
Train_StdReturn : 0.7432249188423157
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.324074074074074
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 487013
TimeSinceStart : 394.7192134857178
Done logging...



********** Iteration 476 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.6553024649620056
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.296296119689941
Train_StdReturn : 0.697339653968811
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.296296296296296
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 488017
TimeSinceStart : 395.44186902046204
Done logging...



********** Iteration 477 ************

Collecting data for eval...
Eval_AverageReturn : 9.511628150939941
Eval_StdReturn : 0.6945666670799255
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.511627906976743
Train_AverageReturn : 9.552380561828613
Train_StdReturn : 0.7681883573532104
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.552380952380952
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 489020
TimeSinceStart : 396.1728992462158
Done logging...



********** Iteration 478 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.7272788882255554
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.383177757263184
Train_StdReturn : 0.7057157754898071
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.383177570093459
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 490024
TimeSinceStart : 397.22250413894653
Done logging...



********** Iteration 479 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.6784005165100098
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.392523765563965
Train_StdReturn : 0.758219838142395
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392523364485982
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 491029
TimeSinceStart : 398.2356719970703
Done logging...



********** Iteration 480 ************

Collecting data for eval...
Eval_AverageReturn : 9.619047164916992
Eval_StdReturn : 0.7221786379814148
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.619047619047619
Train_AverageReturn : 9.383177757263184
Train_StdReturn : 0.7443853616714478
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.383177570093459
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 492033
TimeSinceStart : 398.9721591472626
Done logging...



********** Iteration 481 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.8012773990631104
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.411214828491211
Train_StdReturn : 0.7097883224487305
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.411214953271028
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 493040
TimeSinceStart : 399.6883029937744
Done logging...



********** Iteration 482 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.7782883644104004
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.296296119689941
Train_StdReturn : 0.8194314241409302
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.296296296296296
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 494044
TimeSinceStart : 400.40494656562805
Done logging...



********** Iteration 483 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.8136211633682251
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.462264060974121
Train_StdReturn : 0.6753689646720886
Train_MaxReturn : 10.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.462264150943396
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 495047
TimeSinceStart : 401.3643810749054
Done logging...



********** Iteration 484 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7564398050308228
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.373831748962402
Train_StdReturn : 0.7428584098815918
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.373831775700934
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 496050
TimeSinceStart : 402.3289968967438
Done logging...



********** Iteration 485 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.793428897857666
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.287036895751953
Train_StdReturn : 0.6945679187774658
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.287037037037036
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 497053
TimeSinceStart : 403.0609610080719
Done logging...



********** Iteration 486 ************

Collecting data for eval...
Eval_AverageReturn : 9.113636016845703
Eval_StdReturn : 0.8316442966461182
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.113636363636363
Train_AverageReturn : 9.373831748962402
Train_StdReturn : 0.8033034205436707
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.373831775700934
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 498056
TimeSinceStart : 403.7915506362915
Done logging...



********** Iteration 487 ************

Collecting data for eval...
Eval_AverageReturn : 9.136363983154297
Eval_StdReturn : 0.6938334703445435
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.136363636363637
Train_AverageReturn : 9.220183372497559
Train_StdReturn : 0.7585330605506897
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.220183486238533
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 499061
TimeSinceStart : 404.57631039619446
Done logging...



********** Iteration 488 ************

Collecting data for eval...
Eval_AverageReturn : 9.227272987365723
Eval_StdReturn : 0.669587254524231
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.227272727272727
Train_AverageReturn : 9.268518447875977
Train_StdReturn : 0.7888867259025574
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.268518518518519
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 500062
TimeSinceStart : 405.30921244621277
Done logging...



********** Iteration 489 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.798863410949707
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.268518447875977
Train_StdReturn : 0.6750374436378479
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.268518518518519
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 501063
TimeSinceStart : 406.4733259677887
Done logging...



********** Iteration 490 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.5292933583259583
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.172727584838867
Train_StdReturn : 0.7490489482879639
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.172727272727272
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 502072
TimeSinceStart : 407.18700909614563
Done logging...



********** Iteration 491 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.7303743958473206
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.7394407987594604
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 503073
TimeSinceStart : 408.24531626701355
Done logging...



********** Iteration 492 ************

Collecting data for eval...
Eval_AverageReturn : 9.227272987365723
Eval_StdReturn : 0.821960985660553
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.227272727272727
Train_AverageReturn : 9.259259223937988
Train_StdReturn : 0.7374929189682007
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.25925925925926
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 504073
TimeSinceStart : 408.9727463722229
Done logging...



********** Iteration 493 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 0.5832118391990662
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 9.45283031463623
Train_StdReturn : 0.7285559773445129
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.452830188679245
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 505075
TimeSinceStart : 409.6850891113281
Done logging...



********** Iteration 494 ************

Collecting data for eval...
Eval_AverageReturn : 9.295454978942871
Eval_StdReturn : 0.8140679597854614
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.295454545454545
Train_AverageReturn : 9.392523765563965
Train_StdReturn : 0.7202933430671692
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392523364485982
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 506080
TimeSinceStart : 410.39635825157166
Done logging...



********** Iteration 495 ************

Collecting data for eval...
Eval_AverageReturn : 9.204545021057129
Eval_StdReturn : 0.7561729550361633
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.204545454545455
Train_AverageReturn : 9.268518447875977
Train_StdReturn : 0.8120217323303223
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.268518518518519
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 507081
TimeSinceStart : 411.1036412715912
Done logging...



********** Iteration 496 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.7272788286209106
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.392523765563965
Train_StdReturn : 0.7704471349716187
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392523364485982
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 508086
TimeSinceStart : 411.8434522151947
Done logging...



********** Iteration 497 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.7228032350540161
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7900375127792358
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 509088
TimeSinceStart : 413.02024936676025
Done logging...



********** Iteration 498 ************

Collecting data for eval...
Eval_AverageReturn : 9.181818008422852
Eval_StdReturn : 0.7158189415931702
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.181818181818182
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7660130858421326
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 510090
TimeSinceStart : 413.74197578430176
Done logging...



********** Iteration 499 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.738349199295044
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.411214828491211
Train_StdReturn : 0.7228354215621948
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.411214953271028
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 511097
TimeSinceStart : 414.46223187446594
Done logging...


########################
logging outputs to  /home/jaehyun-jeong/UCBerkeley_cs285/hw2/cs285/scripts/../../data/q2_pg_cartpole_rtg_na_CartPole-v0_17-08-2024_01-25-37
########################
Using GPU id 0
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/envs/registration.py:593: UserWarning: [33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.[0m
  logger.warn(
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/core.py:317: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(

********** Iteration 0 ************
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):

Collecting data for eval...
Eval_AverageReturn : 9.136363983154297
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/tensorboardX/summary.py:153: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
  scalar = float(scalar)
Eval_StdReturn : 0.6938334703445435
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.136363636363637
Train_AverageReturn : 35.068965911865234
Train_StdReturn : 13.653169631958008
Train_MaxReturn : 70.0
Train_MinReturn : 20.0
Train_AverageEpLen : 35.06896551724138
Actor Loss : -0.050571441650390625
Train_EnvstepsSoFar : 1017
TimeSinceStart : 2.362539529800415
Initial_DataCollection_AverageReturn : 35.068965911865234
Done logging...



********** Iteration 1 ************

Collecting data for eval...
Eval_AverageReturn : 10.736842155456543
Eval_StdReturn : 1.1626695394515991
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.736842105263158
Train_AverageReturn : 9.420560836791992
Train_StdReturn : 0.7108949422836304
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.42056074766355
Actor Loss : -29.136428833007812
Train_EnvstepsSoFar : 2025
TimeSinceStart : 3.1402783393859863
Done logging...



********** Iteration 2 ************

Collecting data for eval...
Eval_AverageReturn : 10.815789222717285
Eval_StdReturn : 1.166534662246704
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.81578947368421
Train_AverageReturn : 10.967391014099121
Train_StdReturn : 1.3866684436798096
Train_MaxReturn : 14.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.967391304347826
Actor Loss : -70.74077606201172
Train_EnvstepsSoFar : 3034
TimeSinceStart : 4.86846661567688
Done logging...



********** Iteration 3 ************

Collecting data for eval...
Eval_AverageReturn : 10.410256385803223
Eval_StdReturn : 1.1028623580932617
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.41025641025641
Train_AverageReturn : 10.860215187072754
Train_StdReturn : 1.3082977533340454
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.86021505376344
Actor Loss : -99.18855285644531
Train_EnvstepsSoFar : 4044
TimeSinceStart : 6.0594446659088135
Done logging...



********** Iteration 4 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.8067178130149841
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 10.202020645141602
Train_StdReturn : 1.0538990497589111
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.202020202020202
Actor Loss : -143.45668029785156
Train_EnvstepsSoFar : 5054
TimeSinceStart : 6.827253818511963
Done logging...



********** Iteration 5 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.6165754795074463
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.411214828491211
Train_StdReturn : 0.8422629237174988
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.411214953271028
Actor Loss : -178.66888427734375
Train_EnvstepsSoFar : 6061
TimeSinceStart : 7.596916675567627
Done logging...



********** Iteration 6 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 0.7604151964187622
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 9.383177757263184
Train_StdReturn : 0.7568362951278687
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.383177570093459
Actor Loss : -178.08670043945312
Train_EnvstepsSoFar : 7065
TimeSinceStart : 8.378214359283447
Done logging...



********** Iteration 7 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.8689089417457581
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.44339656829834
Train_StdReturn : 0.7533596158027649
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.443396226415095
Actor Loss : -190.96542358398438
Train_EnvstepsSoFar : 8066
TimeSinceStart : 9.166273355484009
Done logging...



********** Iteration 8 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.8970838189125061
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.429906845092773
Train_StdReturn : 0.8550252914428711
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.429906542056075
Actor Loss : -208.33038330078125
Train_EnvstepsSoFar : 9075
TimeSinceStart : 9.931104898452759
Done logging...



********** Iteration 9 ************

Collecting data for eval...
Eval_AverageReturn : 9.756097793579102
Eval_StdReturn : 0.7895811796188354
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.75609756097561
Train_AverageReturn : 9.50943374633789
Train_StdReturn : 0.9239504933357239
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.50943396226415
Actor Loss : -214.83590698242188
Train_EnvstepsSoFar : 10083
TimeSinceStart : 10.690962314605713
Done logging...



********** Iteration 10 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.8908708691596985
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 9.852941513061523
Train_StdReturn : 0.889999508857727
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.852941176470589
Actor Loss : -213.92434692382812
Train_EnvstepsSoFar : 11088
TimeSinceStart : 11.469011545181274
Done logging...



********** Iteration 11 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.835710883140564
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 9.960395812988281
Train_StdReturn : 0.8665488958358765
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.96039603960396
Actor Loss : -215.9282684326172
Train_EnvstepsSoFar : 12094
TimeSinceStart : 12.251474380493164
Done logging...



********** Iteration 12 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.9120312929153442
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.663461685180664
Train_StdReturn : 0.861690878868103
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.663461538461538
Actor Loss : -216.46505737304688
Train_EnvstepsSoFar : 13099
TimeSinceStart : 13.031763553619385
Done logging...



********** Iteration 13 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.8391450643539429
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.552380561828613
Train_StdReturn : 0.8942243456840515
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.552380952380952
Actor Loss : -213.9815673828125
Train_EnvstepsSoFar : 14102
TimeSinceStart : 13.81183385848999
Done logging...



********** Iteration 14 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.7817551493644714
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.420560836791992
Train_StdReturn : 0.9072643518447876
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.42056074766355
Actor Loss : -206.63418579101562
Train_EnvstepsSoFar : 15110
TimeSinceStart : 14.588223934173584
Done logging...



********** Iteration 15 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.7741077542304993
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.561904907226562
Train_StdReturn : 0.8038455843925476
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.561904761904762
Actor Loss : -202.4996337890625
Train_EnvstepsSoFar : 16114
TimeSinceStart : 15.34481143951416
Done logging...



********** Iteration 16 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.9078707695007324
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.433961868286133
Train_StdReturn : 0.8469576239585876
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.433962264150944
Actor Loss : -198.4857635498047
Train_EnvstepsSoFar : 17114
TimeSinceStart : 16.10571551322937
Done logging...



********** Iteration 17 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.8970837593078613
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.45283031463623
Train_StdReturn : 0.9227939248085022
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.452830188679245
Actor Loss : -202.69786071777344
Train_EnvstepsSoFar : 18116
TimeSinceStart : 16.892780780792236
Done logging...



********** Iteration 18 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 0.9547589421272278
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 9.552380561828613
Train_StdReturn : 0.8835098147392273
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.552380952380952
Actor Loss : -209.45867919921875
Train_EnvstepsSoFar : 19119
TimeSinceStart : 17.66331672668457
Done logging...



********** Iteration 19 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.9855637550354004
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.571428298950195
Train_StdReturn : 0.9547589421272278
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.571428571428571
Actor Loss : -208.50384521484375
Train_EnvstepsSoFar : 20124
TimeSinceStart : 18.431241035461426
Done logging...



********** Iteration 20 ************

Collecting data for eval...
Eval_AverageReturn : 9.619047164916992
Eval_StdReturn : 0.9988656044006348
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.619047619047619
Train_AverageReturn : 9.615385055541992
Train_StdReturn : 0.9020029902458191
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.615384615384615
Actor Loss : -210.2278594970703
Train_EnvstepsSoFar : 21124
TimeSinceStart : 19.223957538604736
Done logging...



********** Iteration 21 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.9060142040252686
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.728155136108398
Train_StdReturn : 0.9158176183700562
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.728155339805825
Actor Loss : -213.63507080078125
Train_EnvstepsSoFar : 22126
TimeSinceStart : 20.004008054733276
Done logging...



********** Iteration 22 ************

Collecting data for eval...
Eval_AverageReturn : 9.87804889678955
Eval_StdReturn : 0.8022870421409607
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.878048780487806
Train_AverageReturn : 9.552380561828613
Train_StdReturn : 0.9152771830558777
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.552380952380952
Actor Loss : -213.89956665039062
Train_EnvstepsSoFar : 23129
TimeSinceStart : 20.790063858032227
Done logging...



********** Iteration 23 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.7885949611663818
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 9.65384578704834
Train_StdReturn : 0.9977785348892212
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.653846153846153
Actor Loss : -214.04348754882812
Train_EnvstepsSoFar : 24133
TimeSinceStart : 21.57381319999695
Done logging...



********** Iteration 24 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.8067178130149841
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 9.682692527770996
Train_StdReturn : 0.9015417098999023
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.682692307692308
Actor Loss : -217.04617309570312
Train_EnvstepsSoFar : 25140
TimeSinceStart : 22.367571115493774
Done logging...



********** Iteration 25 ************

Collecting data for eval...
Eval_AverageReturn : 9.829268455505371
Eval_StdReturn : 0.96024489402771
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.829268292682928
Train_AverageReturn : 9.84313678741455
Train_StdReturn : 0.9974977970123291
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.843137254901961
Actor Loss : -218.1302490234375
Train_EnvstepsSoFar : 26144
TimeSinceStart : 23.175199031829834
Done logging...



********** Iteration 26 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.917207658290863
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 9.708738327026367
Train_StdReturn : 0.9617041945457458
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.70873786407767
Actor Loss : -217.5282745361328
Train_EnvstepsSoFar : 27144
TimeSinceStart : 23.958492517471313
Done logging...



********** Iteration 27 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.8744936585426331
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 9.65384578704834
Train_StdReturn : 0.8177034854888916
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.653846153846153
Actor Loss : -220.7708740234375
Train_EnvstepsSoFar : 28148
TimeSinceStart : 24.757725954055786
Done logging...



********** Iteration 28 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.7886430025100708
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.590476036071777
Train_StdReturn : 0.824566125869751
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.59047619047619
Actor Loss : -222.64854431152344
Train_EnvstepsSoFar : 29155
TimeSinceStart : 25.545859575271606
Done logging...



********** Iteration 29 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.8436444997787476
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.600000381469727
Train_StdReturn : 0.9521904587745667
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.6
Actor Loss : -219.36370849609375
Train_EnvstepsSoFar : 30163
TimeSinceStart : 26.3396954536438
Done logging...



********** Iteration 30 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.7782883644104004
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.561904907226562
Train_StdReturn : 0.8156073093414307
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.561904761904762
Actor Loss : -220.13412475585938
Train_EnvstepsSoFar : 31167
TimeSinceStart : 27.134640216827393
Done logging...



********** Iteration 31 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.9078707098960876
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7900375723838806
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : -218.34678649902344
Train_EnvstepsSoFar : 32169
TimeSinceStart : 27.9585599899292
Done logging...



********** Iteration 32 ************

Collecting data for eval...
Eval_AverageReturn : 9.619047164916992
Eval_StdReturn : 0.8715716600418091
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.619047619047619
Train_AverageReturn : 9.333333015441895
Train_StdReturn : 0.8277591466903687
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.333333333333334
Actor Loss : -222.95538330078125
Train_EnvstepsSoFar : 33177
TimeSinceStart : 28.718559741973877
Done logging...



********** Iteration 33 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.8720154762268066
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.634614944458008
Train_StdReturn : 0.8210885524749756
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.634615384615385
Actor Loss : -227.46888732910156
Train_EnvstepsSoFar : 34179
TimeSinceStart : 29.509548664093018
Done logging...



********** Iteration 34 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.9060142040252686
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.383177757263184
Train_StdReturn : 0.8716174364089966
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.383177570093459
Actor Loss : -225.86964416503906
Train_EnvstepsSoFar : 35183
TimeSinceStart : 30.954009771347046
Done logging...



********** Iteration 35 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.8356716632843018
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.49056625366211
Train_StdReturn : 0.8382965326309204
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.49056603773585
Actor Loss : -227.6900634765625
Train_EnvstepsSoFar : 36189
TimeSinceStart : 31.747605562210083
Done logging...



********** Iteration 36 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 1.0168935060501099
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.40186882019043
Train_StdReturn : 0.7716932892799377
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.401869158878505
Actor Loss : -227.7732391357422
Train_EnvstepsSoFar : 37195
TimeSinceStart : 32.5573832988739
Done logging...



********** Iteration 37 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.8508365750312805
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 9.45283031463623
Train_StdReturn : 0.8370215892791748
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.452830188679245
Actor Loss : -229.3902587890625
Train_EnvstepsSoFar : 38197
TimeSinceStart : 33.30722212791443
Done logging...



********** Iteration 38 ************

Collecting data for eval...
Eval_AverageReturn : 9.756097793579102
Eval_StdReturn : 0.7251741290092468
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.75609756097561
Train_AverageReturn : 9.333333015441895
Train_StdReturn : 0.8606629371643066
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.333333333333334
Actor Loss : -230.50845336914062
Train_EnvstepsSoFar : 39205
TimeSinceStart : 34.090760469436646
Done logging...



********** Iteration 39 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.8793421983718872
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.600000381469727
Train_StdReturn : 0.8684962391853333
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.6
Actor Loss : -233.65176391601562
Train_EnvstepsSoFar : 40213
TimeSinceStart : 34.86750268936157
Done logging...



********** Iteration 40 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.7423856258392334
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.471697807312012
Train_StdReturn : 0.8600959777832031
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.471698113207546
Actor Loss : -231.9403076171875
Train_EnvstepsSoFar : 41217
TimeSinceStart : 35.66289973258972
Done logging...



********** Iteration 41 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.8508366346359253
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 9.433961868286133
Train_StdReturn : 0.8580239415168762
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.433962264150944
Actor Loss : -231.9039764404297
Train_EnvstepsSoFar : 42217
TimeSinceStart : 36.42895531654358
Done logging...



********** Iteration 42 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.8109579086303711
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.471697807312012
Train_StdReturn : 0.8265357613563538
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.471698113207546
Actor Loss : -235.01986694335938
Train_EnvstepsSoFar : 43221
TimeSinceStart : 37.21131753921509
Done logging...



********** Iteration 43 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.9486547112464905
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.247706413269043
Train_StdReturn : 0.8145010471343994
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.247706422018348
Actor Loss : -235.6738739013672
Train_EnvstepsSoFar : 44229
TimeSinceStart : 38.010661125183105
Done logging...



********** Iteration 44 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.7514183521270752
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.471697807312012
Train_StdReturn : 0.8150420188903809
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.471698113207546
Actor Loss : -237.05239868164062
Train_EnvstepsSoFar : 45233
TimeSinceStart : 38.77792239189148
Done logging...



********** Iteration 45 ************

Collecting data for eval...
Eval_AverageReturn : 9.159090995788574
Eval_StdReturn : 0.9031052589416504
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.159090909090908
Train_AverageReturn : 9.433961868286133
Train_StdReturn : 0.8128551840782166
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.433962264150944
Actor Loss : -237.66329956054688
Train_EnvstepsSoFar : 46233
TimeSinceStart : 39.595258951187134
Done logging...



********** Iteration 46 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.9678443074226379
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.49056625366211
Train_StdReturn : 0.8269662857055664
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.49056603773585
Actor Loss : -239.40750122070312
Train_EnvstepsSoFar : 47239
TimeSinceStart : 40.36102843284607
Done logging...



********** Iteration 47 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.8744936585426331
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 9.552380561828613
Train_StdReturn : 0.8278595805168152
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.552380952380952
Actor Loss : -241.48870849609375
Train_EnvstepsSoFar : 48242
TimeSinceStart : 41.139543533325195
Done logging...



********** Iteration 48 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.8234103322029114
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.65384578704834
Train_StdReturn : 0.8408926725387573
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.653846153846153
Actor Loss : -243.26162719726562
Train_EnvstepsSoFar : 49246
TimeSinceStart : 41.92159175872803
Done logging...



********** Iteration 49 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.7622767090797424
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 9.433961868286133
Train_StdReturn : 0.7525913715362549
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.433962264150944
Actor Loss : -242.02157592773438
Train_EnvstepsSoFar : 50246
TimeSinceStart : 42.68970513343811
Done logging...



********** Iteration 50 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.8468294739723206
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 9.49056625366211
Train_StdReturn : 0.8605097532272339
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.49056603773585
Actor Loss : -245.40191650390625
Train_EnvstepsSoFar : 51252
TimeSinceStart : 43.47042226791382
Done logging...



********** Iteration 51 ************

Collecting data for eval...
Eval_AverageReturn : 9.714285850524902
Eval_StdReturn : 0.9072647094726562
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.714285714285714
Train_AverageReturn : 9.523809432983398
Train_StdReturn : 0.8058741092681885
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.523809523809524
Actor Loss : -247.06024169921875
Train_EnvstepsSoFar : 52252
TimeSinceStart : 44.245248794555664
Done logging...



********** Iteration 52 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.9155822992324829
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.411214828491211
Train_StdReturn : 0.853286862373352
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.411214953271028
Actor Loss : -248.52096557617188
Train_EnvstepsSoFar : 53259
TimeSinceStart : 45.04627776145935
Done logging...



********** Iteration 53 ************

Collecting data for eval...
Eval_AverageReturn : 10.175000190734863
Eval_StdReturn : 0.7378177046775818
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.175
Train_AverageReturn : 9.45283031463623
Train_StdReturn : 0.8482175469398499
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.452830188679245
Actor Loss : -248.08566284179688
Train_EnvstepsSoFar : 54261
TimeSinceStart : 45.82930111885071
Done logging...



********** Iteration 54 ************

Collecting data for eval...
Eval_AverageReturn : 9.804878234863281
Eval_StdReturn : 0.889491856098175
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.804878048780488
Train_AverageReturn : 9.600000381469727
Train_StdReturn : 0.9913915395736694
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.6
Actor Loss : -249.7230224609375
Train_EnvstepsSoFar : 55269
TimeSinceStart : 46.62604308128357
Done logging...



********** Iteration 55 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.9773512482643127
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 10.0
Train_StdReturn : 0.8717797994613647
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.0
Actor Loss : -245.0854949951172
Train_EnvstepsSoFar : 56269
TimeSinceStart : 47.42822885513306
Done logging...



********** Iteration 56 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.7496556043624878
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.9196946024894714
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : -250.82167053222656
Train_EnvstepsSoFar : 57270
TimeSinceStart : 49.14535403251648
Done logging...



********** Iteration 57 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.9078707695007324
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.342592239379883
Train_StdReturn : 0.8069379925727844
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.342592592592593
Actor Loss : -254.72537231445312
Train_EnvstepsSoFar : 58279
TimeSinceStart : 49.90903615951538
Done logging...



********** Iteration 58 ************

Collecting data for eval...
Eval_AverageReturn : 9.714285850524902
Eval_StdReturn : 0.880630612373352
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.714285714285714
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.8231729865074158
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : -255.23208618164062
Train_EnvstepsSoFar : 59280
TimeSinceStart : 50.68088364601135
Done logging...



********** Iteration 59 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.9526785612106323
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 9.634614944458008
Train_StdReturn : 0.9308566451072693
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.634615384615385
Actor Loss : -255.4394989013672
Train_EnvstepsSoFar : 60282
TimeSinceStart : 51.46583843231201
Done logging...



********** Iteration 60 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.7453559637069702
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 9.590476036071777
Train_StdReturn : 0.891176164150238
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.59047619047619
Actor Loss : -258.43585205078125
Train_EnvstepsSoFar : 61289
TimeSinceStart : 52.242183446884155
Done logging...



********** Iteration 61 ************

Collecting data for eval...
Eval_AverageReturn : 9.136363983154297
Eval_StdReturn : 0.8684078454971313
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.136363636363637
Train_AverageReturn : 9.433961868286133
Train_StdReturn : 0.8580239415168762
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.433962264150944
Actor Loss : -258.94720458984375
Train_EnvstepsSoFar : 62289
TimeSinceStart : 52.99753189086914
Done logging...



********** Iteration 62 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 0.9614442586898804
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.6870271563529968
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : -263.5389404296875
Train_EnvstepsSoFar : 63290
TimeSinceStart : 53.731595516204834
Done logging...



********** Iteration 63 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.8744936585426331
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 9.833333015441895
Train_StdReturn : 0.981029212474823
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.833333333333334
Actor Loss : -253.55349731445312
Train_EnvstepsSoFar : 64293
TimeSinceStart : 54.50002312660217
Done logging...



********** Iteration 64 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.6428034901618958
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.757281303405762
Train_StdReturn : 0.8864243030548096
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.757281553398059
Actor Loss : -261.4909973144531
Train_EnvstepsSoFar : 65298
TimeSinceStart : 55.255637645721436
Done logging...



********** Iteration 65 ************

Collecting data for eval...
Eval_AverageReturn : 10.282051086425781
Eval_StdReturn : 0.9857630729675293
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.282051282051283
Train_AverageReturn : 9.296296119689941
Train_StdReturn : 0.7848007678985596
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.296296296296296
Actor Loss : -228.28030395507812
Train_EnvstepsSoFar : 66302
TimeSinceStart : 55.99949669837952
Done logging...



********** Iteration 66 ************

Collecting data for eval...
Eval_AverageReturn : 10.605262756347656
Eval_StdReturn : 1.0397236347198486
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.605263157894736
Train_AverageReturn : 9.970296859741211
Train_StdReturn : 1.0288457870483398
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.970297029702971
Actor Loss : -251.889892578125
Train_EnvstepsSoFar : 67309
TimeSinceStart : 56.77831768989563
Done logging...



********** Iteration 67 ************

Collecting data for eval...
Eval_AverageReturn : 10.6578950881958
Eval_StdReturn : 1.1068285703659058
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.657894736842104
Train_AverageReturn : 10.557894706726074
Train_StdReturn : 1.102301836013794
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.557894736842105
Actor Loss : -226.095458984375
Train_EnvstepsSoFar : 68312
TimeSinceStart : 57.540961265563965
Done logging...



********** Iteration 68 ************

Collecting data for eval...
Eval_AverageReturn : 10.684210777282715
Eval_StdReturn : 1.0539464950561523
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.68421052631579
Train_AverageReturn : 10.8804349899292
Train_StdReturn : 1.1310094594955444
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.880434782608695
Actor Loss : -220.31715393066406
Train_EnvstepsSoFar : 69313
TimeSinceStart : 58.318498849868774
Done logging...



********** Iteration 69 ************

Collecting data for eval...
Eval_AverageReturn : 10.050000190734863
Eval_StdReturn : 0.9733961224555969
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.05
Train_AverageReturn : 10.691489219665527
Train_StdReturn : 1.120662808418274
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.691489361702128
Actor Loss : -225.97406005859375
Train_EnvstepsSoFar : 70318
TimeSinceStart : 59.06951403617859
Done logging...



********** Iteration 70 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.6827868223190308
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.98019790649414
Train_StdReturn : 0.9645209908485413
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.98019801980198
Actor Loss : -248.29238891601562
Train_EnvstepsSoFar : 71326
TimeSinceStart : 59.819143533706665
Done logging...



********** Iteration 71 ************

Collecting data for eval...
Eval_AverageReturn : 10.175000190734863
Eval_StdReturn : 0.9188988208770752
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.175
Train_AverageReturn : 9.314814567565918
Train_StdReturn : 0.7775572538375854
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.314814814814815
Actor Loss : -257.53594970703125
Train_EnvstepsSoFar : 72332
TimeSinceStart : 60.58492112159729
Done logging...



********** Iteration 72 ************

Collecting data for eval...
Eval_AverageReturn : 10.149999618530273
Eval_StdReturn : 1.2757350206375122
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.15
Train_AverageReturn : 10.050000190734863
Train_StdReturn : 0.9420721530914307
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.05
Actor Loss : -256.20770263671875
Train_EnvstepsSoFar : 73337
TimeSinceStart : 61.3347852230072
Done logging...



********** Iteration 73 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.9219544529914856
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 10.050000190734863
Train_StdReturn : 0.9836158156394958
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.05
Actor Loss : -245.3483428955078
Train_EnvstepsSoFar : 74342
TimeSinceStart : 62.08686709403992
Done logging...



********** Iteration 74 ************

Collecting data for eval...
Eval_AverageReturn : 9.690476417541504
Eval_StdReturn : 0.8587946891784668
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.69047619047619
Train_AverageReturn : 10.0
Train_StdReturn : 1.1224972009658813
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.0
Actor Loss : -247.20904541015625
Train_EnvstepsSoFar : 75342
TimeSinceStart : 63.29395127296448
Done logging...



********** Iteration 75 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.711491048336029
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.615385055541992
Train_StdReturn : 0.9126008152961731
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.615384615384615
Actor Loss : -262.40838623046875
Train_EnvstepsSoFar : 76342
TimeSinceStart : 64.0561215877533
Done logging...



********** Iteration 76 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.8689089417457581
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.373831748962402
Train_StdReturn : 0.7428584098815918
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.373831775700934
Actor Loss : -237.46376037597656
Train_EnvstepsSoFar : 77345
TimeSinceStart : 64.80314016342163
Done logging...



********** Iteration 77 ************

Collecting data for eval...
Eval_AverageReturn : 9.87804889678955
Eval_StdReturn : 0.8609445095062256
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.878048780487806
Train_AverageReturn : 9.45283031463623
Train_StdReturn : 0.8701775074005127
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.452830188679245
Actor Loss : -266.75347900390625
Train_EnvstepsSoFar : 78347
TimeSinceStart : 65.56504321098328
Done logging...



********** Iteration 78 ************

Collecting data for eval...
Eval_AverageReturn : 9.92682933807373
Eval_StdReturn : 1.0214824676513672
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.926829268292684
Train_AverageReturn : 9.833333015441895
Train_StdReturn : 0.875408411026001
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.833333333333334
Actor Loss : -259.9693908691406
Train_EnvstepsSoFar : 79350
TimeSinceStart : 66.32507276535034
Done logging...



********** Iteration 79 ************

Collecting data for eval...
Eval_AverageReturn : 9.829268455505371
Eval_StdReturn : 0.96024489402771
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.829268292682928
Train_AverageReturn : 10.050000190734863
Train_StdReturn : 0.9937303066253662
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.05
Actor Loss : -254.768310546875
Train_EnvstepsSoFar : 80355
TimeSinceStart : 67.07420659065247
Done logging...



********** Iteration 80 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.7126966118812561
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 9.77669906616211
Train_StdReturn : 0.9546213150024414
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.776699029126213
Actor Loss : -257.362060546875
Train_EnvstepsSoFar : 81362
TimeSinceStart : 67.84009432792664
Done logging...



********** Iteration 81 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.738349199295044
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.65384578704834
Train_StdReturn : 0.9278721213340759
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.653846153846153
Actor Loss : -263.3014831542969
Train_EnvstepsSoFar : 82366
TimeSinceStart : 68.5825469493866
Done logging...



********** Iteration 82 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.835710883140564
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 9.342592239379883
Train_StdReturn : 0.7221629619598389
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.342592592592593
Actor Loss : -262.1531066894531
Train_EnvstepsSoFar : 83375
TimeSinceStart : 69.32929015159607
Done logging...



********** Iteration 83 ************

Collecting data for eval...
Eval_AverageReturn : 10.35897445678711
Eval_StdReturn : 1.024999976158142
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.35897435897436
Train_AverageReturn : 9.757281303405762
Train_StdReturn : 0.8298557996749878
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.757281553398059
Actor Loss : -263.5549011230469
Train_EnvstepsSoFar : 84380
TimeSinceStart : 70.08219027519226
Done logging...



********** Iteration 84 ************

Collecting data for eval...
Eval_AverageReturn : 10.100000381469727
Eval_StdReturn : 0.9695359468460083
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.1
Train_AverageReturn : 9.892156600952148
Train_StdReturn : 0.9487541317939758
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.892156862745098
Actor Loss : -254.4326171875
Train_EnvstepsSoFar : 85389
TimeSinceStart : 70.81423807144165
Done logging...



********** Iteration 85 ************

Collecting data for eval...
Eval_AverageReturn : 9.829268455505371
Eval_StdReturn : 0.9080248475074768
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.829268292682928
Train_AverageReturn : 9.892156600952148
Train_StdReturn : 0.9590319395065308
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.892156862745098
Actor Loss : -255.6841278076172
Train_EnvstepsSoFar : 86398
TimeSinceStart : 71.99736666679382
Done logging...



********** Iteration 86 ************

Collecting data for eval...
Eval_AverageReturn : 9.113636016845703
Eval_StdReturn : 0.7451634407043457
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.113636363636363
Train_AverageReturn : 9.872549057006836
Train_StdReturn : 0.9566237330436707
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.872549019607844
Actor Loss : -263.29400634765625
Train_EnvstepsSoFar : 87405
TimeSinceStart : 72.76470947265625
Done logging...



********** Iteration 87 ************

Collecting data for eval...
Eval_AverageReturn : 9.780488014221191
Eval_StdReturn : 0.9756097197532654
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.78048780487805
Train_AverageReturn : 9.314814567565918
Train_StdReturn : 0.8349778056144714
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.314814814814815
Actor Loss : -263.26580810546875
Train_EnvstepsSoFar : 88411
TimeSinceStart : 73.50948572158813
Done logging...



********** Iteration 88 ************

Collecting data for eval...
Eval_AverageReturn : 10.125
Eval_StdReturn : 0.871421217918396
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.125
Train_AverageReturn : 9.90099048614502
Train_StdReturn : 0.8384917378425598
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.900990099009901
Actor Loss : -265.2244873046875
Train_EnvstepsSoFar : 89411
TimeSinceStart : 74.26690077781677
Done logging...



********** Iteration 89 ************

Collecting data for eval...
Eval_AverageReturn : 9.853658676147461
Eval_StdReturn : 0.8133332133293152
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.853658536585366
Train_AverageReturn : 10.0
Train_StdReturn : 0.9647243618965149
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.0
Actor Loss : -260.9954528808594
Train_EnvstepsSoFar : 90421
TimeSinceStart : 75.0179009437561
Done logging...



********** Iteration 90 ************

Collecting data for eval...
Eval_AverageReturn : 9.756097793579102
Eval_StdReturn : 0.9571422338485718
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.75609756097561
Train_AverageReturn : 9.940593719482422
Train_StdReturn : 0.8767828941345215
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.94059405940594
Actor Loss : -262.8294677734375
Train_EnvstepsSoFar : 91425
TimeSinceStart : 75.76561856269836
Done logging...



********** Iteration 91 ************

Collecting data for eval...
Eval_AverageReturn : 9.181818008422852
Eval_StdReturn : 0.7158189415931702
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.181818181818182
Train_AverageReturn : 9.644230842590332
Train_StdReturn : 0.9084884524345398
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.64423076923077
Actor Loss : -267.2165222167969
Train_EnvstepsSoFar : 92428
TimeSinceStart : 76.51236248016357
Done logging...



********** Iteration 92 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.8062257766723633
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.7004983425140381
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : -265.4449462890625
Train_EnvstepsSoFar : 93429
TimeSinceStart : 77.27405381202698
Done logging...



********** Iteration 93 ************

Collecting data for eval...
Eval_AverageReturn : 10.25
Eval_StdReturn : 0.993730366230011
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.25
Train_AverageReturn : 9.682692527770996
Train_StdReturn : 0.9226261377334595
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.682692307692308
Actor Loss : -264.4188232421875
Train_EnvstepsSoFar : 94436
TimeSinceStart : 78.03581523895264
Done logging...



********** Iteration 94 ************

Collecting data for eval...
Eval_AverageReturn : 9.780488014221191
Eval_StdReturn : 1.047929286956787
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.78048780487805
Train_AverageReturn : 10.050000190734863
Train_StdReturn : 1.1079260110855103
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.05
Actor Loss : -252.30996704101562
Train_EnvstepsSoFar : 95441
TimeSinceStart : 78.78554558753967
Done logging...



********** Iteration 95 ************

Collecting data for eval...
Eval_AverageReturn : 9.92682933807373
Eval_StdReturn : 0.7454003095626831
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.926829268292684
Train_AverageReturn : 10.11111068725586
Train_StdReturn : 0.9628333449363708
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.11111111111111
Actor Loss : -254.88467407226562
Train_EnvstepsSoFar : 96442
TimeSinceStart : 79.5417115688324
Done logging...



********** Iteration 96 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.8156129717826843
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.872549057006836
Train_StdReturn : 0.9253677129745483
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.872549019607844
Actor Loss : -266.0434875488281
Train_EnvstepsSoFar : 97449
TimeSinceStart : 80.30735063552856
Done logging...



********** Iteration 97 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.8320252895355225
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.345794677734375
Train_StdReturn : 0.7375484704971313
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.345794392523365
Actor Loss : -273.5133361816406
Train_EnvstepsSoFar : 98449
TimeSinceStart : 81.07452392578125
Done logging...



********** Iteration 98 ************

Collecting data for eval...
Eval_AverageReturn : 9.756097793579102
Eval_StdReturn : 0.7895811796188354
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 9.75609756097561
Train_AverageReturn : 9.433961868286133
Train_StdReturn : 0.7893019318580627
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.433962264150944
Actor Loss : -255.98812866210938
Train_EnvstepsSoFar : 99449
TimeSinceStart : 81.83301663398743
Done logging...



********** Iteration 99 ************

Collecting data for eval...
Eval_AverageReturn : 10.050000190734863
Eval_StdReturn : 0.9733961224555969
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.05
Train_AverageReturn : 9.872549057006836
Train_StdReturn : 0.812543511390686
Train_MaxReturn : 11.0
Train_MinReturn : 9.0
Train_AverageEpLen : 9.872549019607844
Actor Loss : -270.16387939453125
Train_EnvstepsSoFar : 100456
TimeSinceStart : 82.58322358131409
Done logging...



********** Iteration 100 ************

Collecting data for eval...
Eval_AverageReturn : 10.149999618530273
Eval_StdReturn : 0.9886859655380249
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.15
Train_AverageReturn : 10.171717643737793
Train_StdReturn : 1.0828357934951782
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.171717171717171
Actor Loss : -257.768310546875
Train_EnvstepsSoFar : 101463
TimeSinceStart : 83.35352396965027
Done logging...



********** Iteration 101 ************

Collecting data for eval...
Eval_AverageReturn : 9.90243911743164
Eval_StdReturn : 0.9054005146026611
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.902439024390244
Train_AverageReturn : 10.069999694824219
Train_StdReturn : 1.0512373447418213
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.07
Actor Loss : -258.6441345214844
Train_EnvstepsSoFar : 102470
TimeSinceStart : 84.10666942596436
Done logging...



********** Iteration 102 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.8391450047492981
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.786407470703125
Train_StdReturn : 0.8774466514587402
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.78640776699029
Actor Loss : -269.49566650390625
Train_EnvstepsSoFar : 103478
TimeSinceStart : 84.8491325378418
Done logging...



********** Iteration 103 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.8908708691596985
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 9.44339656829834
Train_StdReturn : 0.7780016660690308
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.443396226415095
Actor Loss : -266.5164794921875
Train_EnvstepsSoFar : 104479
TimeSinceStart : 85.5926194190979
Done logging...



********** Iteration 104 ************

Collecting data for eval...
Eval_AverageReturn : 10.175000190734863
Eval_StdReturn : 0.9188987612724304
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.175
Train_AverageReturn : 9.625
Train_StdReturn : 0.8226072788238525
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.625
Actor Loss : -269.60650634765625
Train_EnvstepsSoFar : 105480
TimeSinceStart : 86.3467800617218
Done logging...



********** Iteration 105 ************

Collecting data for eval...
Eval_AverageReturn : 9.780488014221191
Eval_StdReturn : 0.9242583513259888
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.78048780487805
Train_AverageReturn : 9.86274528503418
Train_StdReturn : 0.9603841304779053
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.862745098039216
Actor Loss : -265.1566162109375
Train_EnvstepsSoFar : 106486
TimeSinceStart : 87.10044312477112
Done logging...



********** Iteration 106 ************

Collecting data for eval...
Eval_AverageReturn : 9.92682933807373
Eval_StdReturn : 0.8941611051559448
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.926829268292684
Train_AverageReturn : 9.813725471496582
Train_StdReturn : 0.8601230978965759
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.813725490196079
Actor Loss : -267.2650451660156
Train_EnvstepsSoFar : 107487
TimeSinceStart : 87.86900615692139
Done logging...



********** Iteration 107 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.7845175862312317
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.625
Train_StdReturn : 0.8569568395614624
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.625
Actor Loss : -272.4071350097656
Train_EnvstepsSoFar : 108488
TimeSinceStart : 88.62469410896301
Done logging...



********** Iteration 108 ************

Collecting data for eval...
Eval_AverageReturn : 9.853658676147461
Eval_StdReturn : 0.7827710509300232
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.853658536585366
Train_AverageReturn : 9.268518447875977
Train_StdReturn : 0.7019348740577698
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.268518518518519
Actor Loss : -263.1187744140625
Train_EnvstepsSoFar : 109489
TimeSinceStart : 89.38218593597412
Done logging...



********** Iteration 109 ************

Collecting data for eval...
Eval_AverageReturn : 10.074999809265137
Eval_StdReturn : 0.9051933884620667
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.075
Train_AverageReturn : 9.823529243469238
Train_StdReturn : 0.8790788650512695
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.823529411764707
Actor Loss : -272.64166259765625
Train_EnvstepsSoFar : 110491
TimeSinceStart : 90.13803577423096
Done logging...



********** Iteration 110 ************

Collecting data for eval...
Eval_AverageReturn : 9.714285850524902
Eval_StdReturn : 0.8247861266136169
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.714285714285714
Train_AverageReturn : 9.882352828979492
Train_StdReturn : 0.931939959526062
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.882352941176471
Actor Loss : -267.9715576171875
Train_EnvstepsSoFar : 111499
TimeSinceStart : 91.11652421951294
Done logging...



********** Iteration 111 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 0.8491692543029785
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 9.920791625976562
Train_StdReturn : 0.9085203409194946
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.92079207920792
Actor Loss : -267.049072265625
Train_EnvstepsSoFar : 112501
TimeSinceStart : 91.87272000312805
Done logging...



********** Iteration 112 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.719804048538208
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.625
Train_StdReturn : 0.8108341097831726
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.625
Actor Loss : -272.6830749511719
Train_EnvstepsSoFar : 113502
TimeSinceStart : 92.61390948295593
Done logging...



********** Iteration 113 ************

Collecting data for eval...
Eval_AverageReturn : 9.780488014221191
Eval_StdReturn : 0.8974814414978027
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.78048780487805
Train_AverageReturn : 9.383177757263184
Train_StdReturn : 0.7690856456756592
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.383177570093459
Actor Loss : -268.9105224609375
Train_EnvstepsSoFar : 114506
TimeSinceStart : 93.35886073112488
Done logging...



********** Iteration 114 ************

Collecting data for eval...
Eval_AverageReturn : 10.282051086425781
Eval_StdReturn : 1.0364811420440674
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.282051282051283
Train_AverageReturn : 9.86274528503418
Train_StdReturn : 0.8860489130020142
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.862745098039216
Actor Loss : -270.9515380859375
Train_EnvstepsSoFar : 115512
TimeSinceStart : 94.09619092941284
Done logging...



********** Iteration 115 ************

Collecting data for eval...
Eval_AverageReturn : 9.97560977935791
Eval_StdReturn : 0.9749997854232788
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.975609756097562
Train_AverageReturn : 10.020000457763672
Train_StdReturn : 0.9997999668121338
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.02
Actor Loss : -260.2259826660156
Train_EnvstepsSoFar : 116514
TimeSinceStart : 94.86773991584778
Done logging...



********** Iteration 116 ************

Collecting data for eval...
Eval_AverageReturn : 9.92682933807373
Eval_StdReturn : 0.7119277715682983
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 9.926829268292684
Train_AverageReturn : 9.91089153289795
Train_StdReturn : 0.9344772696495056
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.910891089108912
Actor Loss : -261.43121337890625
Train_EnvstepsSoFar : 117515
TimeSinceStart : 95.62835097312927
Done logging...



********** Iteration 117 ************

Collecting data for eval...
Eval_AverageReturn : 9.204545021057129
Eval_StdReturn : 0.7561728954315186
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.204545454545455
Train_AverageReturn : 9.872549057006836
Train_StdReturn : 0.824521005153656
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.872549019607844
Actor Loss : -272.33660888671875
Train_EnvstepsSoFar : 118522
TimeSinceStart : 96.39138317108154
Done logging...



********** Iteration 118 ************

Collecting data for eval...
Eval_AverageReturn : 10.074999809265137
Eval_StdReturn : 0.87714022397995
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.075
Train_AverageReturn : 9.314814567565918
Train_StdReturn : 0.7775571942329407
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.314814814814815
Actor Loss : -274.0935974121094
Train_EnvstepsSoFar : 119528
TimeSinceStart : 97.14159655570984
Done logging...



********** Iteration 119 ************

Collecting data for eval...
Eval_AverageReturn : 10.384614944458008
Eval_StdReturn : 0.8657406568527222
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.384615384615385
Train_AverageReturn : 9.803921699523926
Train_StdReturn : 1.0003843307495117
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.803921568627452
Actor Loss : -268.0302429199219
Train_EnvstepsSoFar : 120528
TimeSinceStart : 97.90593910217285
Done logging...



********** Iteration 120 ************

Collecting data for eval...
Eval_AverageReturn : 10.199999809265137
Eval_StdReturn : 0.8717797994613647
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.2
Train_AverageReturn : 9.940593719482422
Train_StdReturn : 1.0974478721618652
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.94059405940594
Actor Loss : -260.9794006347656
Train_EnvstepsSoFar : 121532
TimeSinceStart : 98.6610996723175
Done logging...



********** Iteration 121 ************

Collecting data for eval...
Eval_AverageReturn : 9.829268455505371
Eval_StdReturn : 0.8526126146316528
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.829268292682928
Train_AverageReturn : 9.803921699523926
Train_StdReturn : 1.0003843307495117
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.803921568627452
Actor Loss : -262.8577880859375
Train_EnvstepsSoFar : 122532
TimeSinceStart : 99.41497945785522
Done logging...



********** Iteration 122 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.8952733874320984
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.99009895324707
Train_StdReturn : 0.88435298204422
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.990099009900991
Actor Loss : -275.67828369140625
Train_EnvstepsSoFar : 123541
TimeSinceStart : 100.44923734664917
Done logging...



********** Iteration 123 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.9060142040252686
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.392523765563965
Train_StdReturn : 0.7704471349716187
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392523364485982
Actor Loss : -265.3512268066406
Train_EnvstepsSoFar : 124546
TimeSinceStart : 101.98612880706787
Done logging...



********** Iteration 124 ************

Collecting data for eval...
Eval_AverageReturn : 9.87804889678955
Eval_StdReturn : 0.771287202835083
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 9.878048780487806
Train_AverageReturn : 9.708738327026367
Train_StdReturn : 0.8882300853729248
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.70873786407767
Actor Loss : -276.53399658203125
Train_EnvstepsSoFar : 125546
TimeSinceStart : 102.8708438873291
Done logging...



********** Iteration 125 ************

Collecting data for eval...
Eval_AverageReturn : 9.90243911743164
Eval_StdReturn : 0.849817156791687
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.902439024390244
Train_AverageReturn : 9.786407470703125
Train_StdReturn : 0.9100357294082642
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.78640776699029
Actor Loss : -273.596435546875
Train_EnvstepsSoFar : 126554
TimeSinceStart : 104.03130888938904
Done logging...



********** Iteration 126 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.787956953048706
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.718446731567383
Train_StdReturn : 0.7933887243270874
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.718446601941748
Actor Loss : -274.00445556640625
Train_EnvstepsSoFar : 127555
TimeSinceStart : 104.97062873840332
Done logging...



********** Iteration 127 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.6982323527336121
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.481132507324219
Train_StdReturn : 0.7798298597335815
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.481132075471699
Actor Loss : -279.9599304199219
Train_EnvstepsSoFar : 128560
TimeSinceStart : 105.98306179046631
Done logging...



********** Iteration 128 ************

Collecting data for eval...
Eval_AverageReturn : 9.756097793579102
Eval_StdReturn : 0.8198896050453186
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.75609756097561
Train_AverageReturn : 9.324073791503906
Train_StdReturn : 0.7797044515609741
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.324074074074074
Actor Loss : -266.6127624511719
Train_EnvstepsSoFar : 129567
TimeSinceStart : 106.82117652893066
Done logging...



********** Iteration 129 ************

Collecting data for eval...
Eval_AverageReturn : 9.853658676147461
Eval_StdReturn : 1.072061538696289
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.853658536585366
Train_AverageReturn : 9.73786449432373
Train_StdReturn : 0.8697858452796936
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.737864077669903
Actor Loss : -274.3968811035156
Train_EnvstepsSoFar : 130570
TimeSinceStart : 107.55716395378113
Done logging...



********** Iteration 130 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.9486832618713379
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 10.27550983428955
Train_StdReturn : 1.0476466417312622
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.275510204081632
Actor Loss : -264.88043212890625
Train_EnvstepsSoFar : 131577
TimeSinceStart : 109.06341099739075
Done logging...



********** Iteration 131 ************

Collecting data for eval...
Eval_AverageReturn : 9.756097793579102
Eval_StdReturn : 0.931311309337616
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.75609756097561
Train_AverageReturn : 10.13131332397461
Train_StdReturn : 0.9707486033439636
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.131313131313131
Actor Loss : -265.84283447265625
Train_EnvstepsSoFar : 132580
TimeSinceStart : 110.03739929199219
Done logging...



********** Iteration 132 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7250445485115051
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.77669906616211
Train_StdReturn : 0.8235849738121033
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.776699029126213
Actor Loss : -276.960205078125
Train_EnvstepsSoFar : 133587
TimeSinceStart : 111.00824856758118
Done logging...



********** Iteration 133 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.8468294739723206
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 9.462264060974121
Train_StdReturn : 0.7291054725646973
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.462264150943396
Actor Loss : -268.1346435546875
Train_EnvstepsSoFar : 134590
TimeSinceStart : 111.94037365913391
Done logging...



********** Iteration 134 ************

Collecting data for eval...
Eval_AverageReturn : 9.87804889678955
Eval_StdReturn : 0.942107617855072
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.878048780487806
Train_AverageReturn : 9.682692527770996
Train_StdReturn : 0.8465362191200256
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.682692307692308
Actor Loss : -279.1041259765625
Train_EnvstepsSoFar : 135597
TimeSinceStart : 112.74980401992798
Done logging...



********** Iteration 135 ************

Collecting data for eval...
Eval_AverageReturn : 9.97560977935791
Eval_StdReturn : 0.8111360669136047
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 9.975609756097562
Train_AverageReturn : 9.940593719482422
Train_StdReturn : 0.842224657535553
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.94059405940594
Actor Loss : -275.67694091796875
Train_EnvstepsSoFar : 136601
TimeSinceStart : 114.32712626457214
Done logging...



********** Iteration 136 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.6827868223190308
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.882352828979492
Train_StdReturn : 0.843593180179596
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.882352941176471
Actor Loss : -277.4058837890625
Train_EnvstepsSoFar : 137609
TimeSinceStart : 115.79793643951416
Done logging...



********** Iteration 137 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.9219544529914856
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 9.324073791503906
Train_StdReturn : 0.6780787110328674
Train_MaxReturn : 10.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.324074074074074
Actor Loss : -282.7479248046875
Train_EnvstepsSoFar : 138616
TimeSinceStart : 117.41009855270386
Done logging...



********** Iteration 138 ************

Collecting data for eval...
Eval_AverageReturn : 10.149999618530273
Eval_StdReturn : 0.9886859655380249
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.15
Train_AverageReturn : 10.0600004196167
Train_StdReturn : 0.9361623525619507
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.06
Actor Loss : -274.0504150390625
Train_EnvstepsSoFar : 139622
TimeSinceStart : 118.68984866142273
Done logging...



********** Iteration 139 ************

Collecting data for eval...
Eval_AverageReturn : 9.642857551574707
Eval_StdReturn : 0.8949974179267883
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.642857142857142
Train_AverageReturn : 9.91089153289795
Train_StdReturn : 0.9657399654388428
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.910891089108912
Actor Loss : -270.61102294921875
Train_EnvstepsSoFar : 140623
TimeSinceStart : 120.09527015686035
Done logging...



********** Iteration 140 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7564398050308228
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.625
Train_StdReturn : 0.8791112303733826
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.625
Actor Loss : -278.33599853515625
Train_EnvstepsSoFar : 141624
TimeSinceStart : 121.50595688819885
Done logging...



********** Iteration 141 ************

Collecting data for eval...
Eval_AverageReturn : 9.642857551574707
Eval_StdReturn : 0.8679869174957275
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.642857142857142
Train_AverageReturn : 9.40186882019043
Train_StdReturn : 0.7470792531967163
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.401869158878505
Actor Loss : -266.1585388183594
Train_EnvstepsSoFar : 142630
TimeSinceStart : 123.00582480430603
Done logging...



********** Iteration 142 ************

Collecting data for eval...
Eval_AverageReturn : 9.853658676147461
Eval_StdReturn : 0.8712473511695862
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.853658536585366
Train_AverageReturn : 9.552380561828613
Train_StdReturn : 0.9048120379447937
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.552380952380952
Actor Loss : -278.4134826660156
Train_EnvstepsSoFar : 143633
TimeSinceStart : 124.50826048851013
Done logging...



********** Iteration 143 ************

Collecting data for eval...
Eval_AverageReturn : 9.714285850524902
Eval_StdReturn : 0.7953949570655823
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 9.714285714285714
Train_AverageReturn : 10.0600004196167
Train_StdReturn : 0.8811357021331787
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.06
Actor Loss : -275.7616882324219
Train_EnvstepsSoFar : 144639
TimeSinceStart : 125.92465424537659
Done logging...



********** Iteration 144 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.6519927978515625
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.757281303405762
Train_StdReturn : 0.8642413020133972
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.757281553398059
Actor Loss : -277.951416015625
Train_EnvstepsSoFar : 145644
TimeSinceStart : 127.41628408432007
Done logging...



********** Iteration 145 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 1.140175461769104
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 9.333333015441895
Train_StdReturn : 0.745356023311615
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.333333333333334
Actor Loss : -280.660888671875
Train_EnvstepsSoFar : 146652
TimeSinceStart : 128.8344783782959
Done logging...



********** Iteration 146 ************

Collecting data for eval...
Eval_AverageReturn : 10.274999618530273
Eval_StdReturn : 1.0243901014328003
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.275
Train_AverageReturn : 10.329896926879883
Train_StdReturn : 1.0524556636810303
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.329896907216495
Actor Loss : -266.29974365234375
Train_EnvstepsSoFar : 147654
TimeSinceStart : 130.20470356941223
Done logging...



********** Iteration 147 ************

Collecting data for eval...
Eval_AverageReturn : 10.256410598754883
Eval_StdReturn : 0.9259215593338013
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.256410256410257
Train_AverageReturn : 10.27550983428955
Train_StdReturn : 0.9452417492866516
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.275510204081632
Actor Loss : -264.6754150390625
Train_EnvstepsSoFar : 148661
TimeSinceStart : 131.27616572380066
Done logging...



********** Iteration 148 ************

Collecting data for eval...
Eval_AverageReturn : 9.95121955871582
Eval_StdReturn : 0.8249529004096985
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.951219512195122
Train_AverageReturn : 10.46875
Train_StdReturn : 0.9236829280853271
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.46875
Actor Loss : -265.79205322265625
Train_EnvstepsSoFar : 149666
TimeSinceStart : 132.19994735717773
Done logging...



********** Iteration 149 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.8012773990631104
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 10.0
Train_StdReturn : 0.9165151119232178
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.0
Actor Loss : -275.11279296875
Train_EnvstepsSoFar : 150666
TimeSinceStart : 133.03437161445618
Done logging...



********** Iteration 150 ************

Collecting data for eval...
Eval_AverageReturn : 9.619047164916992
Eval_StdReturn : 0.8715716600418091
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.619047619047619
Train_AverageReturn : 9.333333015441895
Train_StdReturn : 0.7576767206192017
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.333333333333334
Actor Loss : -269.1849670410156
Train_EnvstepsSoFar : 151674
TimeSinceStart : 133.9211404323578
Done logging...



********** Iteration 151 ************

Collecting data for eval...
Eval_AverageReturn : 10.199999809265137
Eval_StdReturn : 1.0049875974655151
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.2
Train_AverageReturn : 9.590476036071777
Train_StdReturn : 0.6574878096580505
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.59047619047619
Actor Loss : -285.55352783203125
Train_EnvstepsSoFar : 152681
TimeSinceStart : 134.75384950637817
Done logging...



********** Iteration 152 ************

Collecting data for eval...
Eval_AverageReturn : 10.282051086425781
Eval_StdReturn : 1.0364811420440674
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.282051282051283
Train_AverageReturn : 10.0
Train_StdReturn : 0.9273618459701538
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.0
Actor Loss : -270.64166259765625
Train_EnvstepsSoFar : 153681
TimeSinceStart : 135.5720317363739
Done logging...



********** Iteration 153 ************

Collecting data for eval...
Eval_AverageReturn : 9.90243911743164
Eval_StdReturn : 0.9319498538970947
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.902439024390244
Train_AverageReturn : 10.079999923706055
Train_StdReturn : 1.1106754541397095
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.08
Actor Loss : -267.79742431640625
Train_EnvstepsSoFar : 154689
TimeSinceStart : 136.62968015670776
Done logging...



********** Iteration 154 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.716037392616272
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.940593719482422
Train_StdReturn : 0.8880035877227783
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.94059405940594
Actor Loss : -276.91845703125
Train_EnvstepsSoFar : 155693
TimeSinceStart : 137.52670669555664
Done logging...



********** Iteration 155 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 0.8799858689308167
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 9.314814567565918
Train_StdReturn : 0.7024843096733093
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.314814814814815
Actor Loss : -277.9729919433594
Train_EnvstepsSoFar : 156699
TimeSinceStart : 138.5697145462036
Done logging...



********** Iteration 156 ************

Collecting data for eval...
Eval_AverageReturn : 10.225000381469727
Eval_StdReturn : 0.8511021733283997
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.225
Train_AverageReturn : 9.950494766235352
Train_StdReturn : 0.958301305770874
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.950495049504951
Actor Loss : -273.9658508300781
Train_EnvstepsSoFar : 157704
TimeSinceStart : 139.59859037399292
Done logging...



********** Iteration 157 ************

Collecting data for eval...
Eval_AverageReturn : 10.175000190734863
Eval_StdReturn : 0.8627716898918152
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.175
Train_AverageReturn : 10.079999923706055
Train_StdReturn : 1.1016350984573364
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.08
Actor Loss : -268.01611328125
Train_EnvstepsSoFar : 158712
TimeSinceStart : 140.68409752845764
Done logging...



********** Iteration 158 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7865830063819885
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 10.020000457763672
Train_StdReturn : 0.9897473454475403
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.02
Actor Loss : -271.5604248046875
Train_EnvstepsSoFar : 159714
TimeSinceStart : 141.54585003852844
Done logging...



********** Iteration 159 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.787956953048706
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.682692527770996
Train_StdReturn : 0.8351004719734192
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.682692307692308
Actor Loss : -283.65130615234375
Train_EnvstepsSoFar : 160721
TimeSinceStart : 142.4289836883545
Done logging...



********** Iteration 160 ************

Collecting data for eval...
Eval_AverageReturn : 9.690476417541504
Eval_StdReturn : 0.8014301061630249
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.69047619047619
Train_AverageReturn : 9.345794677734375
Train_StdReturn : 0.7247662544250488
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.345794392523365
Actor Loss : -269.64794921875
Train_EnvstepsSoFar : 161721
TimeSinceStart : 143.4469633102417
Done logging...



********** Iteration 161 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 0.8799858689308167
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 9.901960372924805
Train_StdReturn : 0.7984029054641724
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.901960784313726
Actor Loss : -282.08343505859375
Train_EnvstepsSoFar : 162731
TimeSinceStart : 144.45305252075195
Done logging...



********** Iteration 162 ************

Collecting data for eval...
Eval_AverageReturn : 10.256410598754883
Eval_StdReturn : 0.9259215593338013
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.256410256410257
Train_AverageReturn : 10.171717643737793
Train_StdReturn : 0.932471513748169
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.171717171717171
Actor Loss : -271.6378173828125
Train_EnvstepsSoFar : 163738
TimeSinceStart : 145.38695764541626
Done logging...



********** Iteration 163 ************

Collecting data for eval...
Eval_AverageReturn : 9.756097793579102
Eval_StdReturn : 0.8773710131645203
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.75609756097561
Train_AverageReturn : 10.255102157592773
Train_StdReturn : 0.9721764326095581
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.255102040816327
Actor Loss : -270.0104675292969
Train_EnvstepsSoFar : 164743
TimeSinceStart : 146.44618010520935
Done logging...



********** Iteration 164 ************

Collecting data for eval...
Eval_AverageReturn : 9.159090995788574
Eval_StdReturn : 0.7367984652519226
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.159090909090908
Train_AverageReturn : 9.90099048614502
Train_StdReturn : 0.9281617999076843
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.900990099009901
Actor Loss : -276.24896240234375
Train_EnvstepsSoFar : 165743
TimeSinceStart : 147.5221939086914
Done logging...



********** Iteration 165 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.8660253882408142
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 9.314814567565918
Train_StdReturn : 0.7409721612930298
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.314814814814815
Actor Loss : -276.1484375
Train_EnvstepsSoFar : 166749
TimeSinceStart : 148.35187005996704
Done logging...



********** Iteration 166 ************

Collecting data for eval...
Eval_AverageReturn : 10.050000190734863
Eval_StdReturn : 1.0712143182754517
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.05
Train_AverageReturn : 9.920791625976562
Train_StdReturn : 0.9193536639213562
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.92079207920792
Actor Loss : -277.8326416015625
Train_EnvstepsSoFar : 167751
TimeSinceStart : 149.42500638961792
Done logging...



********** Iteration 167 ************

Collecting data for eval...
Eval_AverageReturn : 10.074999809265137
Eval_StdReturn : 1.0096410512924194
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.075
Train_AverageReturn : 10.010000228881836
Train_StdReturn : 0.953886866569519
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.01
Actor Loss : -273.04345703125
Train_EnvstepsSoFar : 168752
TimeSinceStart : 150.34458136558533
Done logging...



********** Iteration 168 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.7478109002113342
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.803921699523926
Train_StdReturn : 0.9292545318603516
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.803921568627452
Actor Loss : -277.10479736328125
Train_EnvstepsSoFar : 169752
TimeSinceStart : 151.32385683059692
Done logging...



********** Iteration 169 ************

Collecting data for eval...
Eval_AverageReturn : 10.125
Eval_StdReturn : 0.9536115527153015
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.125
Train_AverageReturn : 9.296296119689941
Train_StdReturn : 0.7360965609550476
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.296296296296296
Actor Loss : -281.54803466796875
Train_EnvstepsSoFar : 170756
TimeSinceStart : 152.25207352638245
Done logging...



********** Iteration 170 ************

Collecting data for eval...
Eval_AverageReturn : 10.282051086425781
Eval_StdReturn : 1.0114401578903198
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.282051282051283
Train_AverageReturn : 10.161616325378418
Train_StdReturn : 1.031886339187622
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.16161616161616
Actor Loss : -271.868896484375
Train_EnvstepsSoFar : 171762
TimeSinceStart : 153.32577204704285
Done logging...



********** Iteration 171 ************

Collecting data for eval...
Eval_AverageReturn : 10.282051086425781
Eval_StdReturn : 1.0114401578903198
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.282051282051283
Train_AverageReturn : 10.181818008422852
Train_StdReturn : 1.0186506509780884
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.181818181818182
Actor Loss : -266.7238464355469
Train_EnvstepsSoFar : 172770
TimeSinceStart : 154.30575108528137
Done logging...



********** Iteration 172 ************

Collecting data for eval...
Eval_AverageReturn : 9.853658676147461
Eval_StdReturn : 0.9515321254730225
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.853658536585366
Train_AverageReturn : 10.27550983428955
Train_StdReturn : 1.0476466417312622
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.275510204081632
Actor Loss : -267.1310729980469
Train_EnvstepsSoFar : 173777
TimeSinceStart : 155.24197554588318
Done logging...



********** Iteration 173 ************

Collecting data for eval...
Eval_AverageReturn : 9.113636016845703
Eval_StdReturn : 0.6814392805099487
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.113636363636363
Train_AverageReturn : 9.882352828979492
Train_StdReturn : 1.0126079320907593
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.882352941176471
Actor Loss : -273.3834228515625
Train_EnvstepsSoFar : 174785
TimeSinceStart : 156.33611583709717
Done logging...



********** Iteration 174 ************

Collecting data for eval...
Eval_AverageReturn : 10.225000381469727
Eval_StdReturn : 0.9350802302360535
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.225
Train_AverageReturn : 9.45283031463623
Train_StdReturn : 0.7540091276168823
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.452830188679245
Actor Loss : -281.3341979980469
Train_EnvstepsSoFar : 175787
TimeSinceStart : 157.3132688999176
Done logging...



********** Iteration 175 ************

Collecting data for eval...
Eval_AverageReturn : 10.175000190734863
Eval_StdReturn : 0.8912771344184875
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.175
Train_AverageReturn : 9.960395812988281
Train_StdReturn : 0.9111064076423645
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.96039603960396
Actor Loss : -278.27734375
Train_EnvstepsSoFar : 176793
TimeSinceStart : 158.16924023628235
Done logging...



********** Iteration 176 ************

Collecting data for eval...
Eval_AverageReturn : 9.95121955871582
Eval_StdReturn : 0.8821044564247131
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.951219512195122
Train_AverageReturn : 10.079999923706055
Train_StdReturn : 1.0067769289016724
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.08
Actor Loss : -275.769775390625
Train_EnvstepsSoFar : 177801
TimeSinceStart : 159.2715699672699
Done logging...



********** Iteration 177 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.5762563943862915
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 10.020000457763672
Train_StdReturn : 0.8715503215789795
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.02
Actor Loss : -281.453369140625
Train_EnvstepsSoFar : 178803
TimeSinceStart : 160.22481298446655
Done logging...



********** Iteration 178 ************

Collecting data for eval...
Eval_AverageReturn : 9.804878234863281
Eval_StdReturn : 0.8328473567962646
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.804878048780488
Train_AverageReturn : 9.45283031463623
Train_StdReturn : 0.7413917779922485
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.452830188679245
Actor Loss : -273.9635009765625
Train_EnvstepsSoFar : 179805
TimeSinceStart : 161.1416745185852
Done logging...



********** Iteration 179 ************

Collecting data for eval...
Eval_AverageReturn : 9.95121955871582
Eval_StdReturn : 0.9614831209182739
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.951219512195122
Train_AverageReturn : 9.91089153289795
Train_StdReturn : 0.8217225670814514
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.910891089108912
Actor Loss : -281.2952880859375
Train_EnvstepsSoFar : 180806
TimeSinceStart : 161.96354246139526
Done logging...



********** Iteration 180 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.9370425939559937
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 10.0600004196167
Train_StdReturn : 0.9361624121665955
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.06
Actor Loss : -274.5384826660156
Train_EnvstepsSoFar : 181812
TimeSinceStart : 163.05529856681824
Done logging...



********** Iteration 181 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.726534903049469
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 10.079999923706055
Train_StdReturn : 0.9346657395362854
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.08
Actor Loss : -276.80535888671875
Train_EnvstepsSoFar : 182820
TimeSinceStart : 163.96269416809082
Done logging...



********** Iteration 182 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7865830063819885
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.786407470703125
Train_StdReturn : 0.8550307750701904
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.78640776699029
Actor Loss : -285.43988037109375
Train_EnvstepsSoFar : 183828
TimeSinceStart : 164.83047485351562
Done logging...



********** Iteration 183 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.5371673107147217
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 9.345794677734375
Train_StdReturn : 0.7624702453613281
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.345794392523365
Actor Loss : -267.9081726074219
Train_EnvstepsSoFar : 184828
TimeSinceStart : 165.66332173347473
Done logging...



********** Iteration 184 ************

Collecting data for eval...
Eval_AverageReturn : 10.199999809265137
Eval_StdReturn : 0.9273618459701538
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.2
Train_AverageReturn : 9.533333778381348
Train_StdReturn : 0.7567683458328247
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.533333333333333
Actor Loss : -283.84088134765625
Train_EnvstepsSoFar : 185829
TimeSinceStart : 167.2534351348877
Done logging...



********** Iteration 185 ************

Collecting data for eval...
Eval_AverageReturn : 10.91891860961914
Eval_StdReturn : 1.1241422891616821
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.91891891891892
Train_AverageReturn : 10.416666984558105
Train_StdReturn : 0.9860132336616516
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.416666666666666
Actor Loss : -262.6720275878906
Train_EnvstepsSoFar : 186829
TimeSinceStart : 168.20039534568787
Done logging...



********** Iteration 186 ************

Collecting data for eval...
Eval_AverageReturn : 10.684210777282715
Eval_StdReturn : 1.2376817464828491
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.68421052631579
Train_AverageReturn : 10.817204475402832
Train_StdReturn : 1.0154317617416382
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.817204301075268
Actor Loss : -247.17059326171875
Train_EnvstepsSoFar : 187835
TimeSinceStart : 169.2861032485962
Done logging...



********** Iteration 187 ************

Collecting data for eval...
Eval_AverageReturn : 10.6578950881958
Eval_StdReturn : 1.1534004211425781
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.657894736842104
Train_AverageReturn : 11.032966613769531
Train_StdReturn : 1.1334140300750732
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 11.032967032967033
Actor Loss : -239.06568908691406
Train_EnvstepsSoFar : 188839
TimeSinceStart : 170.23961544036865
Done logging...



********** Iteration 188 ************

Collecting data for eval...
Eval_AverageReturn : 10.605262756347656
Eval_StdReturn : 0.9607967138290405
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.605263157894736
Train_AverageReturn : 10.838709831237793
Train_StdReturn : 1.0604352951049805
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.838709677419354
Actor Loss : -244.4473419189453
Train_EnvstepsSoFar : 189847
TimeSinceStart : 171.32842826843262
Done logging...



********** Iteration 189 ************

Collecting data for eval...
Eval_AverageReturn : 10.282051086425781
Eval_StdReturn : 0.9857631325721741
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.282051282051283
Train_AverageReturn : 10.631579399108887
Train_StdReturn : 1.0162121057510376
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.631578947368421
Actor Loss : -257.3238220214844
Train_EnvstepsSoFar : 190857
TimeSinceStart : 172.42336678504944
Done logging...



********** Iteration 190 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.7303743958473206
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 10.202020645141602
Train_StdReturn : 1.0345525741577148
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.202020202020202
Actor Loss : -274.8359069824219
Train_EnvstepsSoFar : 191867
TimeSinceStart : 173.27040076255798
Done logging...



********** Iteration 191 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.7324658632278442
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.238532066345215
Train_StdReturn : 0.7406800985336304
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.238532110091743
Actor Loss : -270.7760925292969
Train_EnvstepsSoFar : 192874
TimeSinceStart : 174.37903380393982
Done logging...



********** Iteration 192 ************

Collecting data for eval...
Eval_AverageReturn : 10.100000381469727
Eval_StdReturn : 0.9165151715278625
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.1
Train_AverageReturn : 9.433961868286133
Train_StdReturn : 0.7525913715362549
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.433962264150944
Actor Loss : -271.4090270996094
Train_EnvstepsSoFar : 193874
TimeSinceStart : 175.35068535804749
Done logging...



********** Iteration 193 ************

Collecting data for eval...
Eval_AverageReturn : 10.410256385803223
Eval_StdReturn : 1.0553393363952637
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.41025641025641
Train_AverageReturn : 10.214285850524902
Train_StdReturn : 0.9502953290939331
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.214285714285714
Actor Loss : -274.53973388671875
Train_EnvstepsSoFar : 194875
TimeSinceStart : 176.35158801078796
Done logging...



********** Iteration 194 ************

Collecting data for eval...
Eval_AverageReturn : 10.6578950881958
Eval_StdReturn : 1.0072453022003174
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.657894736842104
Train_AverageReturn : 10.427083015441895
Train_StdReturn : 1.0077283382415771
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.427083333333334
Actor Loss : -263.33917236328125
Train_EnvstepsSoFar : 195876
TimeSinceStart : 177.26533579826355
Done logging...



********** Iteration 195 ************

Collecting data for eval...
Eval_AverageReturn : 10.410256385803223
Eval_StdReturn : 0.9797423481941223
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.41025641025641
Train_AverageReturn : 10.391752243041992
Train_StdReturn : 1.0987969636917114
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.391752577319588
Actor Loss : -258.7943115234375
Train_EnvstepsSoFar : 196884
TimeSinceStart : 178.22734928131104
Done logging...



********** Iteration 196 ************

Collecting data for eval...
Eval_AverageReturn : 10.175000190734863
Eval_StdReturn : 1.0461238622665405
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.175
Train_AverageReturn : 10.26530647277832
Train_StdReturn : 1.0454081296920776
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.26530612244898
Actor Loss : -262.01763916015625
Train_EnvstepsSoFar : 197890
TimeSinceStart : 179.106507062912
Done logging...



********** Iteration 197 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.7928965091705322
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 10.27550983428955
Train_StdReturn : 0.9233989119529724
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.275510204081632
Actor Loss : -271.24908447265625
Train_EnvstepsSoFar : 198897
TimeSinceStart : 180.00259160995483
Done logging...



********** Iteration 198 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.6999961137771606
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.634614944458008
Train_StdReturn : 0.8885780572891235
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.634615384615385
Actor Loss : -280.4937438964844
Train_EnvstepsSoFar : 199899
TimeSinceStart : 180.8631489276886
Done logging...



********** Iteration 199 ************

Collecting data for eval...
Eval_AverageReturn : 9.181818008422852
Eval_StdReturn : 0.7767276167869568
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.181818181818182
Train_AverageReturn : 9.345794677734375
Train_StdReturn : 0.8657858371734619
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.345794392523365
Actor Loss : -261.77655029296875
Train_EnvstepsSoFar : 200899
TimeSinceStart : 181.68369698524475
Done logging...



********** Iteration 200 ************

Collecting data for eval...
Eval_AverageReturn : 9.95121955871582
Eval_StdReturn : 0.9357719421386719
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.951219512195122
Train_AverageReturn : 9.44339656829834
Train_StdReturn : 0.7657797336578369
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.443396226415095
Actor Loss : -267.751708984375
Train_EnvstepsSoFar : 201900
TimeSinceStart : 182.7840564250946
Done logging...



********** Iteration 201 ************

Collecting data for eval...
Eval_AverageReturn : 10.578947067260742
Eval_StdReturn : 1.0913915634155273
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.578947368421053
Train_AverageReturn : 9.813725471496582
Train_StdReturn : 0.9045678377151489
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.813725490196079
Actor Loss : -277.94427490234375
Train_EnvstepsSoFar : 202901
TimeSinceStart : 183.68768000602722
Done logging...



********** Iteration 202 ************

Collecting data for eval...
Eval_AverageReturn : 10.538461685180664
Eval_StdReturn : 1.0088366270065308
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.538461538461538
Train_AverageReturn : 10.319587707519531
Train_StdReturn : 1.0507376194000244
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.31958762886598
Actor Loss : -265.6509704589844
Train_EnvstepsSoFar : 203902
TimeSinceStart : 184.77368927001953
Done logging...



********** Iteration 203 ************

Collecting data for eval...
Eval_AverageReturn : 10.435897827148438
Eval_StdReturn : 1.0572065114974976
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.435897435897436
Train_AverageReturn : 10.416666984558105
Train_StdReturn : 1.057381510734558
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.416666666666666
Actor Loss : -259.63348388671875
Train_EnvstepsSoFar : 204902
TimeSinceStart : 185.60269284248352
Done logging...



********** Iteration 204 ************

Collecting data for eval...
Eval_AverageReturn : 10.199999809265137
Eval_StdReturn : 1.0770330429077148
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.2
Train_AverageReturn : 10.340206146240234
Train_StdReturn : 1.0343241691589355
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.34020618556701
Actor Loss : -261.40948486328125
Train_EnvstepsSoFar : 205905
TimeSinceStart : 186.66135692596436
Done logging...



********** Iteration 205 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.8744936585426331
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 10.38144302368164
Train_StdReturn : 1.078786015510559
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.381443298969073
Actor Loss : -268.779296875
Train_EnvstepsSoFar : 206912
TimeSinceStart : 187.47320127487183
Done logging...



********** Iteration 206 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.7635560035705566
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.823529243469238
Train_StdReturn : 0.8449592590332031
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.823529411764707
Actor Loss : -280.1317138671875
Train_EnvstepsSoFar : 207914
TimeSinceStart : 188.54815554618835
Done logging...



********** Iteration 207 ************

Collecting data for eval...
Eval_AverageReturn : 9.113636016845703
Eval_StdReturn : 0.8585375547409058
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.113636363636363
Train_AverageReturn : 9.238532066345215
Train_StdReturn : 0.7281884551048279
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.238532110091743
Actor Loss : -272.4529724121094
Train_EnvstepsSoFar : 208921
TimeSinceStart : 189.56182146072388
Done logging...



********** Iteration 208 ************

Collecting data for eval...
Eval_AverageReturn : 10.100000381469727
Eval_StdReturn : 0.9695359468460083
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.1
Train_AverageReturn : 9.433961868286133
Train_StdReturn : 0.7893019318580627
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.433962264150944
Actor Loss : -278.1290283203125
Train_EnvstepsSoFar : 209921
TimeSinceStart : 190.43254160881042
Done logging...



********** Iteration 209 ************

Collecting data for eval...
Eval_AverageReturn : 10.815789222717285
Eval_StdReturn : 1.0476857423782349
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.81578947368421
Train_AverageReturn : 10.039999961853027
Train_StdReturn : 1.0762898921966553
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.04
Actor Loss : -269.923828125
Train_EnvstepsSoFar : 210925
TimeSinceStart : 191.51590299606323
Done logging...



********** Iteration 210 ************

Collecting data for eval...
Eval_AverageReturn : 10.605262756347656
Eval_StdReturn : 1.0397236347198486
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.605263157894736
Train_AverageReturn : 10.479166984558105
Train_StdReturn : 0.9680216312408447
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.479166666666666
Actor Loss : -259.4794921875
Train_EnvstepsSoFar : 211931
TimeSinceStart : 192.3428897857666
Done logging...



********** Iteration 211 ************

Collecting data for eval...
Eval_AverageReturn : 10.461538314819336
Eval_StdReturn : 1.1949927806854248
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.461538461538462
Train_AverageReturn : 10.642105102539062
Train_StdReturn : 0.99383145570755
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.642105263157895
Actor Loss : -253.40997314453125
Train_EnvstepsSoFar : 212942
TimeSinceStart : 193.3098065853119
Done logging...



********** Iteration 212 ************

Collecting data for eval...
Eval_AverageReturn : 10.074999809265137
Eval_StdReturn : 0.9324028491973877
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.075
Train_AverageReturn : 10.621052742004395
Train_StdReturn : 1.1623836755752563
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.621052631578948
Actor Loss : -252.97251892089844
Train_EnvstepsSoFar : 213951
TimeSinceStart : 194.39743447303772
Done logging...



********** Iteration 213 ************

Collecting data for eval...
Eval_AverageReturn : 9.95121955871582
Eval_StdReturn : 0.8540068864822388
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.951219512195122
Train_AverageReturn : 10.350515365600586
Train_StdReturn : 1.074936866760254
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.350515463917526
Actor Loss : -263.92388916015625
Train_EnvstepsSoFar : 214955
TimeSinceStart : 195.3967797756195
Done logging...



********** Iteration 214 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.7453559637069702
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 9.77669906616211
Train_StdReturn : 1.0327835083007812
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.776699029126213
Actor Loss : -275.0599365234375
Train_EnvstepsSoFar : 215962
TimeSinceStart : 196.42752528190613
Done logging...



********** Iteration 215 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7061500549316406
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.345794677734375
Train_StdReturn : 0.7624703049659729
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.345794392523365
Actor Loss : -274.7767333984375
Train_EnvstepsSoFar : 216962
TimeSinceStart : 197.388516664505
Done logging...



********** Iteration 216 ************

Collecting data for eval...
Eval_AverageReturn : 9.756097793579102
Eval_StdReturn : 0.8198896050453186
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.75609756097561
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7023661136627197
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : -278.40032958984375
Train_EnvstepsSoFar : 217964
TimeSinceStart : 198.466641664505
Done logging...



********** Iteration 217 ************

Collecting data for eval...
Eval_AverageReturn : 9.87804889678955
Eval_StdReturn : 0.9676504731178284
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.878048780487806
Train_AverageReturn : 9.803921699523926
Train_StdReturn : 0.8860489130020142
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.803921568627452
Actor Loss : -278.4115295410156
Train_EnvstepsSoFar : 218964
TimeSinceStart : 199.46877670288086
Done logging...



********** Iteration 218 ************

Collecting data for eval...
Eval_AverageReturn : 9.829268455505371
Eval_StdReturn : 0.8807546496391296
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.829268292682928
Train_AverageReturn : 9.960395812988281
Train_StdReturn : 0.9111064076423645
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.96039603960396
Actor Loss : -277.10675048828125
Train_EnvstepsSoFar : 219970
TimeSinceStart : 200.5107548236847
Done logging...



********** Iteration 219 ************

Collecting data for eval...
Eval_AverageReturn : 9.780488014221191
Eval_StdReturn : 0.8698806762695312
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.78048780487805
Train_AverageReturn : 10.050000190734863
Train_StdReturn : 0.8529361486434937
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.05
Actor Loss : -279.32696533203125
Train_EnvstepsSoFar : 220975
TimeSinceStart : 201.59541368484497
Done logging...



********** Iteration 220 ************

Collecting data for eval...
Eval_AverageReturn : 9.619047164916992
Eval_StdReturn : 0.6153737306594849
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.619047619047619
Train_AverageReturn : 9.757281303405762
Train_StdReturn : 0.9292028546333313
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.757281553398059
Actor Loss : -281.358154296875
Train_EnvstepsSoFar : 221980
TimeSinceStart : 202.40229678153992
Done logging...



********** Iteration 221 ************

Collecting data for eval...
Eval_AverageReturn : 9.642857551574707
Eval_StdReturn : 0.8679869174957275
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.642857142857142
Train_AverageReturn : 9.268518447875977
Train_StdReturn : 0.7770609855651855
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.268518518518519
Actor Loss : -272.6478271484375
Train_EnvstepsSoFar : 222981
TimeSinceStart : 203.37074089050293
Done logging...



********** Iteration 222 ************

Collecting data for eval...
Eval_AverageReturn : 9.804878234863281
Eval_StdReturn : 0.8616352081298828
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 9.804878048780488
Train_AverageReturn : 9.471697807312012
Train_StdReturn : 0.8378718495368958
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.471698113207546
Actor Loss : -282.28192138671875
Train_EnvstepsSoFar : 223985
TimeSinceStart : 204.4513645172119
Done logging...



********** Iteration 223 ************

Collecting data for eval...
Eval_AverageReturn : 9.7380952835083
Eval_StdReturn : 1.0249162912368774
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.738095238095237
Train_AverageReturn : 9.930692672729492
Train_StdReturn : 0.9361542463302612
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.930693069306932
Actor Loss : -280.367431640625
Train_EnvstepsSoFar : 224988
TimeSinceStart : 205.53435635566711
Done logging...



********** Iteration 224 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 0.9079509973526001
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 10.050000190734863
Train_StdReturn : 0.9205975532531738
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.05
Actor Loss : -279.43096923828125
Train_EnvstepsSoFar : 225993
TimeSinceStart : 206.53889107704163
Done logging...



********** Iteration 225 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 0.7284313440322876
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 9.86274528503418
Train_StdReturn : 0.9397456645965576
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.862745098039216
Actor Loss : -282.58587646484375
Train_EnvstepsSoFar : 226999
TimeSinceStart : 207.56351232528687
Done logging...



********** Iteration 226 ************

Collecting data for eval...
Eval_AverageReturn : 9.87804889678955
Eval_StdReturn : 0.8321327567100525
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.878048780487806
Train_AverageReturn : 9.433961868286133
Train_StdReturn : 0.7006583213806152
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.433962264150944
Actor Loss : -283.833251953125
Train_EnvstepsSoFar : 227999
TimeSinceStart : 208.6347393989563
Done logging...



********** Iteration 227 ************

Collecting data for eval...
Eval_AverageReturn : 9.87804889678955
Eval_StdReturn : 1.0863929986953735
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.878048780487806
Train_AverageReturn : 9.892156600952148
Train_StdReturn : 0.8845832347869873
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.892156862745098
Actor Loss : -284.31207275390625
Train_EnvstepsSoFar : 229008
TimeSinceStart : 209.68073225021362
Done logging...



********** Iteration 228 ************

Collecting data for eval...
Eval_AverageReturn : 9.87804889678955
Eval_StdReturn : 0.8609445095062256
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.878048780487806
Train_AverageReturn : 10.09000015258789
Train_StdReturn : 0.9390953183174133
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.09
Actor Loss : -281.73779296875
Train_EnvstepsSoFar : 230017
TimeSinceStart : 210.56338739395142
Done logging...



********** Iteration 229 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.7633914351463318
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.718446731567383
Train_StdReturn : 0.8055327534675598
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.718446601941748
Actor Loss : -284.31268310546875
Train_EnvstepsSoFar : 231018
TimeSinceStart : 211.56778693199158
Done logging...



********** Iteration 230 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 0.8799858689308167
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 9.333333015441895
Train_StdReturn : 0.7453559637069702
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.333333333333334
Actor Loss : -280.9312438964844
Train_EnvstepsSoFar : 232026
TimeSinceStart : 212.65695524215698
Done logging...



********** Iteration 231 ************

Collecting data for eval...
Eval_AverageReturn : 10.605262756347656
Eval_StdReturn : 0.9878065586090088
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.605263157894736
Train_AverageReturn : 9.823529243469238
Train_StdReturn : 0.8790788650512695
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.823529411764707
Actor Loss : -281.621826171875
Train_EnvstepsSoFar : 233028
TimeSinceStart : 213.66570138931274
Done logging...



********** Iteration 232 ************

Collecting data for eval...
Eval_AverageReturn : 9.829268455505371
Eval_StdReturn : 0.9344996809959412
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.829268292682928
Train_AverageReturn : 10.30927848815918
Train_StdReturn : 1.0969576835632324
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.309278350515465
Actor Loss : -273.6214904785156
Train_EnvstepsSoFar : 234028
TimeSinceStart : 214.4953911304474
Done logging...



********** Iteration 233 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.8744936585426331
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 9.98019790649414
Train_StdReturn : 0.9542005658149719
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.98019801980198
Actor Loss : -280.492431640625
Train_EnvstepsSoFar : 235036
TimeSinceStart : 215.5073139667511
Done logging...



********** Iteration 234 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.6999961137771606
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.45283031463623
Train_StdReturn : 0.8592677116394043
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.452830188679245
Actor Loss : -285.7790832519531
Train_EnvstepsSoFar : 236038
TimeSinceStart : 216.34300804138184
Done logging...



********** Iteration 235 ************

Collecting data for eval...
Eval_AverageReturn : 10.6578950881958
Eval_StdReturn : 0.9535616040229797
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.657894736842104
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.7137153148651123
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : -284.1658935546875
Train_EnvstepsSoFar : 237039
TimeSinceStart : 217.23180317878723
Done logging...



********** Iteration 236 ************

Collecting data for eval...
Eval_AverageReturn : 10.256410598754883
Eval_StdReturn : 0.9797422289848328
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.256410256410257
Train_AverageReturn : 10.391752243041992
Train_StdReturn : 0.9797612428665161
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.391752577319588
Actor Loss : -273.7392578125
Train_EnvstepsSoFar : 238047
TimeSinceStart : 218.14866876602173
Done logging...



********** Iteration 237 ************

Collecting data for eval...
Eval_AverageReturn : 10.384614944458008
Eval_StdReturn : 1.0282020568847656
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.384615384615385
Train_AverageReturn : 10.547368049621582
Train_StdReturn : 1.0639393329620361
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.547368421052632
Actor Loss : -261.916748046875
Train_EnvstepsSoFar : 239049
TimeSinceStart : 219.26799273490906
Done logging...



********** Iteration 238 ************

Collecting data for eval...
Eval_AverageReturn : 10.282051086425781
Eval_StdReturn : 1.0364811420440674
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.282051282051283
Train_AverageReturn : 10.610526084899902
Train_StdReturn : 0.9656711220741272
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.610526315789473
Actor Loss : -265.96588134765625
Train_EnvstepsSoFar : 240057
TimeSinceStart : 220.1579041481018
Done logging...



********** Iteration 239 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.829156219959259
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 10.141413688659668
Train_StdReturn : 1.015138864517212
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.141414141414142
Actor Loss : -274.478759765625
Train_EnvstepsSoFar : 241061
TimeSinceStart : 221.07656741142273
Done logging...



********** Iteration 240 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.6863486170768738
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.411214828491211
Train_StdReturn : 0.853286862373352
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.411214953271028
Actor Loss : -286.8106384277344
Train_EnvstepsSoFar : 242068
TimeSinceStart : 221.94160890579224
Done logging...



********** Iteration 241 ************

Collecting data for eval...
Eval_AverageReturn : 10.074999809265137
Eval_StdReturn : 0.9324028491973877
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.075
Train_AverageReturn : 9.40186882019043
Train_StdReturn : 0.8187044262886047
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.401869158878505
Actor Loss : -283.8436279296875
Train_EnvstepsSoFar : 243074
TimeSinceStart : 222.73826670646667
Done logging...



********** Iteration 242 ************

Collecting data for eval...
Eval_AverageReturn : 10.552631378173828
Eval_StdReturn : 1.0929768085479736
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.552631578947368
Train_AverageReturn : 10.1010103225708
Train_StdReturn : 0.9795376062393188
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.1010101010101
Actor Loss : -275.854736328125
Train_EnvstepsSoFar : 244074
TimeSinceStart : 223.80301523208618
Done logging...



********** Iteration 243 ************

Collecting data for eval...
Eval_AverageReturn : 10.333333015441895
Eval_StdReturn : 1.1839381456375122
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.333333333333334
Train_AverageReturn : 10.329896926879883
Train_StdReturn : 1.0125160217285156
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.329896907216495
Actor Loss : -268.41064453125
Train_EnvstepsSoFar : 245076
TimeSinceStart : 224.69735717773438
Done logging...



********** Iteration 244 ************

Collecting data for eval...
Eval_AverageReturn : 10.050000190734863
Eval_StdReturn : 0.9205976724624634
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.05
Train_AverageReturn : 10.536842346191406
Train_StdReturn : 0.9269136786460876
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.536842105263158
Actor Loss : -270.62872314453125
Train_EnvstepsSoFar : 246077
TimeSinceStart : 225.5194571018219
Done logging...



********** Iteration 245 ************

Collecting data for eval...
Eval_AverageReturn : 9.690476417541504
Eval_StdReturn : 0.9125604033470154
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.69047619047619
Train_AverageReturn : 10.13131332397461
Train_StdReturn : 0.9602868556976318
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.131313131313131
Actor Loss : -276.5932922363281
Train_EnvstepsSoFar : 247080
TimeSinceStart : 226.41490006446838
Done logging...



********** Iteration 246 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.7622767090797424
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.8781068921089172
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : -281.8707275390625
Train_EnvstepsSoFar : 248081
TimeSinceStart : 227.30126523971558
Done logging...



********** Iteration 247 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.7782883644104004
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.314814567565918
Train_StdReturn : 0.7155436873435974
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.314814814814815
Actor Loss : -274.406982421875
Train_EnvstepsSoFar : 249087
TimeSinceStart : 228.2487256526947
Done logging...



********** Iteration 248 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.9106416702270508
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 9.471697807312012
Train_StdReturn : 0.7031942009925842
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.471698113207546
Actor Loss : -284.55810546875
Train_EnvstepsSoFar : 250091
TimeSinceStart : 229.33670902252197
Done logging...



********** Iteration 249 ************

Collecting data for eval...
Eval_AverageReturn : 10.225000381469727
Eval_StdReturn : 0.9614442586898804
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.225
Train_AverageReturn : 9.84313678741455
Train_StdReturn : 0.9573768973350525
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.843137254901961
Actor Loss : -280.1056823730469
Train_EnvstepsSoFar : 251095
TimeSinceStart : 230.2939727306366
Done logging...



********** Iteration 250 ************

Collecting data for eval...
Eval_AverageReturn : 10.256410598754883
Eval_StdReturn : 1.1484202146530151
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.256410256410257
Train_AverageReturn : 10.350515365600586
Train_StdReturn : 0.9529253840446472
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.350515463917526
Actor Loss : -276.6399230957031
Train_EnvstepsSoFar : 252099
TimeSinceStart : 231.21716976165771
Done logging...



********** Iteration 251 ************

Collecting data for eval...
Eval_AverageReturn : 9.87804889678955
Eval_StdReturn : 0.9158529043197632
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.878048780487806
Train_AverageReturn : 10.214285850524902
Train_StdReturn : 0.9285714030265808
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.214285714285714
Actor Loss : -276.48187255859375
Train_EnvstepsSoFar : 253100
TimeSinceStart : 232.13136768341064
Done logging...



********** Iteration 252 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.7257023453712463
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 9.940593719482422
Train_StdReturn : 0.8880035281181335
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.94059405940594
Actor Loss : -281.52783203125
Train_EnvstepsSoFar : 254104
TimeSinceStart : 233.13660836219788
Done logging...



********** Iteration 253 ************

Collecting data for eval...
Eval_AverageReturn : 9.159090995788574
Eval_StdReturn : 0.7961036562919617
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.159090909090908
Train_AverageReturn : 9.481132507324219
Train_StdReturn : 0.8268048763275146
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.481132075471699
Actor Loss : -285.03662109375
Train_EnvstepsSoFar : 255109
TimeSinceStart : 234.17848658561707
Done logging...



********** Iteration 254 ************

Collecting data for eval...
Eval_AverageReturn : 9.92682933807373
Eval_StdReturn : 0.7774330377578735
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 9.926829268292684
Train_AverageReturn : 9.324073791503906
Train_StdReturn : 0.7432249784469604
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.324074074074074
Actor Loss : -280.0306396484375
Train_EnvstepsSoFar : 256116
TimeSinceStart : 234.9973120689392
Done logging...



********** Iteration 255 ************

Collecting data for eval...
Eval_AverageReturn : 10.050000190734863
Eval_StdReturn : 1.0234744548797607
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.05
Train_AverageReturn : 9.91089153289795
Train_StdReturn : 0.8685826063156128
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.910891089108912
Actor Loss : -284.25994873046875
Train_EnvstepsSoFar : 257117
TimeSinceStart : 236.0752465724945
Done logging...



********** Iteration 256 ************

Collecting data for eval...
Eval_AverageReturn : 10.175000190734863
Eval_StdReturn : 0.9717895984649658
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.175
Train_AverageReturn : 10.204081535339355
Train_StdReturn : 1.142492651939392
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.204081632653061
Actor Loss : -273.0274658203125
Train_EnvstepsSoFar : 258117
TimeSinceStart : 236.92684388160706
Done logging...



********** Iteration 257 ************

Collecting data for eval...
Eval_AverageReturn : 10.149999618530273
Eval_StdReturn : 0.9096702337265015
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.15
Train_AverageReturn : 10.4375
Train_StdReturn : 1.0389548540115356
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.4375
Actor Loss : -273.2217102050781
Train_EnvstepsSoFar : 259119
TimeSinceStart : 238.01395630836487
Done logging...



********** Iteration 258 ************

Collecting data for eval...
Eval_AverageReturn : 9.7380952835083
Eval_StdReturn : 0.8744937181472778
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.738095238095237
Train_AverageReturn : 10.214285850524902
Train_StdReturn : 1.0903098583221436
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.214285714285714
Actor Loss : -275.37115478515625
Train_EnvstepsSoFar : 260120
TimeSinceStart : 239.10156750679016
Done logging...



********** Iteration 259 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.7324658036231995
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.580952644348145
Train_StdReturn : 0.8483143448829651
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.58095238095238
Actor Loss : -286.9952392578125
Train_EnvstepsSoFar : 261126
TimeSinceStart : 240.18909645080566
Done logging...



********** Iteration 260 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.8012773990631104
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.30555534362793
Train_StdReturn : 0.7259519100189209
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.305555555555555
Actor Loss : -276.27117919921875
Train_EnvstepsSoFar : 262131
TimeSinceStart : 241.08944177627563
Done logging...



********** Iteration 261 ************

Collecting data for eval...
Eval_AverageReturn : 10.972972869873047
Eval_StdReturn : 1.0776973962783813
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.972972972972974
Train_AverageReturn : 9.229357719421387
Train_StdReturn : 0.7497159242630005
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.229357798165138
Actor Loss : -286.73126220703125
Train_EnvstepsSoFar : 263137
TimeSinceStart : 241.96585869789124
Done logging...



********** Iteration 262 ************

Collecting data for eval...
Eval_AverageReturn : 11.0
Eval_StdReturn : 1.3151918649673462
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 11.0
Train_AverageReturn : 10.78494644165039
Train_StdReturn : 1.1056984663009644
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.78494623655914
Actor Loss : -265.3985595703125
Train_EnvstepsSoFar : 264140
TimeSinceStart : 242.7649426460266
Done logging...



********** Iteration 263 ************

Collecting data for eval...
Eval_AverageReturn : 11.166666984558105
Eval_StdReturn : 1.3437095880508423
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 11.166666666666666
Train_AverageReturn : 11.133333206176758
Train_StdReturn : 1.1944315433502197
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 11.133333333333333
Actor Loss : -250.66452026367188
Train_EnvstepsSoFar : 265142
TimeSinceStart : 243.83819317817688
Done logging...



********** Iteration 264 ************

Collecting data for eval...
Eval_AverageReturn : 11.166666984558105
Eval_StdReturn : 1.2360330820083618
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 11.166666666666666
Train_AverageReturn : 11.363636016845703
Train_StdReturn : 1.1983113288879395
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 11.363636363636363
Actor Loss : -243.52044677734375
Train_EnvstepsSoFar : 266142
TimeSinceStart : 244.69467782974243
Done logging...



********** Iteration 265 ************

Collecting data for eval...
Eval_AverageReturn : 11.36111068725586
Eval_StdReturn : 0.917508065700531
Eval_MaxReturn : 13.0
Eval_MinReturn : 10.0
Eval_AverageEpLen : 11.36111111111111
Train_AverageReturn : 11.166666984558105
Train_StdReturn : 1.1666667461395264
Train_MaxReturn : 14.0
Train_MinReturn : 9.0
Train_AverageEpLen : 11.166666666666666
Actor Loss : -248.49661254882812
Train_EnvstepsSoFar : 267147
TimeSinceStart : 245.78462171554565
Done logging...



********** Iteration 266 ************

Collecting data for eval...
Eval_AverageReturn : 10.763157844543457
Eval_StdReturn : 1.0113619565963745
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.763157894736842
Train_AverageReturn : 10.956521987915039
Train_StdReturn : 1.0205821990966797
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.956521739130435
Actor Loss : -255.56610107421875
Train_EnvstepsSoFar : 268155
TimeSinceStart : 246.6074776649475
Done logging...



********** Iteration 267 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.8908708095550537
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 10.680850982666016
Train_StdReturn : 1.0739939212799072
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.680851063829786
Actor Loss : -268.3272705078125
Train_EnvstepsSoFar : 269159
TimeSinceStart : 247.69588470458984
Done logging...



********** Iteration 268 ************

Collecting data for eval...
Eval_AverageReturn : 9.227272987365723
Eval_StdReturn : 0.821960985660553
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.227272727272727
Train_AverageReturn : 9.786407470703125
Train_StdReturn : 0.8320112228393555
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.78640776699029
Actor Loss : -287.4184875488281
Train_EnvstepsSoFar : 270167
TimeSinceStart : 248.79055261611938
Done logging...



********** Iteration 269 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.7741076946258545
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.40186882019043
Train_StdReturn : 0.7594860196113586
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.401869158878505
Actor Loss : -266.1726989746094
Train_EnvstepsSoFar : 271173
TimeSinceStart : 249.615895986557
Done logging...



********** Iteration 270 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.917207658290863
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 9.238532066345215
Train_StdReturn : 0.7650517821311951
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.238532110091743
Actor Loss : -265.863525390625
Train_EnvstepsSoFar : 272180
TimeSinceStart : 250.42851567268372
Done logging...



********** Iteration 271 ************

Collecting data for eval...
Eval_AverageReturn : 10.307692527770996
Eval_StdReturn : 1.1581116914749146
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.307692307692308
Train_AverageReturn : 9.471697807312012
Train_StdReturn : 0.933724045753479
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.471698113207546
Actor Loss : -282.45159912109375
Train_EnvstepsSoFar : 273184
TimeSinceStart : 251.32822155952454
Done logging...



********** Iteration 272 ************

Collecting data for eval...
Eval_AverageReturn : 10.710526466369629
Eval_StdReturn : 0.9433393478393555
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.710526315789474
Train_AverageReturn : 10.360824584960938
Train_StdReturn : 1.132332444190979
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.360824742268042
Actor Loss : -273.18170166015625
Train_EnvstepsSoFar : 274189
TimeSinceStart : 252.2539348602295
Done logging...



********** Iteration 273 ************

Collecting data for eval...
Eval_AverageReturn : 10.526315689086914
Eval_StdReturn : 0.9385554790496826
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.526315789473685
Train_AverageReturn : 10.46875
Train_StdReturn : 1.0601997375488281
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.46875
Actor Loss : -268.1717224121094
Train_EnvstepsSoFar : 275194
TimeSinceStart : 253.15430855751038
Done logging...



********** Iteration 274 ************

Collecting data for eval...
Eval_AverageReturn : 10.48717975616455
Eval_StdReturn : 1.0094881057739258
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.487179487179487
Train_AverageReturn : 10.568421363830566
Train_StdReturn : 1.0224082469940186
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.56842105263158
Actor Loss : -270.70361328125
Train_EnvstepsSoFar : 276198
TimeSinceStart : 254.0462770462036
Done logging...



********** Iteration 275 ************

Collecting data for eval...
Eval_AverageReturn : 9.690476417541504
Eval_StdReturn : 0.7396297454833984
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.69047619047619
Train_AverageReturn : 10.151515007019043
Train_StdReturn : 1.0186506509780884
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.151515151515152
Actor Loss : -276.24090576171875
Train_EnvstepsSoFar : 277203
TimeSinceStart : 254.87597632408142
Done logging...



********** Iteration 276 ************

Collecting data for eval...
Eval_AverageReturn : 9.159090995788574
Eval_StdReturn : 0.7670244574546814
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.159090909090908
Train_AverageReturn : 9.73786449432373
Train_StdReturn : 0.9650309681892395
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.737864077669903
Actor Loss : -283.033203125
Train_EnvstepsSoFar : 278206
TimeSinceStart : 255.70787906646729
Done logging...



********** Iteration 277 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.6780176162719727
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.229357719421387
Train_StdReturn : 0.7373773455619812
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.229357798165138
Actor Loss : -275.29351806640625
Train_EnvstepsSoFar : 279212
TimeSinceStart : 256.80013251304626
Done logging...



********** Iteration 278 ************

Collecting data for eval...
Eval_AverageReturn : 9.780488014221191
Eval_StdReturn : 0.869880735874176
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.78048780487805
Train_AverageReturn : 9.439251899719238
Train_StdReturn : 0.6860092878341675
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.439252336448599
Actor Loss : -286.42059326171875
Train_EnvstepsSoFar : 280222
TimeSinceStart : 257.6341655254364
Done logging...



********** Iteration 279 ************

Collecting data for eval...
Eval_AverageReturn : 10.100000381469727
Eval_StdReturn : 0.8888193964958191
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.1
Train_AverageReturn : 9.84313678741455
Train_StdReturn : 0.8488180637359619
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.843137254901961
Actor Loss : -284.31976318359375
Train_EnvstepsSoFar : 281226
TimeSinceStart : 258.6699900627136
Done logging...



********** Iteration 280 ************

Collecting data for eval...
Eval_AverageReturn : 10.199999809265137
Eval_StdReturn : 1.0049875974655151
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.2
Train_AverageReturn : 10.121212005615234
Train_StdReturn : 1.0276256799697876
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.121212121212121
Actor Loss : -276.990966796875
Train_EnvstepsSoFar : 282228
TimeSinceStart : 259.49591994285583
Done logging...



********** Iteration 281 ************

Collecting data for eval...
Eval_AverageReturn : 9.92682933807373
Eval_StdReturn : 0.9471457600593567
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.926829268292684
Train_AverageReturn : 10.340206146240234
Train_StdReturn : 1.174353003501892
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.34020618556701
Actor Loss : -274.189453125
Train_EnvstepsSoFar : 283231
TimeSinceStart : 260.47016310691833
Done logging...



********** Iteration 282 ************

Collecting data for eval...
Eval_AverageReturn : 9.642857551574707
Eval_StdReturn : 0.9467093348503113
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.642857142857142
Train_AverageReturn : 10.151515007019043
Train_StdReturn : 0.935966432094574
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.151515151515152
Actor Loss : -282.1844482421875
Train_EnvstepsSoFar : 284236
TimeSinceStart : 261.4589695930481
Done logging...



********** Iteration 283 ************

Collecting data for eval...
Eval_AverageReturn : 9.227272987365723
Eval_StdReturn : 0.7343406081199646
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.227272727272727
Train_AverageReturn : 9.433961868286133
Train_StdReturn : 0.8903981447219849
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.433962264150944
Actor Loss : -284.259765625
Train_EnvstepsSoFar : 285236
TimeSinceStart : 262.3172299861908
Done logging...



********** Iteration 284 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 0.821203351020813
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 9.30555534362793
Train_StdReturn : 0.7130832076072693
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.305555555555555
Actor Loss : -280.51458740234375
Train_EnvstepsSoFar : 286241
TimeSinceStart : 263.16098952293396
Done logging...



********** Iteration 285 ************

Collecting data for eval...
Eval_AverageReturn : 10.461538314819336
Eval_StdReturn : 1.082403540611267
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.461538461538462
Train_AverageReturn : 9.970296859741211
Train_StdReturn : 0.8139312267303467
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.970297029702971
Actor Loss : -288.4799499511719
Train_EnvstepsSoFar : 287248
TimeSinceStart : 264.0739505290985
Done logging...



********** Iteration 286 ************

Collecting data for eval...
Eval_AverageReturn : 10.435897827148438
Eval_StdReturn : 0.9280492067337036
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.435897435897436
Train_AverageReturn : 10.30927848815918
Train_StdReturn : 1.0875189304351807
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.309278350515465
Actor Loss : -277.0859375
Train_EnvstepsSoFar : 288248
TimeSinceStart : 265.1059317588806
Done logging...



********** Iteration 287 ************

Collecting data for eval...
Eval_AverageReturn : 10.074999809265137
Eval_StdReturn : 0.8481597304344177
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.075
Train_AverageReturn : 10.306122779846191
Train_StdReturn : 1.164160132408142
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.306122448979592
Actor Loss : -277.0779724121094
Train_EnvstepsSoFar : 289258
TimeSinceStart : 265.92961740493774
Done logging...



********** Iteration 288 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.719804048538208
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.960395812988281
Train_StdReturn : 0.9535841345787048
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.96039603960396
Actor Loss : -284.8780517578125
Train_EnvstepsSoFar : 290264
TimeSinceStart : 266.77162289619446
Done logging...



********** Iteration 289 ************

Collecting data for eval...
Eval_AverageReturn : 10.050000190734863
Eval_StdReturn : 0.8351646661758423
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.05
Train_AverageReturn : 9.345794677734375
Train_StdReturn : 0.786602795124054
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.345794392523365
Actor Loss : -280.54461669921875
Train_EnvstepsSoFar : 291264
TimeSinceStart : 267.84822702407837
Done logging...



********** Iteration 290 ************

Collecting data for eval...
Eval_AverageReturn : 10.384614944458008
Eval_StdReturn : 0.9504489302635193
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.384615384615385
Train_AverageReturn : 9.786407470703125
Train_StdReturn : 0.8774466514587402
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.78640776699029
Actor Loss : -289.1854248046875
Train_EnvstepsSoFar : 292272
TimeSinceStart : 268.93187952041626
Done logging...



********** Iteration 291 ************

Collecting data for eval...
Eval_AverageReturn : 10.074999809265137
Eval_StdReturn : 0.8181533813476562
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.075
Train_AverageReturn : 10.100000381469727
Train_StdReturn : 0.9848858118057251
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.1
Actor Loss : -284.83319091796875
Train_EnvstepsSoFar : 293282
TimeSinceStart : 269.83083295822144
Done logging...



********** Iteration 292 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.9562421441078186
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 10.255102157592773
Train_StdReturn : 1.0233122110366821
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.255102040816327
Actor Loss : -283.8835754394531
Train_EnvstepsSoFar : 294287
TimeSinceStart : 270.69070410728455
Done logging...



********** Iteration 293 ************

Collecting data for eval...
Eval_AverageReturn : 10.050000190734863
Eval_StdReturn : 0.9987492561340332
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.05
Train_AverageReturn : 9.462264060974121
Train_StdReturn : 0.8374999761581421
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.462264150943396
Actor Loss : -288.0753173828125
Train_EnvstepsSoFar : 295290
TimeSinceStart : 271.7737579345703
Done logging...



********** Iteration 294 ************

Collecting data for eval...
Eval_AverageReturn : 10.25
Eval_StdReturn : 1.1124297380447388
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.25
Train_AverageReturn : 10.13131332397461
Train_StdReturn : 1.0312927961349487
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.131313131313131
Actor Loss : -281.7239990234375
Train_EnvstepsSoFar : 296293
TimeSinceStart : 272.5929126739502
Done logging...



********** Iteration 295 ************

Collecting data for eval...
Eval_AverageReturn : 9.92682933807373
Eval_StdReturn : 1.0450870990753174
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.926829268292684
Train_AverageReturn : 10.204081535339355
Train_StdReturn : 1.0097401142120361
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.204081632653061
Actor Loss : -279.64337158203125
Train_EnvstepsSoFar : 297293
TimeSinceStart : 273.6811499595642
Done logging...



********** Iteration 296 ************

Collecting data for eval...
Eval_AverageReturn : 9.534883499145508
Eval_StdReturn : 0.7578684091567993
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.534883720930232
Train_AverageReturn : 9.91089153289795
Train_StdReturn : 0.9130408763885498
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.910891089108912
Actor Loss : -285.7117919921875
Train_EnvstepsSoFar : 298294
TimeSinceStart : 274.5816161632538
Done logging...



********** Iteration 297 ************

Collecting data for eval...
Eval_AverageReturn : 9.95121955871582
Eval_StdReturn : 0.9865243434906006
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.951219512195122
Train_AverageReturn : 9.30555534362793
Train_StdReturn : 0.7632573843002319
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.305555555555555
Actor Loss : -281.59942626953125
Train_EnvstepsSoFar : 299299
TimeSinceStart : 275.58776664733887
Done logging...



********** Iteration 298 ************

Collecting data for eval...
Eval_AverageReturn : 10.149999618530273
Eval_StdReturn : 0.9886859655380249
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.15
Train_AverageReturn : 9.960395812988281
Train_StdReturn : 0.9111064076423645
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.96039603960396
Actor Loss : -287.94775390625
Train_EnvstepsSoFar : 300305
TimeSinceStart : 276.6782383918762
Done logging...



********** Iteration 299 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 1.0121216773986816
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 10.141413688659668
Train_StdReturn : 1.015138864517212
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.141414141414142
Actor Loss : -282.7005920410156
Train_EnvstepsSoFar : 301309
TimeSinceStart : 277.7734031677246
Done logging...



********** Iteration 300 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.7272788882255554
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 10.020000457763672
Train_StdReturn : 1.0293686389923096
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.02
Actor Loss : -284.0511474609375
Train_EnvstepsSoFar : 302311
TimeSinceStart : 278.7597019672394
Done logging...



********** Iteration 301 ************

Collecting data for eval...
Eval_AverageReturn : 10.333333015441895
Eval_StdReturn : 1.0459527969360352
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.333333333333334
Train_AverageReturn : 9.342592239379883
Train_StdReturn : 0.7092254757881165
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.342592592592593
Actor Loss : -288.98590087890625
Train_EnvstepsSoFar : 303320
TimeSinceStart : 279.5784411430359
Done logging...



********** Iteration 302 ************

Collecting data for eval...
Eval_AverageReturn : 10.6578950881958
Eval_StdReturn : 1.05820894241333
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.657894736842104
Train_AverageReturn : 10.489583015441895
Train_StdReturn : 1.154653549194336
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.489583333333334
Actor Loss : -280.0921630859375
Train_EnvstepsSoFar : 304327
TimeSinceStart : 280.66729640960693
Done logging...



********** Iteration 303 ************

Collecting data for eval...
Eval_AverageReturn : 10.333333015441895
Eval_StdReturn : 1.0459527969360352
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.333333333333334
Train_AverageReturn : 10.610526084899902
Train_StdReturn : 1.0982736349105835
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.610526315789473
Actor Loss : -276.8358154296875
Train_EnvstepsSoFar : 305335
TimeSinceStart : 281.75264072418213
Done logging...



********** Iteration 304 ************

Collecting data for eval...
Eval_AverageReturn : 9.642857551574707
Eval_StdReturn : 0.8949974775314331
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.642857142857142
Train_AverageReturn : 10.204081535339355
Train_StdReturn : 0.9578801393508911
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.204081632653061
Actor Loss : -281.1009826660156
Train_EnvstepsSoFar : 306335
TimeSinceStart : 282.81948256492615
Done logging...



********** Iteration 305 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7061500549316406
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.590476036071777
Train_StdReturn : 0.9630827903747559
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.59047619047619
Actor Loss : -288.0195617675781
Train_EnvstepsSoFar : 307342
TimeSinceStart : 283.9064893722534
Done logging...



********** Iteration 306 ************

Collecting data for eval...
Eval_AverageReturn : 10.736842155456543
Eval_StdReturn : 1.1164844036102295
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.736842105263158
Train_AverageReturn : 9.277777671813965
Train_StdReturn : 0.743282675743103
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.277777777777779
Actor Loss : -286.9508056640625
Train_EnvstepsSoFar : 308344
TimeSinceStart : 284.710839509964
Done logging...



********** Iteration 307 ************

Collecting data for eval...
Eval_AverageReturn : 10.435897827148438
Eval_StdReturn : 0.8410881161689758
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.435897435897436
Train_AverageReturn : 10.5
Train_StdReturn : 1.0606601238250732
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.5
Actor Loss : -281.30035400390625
Train_EnvstepsSoFar : 309352
TimeSinceStart : 285.67971420288086
Done logging...



********** Iteration 308 ************

Collecting data for eval...
Eval_AverageReturn : 10.461538314819336
Eval_StdReturn : 1.1058387756347656
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.461538461538462
Train_AverageReturn : 10.447916984558105
Train_StdReturn : 1.0593806505203247
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.447916666666666
Actor Loss : -274.3619689941406
Train_EnvstepsSoFar : 310355
TimeSinceStart : 286.76300024986267
Done logging...



********** Iteration 309 ************

Collecting data for eval...
Eval_AverageReturn : 10.125
Eval_StdReturn : 0.7806247472763062
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.125
Train_AverageReturn : 10.38144302368164
Train_StdReturn : 1.0497255325317383
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.381443298969073
Actor Loss : -278.50775146484375
Train_EnvstepsSoFar : 311362
TimeSinceStart : 287.8364143371582
Done logging...



********** Iteration 310 ************

Collecting data for eval...
Eval_AverageReturn : 9.136363983154297
Eval_StdReturn : 0.6938334703445435
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.136363636363637
Train_AverageReturn : 9.86274528503418
Train_StdReturn : 0.8749142289161682
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.862745098039216
Actor Loss : -287.85150146484375
Train_EnvstepsSoFar : 312368
TimeSinceStart : 288.92379903793335
Done logging...



********** Iteration 311 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.6982323527336121
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.373831748962402
Train_StdReturn : 0.7553344964981079
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.373831775700934
Actor Loss : -281.218505859375
Train_EnvstepsSoFar : 313371
TimeSinceStart : 290.0051009654999
Done logging...



********** Iteration 312 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 1.01211416721344
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 9.533333778381348
Train_StdReturn : 0.781532883644104
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.533333333333333
Actor Loss : -286.9759521484375
Train_EnvstepsSoFar : 314372
TimeSinceStart : 290.8353328704834
Done logging...



********** Iteration 313 ************

Collecting data for eval...
Eval_AverageReturn : 10.274999618530273
Eval_StdReturn : 0.9483538269996643
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.275
Train_AverageReturn : 10.010000228881836
Train_StdReturn : 0.9848350882530212
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.01
Actor Loss : -281.8620910644531
Train_EnvstepsSoFar : 315373
TimeSinceStart : 292.4731481075287
Done logging...



********** Iteration 314 ************

Collecting data for eval...
Eval_AverageReturn : 10.526315689086914
Eval_StdReturn : 1.0939267873764038
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.526315789473685
Train_AverageReturn : 10.447916984558105
Train_StdReturn : 1.049501895904541
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.447916666666666
Actor Loss : -278.3367919921875
Train_EnvstepsSoFar : 316376
TimeSinceStart : 293.4432911872864
Done logging...



********** Iteration 315 ************

Collecting data for eval...
Eval_AverageReturn : 10.256410598754883
Eval_StdReturn : 0.953211784362793
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.256410256410257
Train_AverageReturn : 10.371133804321289
Train_StdReturn : 1.0776032209396362
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.371134020618557
Actor Loss : -279.341064453125
Train_EnvstepsSoFar : 317382
TimeSinceStart : 294.387088060379
Done logging...



********** Iteration 316 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.8222171664237976
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 10.0
Train_StdReturn : 0.9273618459701538
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.0
Actor Loss : -283.73016357421875
Train_EnvstepsSoFar : 318382
TimeSinceStart : 295.32514476776123
Done logging...



********** Iteration 317 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.738349199295044
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.856556236743927
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : -284.42413330078125
Train_EnvstepsSoFar : 319383
TimeSinceStart : 296.14171862602234
Done logging...



********** Iteration 318 ************

Collecting data for eval...
Eval_AverageReturn : 9.97560977935791
Eval_StdReturn : 0.8968183398246765
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.975609756097562
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7284924983978271
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : -283.6869201660156
Train_EnvstepsSoFar : 320385
TimeSinceStart : 297.0561463832855
Done logging...



********** Iteration 319 ************

Collecting data for eval...
Eval_AverageReturn : 10.605262756347656
Eval_StdReturn : 0.9607967138290405
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.605263157894736
Train_AverageReturn : 10.161616325378418
Train_StdReturn : 0.8611370921134949
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.16161616161616
Actor Loss : -286.4326477050781
Train_EnvstepsSoFar : 321391
TimeSinceStart : 297.9098119735718
Done logging...



********** Iteration 320 ************

Collecting data for eval...
Eval_AverageReturn : 10.51282024383545
Eval_StdReturn : 1.17389976978302
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.512820512820513
Train_AverageReturn : 10.589473724365234
Train_StdReturn : 0.9893617630004883
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.589473684210526
Actor Loss : -279.65655517578125
Train_EnvstepsSoFar : 322397
TimeSinceStart : 299.006644487381
Done logging...



********** Iteration 321 ************

Collecting data for eval...
Eval_AverageReturn : 10.100000381469727
Eval_StdReturn : 0.8888193964958191
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.1
Train_AverageReturn : 10.46875
Train_StdReturn : 1.0403637886047363
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.46875
Actor Loss : -278.51531982421875
Train_EnvstepsSoFar : 323402
TimeSinceStart : 300.0904805660248
Done logging...



********** Iteration 322 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.5444046854972839
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 10.1010103225708
Train_StdReturn : 0.9795376658439636
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.1010101010101
Actor Loss : -284.458251953125
Train_EnvstepsSoFar : 324402
TimeSinceStart : 300.9237217903137
Done logging...



********** Iteration 323 ************

Collecting data for eval...
Eval_AverageReturn : 9.642857551574707
Eval_StdReturn : 0.8401084542274475
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.642857142857142
Train_AverageReturn : 9.259259223937988
Train_StdReturn : 0.8093249797821045
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.25925925925926
Actor Loss : -282.41748046875
Train_EnvstepsSoFar : 325402
TimeSinceStart : 301.7501494884491
Done logging...



********** Iteration 324 ************

Collecting data for eval...
Eval_AverageReturn : 10.225000381469727
Eval_StdReturn : 0.8799858689308167
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.225
Train_AverageReturn : 9.462264060974121
Train_StdReturn : 1.029512882232666
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.462264150943396
Actor Loss : -284.626708984375
Train_EnvstepsSoFar : 326405
TimeSinceStart : 302.8393702507019
Done logging...



********** Iteration 325 ************

Collecting data for eval...
Eval_AverageReturn : 10.35897445678711
Eval_StdReturn : 0.9736841320991516
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.35897435897436
Train_AverageReturn : 10.13131332397461
Train_StdReturn : 0.9810988306999207
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.131313131313131
Actor Loss : -283.1268005371094
Train_EnvstepsSoFar : 327408
TimeSinceStart : 303.66578483581543
Done logging...



********** Iteration 326 ************

Collecting data for eval...
Eval_AverageReturn : 10.149999618530273
Eval_StdReturn : 1.0380269289016724
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.15
Train_AverageReturn : 10.360824584960938
Train_StdReturn : 1.0070428848266602
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.360824742268042
Actor Loss : -281.2608947753906
Train_EnvstepsSoFar : 328413
TimeSinceStart : 304.68781900405884
Done logging...



********** Iteration 327 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 0.8206517696380615
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 10.295918464660645
Train_StdReturn : 1.0322275161743164
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.295918367346939
Actor Loss : -284.1790466308594
Train_EnvstepsSoFar : 329422
TimeSinceStart : 305.7821388244629
Done logging...



********** Iteration 328 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.6553024649620056
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.805825233459473
Train_StdReturn : 0.8708689212799072
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.805825242718447
Actor Loss : -290.7688293457031
Train_EnvstepsSoFar : 330432
TimeSinceStart : 306.8553431034088
Done logging...



********** Iteration 329 ************

Collecting data for eval...
Eval_AverageReturn : 10.175000190734863
Eval_StdReturn : 0.86277174949646
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.175
Train_AverageReturn : 9.392523765563965
Train_StdReturn : 0.6938583254814148
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392523364485982
Actor Loss : -288.53656005859375
Train_EnvstepsSoFar : 331437
TimeSinceStart : 307.942040681839
Done logging...



********** Iteration 330 ************

Collecting data for eval...
Eval_AverageReturn : 10.736842155456543
Eval_StdReturn : 1.0433804988861084
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.736842105263158
Train_AverageReturn : 10.244897842407227
Train_StdReturn : 0.9589664936065674
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.244897959183673
Actor Loss : -283.15960693359375
Train_EnvstepsSoFar : 332441
TimeSinceStart : 308.8460111618042
Done logging...



********** Iteration 331 ************

Collecting data for eval...
Eval_AverageReturn : 10.552631378173828
Eval_StdReturn : 1.0686283111572266
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.552631578947368
Train_AverageReturn : 10.659574508666992
Train_StdReturn : 0.9844880700111389
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.659574468085106
Actor Loss : -276.0546875
Train_EnvstepsSoFar : 333443
TimeSinceStart : 309.7335112094879
Done logging...



********** Iteration 332 ************

Collecting data for eval...
Eval_AverageReturn : 10.175000190734863
Eval_StdReturn : 1.0928746461868286
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.175
Train_AverageReturn : 10.670212745666504
Train_StdReturn : 1.0757313966751099
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.670212765957446
Actor Loss : -275.4295654296875
Train_EnvstepsSoFar : 334446
TimeSinceStart : 310.59004855155945
Done logging...



********** Iteration 333 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.7782883644104004
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 10.161616325378418
Train_StdReturn : 1.002089500427246
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.16161616161616
Actor Loss : -283.7764587402344
Train_EnvstepsSoFar : 335452
TimeSinceStart : 311.4755210876465
Done logging...



********** Iteration 334 ************

Collecting data for eval...
Eval_AverageReturn : 10.050000190734863
Eval_StdReturn : 0.8645808696746826
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.05
Train_AverageReturn : 9.44339656829834
Train_StdReturn : 0.7407312393188477
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.443396226415095
Actor Loss : -287.82720947265625
Train_EnvstepsSoFar : 336453
TimeSinceStart : 312.4496808052063
Done logging...



********** Iteration 335 ************

Collecting data for eval...
Eval_AverageReturn : 10.100000381469727
Eval_StdReturn : 1.0908712148666382
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.1
Train_AverageReturn : 10.0600004196167
Train_StdReturn : 0.8811357021331787
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.06
Actor Loss : -289.7873840332031
Train_EnvstepsSoFar : 337459
TimeSinceStart : 313.4136493206024
Done logging...



********** Iteration 336 ************

Collecting data for eval...
Eval_AverageReturn : 10.333333015441895
Eval_StdReturn : 1.0701866149902344
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.333333333333334
Train_AverageReturn : 9.950494766235352
Train_StdReturn : 0.9583012461662292
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.950495049504951
Actor Loss : -284.5172119140625
Train_EnvstepsSoFar : 338464
TimeSinceStart : 314.23435163497925
Done logging...



********** Iteration 337 ************

Collecting data for eval...
Eval_AverageReturn : 9.95121955871582
Eval_StdReturn : 0.8821044564247131
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.951219512195122
Train_AverageReturn : 10.391752243041992
Train_StdReturn : 1.0702799558639526
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.391752577319588
Actor Loss : -283.5277404785156
Train_EnvstepsSoFar : 339472
TimeSinceStart : 315.1371114253998
Done logging...



********** Iteration 338 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7250445485115051
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 10.0
Train_StdReturn : 0.9119666218757629
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.0
Actor Loss : -289.5362548828125
Train_EnvstepsSoFar : 340482
TimeSinceStart : 316.4717664718628
Done logging...



********** Iteration 339 ************

Collecting data for eval...
Eval_AverageReturn : 10.282051086425781
Eval_StdReturn : 0.9857631325721741
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.282051282051283
Train_AverageReturn : 9.462264060974121
Train_StdReturn : 0.8374999761581421
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.462264150943396
Actor Loss : -288.3301696777344
Train_EnvstepsSoFar : 341485
TimeSinceStart : 317.39447474479675
Done logging...



********** Iteration 340 ************

Collecting data for eval...
Eval_AverageReturn : 10.282051086425781
Eval_StdReturn : 0.9322901368141174
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.282051282051283
Train_AverageReturn : 10.30927848815918
Train_StdReturn : 0.7911993265151978
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.309278350515465
Actor Loss : -288.0276794433594
Train_EnvstepsSoFar : 342485
TimeSinceStart : 318.2695722579956
Done logging...



********** Iteration 341 ************

Collecting data for eval...
Eval_AverageReturn : 9.804878234863281
Eval_StdReturn : 1.0642646551132202
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.804878048780488
Train_AverageReturn : 10.306122779846191
Train_StdReturn : 0.9519921541213989
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.306122448979592
Actor Loss : -286.88739013671875
Train_EnvstepsSoFar : 343495
TimeSinceStart : 319.2333891391754
Done logging...



********** Iteration 342 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.7633914351463318
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.960395812988281
Train_StdReturn : 1.0983407497406006
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.96039603960396
Actor Loss : -285.4446716308594
Train_EnvstepsSoFar : 344501
TimeSinceStart : 320.3872010707855
Done logging...



********** Iteration 343 ************

Collecting data for eval...
Eval_AverageReturn : 10.810811042785645
Eval_StdReturn : 1.0355266332626343
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.81081081081081
Train_AverageReturn : 9.256880760192871
Train_StdReturn : 0.7710789442062378
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.256880733944953
Actor Loss : -291.07354736328125
Train_EnvstepsSoFar : 345510
TimeSinceStart : 321.2840657234192
Done logging...



********** Iteration 344 ************

Collecting data for eval...
Eval_AverageReturn : 10.435897827148438
Eval_StdReturn : 0.955278754234314
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.435897435897436
Train_AverageReturn : 10.557894706726074
Train_StdReturn : 1.07327139377594
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.557894736842105
Actor Loss : -280.40576171875
Train_EnvstepsSoFar : 346513
TimeSinceStart : 322.19354033470154
Done logging...



********** Iteration 345 ************

Collecting data for eval...
Eval_AverageReturn : 10.307692527770996
Eval_StdReturn : 0.9101661443710327
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.307692307692308
Train_AverageReturn : 10.458333015441895
Train_StdReturn : 1.0696247816085815
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.458333333333334
Actor Loss : -278.42529296875
Train_EnvstepsSoFar : 347517
TimeSinceStart : 323.2867829799652
Done logging...



********** Iteration 346 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.7228032350540161
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 10.171717643737793
Train_StdReturn : 1.0154404640197754
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.171717171717171
Actor Loss : -285.77911376953125
Train_EnvstepsSoFar : 348524
TimeSinceStart : 324.1866891384125
Done logging...



********** Iteration 347 ************

Collecting data for eval...
Eval_AverageReturn : 10.199999809265137
Eval_StdReturn : 0.8124038577079773
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.2
Train_AverageReturn : 9.324073791503906
Train_StdReturn : 0.7306605577468872
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.324074074074074
Actor Loss : -288.93621826171875
Train_EnvstepsSoFar : 349531
TimeSinceStart : 325.06953835487366
Done logging...



********** Iteration 348 ************

Collecting data for eval...
Eval_AverageReturn : 10.410256385803223
Eval_StdReturn : 1.0307565927505493
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.41025641025641
Train_AverageReturn : 10.1010103225708
Train_StdReturn : 0.9265440106391907
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.1010101010101
Actor Loss : -285.8446044921875
Train_EnvstepsSoFar : 350531
TimeSinceStart : 325.8853530883789
Done logging...



********** Iteration 349 ************

Collecting data for eval...
Eval_AverageReturn : 9.97560977935791
Eval_StdReturn : 1.0238093137741089
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.975609756097562
Train_AverageReturn : 10.670212745666504
Train_StdReturn : 1.065796136856079
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.670212765957446
Actor Loss : -282.1681823730469
Train_EnvstepsSoFar : 351534
TimeSinceStart : 326.7089602947235
Done logging...



********** Iteration 350 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.8156129717826843
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 10.141413688659668
Train_StdReturn : 0.9321430921554565
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.141414141414142
Actor Loss : -287.6947021484375
Train_EnvstepsSoFar : 352538
TimeSinceStart : 327.80245780944824
Done logging...



********** Iteration 351 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.8818830251693726
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.40186882019043
Train_StdReturn : 0.9054334163665771
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.401869158878505
Actor Loss : -288.15289306640625
Train_EnvstepsSoFar : 353544
TimeSinceStart : 328.87882590293884
Done logging...



********** Iteration 352 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.9746794104576111
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 9.663461685180664
Train_StdReturn : 0.8837265968322754
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.663461538461538
Actor Loss : -289.6007080078125
Train_EnvstepsSoFar : 354549
TimeSinceStart : 329.685604095459
Done logging...



********** Iteration 353 ************

Collecting data for eval...
Eval_AverageReturn : 10.461538314819336
Eval_StdReturn : 1.082403540611267
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.461538461538462
Train_AverageReturn : 10.151515007019043
Train_StdReturn : 0.9986216425895691
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.151515151515152
Actor Loss : -286.3205261230469
Train_EnvstepsSoFar : 355554
TimeSinceStart : 330.72736644744873
Done logging...



********** Iteration 354 ************

Collecting data for eval...
Eval_AverageReturn : 10.050000190734863
Eval_StdReturn : 0.7729812860488892
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.05
Train_AverageReturn : 10.412370681762695
Train_StdReturn : 1.0229589939117432
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.412371134020619
Actor Loss : -286.3015441894531
Train_EnvstepsSoFar : 356564
TimeSinceStart : 331.5416440963745
Done logging...



********** Iteration 355 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.8175997734069824
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 10.069999694824219
Train_StdReturn : 0.9301074743270874
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.07
Actor Loss : -289.27789306640625
Train_EnvstepsSoFar : 357571
TimeSinceStart : 332.5324659347534
Done logging...



********** Iteration 356 ************

Collecting data for eval...
Eval_AverageReturn : 10.225000381469727
Eval_StdReturn : 1.0836858749389648
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.225
Train_AverageReturn : 9.54285717010498
Train_StdReturn : 0.7931681871414185
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.542857142857143
Actor Loss : -289.9021911621094
Train_EnvstepsSoFar : 358573
TimeSinceStart : 333.35512924194336
Done logging...



********** Iteration 357 ************

Collecting data for eval...
Eval_AverageReturn : 10.51282024383545
Eval_StdReturn : 1.0590705871582031
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.512820512820513
Train_AverageReturn : 10.568421363830566
Train_StdReturn : 1.0326526165008545
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.56842105263158
Actor Loss : -281.91961669921875
Train_EnvstepsSoFar : 359577
TimeSinceStart : 334.4397978782654
Done logging...



********** Iteration 358 ************

Collecting data for eval...
Eval_AverageReturn : 10.256410598754883
Eval_StdReturn : 0.9532118439674377
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.256410256410257
Train_AverageReturn : 10.670212745666504
Train_StdReturn : 0.9718188643455505
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.670212765957446
Actor Loss : -279.86029052734375
Train_EnvstepsSoFar : 360580
TimeSinceStart : 335.52086186408997
Done logging...



********** Iteration 359 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 0.6226997971534729
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 10.30927848815918
Train_StdReturn : 0.9670960903167725
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.309278350515465
Actor Loss : -285.1993713378906
Train_EnvstepsSoFar : 361580
TimeSinceStart : 336.45944356918335
Done logging...



********** Iteration 360 ************

Collecting data for eval...
Eval_AverageReturn : 10.149999618530273
Eval_StdReturn : 0.8529360890388489
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.15
Train_AverageReturn : 9.277777671813965
Train_StdReturn : 0.6781420111656189
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.277777777777779
Actor Loss : -286.84881591796875
Train_EnvstepsSoFar : 362582
TimeSinceStart : 337.53698444366455
Done logging...



********** Iteration 361 ************

Collecting data for eval...
Eval_AverageReturn : 10.526315689086914
Eval_StdReturn : 0.9385555386543274
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.526315789473685
Train_AverageReturn : 10.204081535339355
Train_StdReturn : 0.9893223643302917
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.204081632653061
Actor Loss : -286.00604248046875
Train_EnvstepsSoFar : 363582
TimeSinceStart : 338.45605301856995
Done logging...



********** Iteration 362 ************

Collecting data for eval...
Eval_AverageReturn : 10.410256385803223
Eval_StdReturn : 1.0307564735412598
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.41025641025641
Train_AverageReturn : 10.5
Train_StdReturn : 1.0507932901382446
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.5
Actor Loss : -282.3475341796875
Train_EnvstepsSoFar : 364590
TimeSinceStart : 339.3975033760071
Done logging...



********** Iteration 363 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.9475138783454895
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 10.285714149475098
Train_StdReturn : 1.0594569444656372
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.285714285714286
Actor Loss : -285.6009521484375
Train_EnvstepsSoFar : 365598
TimeSinceStart : 340.2065317630768
Done logging...



********** Iteration 364 ************

Collecting data for eval...
Eval_AverageReturn : 9.95121955871582
Eval_StdReturn : 0.8249528408050537
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.951219512195122
Train_AverageReturn : 9.5
Train_StdReturn : 0.8605614304542542
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.5
Actor Loss : -289.803466796875
Train_EnvstepsSoFar : 366605
TimeSinceStart : 341.09533953666687
Done logging...



********** Iteration 365 ************

Collecting data for eval...
Eval_AverageReturn : 10.6578950881958
Eval_StdReturn : 1.130354404449463
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.657894736842104
Train_AverageReturn : 9.90099048614502
Train_StdReturn : 0.8384917378425598
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.900990099009901
Actor Loss : -289.24188232421875
Train_EnvstepsSoFar : 367605
TimeSinceStart : 341.91529393196106
Done logging...



********** Iteration 366 ************

Collecting data for eval...
Eval_AverageReturn : 10.384614944458008
Eval_StdReturn : 1.1235336065292358
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.384615384615385
Train_AverageReturn : 10.306122779846191
Train_StdReturn : 1.0142672061920166
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.306122448979592
Actor Loss : -285.17486572265625
Train_EnvstepsSoFar : 368615
TimeSinceStart : 342.9903039932251
Done logging...



********** Iteration 367 ************

Collecting data for eval...
Eval_AverageReturn : 9.829268455505371
Eval_StdReturn : 0.7619755864143372
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 9.829268292682928
Train_AverageReturn : 10.26530647277832
Train_StdReturn : 1.0742915868759155
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.26530612244898
Actor Loss : -285.0402526855469
Train_EnvstepsSoFar : 369621
TimeSinceStart : 343.8182179927826
Done logging...



********** Iteration 368 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.7514183521270752
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.747572898864746
Train_StdReturn : 0.9000372290611267
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.74757281553398
Actor Loss : -289.82586669921875
Train_EnvstepsSoFar : 370625
TimeSinceStart : 344.6312589645386
Done logging...



********** Iteration 369 ************

Collecting data for eval...
Eval_AverageReturn : 10.435897827148438
Eval_StdReturn : 0.955278754234314
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.435897435897436
Train_AverageReturn : 9.523809432983398
Train_StdReturn : 0.7571278810501099
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.523809523809524
Actor Loss : -289.741943359375
Train_EnvstepsSoFar : 371625
TimeSinceStart : 345.4645438194275
Done logging...



********** Iteration 370 ************

Collecting data for eval...
Eval_AverageReturn : 10.51282024383545
Eval_StdReturn : 0.9837602376937866
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.512820512820513
Train_AverageReturn : 10.621052742004395
Train_StdReturn : 1.0278127193450928
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.621052631578948
Actor Loss : -286.65155029296875
Train_EnvstepsSoFar : 372634
TimeSinceStart : 346.28243136405945
Done logging...



********** Iteration 371 ************

Collecting data for eval...
Eval_AverageReturn : 10.050000190734863
Eval_StdReturn : 0.8046738505363464
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.05
Train_AverageReturn : 10.458333015441895
Train_StdReturn : 0.9673488736152649
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.458333333333334
Actor Loss : -283.6103210449219
Train_EnvstepsSoFar : 373638
TimeSinceStart : 347.1051194667816
Done logging...



********** Iteration 372 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.8508365750312805
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 9.920791625976562
Train_StdReturn : 0.9918795824050903
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.92079207920792
Actor Loss : -288.12652587890625
Train_EnvstepsSoFar : 374640
TimeSinceStart : 347.9219868183136
Done logging...



********** Iteration 373 ************

Collecting data for eval...
Eval_AverageReturn : 10.25
Eval_StdReturn : 1.1124297380447388
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.25
Train_AverageReturn : 9.49056625366211
Train_StdReturn : 0.9136829972267151
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.49056603773585
Actor Loss : -289.11590576171875
Train_EnvstepsSoFar : 375646
TimeSinceStart : 348.8021397590637
Done logging...



********** Iteration 374 ************

Collecting data for eval...
Eval_AverageReturn : 10.631579399108887
Eval_StdReturn : 1.0110195875167847
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.631578947368421
Train_AverageReturn : 10.38144302368164
Train_StdReturn : 1.0198372602462769
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.381443298969073
Actor Loss : -283.77874755859375
Train_EnvstepsSoFar : 376653
TimeSinceStart : 349.6127691268921
Done logging...



********** Iteration 375 ************

Collecting data for eval...
Eval_AverageReturn : 9.7380952835083
Eval_StdReturn : 0.8744937181472778
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.738095238095237
Train_AverageReturn : 10.536842346191406
Train_StdReturn : 1.1314687728881836
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.536842105263158
Actor Loss : -279.91583251953125
Train_EnvstepsSoFar : 377654
TimeSinceStart : 350.43629693984985
Done logging...



********** Iteration 376 ************

Collecting data for eval...
Eval_AverageReturn : 9.511628150939941
Eval_StdReturn : 0.7886430025100708
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.511627906976743
Train_AverageReturn : 9.833333015441895
Train_StdReturn : 0.8641365766525269
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.833333333333334
Actor Loss : -290.28717041015625
Train_EnvstepsSoFar : 378657
TimeSinceStart : 351.2579574584961
Done logging...



********** Iteration 377 ************

Collecting data for eval...
Eval_AverageReturn : 10.435897827148438
Eval_StdReturn : 1.0326682329177856
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.435897435897436
Train_AverageReturn : 9.439251899719238
Train_StdReturn : 0.8983637094497681
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.439252336448599
Actor Loss : -290.6045837402344
Train_EnvstepsSoFar : 379667
TimeSinceStart : 352.0992889404297
Done logging...



********** Iteration 378 ************

Collecting data for eval...
Eval_AverageReturn : 10.6578950881958
Eval_StdReturn : 1.0072451829910278
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.657894736842104
Train_AverageReturn : 10.5
Train_StdReturn : 1.1365151405334473
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.5
Actor Loss : -284.7899475097656
Train_EnvstepsSoFar : 380675
TimeSinceStart : 352.90095949172974
Done logging...



********** Iteration 379 ************

Collecting data for eval...
Eval_AverageReturn : 9.97560977935791
Eval_StdReturn : 0.7804878354072571
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.975609756097562
Train_AverageReturn : 10.78494644165039
Train_StdReturn : 1.0037505626678467
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.78494623655914
Actor Loss : -283.64892578125
Train_EnvstepsSoFar : 381678
TimeSinceStart : 353.7212896347046
Done logging...



********** Iteration 380 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.7478109002113342
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.99009895324707
Train_StdReturn : 0.9280561208724976
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.990099009900991
Actor Loss : -290.7902526855469
Train_EnvstepsSoFar : 382687
TimeSinceStart : 354.5481045246124
Done logging...



********** Iteration 381 ************

Collecting data for eval...
Eval_AverageReturn : 10.050000190734863
Eval_StdReturn : 0.7399324178695679
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.05
Train_AverageReturn : 9.49056625366211
Train_StdReturn : 0.7800009846687317
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.49056603773585
Actor Loss : -290.7681884765625
Train_EnvstepsSoFar : 383693
TimeSinceStart : 355.361524105072
Done logging...



********** Iteration 382 ************

Collecting data for eval...
Eval_AverageReturn : 10.410256385803223
Eval_StdReturn : 1.079362392425537
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.41025641025641
Train_AverageReturn : 10.329896926879883
Train_StdReturn : 0.9163087606430054
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.329896907216495
Actor Loss : -288.1445007324219
Train_EnvstepsSoFar : 384695
TimeSinceStart : 356.1628119945526
Done logging...



********** Iteration 383 ************

Collecting data for eval...
Eval_AverageReturn : 10.333333015441895
Eval_StdReturn : 1.0938836336135864
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.333333333333334
Train_AverageReturn : 10.600000381469727
Train_StdReturn : 1.0992820262908936
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.6
Actor Loss : -282.56915283203125
Train_EnvstepsSoFar : 385702
TimeSinceStart : 356.94807171821594
Done logging...



********** Iteration 384 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7865830063819885
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 10.489583015441895
Train_StdReturn : 1.154653549194336
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.489583333333334
Actor Loss : -284.00701904296875
Train_EnvstepsSoFar : 386709
TimeSinceStart : 358.34134817123413
Done logging...



********** Iteration 385 ************

Collecting data for eval...
Eval_AverageReturn : 9.95121955871582
Eval_StdReturn : 0.8821044564247131
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.951219512195122
Train_AverageReturn : 9.462264060974121
Train_StdReturn : 0.7911601662635803
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.462264150943396
Actor Loss : -289.93255615234375
Train_EnvstepsSoFar : 387712
TimeSinceStart : 359.150199174881
Done logging...



********** Iteration 386 ************

Collecting data for eval...
Eval_AverageReturn : 10.282051086425781
Eval_StdReturn : 1.0609313249588013
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.282051282051283
Train_AverageReturn : 9.823529243469238
Train_StdReturn : 0.9539573192596436
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.823529411764707
Actor Loss : -289.35504150390625
Train_EnvstepsSoFar : 388714
TimeSinceStart : 359.9420509338379
Done logging...



********** Iteration 387 ************

Collecting data for eval...
Eval_AverageReturn : 10.25
Eval_StdReturn : 1.0185774564743042
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.25
Train_AverageReturn : 10.416666984558105
Train_StdReturn : 0.9860133528709412
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.416666666666666
Actor Loss : -282.07452392578125
Train_EnvstepsSoFar : 389714
TimeSinceStart : 360.73500895500183
Done logging...



********** Iteration 388 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.8783745765686035
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 10.568421363830566
Train_StdReturn : 1.032652497291565
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.56842105263158
Actor Loss : -283.91253662109375
Train_EnvstepsSoFar : 390718
TimeSinceStart : 361.5394515991211
Done logging...



********** Iteration 389 ************

Collecting data for eval...
Eval_AverageReturn : 9.829268455505371
Eval_StdReturn : 0.96024489402771
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.829268292682928
Train_AverageReturn : 9.692307472229004
Train_StdReturn : 0.8213136792182922
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.692307692307692
Actor Loss : -292.5457458496094
Train_EnvstepsSoFar : 391726
TimeSinceStart : 362.34909677505493
Done logging...



********** Iteration 390 ************

Collecting data for eval...
Eval_AverageReturn : 10.552631378173828
Eval_StdReturn : 1.0437121391296387
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.552631578947368
Train_AverageReturn : 9.833333015441895
Train_StdReturn : 0.8865368962287903
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.833333333333334
Actor Loss : -290.47015380859375
Train_EnvstepsSoFar : 392729
TimeSinceStart : 363.2960810661316
Done logging...



********** Iteration 391 ************

Collecting data for eval...
Eval_AverageReturn : 10.256410598754883
Eval_StdReturn : 1.0307564735412598
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.256410256410257
Train_AverageReturn : 10.4375
Train_StdReturn : 0.9220956563949585
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.4375
Actor Loss : -285.32659912109375
Train_EnvstepsSoFar : 393731
TimeSinceStart : 364.07810068130493
Done logging...



********** Iteration 392 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.917207658290863
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 10.427083015441895
Train_StdReturn : 0.9973379969596863
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.427083333333334
Actor Loss : -285.5241394042969
Train_EnvstepsSoFar : 394732
TimeSinceStart : 364.8750650882721
Done logging...



********** Iteration 393 ************

Collecting data for eval...
Eval_AverageReturn : 10.125
Eval_StdReturn : 0.8996527194976807
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.125
Train_AverageReturn : 9.625
Train_StdReturn : 0.9526026844978333
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.625
Actor Loss : -288.95068359375
Train_EnvstepsSoFar : 395733
TimeSinceStart : 365.6720669269562
Done logging...



********** Iteration 394 ************

Collecting data for eval...
Eval_AverageReturn : 10.282051086425781
Eval_StdReturn : 0.9857631325721741
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.282051282051283
Train_AverageReturn : 10.0
Train_StdReturn : 0.9695359468460083
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.0
Actor Loss : -287.1873474121094
Train_EnvstepsSoFar : 396733
TimeSinceStart : 366.4709610939026
Done logging...



********** Iteration 395 ************

Collecting data for eval...
Eval_AverageReturn : 10.384614944458008
Eval_StdReturn : 0.8657406568527222
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.384615384615385
Train_AverageReturn : 10.547368049621582
Train_StdReturn : 1.0439643859863281
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.547368421052632
Actor Loss : -284.2676086425781
Train_EnvstepsSoFar : 397735
TimeSinceStart : 367.25529646873474
Done logging...



********** Iteration 396 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 0.9871044158935547
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 10.11111068725586
Train_StdReturn : 0.8748897910118103
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.11111111111111
Actor Loss : -290.2051086425781
Train_EnvstepsSoFar : 398736
TimeSinceStart : 368.0474374294281
Done logging...



********** Iteration 397 ************

Collecting data for eval...
Eval_AverageReturn : 10.736842155456543
Eval_StdReturn : 0.9370786547660828
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.736842105263158
Train_AverageReturn : 9.950494766235352
Train_StdReturn : 0.8830218315124512
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.950495049504951
Actor Loss : -291.1298828125
Train_EnvstepsSoFar : 399741
TimeSinceStart : 369.7678470611572
Done logging...



********** Iteration 398 ************

Collecting data for eval...
Eval_AverageReturn : 10.605262756347656
Eval_StdReturn : 1.1130677461624146
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.605263157894736
Train_AverageReturn : 10.5
Train_StdReturn : 1.0307763814926147
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.5
Actor Loss : -283.93115234375
Train_EnvstepsSoFar : 400749
TimeSinceStart : 370.57481932640076
Done logging...



********** Iteration 399 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.6982323527336121
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 10.547368049621582
Train_StdReturn : 1.0132638216018677
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.547368421052632
Actor Loss : -283.34197998046875
Train_EnvstepsSoFar : 401751
TimeSinceStart : 371.3731722831726
Done logging...



********** Iteration 400 ************

Collecting data for eval...
Eval_AverageReturn : 10.578947067260742
Eval_StdReturn : 1.1152430772781372
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.578947368421053
Train_AverageReturn : 9.277777671813965
Train_StdReturn : 0.8258926868438721
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.277777777777779
Actor Loss : -287.3435363769531
Train_EnvstepsSoFar : 402753
TimeSinceStart : 372.17812752723694
Done logging...



********** Iteration 401 ************

Collecting data for eval...
Eval_AverageReturn : 10.763157844543457
Eval_StdReturn : 1.0370558500289917
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.763157894736842
Train_AverageReturn : 10.319587707519531
Train_StdReturn : 1.0309278964996338
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.31958762886598
Actor Loss : -283.36529541015625
Train_EnvstepsSoFar : 403754
TimeSinceStart : 372.9717390537262
Done logging...



********** Iteration 402 ************

Collecting data for eval...
Eval_AverageReturn : 9.90243911743164
Eval_StdReturn : 0.98289954662323
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.902439024390244
Train_AverageReturn : 10.526315689086914
Train_StdReturn : 0.9823936223983765
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.526315789473685
Actor Loss : -283.09527587890625
Train_EnvstepsSoFar : 404754
TimeSinceStart : 373.79497146606445
Done logging...



********** Iteration 403 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.9746794104576111
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 9.90099048614502
Train_StdReturn : 0.8844638466835022
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.900990099009901
Actor Loss : -290.49273681640625
Train_EnvstepsSoFar : 405754
TimeSinceStart : 374.5752980709076
Done logging...



********** Iteration 404 ************

Collecting data for eval...
Eval_AverageReturn : 10.384614944458008
Eval_StdReturn : 1.002954363822937
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.384615384615385
Train_AverageReturn : 9.84313678741455
Train_StdReturn : 0.9261462688446045
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.843137254901961
Actor Loss : -290.43658447265625
Train_EnvstepsSoFar : 406758
TimeSinceStart : 375.38358545303345
Done logging...



********** Iteration 405 ************

Collecting data for eval...
Eval_AverageReturn : 9.87804889678955
Eval_StdReturn : 0.9158528447151184
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.878048780487806
Train_AverageReturn : 10.30927848815918
Train_StdReturn : 1.0190032720565796
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.309278350515465
Actor Loss : -286.2777099609375
Train_EnvstepsSoFar : 407758
TimeSinceStart : 376.2754499912262
Done logging...



********** Iteration 406 ************

Collecting data for eval...
Eval_AverageReturn : 9.780488014221191
Eval_StdReturn : 0.9502809047698975
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.78048780487805
Train_AverageReturn : 10.191919326782227
Train_StdReturn : 0.8607814908027649
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.191919191919192
Actor Loss : -292.8896484375
Train_EnvstepsSoFar : 408767
TimeSinceStart : 377.48928809165955
Done logging...



********** Iteration 407 ************

Collecting data for eval...
Eval_AverageReturn : 10.050000190734863
Eval_StdReturn : 0.9987492561340332
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.05
Train_AverageReturn : 9.73786449432373
Train_StdReturn : 0.82392817735672
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.737864077669903
Actor Loss : -291.75506591796875
Train_EnvstepsSoFar : 409770
TimeSinceStart : 378.2887589931488
Done logging...



********** Iteration 408 ************

Collecting data for eval...
Eval_AverageReturn : 10.410256385803223
Eval_StdReturn : 0.7751905918121338
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.41025641025641
Train_AverageReturn : 10.181818008422852
Train_StdReturn : 0.845231831073761
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.181818181818182
Actor Loss : -292.3243408203125
Train_EnvstepsSoFar : 410778
TimeSinceStart : 379.10510063171387
Done logging...



********** Iteration 409 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.8062257766723633
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 10.204081535339355
Train_StdReturn : 0.9030467867851257
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.204081632653061
Actor Loss : -289.21209716796875
Train_EnvstepsSoFar : 411778
TimeSinceStart : 379.90385150909424
Done logging...



********** Iteration 410 ************

Collecting data for eval...
Eval_AverageReturn : 10.763157844543457
Eval_StdReturn : 0.9579091668128967
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.763157894736842
Train_AverageReturn : 10.13131332397461
Train_StdReturn : 0.8949517607688904
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.131313131313131
Actor Loss : -291.85870361328125
Train_EnvstepsSoFar : 412781
TimeSinceStart : 380.6942813396454
Done logging...



********** Iteration 411 ************

Collecting data for eval...
Eval_AverageReturn : 9.90243911743164
Eval_StdReturn : 0.849817156791687
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 9.902439024390244
Train_AverageReturn : 10.427083015441895
Train_StdReturn : 1.0482603311538696
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.427083333333334
Actor Loss : -283.86248779296875
Train_EnvstepsSoFar : 413782
TimeSinceStart : 381.51774430274963
Done logging...



********** Iteration 412 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 0.8206517696380615
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 9.882352828979492
Train_StdReturn : 0.8777658343315125
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.882352941176471
Actor Loss : -292.6624755859375
Train_EnvstepsSoFar : 414790
TimeSinceStart : 383.2509865760803
Done logging...



********** Iteration 413 ************

Collecting data for eval...
Eval_AverageReturn : 10.837838172912598
Eval_StdReturn : 1.0270271301269531
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.837837837837839
Train_AverageReturn : 9.571428298950195
Train_StdReturn : 0.7911070585250854
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.571428571428571
Actor Loss : -292.2907409667969
Train_EnvstepsSoFar : 415795
TimeSinceStart : 384.07244968414307
Done logging...



********** Iteration 414 ************

Collecting data for eval...
Eval_AverageReturn : 10.837838172912598
Eval_StdReturn : 1.1273866891860962
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.837837837837839
Train_AverageReturn : 10.8804349899292
Train_StdReturn : 1.1872730255126953
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.880434782608695
Actor Loss : -275.16790771484375
Train_EnvstepsSoFar : 416796
TimeSinceStart : 384.89457154273987
Done logging...



********** Iteration 415 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.7585816383361816
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 10.8804349899292
Train_StdReturn : 1.1500698328018188
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.880434782608695
Actor Loss : -276.8424072265625
Train_EnvstepsSoFar : 417797
TimeSinceStart : 386.4971489906311
Done logging...



********** Iteration 416 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.7514183521270752
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.481132507324219
Train_StdReturn : 0.8036606907844543
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.481132075471699
Actor Loss : -292.171630859375
Train_EnvstepsSoFar : 418802
TimeSinceStart : 387.3084547519684
Done logging...



********** Iteration 417 ************

Collecting data for eval...
Eval_AverageReturn : 10.578947067260742
Eval_StdReturn : 1.0913915634155273
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.578947368421053
Train_AverageReturn : 9.314814567565918
Train_StdReturn : 0.6891775727272034
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.314814814814815
Actor Loss : -290.31817626953125
Train_EnvstepsSoFar : 419808
TimeSinceStart : 388.4733102321625
Done logging...



********** Iteration 418 ************

Collecting data for eval...
Eval_AverageReturn : 10.710526466369629
Eval_StdReturn : 1.1677215099334717
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.710526315789474
Train_AverageReturn : 10.536842346191406
Train_StdReturn : 1.140734076499939
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.536842105263158
Actor Loss : -281.101318359375
Train_EnvstepsSoFar : 420809
TimeSinceStart : 389.3048858642578
Done logging...



********** Iteration 419 ************

Collecting data for eval...
Eval_AverageReturn : 10.410256385803223
Eval_StdReturn : 1.005573034286499
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.41025641025641
Train_AverageReturn : 10.75268840789795
Train_StdReturn : 1.0539828538894653
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.75268817204301
Actor Loss : -278.71697998046875
Train_EnvstepsSoFar : 421809
TimeSinceStart : 390.12559747695923
Done logging...



********** Iteration 420 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.716037392616272
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 10.416666984558105
Train_StdReturn : 1.1606990098953247
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.416666666666666
Actor Loss : -282.75067138671875
Train_EnvstepsSoFar : 422809
TimeSinceStart : 390.95665192604065
Done logging...



********** Iteration 421 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.6867359280586243
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.7394407987594604
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : -285.7061462402344
Train_EnvstepsSoFar : 423810
TimeSinceStart : 391.76085019111633
Done logging...



********** Iteration 422 ************

Collecting data for eval...
Eval_AverageReturn : 9.804878234863281
Eval_StdReturn : 0.7397927641868591
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.804878048780488
Train_AverageReturn : 9.481132507324219
Train_StdReturn : 0.7167949080467224
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.481132075471699
Actor Loss : -285.1394958496094
Train_EnvstepsSoFar : 424815
TimeSinceStart : 392.58785033226013
Done logging...



********** Iteration 423 ************

Collecting data for eval...
Eval_AverageReturn : 9.95121955871582
Eval_StdReturn : 1.010945439338684
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 9.951219512195122
Train_AverageReturn : 9.803921699523926
Train_StdReturn : 0.8048775792121887
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.803921568627452
Actor Loss : -288.8911437988281
Train_EnvstepsSoFar : 425815
TimeSinceStart : 393.4133245944977
Done logging...



********** Iteration 424 ************

Collecting data for eval...
Eval_AverageReturn : 10.48717975616455
Eval_StdReturn : 1.1518499851226807
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.487179487179487
Train_AverageReturn : 10.23469352722168
Train_StdReturn : 1.0182119607925415
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.23469387755102
Actor Loss : -284.80267333984375
Train_EnvstepsSoFar : 426818
TimeSinceStart : 394.2340610027313
Done logging...



********** Iteration 425 ************

Collecting data for eval...
Eval_AverageReturn : 10.149999618530273
Eval_StdReturn : 0.8529360890388489
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.15
Train_AverageReturn : 10.536842346191406
Train_StdReturn : 1.0643558502197266
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.536842105263158
Actor Loss : -282.89154052734375
Train_EnvstepsSoFar : 427819
TimeSinceStart : 395.0378723144531
Done logging...



********** Iteration 426 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 0.8206517696380615
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 10.020000457763672
Train_StdReturn : 0.8364208936691284
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.02
Actor Loss : -288.7987365722656
Train_EnvstepsSoFar : 428821
TimeSinceStart : 395.8538086414337
Done logging...



********** Iteration 427 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.659416139125824
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.44339656829834
Train_StdReturn : 0.8135664463043213
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.443396226415095
Actor Loss : -285.6719970703125
Train_EnvstepsSoFar : 429822
TimeSinceStart : 396.6622693538666
Done logging...



********** Iteration 428 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.8320252895355225
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.715548574924469
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : -286.334228515625
Train_EnvstepsSoFar : 430824
TimeSinceStart : 397.4995160102844
Done logging...



********** Iteration 429 ************

Collecting data for eval...
Eval_AverageReturn : 10.6578950881958
Eval_StdReturn : 0.8668246269226074
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.657894736842104
Train_AverageReturn : 9.45283031463623
Train_StdReturn : 0.9430187344551086
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.452830188679245
Actor Loss : -287.0830383300781
Train_EnvstepsSoFar : 431826
TimeSinceStart : 398.35661339759827
Done logging...



********** Iteration 430 ************

Collecting data for eval...
Eval_AverageReturn : 10.837838172912598
Eval_StdReturn : 1.103153109550476
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.837837837837839
Train_AverageReturn : 10.329896926879883
Train_StdReturn : 1.0326789617538452
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.329896907216495
Actor Loss : -285.539306640625
Train_EnvstepsSoFar : 432828
TimeSinceStart : 399.1950922012329
Done logging...



********** Iteration 431 ************

Collecting data for eval...
Eval_AverageReturn : 10.48717975616455
Eval_StdReturn : 1.0094881057739258
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.487179487179487
Train_AverageReturn : 10.30927848815918
Train_StdReturn : 1.1339268684387207
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.309278350515465
Actor Loss : -279.7545166015625
Train_EnvstepsSoFar : 433828
TimeSinceStart : 400.01746678352356
Done logging...



********** Iteration 432 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.8076164722442627
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 10.171717643737793
Train_StdReturn : 1.005443811416626
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.171717171717171
Actor Loss : -287.9744873046875
Train_EnvstepsSoFar : 434835
TimeSinceStart : 400.87096643447876
Done logging...



********** Iteration 433 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.859521746635437
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.392523765563965
Train_StdReturn : 0.7202933430671692
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392523364485982
Actor Loss : -292.5042724609375
Train_EnvstepsSoFar : 435840
TimeSinceStart : 401.9518074989319
Done logging...



********** Iteration 434 ************

Collecting data for eval...
Eval_AverageReturn : 11.027027130126953
Eval_StdReturn : 1.126738429069519
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 11.027027027027026
Train_AverageReturn : 9.615385055541992
Train_StdReturn : 0.9020029902458191
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.615384615384615
Actor Loss : -290.0043640136719
Train_EnvstepsSoFar : 436840
TimeSinceStart : 403.0212399959564
Done logging...



********** Iteration 435 ************

Collecting data for eval...
Eval_AverageReturn : 11.027027130126953
Eval_StdReturn : 1.1737325191497803
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 11.027027027027026
Train_AverageReturn : 10.806451797485352
Train_StdReturn : 1.1383638381958008
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.806451612903226
Actor Loss : -278.6701965332031
Train_EnvstepsSoFar : 437845
TimeSinceStart : 403.81318640708923
Done logging...



********** Iteration 436 ************

Collecting data for eval...
Eval_AverageReturn : 9.92682933807373
Eval_StdReturn : 0.9471457600593567
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.926829268292684
Train_AverageReturn : 11.01098918914795
Train_StdReturn : 1.2179473638534546
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 11.010989010989011
Actor Loss : -276.32012939453125
Train_EnvstepsSoFar : 438847
TimeSinceStart : 404.60818696022034
Done logging...



********** Iteration 437 ************

Collecting data for eval...
Eval_AverageReturn : 10.631579399108887
Eval_StdReturn : 1.0110195875167847
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.631578947368421
Train_AverageReturn : 9.747572898864746
Train_StdReturn : 0.8670724034309387
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.74757281553398
Actor Loss : -291.0907287597656
Train_EnvstepsSoFar : 439851
TimeSinceStart : 405.4175796508789
Done logging...



********** Iteration 438 ************

Collecting data for eval...
Eval_AverageReturn : 10.684210777282715
Eval_StdReturn : 1.0539464950561523
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.68421052631579
Train_AverageReturn : 10.670212745666504
Train_StdReturn : 1.0456424951553345
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.670212765957446
Actor Loss : -285.09783935546875
Train_EnvstepsSoFar : 440854
TimeSinceStart : 406.2401649951935
Done logging...



********** Iteration 439 ************

Collecting data for eval...
Eval_AverageReturn : 9.95121955871582
Eval_StdReturn : 0.9357719421386719
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.951219512195122
Train_AverageReturn : 10.75268840789795
Train_StdReturn : 0.9908822178840637
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.75268817204301
Actor Loss : -285.8624267578125
Train_EnvstepsSoFar : 441854
TimeSinceStart : 407.07021594047546
Done logging...



********** Iteration 440 ************

Collecting data for eval...
Eval_AverageReturn : 11.166666984558105
Eval_StdReturn : 1.1180340051651
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 11.166666666666666
Train_AverageReturn : 9.86274528503418
Train_StdReturn : 0.9079087972640991
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.862745098039216
Actor Loss : -291.48699951171875
Train_EnvstepsSoFar : 442860
TimeSinceStart : 408.33669686317444
Done logging...



********** Iteration 441 ************

Collecting data for eval...
Eval_AverageReturn : 10.552631378173828
Eval_StdReturn : 1.0929768085479736
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.552631578947368
Train_AverageReturn : 10.913043022155762
Train_StdReturn : 1.1387653350830078
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.91304347826087
Actor Loss : -281.55126953125
Train_EnvstepsSoFar : 443864
TimeSinceStart : 409.1764485836029
Done logging...



********** Iteration 442 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.9120312929153442
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 10.631579399108887
Train_StdReturn : 1.0568337440490723
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.631578947368421
Actor Loss : -286.4700927734375
Train_EnvstepsSoFar : 444874
TimeSinceStart : 409.99930691719055
Done logging...



********** Iteration 443 ************

Collecting data for eval...
Eval_AverageReturn : 10.35897445678711
Eval_StdReturn : 1.024999976158142
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.35897435897436
Train_AverageReturn : 9.392523765563965
Train_StdReturn : 0.7704471945762634
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392523364485982
Actor Loss : -290.0905456542969
Train_EnvstepsSoFar : 445879
TimeSinceStart : 411.0138838291168
Done logging...



********** Iteration 444 ************

Collecting data for eval...
Eval_AverageReturn : 10.384614944458008
Eval_StdReturn : 0.9770544171333313
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.384615384615385
Train_AverageReturn : 10.621052742004395
Train_StdReturn : 1.058091163635254
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.621052631578948
Actor Loss : -286.47271728515625
Train_EnvstepsSoFar : 446888
TimeSinceStart : 412.09205055236816
Done logging...



********** Iteration 445 ************

Collecting data for eval...
Eval_AverageReturn : 10.074999809265137
Eval_StdReturn : 0.9051933884620667
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.075
Train_AverageReturn : 10.578947067260742
Train_StdReturn : 1.052105188369751
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.578947368421053
Actor Loss : -284.8140869140625
Train_EnvstepsSoFar : 447893
TimeSinceStart : 412.9152343273163
Done logging...



********** Iteration 446 ************

Collecting data for eval...
Eval_AverageReturn : 9.642857551574707
Eval_StdReturn : 0.8949974179267883
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.642857142857142
Train_AverageReturn : 10.069999694824219
Train_StdReturn : 0.9513673782348633
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.07
Actor Loss : -291.31610107421875
Train_EnvstepsSoFar : 448900
TimeSinceStart : 413.7226519584656
Done logging...



********** Iteration 447 ************

Collecting data for eval...
Eval_AverageReturn : 9.87804889678955
Eval_StdReturn : 0.9421076774597168
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.878048780487806
Train_AverageReturn : 9.747572898864746
Train_StdReturn : 0.9000371694564819
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.74757281553398
Actor Loss : -289.6602783203125
Train_EnvstepsSoFar : 449904
TimeSinceStart : 414.5460443496704
Done logging...



********** Iteration 448 ************

Collecting data for eval...
Eval_AverageReturn : 10.125
Eval_StdReturn : 1.0532686710357666
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.125
Train_AverageReturn : 9.747572898864746
Train_StdReturn : 0.9000372290611267
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.74757281553398
Actor Loss : -290.49273681640625
Train_EnvstepsSoFar : 450908
TimeSinceStart : 415.35930037498474
Done logging...



********** Iteration 449 ************

Collecting data for eval...
Eval_AverageReturn : 10.48717975616455
Eval_StdReturn : 1.0094882249832153
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.487179487179487
Train_AverageReturn : 10.319587707519531
Train_StdReturn : 1.0408798456192017
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.31958762886598
Actor Loss : -286.1844482421875
Train_EnvstepsSoFar : 451909
TimeSinceStart : 416.17638301849365
Done logging...



********** Iteration 450 ************

Collecting data for eval...
Eval_AverageReturn : 9.829268455505371
Eval_StdReturn : 0.96024489402771
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.829268292682928
Train_AverageReturn : 10.11111068725586
Train_StdReturn : 0.9416177868843079
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.11111111111111
Actor Loss : -287.7700500488281
Train_EnvstepsSoFar : 452910
TimeSinceStart : 416.9947419166565
Done logging...



********** Iteration 451 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 1.0033955574035645
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 9.747572898864746
Train_StdReturn : 0.855802059173584
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.74757281553398
Actor Loss : -290.6084899902344
Train_EnvstepsSoFar : 453914
TimeSinceStart : 417.8155174255371
Done logging...



********** Iteration 452 ************

Collecting data for eval...
Eval_AverageReturn : 9.92682933807373
Eval_StdReturn : 0.9210345149040222
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.926829268292684
Train_AverageReturn : 9.682692527770996
Train_StdReturn : 0.9432393908500671
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.682692307692308
Actor Loss : -290.086181640625
Train_EnvstepsSoFar : 454921
TimeSinceStart : 419.0009939670563
Done logging...



********** Iteration 453 ************

Collecting data for eval...
Eval_AverageReturn : 10.684210777282715
Eval_StdReturn : 0.9761704206466675
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.68421052631579
Train_AverageReturn : 10.050000190734863
Train_StdReturn : 0.89860999584198
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.05
Actor Loss : -291.64923095703125
Train_EnvstepsSoFar : 455926
TimeSinceStart : 419.8231701850891
Done logging...



********** Iteration 454 ************

Collecting data for eval...
Eval_AverageReturn : 10.199999809265137
Eval_StdReturn : 0.842615008354187
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.2
Train_AverageReturn : 10.723403930664062
Train_StdReturn : 1.0559282302856445
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.72340425531915
Actor Loss : -287.92291259765625
Train_EnvstepsSoFar : 456934
TimeSinceStart : 420.6333718299866
Done logging...



********** Iteration 455 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.8637312650680542
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 10.329896926879883
Train_StdReturn : 0.8701421618461609
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.329896907216495
Actor Loss : -291.209228515625
Train_EnvstepsSoFar : 457936
TimeSinceStart : 422.299831867218
Done logging...



********** Iteration 456 ************

Collecting data for eval...
Eval_AverageReturn : 10.736842155456543
Eval_StdReturn : 0.9647527933120728
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.736842105263158
Train_AverageReturn : 9.701923370361328
Train_StdReturn : 0.875739336013794
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.701923076923077
Actor Loss : -293.104736328125
Train_EnvstepsSoFar : 458945
TimeSinceStart : 423.11714267730713
Done logging...



********** Iteration 457 ************

Collecting data for eval...
Eval_AverageReturn : 10.736842155456543
Eval_StdReturn : 1.0926599502563477
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.736842105263158
Train_AverageReturn : 10.75268840789795
Train_StdReturn : 1.1791733503341675
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.75268817204301
Actor Loss : -279.8841552734375
Train_EnvstepsSoFar : 459945
TimeSinceStart : 425.23252868652344
Done logging...



********** Iteration 458 ************

Collecting data for eval...
Eval_AverageReturn : 9.295454978942871
Eval_StdReturn : 0.7561728954315186
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.295454545454545
Train_AverageReturn : 10.510416984558105
Train_StdReturn : 1.0507417917251587
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.510416666666666
Actor Loss : -287.11273193359375
Train_EnvstepsSoFar : 460954
TimeSinceStart : 426.6146414279938
Done logging...



********** Iteration 459 ************

Collecting data for eval...
Eval_AverageReturn : 10.100000381469727
Eval_StdReturn : 0.994987428188324
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.1
Train_AverageReturn : 9.420560836791992
Train_StdReturn : 0.8092615604400635
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.42056074766355
Actor Loss : -287.23687744140625
Train_EnvstepsSoFar : 461962
TimeSinceStart : 427.4235055446625
Done logging...



********** Iteration 460 ************

Collecting data for eval...
Eval_AverageReturn : 10.815789222717285
Eval_StdReturn : 1.1437532901763916
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.81578947368421
Train_AverageReturn : 10.13131332397461
Train_StdReturn : 1.0312927961349487
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.131313131313131
Actor Loss : -289.81732177734375
Train_EnvstepsSoFar : 462965
TimeSinceStart : 428.96784949302673
Done logging...



********** Iteration 461 ************

Collecting data for eval...
Eval_AverageReturn : 10.86486530303955
Eval_StdReturn : 1.1891893148422241
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.864864864864865
Train_AverageReturn : 10.838709831237793
Train_StdReturn : 1.0084623098373413
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.838709677419354
Actor Loss : -281.6654052734375
Train_EnvstepsSoFar : 463973
TimeSinceStart : 430.91502237319946
Done logging...



********** Iteration 462 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.8067178130149841
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 10.670212745666504
Train_StdReturn : 1.0757313966751099
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.670212765957446
Actor Loss : -283.90655517578125
Train_EnvstepsSoFar : 464976
TimeSinceStart : 432.10679364204407
Done logging...



********** Iteration 463 ************

Collecting data for eval...
Eval_AverageReturn : 9.511628150939941
Eval_StdReturn : 0.6945666670799255
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.511627906976743
Train_AverageReturn : 9.533333778381348
Train_StdReturn : 0.8172737956047058
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.533333333333333
Actor Loss : -290.24725341796875
Train_EnvstepsSoFar : 465977
TimeSinceStart : 433.3159439563751
Done logging...



********** Iteration 464 ************

Collecting data for eval...
Eval_AverageReturn : 10.149999618530273
Eval_StdReturn : 1.1079260110855103
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.15
Train_AverageReturn : 9.296296119689941
Train_StdReturn : 0.7729125022888184
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.296296296296296
Actor Loss : -289.2596130371094
Train_EnvstepsSoFar : 466981
TimeSinceStart : 434.5134799480438
Done logging...



********** Iteration 465 ************

Collecting data for eval...
Eval_AverageReturn : 10.384614944458008
Eval_StdReturn : 1.0769232511520386
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.384615384615385
Train_AverageReturn : 10.244897842407227
Train_StdReturn : 1.0006245374679565
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.244897959183673
Actor Loss : -288.9185791015625
Train_EnvstepsSoFar : 467985
TimeSinceStart : 436.3590214252472
Done logging...



********** Iteration 466 ************

Collecting data for eval...
Eval_AverageReturn : 10.256410598754883
Eval_StdReturn : 1.0307564735412598
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.256410256410257
Train_AverageReturn : 10.680850982666016
Train_StdReturn : 0.9808024764060974
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.680851063829786
Actor Loss : -286.2852783203125
Train_EnvstepsSoFar : 468989
TimeSinceStart : 437.5438024997711
Done logging...



********** Iteration 467 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.9428091049194336
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 10.27550983428955
Train_StdReturn : 1.0669488906860352
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.275510204081632
Actor Loss : -288.1990966796875
Train_EnvstepsSoFar : 469996
TimeSinceStart : 438.7184855937958
Done logging...



********** Iteration 468 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.8637312650680542
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 9.625
Train_StdReturn : 0.9824175238609314
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.625
Actor Loss : -287.8553466796875
Train_EnvstepsSoFar : 470997
TimeSinceStart : 440.4392120838165
Done logging...



********** Iteration 469 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.7963330745697021
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 9.619047164916992
Train_StdReturn : 0.9399184584617615
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.619047619047619
Actor Loss : -290.68896484375
Train_EnvstepsSoFar : 472007
TimeSinceStart : 441.83409452438354
Done logging...



********** Iteration 470 ************

Collecting data for eval...
Eval_AverageReturn : 10.631579399108887
Eval_StdReturn : 1.0367218255996704
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.631578947368421
Train_AverageReturn : 9.882352828979492
Train_StdReturn : 0.9831334352493286
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.882352941176471
Actor Loss : -291.105224609375
Train_EnvstepsSoFar : 473015
TimeSinceStart : 443.930846452713
Done logging...



********** Iteration 471 ************

Collecting data for eval...
Eval_AverageReturn : 10.552631378173828
Eval_StdReturn : 0.9920039772987366
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.552631578947368
Train_AverageReturn : 10.547368049621582
Train_StdReturn : 1.0639392137527466
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.547368421052632
Actor Loss : -285.1611328125
Train_EnvstepsSoFar : 474017
TimeSinceStart : 445.08784770965576
Done logging...



********** Iteration 472 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.9273496270179749
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 10.27550983428955
Train_StdReturn : 1.0378609895706177
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.275510204081632
Actor Loss : -288.9014587402344
Train_EnvstepsSoFar : 475024
TimeSinceStart : 446.2604694366455
Done logging...



********** Iteration 473 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.7453559637069702
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 9.692307472229004
Train_StdReturn : 0.8995396494865417
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.692307692307692
Actor Loss : -292.3934326171875
Train_EnvstepsSoFar : 476032
TimeSinceStart : 447.44208002090454
Done logging...



********** Iteration 474 ************

Collecting data for eval...
Eval_AverageReturn : 10.710526466369629
Eval_StdReturn : 1.0738003253936768
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.710526315789474
Train_AverageReturn : 9.571428298950195
Train_StdReturn : 0.7911070585250854
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.571428571428571
Actor Loss : -292.61419677734375
Train_EnvstepsSoFar : 477037
TimeSinceStart : 448.62991404533386
Done logging...



********** Iteration 475 ************

Collecting data for eval...
Eval_AverageReturn : 10.736842155456543
Eval_StdReturn : 0.9647527933120728
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.736842105263158
Train_AverageReturn : 10.547368049621582
Train_StdReturn : 1.023599624633789
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.547368421052632
Actor Loss : -284.3568115234375
Train_EnvstepsSoFar : 478039
TimeSinceStart : 450.7096457481384
Done logging...



********** Iteration 476 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.8449257016181946
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 10.691489219665527
Train_StdReturn : 1.0621795654296875
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.691489361702128
Actor Loss : -285.3555603027344
Train_EnvstepsSoFar : 479044
TimeSinceStart : 452.8037965297699
Done logging...



********** Iteration 477 ************

Collecting data for eval...
Eval_AverageReturn : 10.307692527770996
Eval_StdReturn : 1.0658774375915527
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.307692307692308
Train_AverageReturn : 9.580952644348145
Train_StdReturn : 0.8920918107032776
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.58095238095238
Actor Loss : -292.24951171875
Train_EnvstepsSoFar : 480050
TimeSinceStart : 454.8975667953491
Done logging...



********** Iteration 478 ************

Collecting data for eval...
Eval_AverageReturn : 10.972972869873047
Eval_StdReturn : 0.9440135359764099
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.972972972972974
Train_AverageReturn : 10.578947067260742
Train_StdReturn : 1.0008307695388794
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.578947368421053
Actor Loss : -287.74212646484375
Train_EnvstepsSoFar : 481055
TimeSinceStart : 456.0838463306427
Done logging...



********** Iteration 479 ************

Collecting data for eval...
Eval_AverageReturn : 9.92682933807373
Eval_StdReturn : 0.7119277715682983
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.926829268292684
Train_AverageReturn : 10.557894706726074
Train_StdReturn : 1.0534733533859253
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.557894736842105
Actor Loss : -286.3850402832031
Train_EnvstepsSoFar : 482058
TimeSinceStart : 457.2788677215576
Done logging...



********** Iteration 480 ************

Collecting data for eval...
Eval_AverageReturn : 10.435897827148438
Eval_StdReturn : 1.0326682329177856
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.435897435897436
Train_AverageReturn : 9.50943374633789
Train_StdReturn : 0.8494757413864136
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.50943396226415
Actor Loss : -293.1451416015625
Train_EnvstepsSoFar : 483066
TimeSinceStart : 458.4616165161133
Done logging...



********** Iteration 481 ************

Collecting data for eval...
Eval_AverageReturn : 10.410256385803223
Eval_StdReturn : 1.0553393363952637
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.41025641025641
Train_AverageReturn : 11.0
Train_StdReturn : 1.157868504524231
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 11.0
Actor Loss : -281.52484130859375
Train_EnvstepsSoFar : 484067
TimeSinceStart : 460.5438723564148
Done logging...



********** Iteration 482 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.7782883644104004
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 10.734042167663574
Train_StdReturn : 1.0736252069473267
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.73404255319149
Actor Loss : -288.1090087890625
Train_EnvstepsSoFar : 485076
TimeSinceStart : 461.4573538303375
Done logging...



********** Iteration 483 ************

Collecting data for eval...
Eval_AverageReturn : 10.199999809265137
Eval_StdReturn : 0.842615008354187
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.2
Train_AverageReturn : 9.44339656829834
Train_StdReturn : 0.8803964257240295
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.443396226415095
Actor Loss : -289.19921875
Train_EnvstepsSoFar : 486077
TimeSinceStart : 462.64541578292847
Done logging...



********** Iteration 484 ************

Collecting data for eval...
Eval_AverageReturn : 11.0
Eval_StdReturn : 0.9299811124801636
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 11.0
Train_AverageReturn : 9.940593719482422
Train_StdReturn : 0.942104160785675
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.94059405940594
Actor Loss : -290.642333984375
Train_EnvstepsSoFar : 487081
TimeSinceStart : 464.1242845058441
Done logging...



********** Iteration 485 ************

Collecting data for eval...
Eval_AverageReturn : 10.578947067260742
Eval_StdReturn : 0.9902572631835938
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.578947368421053
Train_AverageReturn : 10.849462509155273
Train_StdReturn : 1.0569405555725098
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.849462365591398
Actor Loss : -285.5533142089844
Train_EnvstepsSoFar : 488090
TimeSinceStart : 464.9370937347412
Done logging...



********** Iteration 486 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.8320252895355225
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 10.5
Train_StdReturn : 1.0606601238250732
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.5
Actor Loss : -289.21002197265625
Train_EnvstepsSoFar : 489098
TimeSinceStart : 466.90381479263306
Done logging...



********** Iteration 487 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.8136211633682251
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.54285717010498
Train_StdReturn : 0.7687785625457764
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.542857142857143
Actor Loss : -290.4027099609375
Train_EnvstepsSoFar : 490100
TimeSinceStart : 468.400249004364
Done logging...



********** Iteration 488 ************

Collecting data for eval...
Eval_AverageReturn : 10.307692527770996
Eval_StdReturn : 1.0658773183822632
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.307692307692308
Train_AverageReturn : 9.44339656829834
Train_StdReturn : 0.7780016660690308
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.443396226415095
Actor Loss : -290.07867431640625
Train_EnvstepsSoFar : 491101
TimeSinceStart : 469.57693672180176
Done logging...



********** Iteration 489 ************

Collecting data for eval...
Eval_AverageReturn : 11.08108139038086
Eval_StdReturn : 1.1712403297424316
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 11.08108108108108
Train_AverageReturn : 10.458333015441895
Train_StdReturn : 1.1539485454559326
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.458333333333334
Actor Loss : -288.00543212890625
Train_EnvstepsSoFar : 492105
TimeSinceStart : 471.6949496269226
Done logging...



********** Iteration 490 ************

Collecting data for eval...
Eval_AverageReturn : 10.384614944458008
Eval_StdReturn : 1.1235336065292358
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.384615384615385
Train_AverageReturn : 10.76344108581543
Train_StdReturn : 1.0306886434555054
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.763440860215054
Actor Loss : -284.30950927734375
Train_EnvstepsSoFar : 493106
TimeSinceStart : 473.7980227470398
Done logging...



********** Iteration 491 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.8417191505432129
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 10.427083015441895
Train_StdReturn : 1.067949652671814
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.427083333333334
Actor Loss : -286.62969970703125
Train_EnvstepsSoFar : 494107
TimeSinceStart : 474.99003434181213
Done logging...



********** Iteration 492 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.9273496270179749
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 9.54285717010498
Train_StdReturn : 0.7562888264656067
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.542857142857143
Actor Loss : -290.544189453125
Train_EnvstepsSoFar : 495109
TimeSinceStart : 477.03912258148193
Done logging...



********** Iteration 493 ************

Collecting data for eval...
Eval_AverageReturn : 10.461538314819336
Eval_StdReturn : 0.7794198393821716
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.461538461538462
Train_AverageReturn : 9.324073791503906
Train_StdReturn : 0.9111318588256836
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.324074074074074
Actor Loss : -289.62347412109375
Train_EnvstepsSoFar : 496116
TimeSinceStart : 479.1451394557953
Done logging...



********** Iteration 494 ************

Collecting data for eval...
Eval_AverageReturn : 10.891891479492188
Eval_StdReturn : 1.2032339572906494
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.891891891891891
Train_AverageReturn : 10.621052742004395
Train_StdReturn : 1.0875269174575806
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.621052631578948
Actor Loss : -287.70404052734375
Train_EnvstepsSoFar : 497125
TimeSinceStart : 481.2493543624878
Done logging...



********** Iteration 495 ************

Collecting data for eval...
Eval_AverageReturn : 10.35897445678711
Eval_StdReturn : 1.0497175455093384
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.35897435897436
Train_AverageReturn : 10.702127456665039
Train_StdReturn : 1.2189093828201294
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.702127659574469
Actor Loss : -283.14971923828125
Train_EnvstepsSoFar : 498131
TimeSinceStart : 482.0663707256317
Done logging...



********** Iteration 496 ************

Collecting data for eval...
Eval_AverageReturn : 9.92682933807373
Eval_StdReturn : 0.8664546012878418
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.926829268292684
Train_AverageReturn : 10.244897842407227
Train_StdReturn : 1.069629192352295
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.244897959183673
Actor Loss : -288.26739501953125
Train_EnvstepsSoFar : 499135
TimeSinceStart : 483.27042150497437
Done logging...



********** Iteration 497 ************

Collecting data for eval...
Eval_AverageReturn : 10.125
Eval_StdReturn : 0.871421217918396
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.125
Train_AverageReturn : 9.872549057006836
Train_StdReturn : 0.903930127620697
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.872549019607844
Actor Loss : -292.49053955078125
Train_EnvstepsSoFar : 500142
TimeSinceStart : 485.3848834037781
Done logging...



********** Iteration 498 ************

Collecting data for eval...
Eval_AverageReturn : 10.684210777282715
Eval_StdReturn : 1.1263649463653564
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.68421052631579
Train_AverageReturn : 10.27550983428955
Train_StdReturn : 1.0079339742660522
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.275510204081632
Actor Loss : -290.2430114746094
Train_EnvstepsSoFar : 501149
TimeSinceStart : 487.2280101776123
Done logging...



********** Iteration 499 ************

Collecting data for eval...
Eval_AverageReturn : 10.225000381469727
Eval_StdReturn : 1.0365206003189087
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.225
Train_AverageReturn : 10.75268840789795
Train_StdReturn : 1.0940299034118652
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.75268817204301
Actor Loss : -283.2617492675781
Train_EnvstepsSoFar : 502149
TimeSinceStart : 488.41103768348694
Done logging...


########################
logging outputs to  /home/jaehyun-jeong/UCBerkeley_cs285/hw2/cs285/scripts/../../data/q2_pg_cartpole_lb_CartPole-v0_17-08-2024_01-33-53
########################
Using GPU id 0
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/envs/registration.py:593: UserWarning: [33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.[0m
  logger.warn(
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/core.py:317: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(

********** Iteration 0 ************
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):

Collecting data for eval...
Eval_AverageReturn : 50.77777862548828
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/tensorboardX/summary.py:153: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
  scalar = float(scalar)
Eval_StdReturn : 11.914302825927734
Eval_MaxReturn : 69.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 50.77777777777778
Train_AverageReturn : 36.12612533569336
Train_StdReturn : 14.121809959411621
Train_MaxReturn : 98.0
Train_MinReturn : 20.0
Train_AverageEpLen : 36.126126126126124
Actor Loss : 113723.6171875
Train_EnvstepsSoFar : 4010
TimeSinceStart : 5.4307050704956055
Initial_DataCollection_AverageReturn : 36.12612533569336
Done logging...



********** Iteration 1 ************

Collecting data for eval...
Eval_AverageReturn : 47.44444274902344
Eval_StdReturn : 18.148223876953125
Eval_MaxReturn : 96.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 47.44444444444444
Train_AverageReturn : 42.147369384765625
Train_StdReturn : 13.105216979980469
Train_MaxReturn : 74.0
Train_MinReturn : 25.0
Train_AverageEpLen : 42.14736842105263
Actor Loss : 117763.2578125
Train_EnvstepsSoFar : 8014
TimeSinceStart : 8.258524179458618
Done logging...



********** Iteration 2 ************

Collecting data for eval...
Eval_AverageReturn : 57.57143020629883
Eval_StdReturn : 18.707197189331055
Eval_MaxReturn : 98.0
Eval_MinReturn : 39.0
Eval_AverageEpLen : 57.57142857142857
Train_AverageReturn : 60.92424392700195
Train_StdReturn : 27.830827713012695
Train_MaxReturn : 129.0
Train_MinReturn : 31.0
Train_AverageEpLen : 60.92424242424242
Actor Loss : 175469.53125
Train_EnvstepsSoFar : 12035
TimeSinceStart : 11.918052434921265
Done logging...



********** Iteration 3 ************

Collecting data for eval...
Eval_AverageReturn : 66.66666412353516
Eval_StdReturn : 10.322575569152832
Eval_MaxReturn : 85.0
Eval_MinReturn : 52.0
Eval_AverageEpLen : 66.66666666666667
Train_AverageReturn : 61.69696807861328
Train_StdReturn : 23.194154739379883
Train_MaxReturn : 142.0
Train_MinReturn : 37.0
Train_AverageEpLen : 61.696969696969695
Actor Loss : 157259.578125
Train_EnvstepsSoFar : 16107
TimeSinceStart : 15.038915157318115
Done logging...



********** Iteration 4 ************

Collecting data for eval...
Eval_AverageReturn : 143.75
Eval_StdReturn : 33.77406692504883
Eval_MaxReturn : 188.0
Eval_MinReturn : 93.0
Eval_AverageEpLen : 143.75
Train_AverageReturn : 77.4339599609375
Train_StdReturn : 28.17098045349121
Train_MaxReturn : 164.0
Train_MinReturn : 42.0
Train_AverageEpLen : 77.43396226415095
Actor Loss : 181221.8125
Train_EnvstepsSoFar : 20211
TimeSinceStart : 17.72908329963684
Done logging...



********** Iteration 5 ************

Collecting data for eval...
Eval_AverageReturn : 100.0
Eval_StdReturn : 39.579036712646484
Eval_MaxReturn : 166.0
Eval_MinReturn : 61.0
Eval_AverageEpLen : 100.0
Train_AverageReturn : 95.26190185546875
Train_StdReturn : 39.006141662597656
Train_MaxReturn : 200.0
Train_MinReturn : 52.0
Train_AverageEpLen : 95.26190476190476
Actor Loss : 203365.671875
Train_EnvstepsSoFar : 24212
TimeSinceStart : 20.146251678466797
Done logging...



********** Iteration 6 ************

Collecting data for eval...
Eval_AverageReturn : 105.0
Eval_StdReturn : 32.81005859375
Eval_MaxReturn : 152.0
Eval_MinReturn : 70.0
Eval_AverageEpLen : 105.0
Train_AverageReturn : 118.52941131591797
Train_StdReturn : 47.755035400390625
Train_MaxReturn : 200.0
Train_MinReturn : 57.0
Train_AverageEpLen : 118.52941176470588
Actor Loss : 227483.4375
Train_EnvstepsSoFar : 28242
TimeSinceStart : 22.570995807647705
Done logging...



********** Iteration 7 ************

Collecting data for eval...
Eval_AverageReturn : 102.0
Eval_StdReturn : 28.521921157836914
Eval_MaxReturn : 150.0
Eval_MinReturn : 80.0
Eval_AverageEpLen : 102.0
Train_AverageReturn : 143.17857360839844
Train_StdReturn : 48.84016036987305
Train_MaxReturn : 200.0
Train_MinReturn : 59.0
Train_AverageEpLen : 143.17857142857142
Actor Loss : 235095.28125
Train_EnvstepsSoFar : 32251
TimeSinceStart : 27.29401683807373
Done logging...



********** Iteration 8 ************

Collecting data for eval...
Eval_AverageReturn : 109.75
Eval_StdReturn : 34.22991943359375
Eval_MaxReturn : 144.0
Eval_MinReturn : 63.0
Eval_AverageEpLen : 109.75
Train_AverageReturn : 117.11428833007812
Train_StdReturn : 41.67888641357422
Train_MaxReturn : 200.0
Train_MinReturn : 59.0
Train_AverageEpLen : 117.11428571428571
Actor Loss : 173911.84375
Train_EnvstepsSoFar : 36350
TimeSinceStart : 30.98527979850769
Done logging...



********** Iteration 9 ************

Collecting data for eval...
Eval_AverageReturn : 112.5
Eval_StdReturn : 34.25273895263672
Eval_MaxReturn : 160.0
Eval_MinReturn : 67.0
Eval_AverageEpLen : 112.5
Train_AverageReturn : 129.40625
Train_StdReturn : 42.85721969604492
Train_MaxReturn : 200.0
Train_MinReturn : 63.0
Train_AverageEpLen : 129.40625
Actor Loss : 168384.90625
Train_EnvstepsSoFar : 40491
TimeSinceStart : 33.686087131500244
Done logging...



********** Iteration 10 ************

Collecting data for eval...
Eval_AverageReturn : 158.0
Eval_StdReturn : 33.89198303222656
Eval_MaxReturn : 200.0
Eval_MinReturn : 117.0
Eval_AverageEpLen : 158.0
Train_AverageReturn : 129.6875
Train_StdReturn : 41.727867126464844
Train_MaxReturn : 200.0
Train_MinReturn : 65.0
Train_AverageEpLen : 129.6875
Actor Loss : 144983.421875
Train_EnvstepsSoFar : 44641
TimeSinceStart : 36.22609782218933
Done logging...



********** Iteration 11 ************

Collecting data for eval...
Eval_AverageReturn : 107.80000305175781
Eval_StdReturn : 37.05887222290039
Eval_MaxReturn : 167.0
Eval_MinReturn : 68.0
Eval_AverageEpLen : 107.8
Train_AverageReturn : 127.46875
Train_StdReturn : 40.94812774658203
Train_MaxReturn : 200.0
Train_MinReturn : 67.0
Train_AverageEpLen : 127.46875
Actor Loss : 126432.34375
Train_EnvstepsSoFar : 48720
TimeSinceStart : 40.6531343460083
Done logging...



********** Iteration 12 ************

Collecting data for eval...
Eval_AverageReturn : 83.5999984741211
Eval_StdReturn : 18.51053810119629
Eval_MaxReturn : 102.0
Eval_MinReturn : 58.0
Eval_AverageEpLen : 83.6
Train_AverageReturn : 124.24242401123047
Train_StdReturn : 41.91624450683594
Train_MaxReturn : 200.0
Train_MinReturn : 61.0
Train_AverageEpLen : 124.24242424242425
Actor Loss : 106709.359375
Train_EnvstepsSoFar : 52820
TimeSinceStart : 43.090956926345825
Done logging...



********** Iteration 13 ************

Collecting data for eval...
Eval_AverageReturn : 110.75
Eval_StdReturn : 34.23722457885742
Eval_MaxReturn : 161.0
Eval_MinReturn : 65.0
Eval_AverageEpLen : 110.75
Train_AverageReturn : 115.4000015258789
Train_StdReturn : 35.2259635925293
Train_MaxReturn : 184.0
Train_MinReturn : 64.0
Train_AverageEpLen : 115.4
Actor Loss : 85450.5078125
Train_EnvstepsSoFar : 56859
TimeSinceStart : 45.633058309555054
Done logging...



********** Iteration 14 ************

Collecting data for eval...
Eval_AverageReturn : 78.0
Eval_StdReturn : 11.532562255859375
Eval_MaxReturn : 95.0
Eval_MinReturn : 65.0
Eval_AverageEpLen : 78.0
Train_AverageReturn : 108.2631607055664
Train_StdReturn : 43.79899215698242
Train_MaxReturn : 200.0
Train_MinReturn : 61.0
Train_AverageEpLen : 108.26315789473684
Actor Loss : 74019.0234375
Train_EnvstepsSoFar : 60973
TimeSinceStart : 48.521384716033936
Done logging...



********** Iteration 15 ************

Collecting data for eval...
Eval_AverageReturn : 141.0
Eval_StdReturn : 53.74631881713867
Eval_MaxReturn : 200.0
Eval_MinReturn : 70.0
Eval_AverageEpLen : 141.0
Train_AverageReturn : 119.55882263183594
Train_StdReturn : 47.56245803833008
Train_MaxReturn : 200.0
Train_MinReturn : 59.0
Train_AverageEpLen : 119.55882352941177
Actor Loss : 76850.984375
Train_EnvstepsSoFar : 65038
TimeSinceStart : 53.35667967796326
Done logging...



********** Iteration 16 ************

Collecting data for eval...
Eval_AverageReturn : 120.0
Eval_StdReturn : 30.21588897705078
Eval_MaxReturn : 169.0
Eval_MinReturn : 89.0
Eval_AverageEpLen : 120.0
Train_AverageReturn : 110.2631607055664
Train_StdReturn : 40.928489685058594
Train_MaxReturn : 200.0
Train_MinReturn : 59.0
Train_AverageEpLen : 110.26315789473684
Actor Loss : 63432.66796875
Train_EnvstepsSoFar : 69228
TimeSinceStart : 55.87450456619263
Done logging...



********** Iteration 17 ************

Collecting data for eval...
Eval_AverageReturn : 130.25
Eval_StdReturn : 17.25362205505371
Eval_MaxReturn : 149.0
Eval_MinReturn : 103.0
Eval_AverageEpLen : 130.25
Train_AverageReturn : 122.69696807861328
Train_StdReturn : 47.601558685302734
Train_MaxReturn : 200.0
Train_MinReturn : 63.0
Train_AverageEpLen : 122.6969696969697
Actor Loss : 64322.0078125
Train_EnvstepsSoFar : 73277
TimeSinceStart : 58.35688233375549
Done logging...



********** Iteration 18 ************

Collecting data for eval...
Eval_AverageReturn : 141.25
Eval_StdReturn : 40.01483917236328
Eval_MaxReturn : 181.0
Eval_MinReturn : 76.0
Eval_AverageEpLen : 141.25
Train_AverageReturn : 113.47222137451172
Train_StdReturn : 43.11321258544922
Train_MaxReturn : 200.0
Train_MinReturn : 59.0
Train_AverageEpLen : 113.47222222222223
Actor Loss : 49882.484375
Train_EnvstepsSoFar : 77362
TimeSinceStart : 60.87513542175293
Done logging...



********** Iteration 19 ************

Collecting data for eval...
Eval_AverageReturn : 103.5
Eval_StdReturn : 47.03987503051758
Eval_MaxReturn : 179.0
Eval_MinReturn : 61.0
Eval_AverageEpLen : 103.5
Train_AverageReturn : 117.9142837524414
Train_StdReturn : 48.03889846801758
Train_MaxReturn : 200.0
Train_MinReturn : 55.0
Train_AverageEpLen : 117.91428571428571
Actor Loss : 59521.37109375
Train_EnvstepsSoFar : 81489
TimeSinceStart : 63.402100801467896
Done logging...



********** Iteration 20 ************

Collecting data for eval...
Eval_AverageReturn : 114.5
Eval_StdReturn : 34.514488220214844
Eval_MaxReturn : 166.0
Eval_MinReturn : 69.0
Eval_AverageEpLen : 114.5
Train_AverageReturn : 103.875
Train_StdReturn : 40.35974884033203
Train_MaxReturn : 193.0
Train_MinReturn : 56.0
Train_AverageEpLen : 103.875
Actor Loss : 42770.0390625
Train_EnvstepsSoFar : 85644
TimeSinceStart : 65.96171832084656
Done logging...



********** Iteration 21 ************

Collecting data for eval...
Eval_AverageReturn : 98.4000015258789
Eval_StdReturn : 55.78386688232422
Eval_MaxReturn : 200.0
Eval_MinReturn : 53.0
Eval_AverageEpLen : 98.4
Train_AverageReturn : 109.0810775756836
Train_StdReturn : 44.07756042480469
Train_MaxReturn : 195.0
Train_MinReturn : 59.0
Train_AverageEpLen : 109.08108108108108
Actor Loss : 43949.39453125
Train_EnvstepsSoFar : 89680
TimeSinceStart : 68.49501895904541
Done logging...



********** Iteration 22 ************

Collecting data for eval...
Eval_AverageReturn : 75.33333587646484
Eval_StdReturn : 13.707257270812988
Eval_MaxReturn : 97.0
Eval_MinReturn : 62.0
Eval_AverageEpLen : 75.33333333333333
Train_AverageReturn : 97.63414764404297
Train_StdReturn : 35.77964782714844
Train_MaxReturn : 185.0
Train_MinReturn : 52.0
Train_AverageEpLen : 97.63414634146342
Actor Loss : 33272.40625
Train_EnvstepsSoFar : 93683
TimeSinceStart : 70.95354199409485
Done logging...



********** Iteration 23 ************

Collecting data for eval...
Eval_AverageReturn : 140.0
Eval_StdReturn : 55.71953582763672
Eval_MaxReturn : 193.0
Eval_MinReturn : 63.0
Eval_AverageEpLen : 140.0
Train_AverageReturn : 101.07499694824219
Train_StdReturn : 37.023902893066406
Train_MaxReturn : 195.0
Train_MinReturn : 52.0
Train_AverageEpLen : 101.075
Actor Loss : 35616.70703125
Train_EnvstepsSoFar : 97726
TimeSinceStart : 74.89702558517456
Done logging...



********** Iteration 24 ************

Collecting data for eval...
Eval_AverageReturn : 106.75
Eval_StdReturn : 33.19921112060547
Eval_MaxReturn : 131.0
Eval_MinReturn : 50.0
Eval_AverageEpLen : 106.75
Train_AverageReturn : 81.73469543457031
Train_StdReturn : 27.715593338012695
Train_MaxReturn : 191.0
Train_MinReturn : 52.0
Train_AverageEpLen : 81.73469387755102
Actor Loss : 21882.5703125
Train_EnvstepsSoFar : 101731
TimeSinceStart : 77.36810040473938
Done logging...



********** Iteration 25 ************

Collecting data for eval...
Eval_AverageReturn : 153.0
Eval_StdReturn : 65.05894470214844
Eval_MaxReturn : 200.0
Eval_MinReturn : 61.0
Eval_AverageEpLen : 153.0
Train_AverageReturn : 93.65116119384766
Train_StdReturn : 38.089176177978516
Train_MaxReturn : 200.0
Train_MinReturn : 51.0
Train_AverageEpLen : 93.65116279069767
Actor Loss : 30139.80078125
Train_EnvstepsSoFar : 105758
TimeSinceStart : 79.83507180213928
Done logging...



********** Iteration 26 ************

Collecting data for eval...
Eval_AverageReturn : 107.5
Eval_StdReturn : 46.65029525756836
Eval_MaxReturn : 176.0
Eval_MinReturn : 57.0
Eval_AverageEpLen : 107.5
Train_AverageReturn : 94.39534759521484
Train_StdReturn : 32.938377380371094
Train_MaxReturn : 200.0
Train_MinReturn : 51.0
Train_AverageEpLen : 94.3953488372093
Actor Loss : 28399.458984375
Train_EnvstepsSoFar : 109817
TimeSinceStart : 82.32769393920898
Done logging...



********** Iteration 27 ************

Collecting data for eval...
Eval_AverageReturn : 107.0
Eval_StdReturn : 50.78385543823242
Eval_MaxReturn : 194.0
Eval_MinReturn : 66.0
Eval_AverageEpLen : 107.0
Train_AverageReturn : 101.05000305175781
Train_StdReturn : 45.39821243286133
Train_MaxReturn : 200.0
Train_MinReturn : 49.0
Train_AverageEpLen : 101.05
Actor Loss : 32272.765625
Train_EnvstepsSoFar : 113859
TimeSinceStart : 84.78226709365845
Done logging...



********** Iteration 28 ************

Collecting data for eval...
Eval_AverageReturn : 84.19999694824219
Eval_StdReturn : 28.79861068725586
Eval_MaxReturn : 141.0
Eval_MinReturn : 62.0
Eval_AverageEpLen : 84.2
Train_AverageReturn : 118.14705657958984
Train_StdReturn : 48.648277282714844
Train_MaxReturn : 200.0
Train_MinReturn : 47.0
Train_AverageEpLen : 118.1470588235294
Actor Loss : 32914.2421875
Train_EnvstepsSoFar : 117876
TimeSinceStart : 87.2612566947937
Done logging...



********** Iteration 29 ************

Collecting data for eval...
Eval_AverageReturn : 153.6666717529297
Eval_StdReturn : 40.94169235229492
Eval_MaxReturn : 187.0
Eval_MinReturn : 96.0
Eval_AverageEpLen : 153.66666666666666
Train_AverageReturn : 112.27777862548828
Train_StdReturn : 50.668643951416016
Train_MaxReturn : 200.0
Train_MinReturn : 49.0
Train_AverageEpLen : 112.27777777777777
Actor Loss : 32355.86328125
Train_EnvstepsSoFar : 121918
TimeSinceStart : 89.7611141204834
Done logging...



********** Iteration 30 ************

Collecting data for eval...
Eval_AverageReturn : 143.3333282470703
Eval_StdReturn : 53.816558837890625
Eval_MaxReturn : 200.0
Eval_MinReturn : 71.0
Eval_AverageEpLen : 143.33333333333334
Train_AverageReturn : 118.5882339477539
Train_StdReturn : 53.61305618286133
Train_MaxReturn : 200.0
Train_MinReturn : 52.0
Train_AverageEpLen : 118.58823529411765
Actor Loss : 35734.296875
Train_EnvstepsSoFar : 125950
TimeSinceStart : 92.30052852630615
Done logging...



********** Iteration 31 ************

Collecting data for eval...
Eval_AverageReturn : 101.5
Eval_StdReturn : 42.54703140258789
Eval_MaxReturn : 173.0
Eval_MinReturn : 64.0
Eval_AverageEpLen : 101.5
Train_AverageReturn : 108.40540313720703
Train_StdReturn : 50.99786376953125
Train_MaxReturn : 200.0
Train_MinReturn : 57.0
Train_AverageEpLen : 108.4054054054054
Actor Loss : 26174.1171875
Train_EnvstepsSoFar : 129961
TimeSinceStart : 94.75361657142639
Done logging...



********** Iteration 32 ************

Collecting data for eval...
Eval_AverageReturn : 108.5
Eval_StdReturn : 53.09661102294922
Eval_MaxReturn : 200.0
Eval_MinReturn : 70.0
Eval_AverageEpLen : 108.5
Train_AverageReturn : 115.4857177734375
Train_StdReturn : 48.48350143432617
Train_MaxReturn : 200.0
Train_MinReturn : 57.0
Train_AverageEpLen : 115.48571428571428
Actor Loss : 24129.1640625
Train_EnvstepsSoFar : 134003
TimeSinceStart : 97.2534818649292
Done logging...



********** Iteration 33 ************

Collecting data for eval...
Eval_AverageReturn : 115.75
Eval_StdReturn : 27.779264450073242
Eval_MaxReturn : 142.0
Eval_MinReturn : 69.0
Eval_AverageEpLen : 115.75
Train_AverageReturn : 127.15625
Train_StdReturn : 50.84296417236328
Train_MaxReturn : 200.0
Train_MinReturn : 62.0
Train_AverageEpLen : 127.15625
Actor Loss : 31281.517578125
Train_EnvstepsSoFar : 138072
TimeSinceStart : 99.73499155044556
Done logging...



********** Iteration 34 ************

Collecting data for eval...
Eval_AverageReturn : 155.6666717529297
Eval_StdReturn : 62.696800231933594
Eval_MaxReturn : 200.0
Eval_MinReturn : 67.0
Eval_AverageEpLen : 155.66666666666666
Train_AverageReturn : 127.21875
Train_StdReturn : 50.388946533203125
Train_MaxReturn : 200.0
Train_MinReturn : 56.0
Train_AverageEpLen : 127.21875
Actor Loss : 27517.70703125
Train_EnvstepsSoFar : 142143
TimeSinceStart : 102.25648021697998
Done logging...



********** Iteration 35 ************

Collecting data for eval...
Eval_AverageReturn : 103.25
Eval_StdReturn : 28.568994522094727
Eval_MaxReturn : 148.0
Eval_MinReturn : 73.0
Eval_AverageEpLen : 103.25
Train_AverageReturn : 122.63636016845703
Train_StdReturn : 54.52873229980469
Train_MaxReturn : 200.0
Train_MinReturn : 58.0
Train_AverageEpLen : 122.63636363636364
Actor Loss : 30230.185546875
Train_EnvstepsSoFar : 146190
TimeSinceStart : 104.71662998199463
Done logging...



********** Iteration 36 ************

Collecting data for eval...
Eval_AverageReturn : 111.5
Eval_StdReturn : 51.742149353027344
Eval_MaxReturn : 200.0
Eval_MinReturn : 71.0
Eval_AverageEpLen : 111.5
Train_AverageReturn : 126.65625
Train_StdReturn : 55.15070724487305
Train_MaxReturn : 200.0
Train_MinReturn : 61.0
Train_AverageEpLen : 126.65625
Actor Loss : 30569.2421875
Train_EnvstepsSoFar : 150243
TimeSinceStart : 107.8704674243927
Done logging...



********** Iteration 37 ************

Collecting data for eval...
Eval_AverageReturn : 112.0
Eval_StdReturn : 54.00463104248047
Eval_MaxReturn : 200.0
Eval_MinReturn : 63.0
Eval_AverageEpLen : 112.0
Train_AverageReturn : 149.8518524169922
Train_StdReturn : 53.85832214355469
Train_MaxReturn : 200.0
Train_MinReturn : 65.0
Train_AverageEpLen : 149.85185185185185
Actor Loss : 33940.5
Train_EnvstepsSoFar : 154289
TimeSinceStart : 110.33426904678345
Done logging...



********** Iteration 38 ************

Collecting data for eval...
Eval_AverageReturn : 127.5
Eval_StdReturn : 46.241214752197266
Eval_MaxReturn : 200.0
Eval_MinReturn : 83.0
Eval_AverageEpLen : 127.5
Train_AverageReturn : 130.53125
Train_StdReturn : 56.41087341308594
Train_MaxReturn : 200.0
Train_MinReturn : 59.0
Train_AverageEpLen : 130.53125
Actor Loss : 46425.4453125
Train_EnvstepsSoFar : 158466
TimeSinceStart : 112.90386819839478
Done logging...



********** Iteration 39 ************

Collecting data for eval...
Eval_AverageReturn : 148.75
Eval_StdReturn : 57.38194274902344
Eval_MaxReturn : 200.0
Eval_MinReturn : 61.0
Eval_AverageEpLen : 148.75
Train_AverageReturn : 126.81818389892578
Train_StdReturn : 56.377220153808594
Train_MaxReturn : 200.0
Train_MinReturn : 55.0
Train_AverageEpLen : 126.81818181818181
Actor Loss : 35379.8359375
Train_EnvstepsSoFar : 162651
TimeSinceStart : 115.54389357566833
Done logging...



********** Iteration 40 ************

Collecting data for eval...
Eval_AverageReturn : 156.6666717529297
Eval_StdReturn : 53.69253921508789
Eval_MaxReturn : 200.0
Eval_MinReturn : 81.0
Eval_AverageEpLen : 156.66666666666666
Train_AverageReturn : 126.54545593261719
Train_StdReturn : 56.55841064453125
Train_MaxReturn : 200.0
Train_MinReturn : 61.0
Train_AverageEpLen : 126.54545454545455
Actor Loss : 35781.05078125
Train_EnvstepsSoFar : 166827
TimeSinceStart : 118.094407081604
Done logging...



********** Iteration 41 ************

Collecting data for eval...
Eval_AverageReturn : 131.25
Eval_StdReturn : 68.77272033691406
Eval_MaxReturn : 200.0
Eval_MinReturn : 60.0
Eval_AverageEpLen : 131.25
Train_AverageReturn : 117.14286041259766
Train_StdReturn : 55.90304946899414
Train_MaxReturn : 200.0
Train_MinReturn : 57.0
Train_AverageEpLen : 117.14285714285714
Actor Loss : 31709.65625
Train_EnvstepsSoFar : 170927
TimeSinceStart : 120.87425637245178
Done logging...



********** Iteration 42 ************

Collecting data for eval...
Eval_AverageReturn : 125.75
Eval_StdReturn : 44.28529739379883
Eval_MaxReturn : 200.0
Eval_MinReturn : 84.0
Eval_AverageEpLen : 125.75
Train_AverageReturn : 126.0
Train_StdReturn : 57.40209197998047
Train_MaxReturn : 200.0
Train_MinReturn : 57.0
Train_AverageEpLen : 126.0
Actor Loss : 32977.42578125
Train_EnvstepsSoFar : 174959
TimeSinceStart : 123.39438366889954
Done logging...



********** Iteration 43 ************

Collecting data for eval...
Eval_AverageReturn : 113.25
Eval_StdReturn : 51.353553771972656
Eval_MaxReturn : 200.0
Eval_MinReturn : 69.0
Eval_AverageEpLen : 113.25
Train_AverageReturn : 118.94117736816406
Train_StdReturn : 54.87416076660156
Train_MaxReturn : 200.0
Train_MinReturn : 54.0
Train_AverageEpLen : 118.94117647058823
Actor Loss : 32181.041015625
Train_EnvstepsSoFar : 179003
TimeSinceStart : 125.86736798286438
Done logging...



********** Iteration 44 ************

Collecting data for eval...
Eval_AverageReturn : 171.6666717529297
Eval_StdReturn : 40.06938552856445
Eval_MaxReturn : 200.0
Eval_MinReturn : 115.0
Eval_AverageEpLen : 171.66666666666666
Train_AverageReturn : 117.9117660522461
Train_StdReturn : 55.33074951171875
Train_MaxReturn : 200.0
Train_MinReturn : 54.0
Train_AverageEpLen : 117.91176470588235
Actor Loss : 32014.720703125
Train_EnvstepsSoFar : 183012
TimeSinceStart : 128.6431279182434
Done logging...



********** Iteration 45 ************

Collecting data for eval...
Eval_AverageReturn : 121.25
Eval_StdReturn : 49.50946807861328
Eval_MaxReturn : 200.0
Eval_MinReturn : 79.0
Eval_AverageEpLen : 121.25
Train_AverageReturn : 108.35134887695312
Train_StdReturn : 51.475643157958984
Train_MaxReturn : 200.0
Train_MinReturn : 50.0
Train_AverageEpLen : 108.35135135135135
Actor Loss : 21903.931640625
Train_EnvstepsSoFar : 187021
TimeSinceStart : 131.1196050643921
Done logging...



********** Iteration 46 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 108.59459686279297
Train_StdReturn : 48.266971588134766
Train_MaxReturn : 200.0
Train_MinReturn : 55.0
Train_AverageEpLen : 108.5945945945946
Actor Loss : 24900.837890625
Train_EnvstepsSoFar : 191039
TimeSinceStart : 134.1695818901062
Done logging...



********** Iteration 47 ************

Collecting data for eval...
Eval_AverageReturn : 137.5
Eval_StdReturn : 63.782833099365234
Eval_MaxReturn : 200.0
Eval_MinReturn : 57.0
Eval_AverageEpLen : 137.5
Train_AverageReturn : 127.0
Train_StdReturn : 55.01761245727539
Train_MaxReturn : 200.0
Train_MinReturn : 61.0
Train_AverageEpLen : 127.0
Actor Loss : 44969.953125
Train_EnvstepsSoFar : 195103
TimeSinceStart : 136.76783514022827
Done logging...



********** Iteration 48 ************

Collecting data for eval...
Eval_AverageReturn : 169.3333282470703
Eval_StdReturn : 43.36921310424805
Eval_MaxReturn : 200.0
Eval_MinReturn : 108.0
Eval_AverageEpLen : 169.33333333333334
Train_AverageReturn : 130.21875
Train_StdReturn : 60.37007522583008
Train_MaxReturn : 200.0
Train_MinReturn : 62.0
Train_AverageEpLen : 130.21875
Actor Loss : 51226.2421875
Train_EnvstepsSoFar : 199270
TimeSinceStart : 139.41170954704285
Done logging...



********** Iteration 49 ************

Collecting data for eval...
Eval_AverageReturn : 139.6666717529297
Eval_StdReturn : 43.683204650878906
Eval_MaxReturn : 200.0
Eval_MinReturn : 98.0
Eval_AverageEpLen : 139.66666666666666
Train_AverageReturn : 138.79310607910156
Train_StdReturn : 62.63819122314453
Train_MaxReturn : 200.0
Train_MinReturn : 59.0
Train_AverageEpLen : 138.79310344827587
Actor Loss : 44177.8125
Train_EnvstepsSoFar : 203295
TimeSinceStart : 141.82159757614136
Done logging...



********** Iteration 50 ************

Collecting data for eval...
Eval_AverageReturn : 163.6666717529297
Eval_StdReturn : 51.383094787597656
Eval_MaxReturn : 200.0
Eval_MinReturn : 91.0
Eval_AverageEpLen : 163.66666666666666
Train_AverageReturn : 158.11538696289062
Train_StdReturn : 53.27745056152344
Train_MaxReturn : 200.0
Train_MinReturn : 61.0
Train_AverageEpLen : 158.1153846153846
Actor Loss : 39312.80859375
Train_EnvstepsSoFar : 207406
TimeSinceStart : 144.37158703804016
Done logging...



********** Iteration 51 ************

Collecting data for eval...
Eval_AverageReturn : 104.25
Eval_StdReturn : 56.85232925415039
Eval_MaxReturn : 200.0
Eval_MinReturn : 61.0
Eval_AverageEpLen : 104.25
Train_AverageReturn : 149.55555725097656
Train_StdReturn : 58.18255615234375
Train_MaxReturn : 200.0
Train_MinReturn : 64.0
Train_AverageEpLen : 149.55555555555554
Actor Loss : 55456.90625
Train_EnvstepsSoFar : 211444
TimeSinceStart : 146.81238341331482
Done logging...



********** Iteration 52 ************

Collecting data for eval...
Eval_AverageReturn : 87.4000015258789
Eval_StdReturn : 25.09661293029785
Eval_MaxReturn : 137.0
Eval_MinReturn : 71.0
Eval_AverageEpLen : 87.4
Train_AverageReturn : 132.35484313964844
Train_StdReturn : 59.09672164916992
Train_MaxReturn : 200.0
Train_MinReturn : 57.0
Train_AverageEpLen : 132.3548387096774
Actor Loss : 47868.109375
Train_EnvstepsSoFar : 215547
TimeSinceStart : 149.3077733516693
Done logging...



********** Iteration 53 ************

Collecting data for eval...
Eval_AverageReturn : 147.0
Eval_StdReturn : 53.791263580322266
Eval_MaxReturn : 200.0
Eval_MinReturn : 81.0
Eval_AverageEpLen : 147.0
Train_AverageReturn : 118.0882339477539
Train_StdReturn : 55.25096130371094
Train_MaxReturn : 200.0
Train_MinReturn : 57.0
Train_AverageEpLen : 118.08823529411765
Actor Loss : 29278.62109375
Train_EnvstepsSoFar : 219562
TimeSinceStart : 151.85190105438232
Done logging...



********** Iteration 54 ************

Collecting data for eval...
Eval_AverageReturn : 141.5
Eval_StdReturn : 59.1121826171875
Eval_MaxReturn : 200.0
Eval_MinReturn : 71.0
Eval_AverageEpLen : 141.5
Train_AverageReturn : 145.25
Train_StdReturn : 57.14931869506836
Train_MaxReturn : 200.0
Train_MinReturn : 65.0
Train_AverageEpLen : 145.25
Actor Loss : 54579.6875
Train_EnvstepsSoFar : 223629
TimeSinceStart : 154.81177735328674
Done logging...



********** Iteration 55 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 135.22579956054688
Train_StdReturn : 54.05057907104492
Train_MaxReturn : 200.0
Train_MinReturn : 68.0
Train_AverageEpLen : 135.2258064516129
Actor Loss : 45198.3671875
Train_EnvstepsSoFar : 227821
TimeSinceStart : 157.71760368347168
Done logging...



********** Iteration 56 ************

Collecting data for eval...
Eval_AverageReturn : 102.25
Eval_StdReturn : 56.499446868896484
Eval_MaxReturn : 200.0
Eval_MinReturn : 67.0
Eval_AverageEpLen : 102.25
Train_AverageReturn : 142.03448486328125
Train_StdReturn : 60.85396957397461
Train_MaxReturn : 200.0
Train_MinReturn : 59.0
Train_AverageEpLen : 142.0344827586207
Actor Loss : 52657.859375
Train_EnvstepsSoFar : 231940
TimeSinceStart : 160.4284017086029
Done logging...



********** Iteration 57 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 155.44444274902344
Train_StdReturn : 51.08042526245117
Train_MaxReturn : 200.0
Train_MinReturn : 73.0
Train_AverageEpLen : 155.44444444444446
Actor Loss : 69905.890625
Train_EnvstepsSoFar : 236137
TimeSinceStart : 162.93260741233826
Done logging...



********** Iteration 58 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 174.56521606445312
Train_StdReturn : 44.61119842529297
Train_MaxReturn : 200.0
Train_MinReturn : 79.0
Train_AverageEpLen : 174.56521739130434
Actor Loss : 50946.7578125
Train_EnvstepsSoFar : 240152
TimeSinceStart : 165.3628921508789
Done logging...



********** Iteration 59 ************

Collecting data for eval...
Eval_AverageReturn : 160.3333282470703
Eval_StdReturn : 56.097137451171875
Eval_MaxReturn : 200.0
Eval_MinReturn : 81.0
Eval_AverageEpLen : 160.33333333333334
Train_AverageReturn : 144.92857360839844
Train_StdReturn : 50.749332427978516
Train_MaxReturn : 200.0
Train_MinReturn : 70.0
Train_AverageEpLen : 144.92857142857142
Actor Loss : 48683.4609375
Train_EnvstepsSoFar : 244210
TimeSinceStart : 167.89766430854797
Done logging...



********** Iteration 60 ************

Collecting data for eval...
Eval_AverageReturn : 140.6666717529297
Eval_StdReturn : 42.08192825317383
Eval_MaxReturn : 200.0
Eval_MinReturn : 107.0
Eval_AverageEpLen : 140.66666666666666
Train_AverageReturn : 171.25
Train_StdReturn : 50.32250213623047
Train_MaxReturn : 200.0
Train_MinReturn : 67.0
Train_AverageEpLen : 171.25
Actor Loss : 98094.0234375
Train_EnvstepsSoFar : 248320
TimeSinceStart : 170.75630283355713
Done logging...



********** Iteration 61 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 125.33333587646484
Train_StdReturn : 54.55643081665039
Train_MaxReturn : 200.0
Train_MinReturn : 68.0
Train_AverageEpLen : 125.33333333333333
Actor Loss : 69711.296875
Train_EnvstepsSoFar : 252456
TimeSinceStart : 173.68597650527954
Done logging...



********** Iteration 62 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 134.96774291992188
Train_StdReturn : 51.296409606933594
Train_MaxReturn : 200.0
Train_MinReturn : 68.0
Train_AverageEpLen : 134.96774193548387
Actor Loss : 36115.44921875
Train_EnvstepsSoFar : 256640
TimeSinceStart : 176.229257106781
Done logging...



********** Iteration 63 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 182.18182373046875
Train_StdReturn : 43.96552276611328
Train_MaxReturn : 200.0
Train_MinReturn : 65.0
Train_AverageEpLen : 182.1818181818182
Actor Loss : 95502.3046875
Train_EnvstepsSoFar : 260648
TimeSinceStart : 178.65326309204102
Done logging...



********** Iteration 64 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 157.1923065185547
Train_StdReturn : 55.24770736694336
Train_MaxReturn : 200.0
Train_MinReturn : 64.0
Train_AverageEpLen : 157.19230769230768
Actor Loss : 58607.20703125
Train_EnvstepsSoFar : 264735
TimeSinceStart : 181.12748908996582
Done logging...



********** Iteration 65 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 148.7142791748047
Train_StdReturn : 55.79225540161133
Train_MaxReturn : 200.0
Train_MinReturn : 72.0
Train_AverageEpLen : 148.71428571428572
Actor Loss : 77798.421875
Train_EnvstepsSoFar : 268899
TimeSinceStart : 183.6509301662445
Done logging...



********** Iteration 66 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 154.07408142089844
Train_StdReturn : 53.63037109375
Train_MaxReturn : 200.0
Train_MinReturn : 71.0
Train_AverageEpLen : 154.07407407407408
Actor Loss : 88819.5078125
Train_EnvstepsSoFar : 273059
TimeSinceStart : 186.13307547569275
Done logging...



********** Iteration 67 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 150.8518524169922
Train_StdReturn : 56.34267044067383
Train_MaxReturn : 200.0
Train_MinReturn : 72.0
Train_AverageEpLen : 150.85185185185185
Actor Loss : 90761.5390625
Train_EnvstepsSoFar : 277132
TimeSinceStart : 188.5589940547943
Done logging...



********** Iteration 68 ************

Collecting data for eval...
Eval_AverageReturn : 143.0
Eval_StdReturn : 44.6392936706543
Eval_MaxReturn : 200.0
Eval_MinReturn : 91.0
Eval_AverageEpLen : 143.0
Train_AverageReturn : 134.8000030517578
Train_StdReturn : 50.572322845458984
Train_MaxReturn : 200.0
Train_MinReturn : 72.0
Train_AverageEpLen : 134.8
Actor Loss : 52384.390625
Train_EnvstepsSoFar : 281176
TimeSinceStart : 190.99176216125488
Done logging...



********** Iteration 69 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 154.11538696289062
Train_StdReturn : 51.11474609375
Train_MaxReturn : 200.0
Train_MinReturn : 79.0
Train_AverageEpLen : 154.1153846153846
Actor Loss : 77370.828125
Train_EnvstepsSoFar : 285183
TimeSinceStart : 193.41662764549255
Done logging...



********** Iteration 70 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 160.8800048828125
Train_StdReturn : 53.024009704589844
Train_MaxReturn : 200.0
Train_MinReturn : 66.0
Train_AverageEpLen : 160.88
Actor Loss : 83601.59375
Train_EnvstepsSoFar : 289205
TimeSinceStart : 195.8236005306244
Done logging...



********** Iteration 71 ************

Collecting data for eval...
Eval_AverageReturn : 129.75
Eval_StdReturn : 42.920711517333984
Eval_MaxReturn : 200.0
Eval_MinReturn : 84.0
Eval_AverageEpLen : 129.75
Train_AverageReturn : 139.79310607910156
Train_StdReturn : 51.516571044921875
Train_MaxReturn : 200.0
Train_MinReturn : 78.0
Train_AverageEpLen : 139.79310344827587
Actor Loss : 59364.92578125
Train_EnvstepsSoFar : 293259
TimeSinceStart : 198.3723108768463
Done logging...



********** Iteration 72 ************

Collecting data for eval...
Eval_AverageReturn : 161.3333282470703
Eval_StdReturn : 54.682926177978516
Eval_MaxReturn : 200.0
Eval_MinReturn : 84.0
Eval_AverageEpLen : 161.33333333333334
Train_AverageReturn : 168.625
Train_StdReturn : 49.40631866455078
Train_MaxReturn : 200.0
Train_MinReturn : 68.0
Train_AverageEpLen : 168.625
Actor Loss : 107076.3515625
Train_EnvstepsSoFar : 297306
TimeSinceStart : 200.9016833305359
Done logging...



********** Iteration 73 ************

Collecting data for eval...
Eval_AverageReturn : 174.0
Eval_StdReturn : 36.769554138183594
Eval_MaxReturn : 200.0
Eval_MinReturn : 122.0
Eval_AverageEpLen : 174.0
Train_AverageReturn : 156.88461303710938
Train_StdReturn : 54.855987548828125
Train_MaxReturn : 200.0
Train_MinReturn : 78.0
Train_AverageEpLen : 156.8846153846154
Actor Loss : 93421.9375
Train_EnvstepsSoFar : 301385
TimeSinceStart : 203.4877200126648
Done logging...



********** Iteration 74 ************

Collecting data for eval...
Eval_AverageReturn : 181.0
Eval_StdReturn : 26.870058059692383
Eval_MaxReturn : 200.0
Eval_MinReturn : 143.0
Eval_AverageEpLen : 181.0
Train_AverageReturn : 149.0357208251953
Train_StdReturn : 56.20656204223633
Train_MaxReturn : 200.0
Train_MinReturn : 75.0
Train_AverageEpLen : 149.03571428571428
Actor Loss : 83062.09375
Train_EnvstepsSoFar : 305558
TimeSinceStart : 206.0598692893982
Done logging...



********** Iteration 75 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 160.47999572753906
Train_StdReturn : 51.107826232910156
Train_MaxReturn : 200.0
Train_MinReturn : 80.0
Train_AverageEpLen : 160.48
Actor Loss : 111520.96875
Train_EnvstepsSoFar : 309570
TimeSinceStart : 208.4676423072815
Done logging...



********** Iteration 76 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 160.0
Train_StdReturn : 53.88431930541992
Train_MaxReturn : 200.0
Train_MinReturn : 66.0
Train_AverageEpLen : 160.0
Actor Loss : 120821.234375
Train_EnvstepsSoFar : 313570
TimeSinceStart : 211.85787391662598
Done logging...



********** Iteration 77 ************

Collecting data for eval...
Eval_AverageReturn : 160.0
Eval_StdReturn : 56.56854248046875
Eval_MaxReturn : 200.0
Eval_MinReturn : 80.0
Eval_AverageEpLen : 160.0
Train_AverageReturn : 161.60000610351562
Train_StdReturn : 51.679012298583984
Train_MaxReturn : 200.0
Train_MinReturn : 75.0
Train_AverageEpLen : 161.6
Actor Loss : 104007.453125
Train_EnvstepsSoFar : 317610
TimeSinceStart : 214.3402543067932
Done logging...



********** Iteration 78 ************

Collecting data for eval...
Eval_AverageReturn : 179.6666717529297
Eval_StdReturn : 28.75567626953125
Eval_MaxReturn : 200.0
Eval_MinReturn : 139.0
Eval_AverageEpLen : 179.66666666666666
Train_AverageReturn : 160.6923065185547
Train_StdReturn : 51.49590301513672
Train_MaxReturn : 200.0
Train_MinReturn : 79.0
Train_AverageEpLen : 160.69230769230768
Actor Loss : 101115.5078125
Train_EnvstepsSoFar : 321788
TimeSinceStart : 216.93729305267334
Done logging...



********** Iteration 79 ************

Collecting data for eval...
Eval_AverageReturn : 186.3333282470703
Eval_StdReturn : 19.327585220336914
Eval_MaxReturn : 200.0
Eval_MinReturn : 159.0
Eval_AverageEpLen : 186.33333333333334
Train_AverageReturn : 174.47825622558594
Train_StdReturn : 44.427635192871094
Train_MaxReturn : 200.0
Train_MinReturn : 80.0
Train_AverageEpLen : 174.47826086956522
Actor Loss : 129288.2109375
Train_EnvstepsSoFar : 325801
TimeSinceStart : 222.31136965751648
Done logging...



********** Iteration 80 ************

Collecting data for eval...
Eval_AverageReturn : 146.3333282470703
Eval_StdReturn : 42.523197174072266
Eval_MaxReturn : 200.0
Eval_MinReturn : 96.0
Eval_AverageEpLen : 146.33333333333334
Train_AverageReturn : 185.68182373046875
Train_StdReturn : 36.27970504760742
Train_MaxReturn : 200.0
Train_MinReturn : 85.0
Train_AverageEpLen : 185.6818181818182
Actor Loss : 143857.15625
Train_EnvstepsSoFar : 329886
TimeSinceStart : 224.8089153766632
Done logging...



********** Iteration 81 ************

Collecting data for eval...
Eval_AverageReturn : 186.3333282470703
Eval_StdReturn : 19.327585220336914
Eval_MaxReturn : 200.0
Eval_MinReturn : 159.0
Eval_AverageEpLen : 186.33333333333334
Train_AverageReturn : 165.60000610351562
Train_StdReturn : 48.10737991333008
Train_MaxReturn : 200.0
Train_MinReturn : 77.0
Train_AverageEpLen : 165.6
Actor Loss : 96586.4453125
Train_EnvstepsSoFar : 334026
TimeSinceStart : 227.38636255264282
Done logging...



********** Iteration 82 ************

Collecting data for eval...
Eval_AverageReturn : 138.6666717529297
Eval_StdReturn : 44.289451599121094
Eval_MaxReturn : 200.0
Eval_MinReturn : 97.0
Eval_AverageEpLen : 138.66666666666666
Train_AverageReturn : 180.3478240966797
Train_StdReturn : 42.945472717285156
Train_MaxReturn : 200.0
Train_MinReturn : 77.0
Train_AverageEpLen : 180.34782608695653
Actor Loss : 128667.453125
Train_EnvstepsSoFar : 338174
TimeSinceStart : 230.22908735275269
Done logging...



********** Iteration 83 ************

Collecting data for eval...
Eval_AverageReturn : 169.6666717529297
Eval_StdReturn : 42.89781188964844
Eval_MaxReturn : 200.0
Eval_MinReturn : 109.0
Eval_AverageEpLen : 169.66666666666666
Train_AverageReturn : 174.9130401611328
Train_StdReturn : 43.680572509765625
Train_MaxReturn : 200.0
Train_MinReturn : 80.0
Train_AverageEpLen : 174.91304347826087
Actor Loss : 131946.90625
Train_EnvstepsSoFar : 342197
TimeSinceStart : 232.77763628959656
Done logging...



********** Iteration 84 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 170.6666717529297
Train_StdReturn : 46.89497756958008
Train_MaxReturn : 200.0
Train_MinReturn : 81.0
Train_AverageEpLen : 170.66666666666666
Actor Loss : 124173.515625
Train_EnvstepsSoFar : 346293
TimeSinceStart : 235.2000699043274
Done logging...



********** Iteration 85 ************

Collecting data for eval...
Eval_AverageReturn : 167.6666717529297
Eval_StdReturn : 45.72623825073242
Eval_MaxReturn : 200.0
Eval_MinReturn : 103.0
Eval_AverageEpLen : 167.66666666666666
Train_AverageReturn : 167.0800018310547
Train_StdReturn : 48.546817779541016
Train_MaxReturn : 200.0
Train_MinReturn : 83.0
Train_AverageEpLen : 167.08
Actor Loss : 113616.6015625
Train_EnvstepsSoFar : 350470
TimeSinceStart : 237.7675449848175
Done logging...



********** Iteration 86 ************

Collecting data for eval...
Eval_AverageReturn : 167.0
Eval_StdReturn : 46.66904830932617
Eval_MaxReturn : 200.0
Eval_MinReturn : 101.0
Eval_AverageEpLen : 167.0
Train_AverageReturn : 177.7391357421875
Train_StdReturn : 40.70596694946289
Train_MaxReturn : 200.0
Train_MinReturn : 91.0
Train_AverageEpLen : 177.7391304347826
Actor Loss : 121210.75
Train_EnvstepsSoFar : 354558
TimeSinceStart : 241.88090133666992
Done logging...



********** Iteration 87 ************

Collecting data for eval...
Eval_AverageReturn : 159.3333282470703
Eval_StdReturn : 28.8020076751709
Eval_MaxReturn : 200.0
Eval_MinReturn : 137.0
Eval_AverageEpLen : 159.33333333333334
Train_AverageReturn : 168.0
Train_StdReturn : 46.2484245300293
Train_MaxReturn : 200.0
Train_MinReturn : 88.0
Train_AverageEpLen : 168.0
Actor Loss : 112391.125
Train_EnvstepsSoFar : 358590
TimeSinceStart : 244.3551127910614
Done logging...



********** Iteration 88 ************

Collecting data for eval...
Eval_AverageReturn : 180.0
Eval_StdReturn : 28.284271240234375
Eval_MaxReturn : 200.0
Eval_MinReturn : 140.0
Eval_AverageEpLen : 180.0
Train_AverageReturn : 162.72000122070312
Train_StdReturn : 47.00001525878906
Train_MaxReturn : 200.0
Train_MinReturn : 85.0
Train_AverageEpLen : 162.72
Actor Loss : 106250.8203125
Train_EnvstepsSoFar : 362658
TimeSinceStart : 246.91166758537292
Done logging...



********** Iteration 89 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 154.0
Train_StdReturn : 49.8390007019043
Train_MaxReturn : 200.0
Train_MinReturn : 87.0
Train_AverageEpLen : 154.0
Actor Loss : 93199.5
Train_EnvstepsSoFar : 366816
TimeSinceStart : 249.38974523544312
Done logging...



********** Iteration 90 ************

Collecting data for eval...
Eval_AverageReturn : 176.0
Eval_StdReturn : 33.941123962402344
Eval_MaxReturn : 200.0
Eval_MinReturn : 128.0
Eval_AverageEpLen : 176.0
Train_AverageReturn : 184.5
Train_StdReturn : 33.814666748046875
Train_MaxReturn : 200.0
Train_MinReturn : 90.0
Train_AverageEpLen : 184.5
Actor Loss : 116814.5625
Train_EnvstepsSoFar : 370875
TimeSinceStart : 251.9097490310669
Done logging...



********** Iteration 91 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 191.38095092773438
Train_StdReturn : 27.23876190185547
Train_MaxReturn : 200.0
Train_MinReturn : 90.0
Train_AverageEpLen : 191.38095238095238
Actor Loss : 133476.703125
Train_EnvstepsSoFar : 374894
TimeSinceStart : 254.36088371276855
Done logging...



********** Iteration 92 ************

Collecting data for eval...
Eval_AverageReturn : 165.3333282470703
Eval_StdReturn : 49.02606964111328
Eval_MaxReturn : 200.0
Eval_MinReturn : 96.0
Eval_AverageEpLen : 165.33333333333334
Train_AverageReturn : 177.6521759033203
Train_StdReturn : 38.36847686767578
Train_MaxReturn : 200.0
Train_MinReturn : 98.0
Train_AverageEpLen : 177.65217391304347
Actor Loss : 118954.84375
Train_EnvstepsSoFar : 378980
TimeSinceStart : 256.9389088153839
Done logging...



********** Iteration 93 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 170.4166717529297
Train_StdReturn : 43.05414962768555
Train_MaxReturn : 200.0
Train_MinReturn : 94.0
Train_AverageEpLen : 170.41666666666666
Actor Loss : 104414.9921875
Train_EnvstepsSoFar : 383070
TimeSinceStart : 259.4142460823059
Done logging...



********** Iteration 94 ************

Collecting data for eval...
Eval_AverageReturn : 128.75
Eval_StdReturn : 42.31060791015625
Eval_MaxReturn : 200.0
Eval_MinReturn : 95.0
Eval_AverageEpLen : 128.75
Train_AverageReturn : 174.8333282470703
Train_StdReturn : 39.621826171875
Train_MaxReturn : 200.0
Train_MinReturn : 94.0
Train_AverageEpLen : 174.83333333333334
Actor Loss : 115104.8125
Train_EnvstepsSoFar : 387266
TimeSinceStart : 262.02937507629395
Done logging...



********** Iteration 95 ************

Collecting data for eval...
Eval_AverageReturn : 128.0
Eval_StdReturn : 34.92134094238281
Eval_MaxReturn : 185.0
Eval_MinReturn : 92.0
Eval_AverageEpLen : 128.0
Train_AverageReturn : 174.78260803222656
Train_StdReturn : 39.05955123901367
Train_MaxReturn : 200.0
Train_MinReturn : 99.0
Train_AverageEpLen : 174.7826086956522
Actor Loss : 98407.1875
Train_EnvstepsSoFar : 391286
TimeSinceStart : 264.5363042354584
Done logging...



********** Iteration 96 ************

Collecting data for eval...
Eval_AverageReturn : 148.0
Eval_StdReturn : 36.9954948425293
Eval_MaxReturn : 200.0
Eval_MinReturn : 117.0
Eval_AverageEpLen : 148.0
Train_AverageReturn : 176.3913116455078
Train_StdReturn : 40.554569244384766
Train_MaxReturn : 200.0
Train_MinReturn : 88.0
Train_AverageEpLen : 176.3913043478261
Actor Loss : 109562.0703125
Train_EnvstepsSoFar : 395343
TimeSinceStart : 266.99683237075806
Done logging...



********** Iteration 97 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 161.42308044433594
Train_StdReturn : 42.755271911621094
Train_MaxReturn : 200.0
Train_MinReturn : 95.0
Train_AverageEpLen : 161.42307692307693
Actor Loss : 85632.6015625
Train_EnvstepsSoFar : 399540
TimeSinceStart : 269.47535610198975
Done logging...



********** Iteration 98 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 174.86956787109375
Train_StdReturn : 39.01873016357422
Train_MaxReturn : 200.0
Train_MinReturn : 99.0
Train_AverageEpLen : 174.8695652173913
Actor Loss : 105407.5234375
Train_EnvstepsSoFar : 403562
TimeSinceStart : 271.91120648384094
Done logging...



********** Iteration 99 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 181.0
Train_StdReturn : 32.1261100769043
Train_MaxReturn : 200.0
Train_MinReturn : 115.0
Train_AverageEpLen : 181.0
Actor Loss : 102311.84375
Train_EnvstepsSoFar : 407725
TimeSinceStart : 274.3999125957489
Done logging...



********** Iteration 100 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 176.3913116455078
Train_StdReturn : 33.61642837524414
Train_MaxReturn : 200.0
Train_MinReturn : 110.0
Train_AverageEpLen : 176.3913043478261
Actor Loss : 92420.15625
Train_EnvstepsSoFar : 411782
TimeSinceStart : 276.8120617866516
Done logging...



********** Iteration 101 ************

Collecting data for eval...
Eval_AverageReturn : 161.6666717529297
Eval_StdReturn : 28.429248809814453
Eval_MaxReturn : 200.0
Eval_MinReturn : 132.0
Eval_AverageEpLen : 161.66666666666666
Train_AverageReturn : 172.3333282470703
Train_StdReturn : 37.295738220214844
Train_MaxReturn : 200.0
Train_MinReturn : 94.0
Train_AverageEpLen : 172.33333333333334
Actor Loss : 94562.25
Train_EnvstepsSoFar : 415918
TimeSinceStart : 280.41026067733765
Done logging...



********** Iteration 102 ************

Collecting data for eval...
Eval_AverageReturn : 183.0
Eval_StdReturn : 12.83225154876709
Eval_MaxReturn : 200.0
Eval_MinReturn : 169.0
Eval_AverageEpLen : 183.0
Train_AverageReturn : 177.0
Train_StdReturn : 32.83026123046875
Train_MaxReturn : 200.0
Train_MinReturn : 113.0
Train_AverageEpLen : 177.0
Actor Loss : 90598.6328125
Train_EnvstepsSoFar : 419989
TimeSinceStart : 282.91087555885315
Done logging...



********** Iteration 103 ************

Collecting data for eval...
Eval_AverageReturn : 181.0
Eval_StdReturn : 26.870058059692383
Eval_MaxReturn : 200.0
Eval_MinReturn : 143.0
Eval_AverageEpLen : 181.0
Train_AverageReturn : 185.27272033691406
Train_StdReturn : 27.594764709472656
Train_MaxReturn : 200.0
Train_MinReturn : 119.0
Train_AverageEpLen : 185.27272727272728
Actor Loss : 108094.296875
Train_EnvstepsSoFar : 424065
TimeSinceStart : 285.41834235191345
Done logging...



********** Iteration 104 ************

Collecting data for eval...
Eval_AverageReturn : 171.6666717529297
Eval_StdReturn : 20.949674606323242
Eval_MaxReturn : 200.0
Eval_MinReturn : 150.0
Eval_AverageEpLen : 171.66666666666666
Train_AverageReturn : 184.68182373046875
Train_StdReturn : 28.920560836791992
Train_MaxReturn : 200.0
Train_MinReturn : 118.0
Train_AverageEpLen : 184.6818181818182
Actor Loss : 100276.6328125
Train_EnvstepsSoFar : 428128
TimeSinceStart : 287.9640233516693
Done logging...



********** Iteration 105 ************

Collecting data for eval...
Eval_AverageReturn : 177.3333282470703
Eval_StdReturn : 32.05550765991211
Eval_MaxReturn : 200.0
Eval_MinReturn : 132.0
Eval_AverageEpLen : 177.33333333333334
Train_AverageReturn : 188.36363220214844
Train_StdReturn : 24.858776092529297
Train_MaxReturn : 200.0
Train_MinReturn : 123.0
Train_AverageEpLen : 188.36363636363637
Actor Loss : 92525.421875
Train_EnvstepsSoFar : 432272
TimeSinceStart : 290.5688898563385
Done logging...



********** Iteration 106 ************

Collecting data for eval...
Eval_AverageReturn : 189.3333282470703
Eval_StdReturn : 15.084944725036621
Eval_MaxReturn : 200.0
Eval_MinReturn : 168.0
Eval_AverageEpLen : 189.33333333333334
Train_AverageReturn : 195.2857208251953
Train_StdReturn : 14.392932891845703
Train_MaxReturn : 200.0
Train_MinReturn : 137.0
Train_AverageEpLen : 195.28571428571428
Actor Loss : 99293.09375
Train_EnvstepsSoFar : 436373
TimeSinceStart : 293.1124885082245
Done logging...



********** Iteration 107 ************

Collecting data for eval...
Eval_AverageReturn : 190.6666717529297
Eval_StdReturn : 13.199326515197754
Eval_MaxReturn : 200.0
Eval_MinReturn : 172.0
Eval_AverageEpLen : 190.66666666666666
Train_AverageReturn : 186.22727966308594
Train_StdReturn : 23.023569107055664
Train_MaxReturn : 200.0
Train_MinReturn : 130.0
Train_AverageEpLen : 186.22727272727272
Actor Loss : 80776.703125
Train_EnvstepsSoFar : 440470
TimeSinceStart : 295.6913938522339
Done logging...



********** Iteration 108 ************

Collecting data for eval...
Eval_AverageReturn : 182.6666717529297
Eval_StdReturn : 24.51303482055664
Eval_MaxReturn : 200.0
Eval_MinReturn : 148.0
Eval_AverageEpLen : 182.66666666666666
Train_AverageReturn : 190.4545440673828
Train_StdReturn : 16.013423919677734
Train_MaxReturn : 200.0
Train_MinReturn : 152.0
Train_AverageEpLen : 190.45454545454547
Actor Loss : 76041.9765625
Train_EnvstepsSoFar : 444660
TimeSinceStart : 298.5267014503479
Done logging...



********** Iteration 109 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 189.68182373046875
Train_StdReturn : 16.352333068847656
Train_MaxReturn : 200.0
Train_MinReturn : 157.0
Train_AverageEpLen : 189.6818181818182
Actor Loss : 81116.015625
Train_EnvstepsSoFar : 448833
TimeSinceStart : 301.0797390937805
Done logging...



********** Iteration 110 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 198.2857208251953
Train_StdReturn : 5.292788028717041
Train_MaxReturn : 200.0
Train_MinReturn : 181.0
Train_AverageEpLen : 198.28571428571428
Actor Loss : 90247.84375
Train_EnvstepsSoFar : 452997
TimeSinceStart : 304.30139660835266
Done logging...



********** Iteration 111 ************

Collecting data for eval...
Eval_AverageReturn : 192.3333282470703
Eval_StdReturn : 10.842304229736328
Eval_MaxReturn : 200.0
Eval_MinReturn : 177.0
Eval_AverageEpLen : 192.33333333333334
Train_AverageReturn : 194.85714721679688
Train_StdReturn : 13.231584548950195
Train_MaxReturn : 200.0
Train_MinReturn : 152.0
Train_AverageEpLen : 194.85714285714286
Actor Loss : 89508.0
Train_EnvstepsSoFar : 457089
TimeSinceStart : 306.8260750770569
Done logging...



********** Iteration 112 ************

Collecting data for eval...
Eval_AverageReturn : 194.6666717529297
Eval_StdReturn : 7.542471885681152
Eval_MaxReturn : 200.0
Eval_MinReturn : 184.0
Eval_AverageEpLen : 194.66666666666666
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 90666.2265625
Train_EnvstepsSoFar : 461089
TimeSinceStart : 309.32675194740295
Done logging...



********** Iteration 113 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 198.38095092773438
Train_StdReturn : 7.240601539611816
Train_MaxReturn : 200.0
Train_MinReturn : 166.0
Train_AverageEpLen : 198.38095238095238
Actor Loss : 93369.671875
Train_EnvstepsSoFar : 465255
TimeSinceStart : 311.82376980781555
Done logging...



********** Iteration 114 ************

Collecting data for eval...
Eval_AverageReturn : 183.3333282470703
Eval_StdReturn : 15.326086044311523
Eval_MaxReturn : 200.0
Eval_MinReturn : 163.0
Eval_AverageEpLen : 183.33333333333334
Train_AverageReturn : 194.38095092773438
Train_StdReturn : 13.674711227416992
Train_MaxReturn : 200.0
Train_MinReturn : 151.0
Train_AverageEpLen : 194.38095238095238
Actor Loss : 67096.6015625
Train_EnvstepsSoFar : 469337
TimeSinceStart : 314.3676161766052
Done logging...



********** Iteration 115 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 197.42857360839844
Train_StdReturn : 7.761757850646973
Train_MaxReturn : 200.0
Train_MinReturn : 164.0
Train_AverageEpLen : 197.42857142857142
Actor Loss : 76208.6328125
Train_EnvstepsSoFar : 473483
TimeSinceStart : 316.85582280158997
Done logging...



********** Iteration 116 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 190.8095245361328
Train_StdReturn : 15.858358383178711
Train_MaxReturn : 200.0
Train_MinReturn : 156.0
Train_AverageEpLen : 190.8095238095238
Actor Loss : 70241.15625
Train_EnvstepsSoFar : 477490
TimeSinceStart : 319.2774438858032
Done logging...



********** Iteration 117 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 196.85714721679688
Train_StdReturn : 8.481271743774414
Train_MaxReturn : 200.0
Train_MinReturn : 169.0
Train_AverageEpLen : 196.85714285714286
Actor Loss : 77269.125
Train_EnvstepsSoFar : 481624
TimeSinceStart : 323.19367384910583
Done logging...



********** Iteration 118 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 196.09524536132812
Train_StdReturn : 8.34325885772705
Train_MaxReturn : 200.0
Train_MinReturn : 175.0
Train_AverageEpLen : 196.0952380952381
Actor Loss : 67182.9921875
Train_EnvstepsSoFar : 485742
TimeSinceStart : 325.676575422287
Done logging...



********** Iteration 119 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 92275.671875
Train_EnvstepsSoFar : 489742
TimeSinceStart : 328.09445452690125
Done logging...



********** Iteration 120 ************

Collecting data for eval...
Eval_AverageReturn : 188.6666717529297
Eval_StdReturn : 16.027753829956055
Eval_MaxReturn : 200.0
Eval_MinReturn : 166.0
Eval_AverageEpLen : 188.66666666666666
Train_AverageReturn : 196.85714721679688
Train_StdReturn : 8.972369194030762
Train_MaxReturn : 200.0
Train_MinReturn : 161.0
Train_AverageEpLen : 196.85714285714286
Actor Loss : 53499.1796875
Train_EnvstepsSoFar : 493876
TimeSinceStart : 330.65121722221375
Done logging...



********** Iteration 121 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 87118.3125
Train_EnvstepsSoFar : 497876
TimeSinceStart : 333.0587532520294
Done logging...



********** Iteration 122 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 198.38095092773438
Train_StdReturn : 5.066004753112793
Train_MaxReturn : 200.0
Train_MinReturn : 177.0
Train_AverageEpLen : 198.38095238095238
Actor Loss : 66307.0859375
Train_EnvstepsSoFar : 502042
TimeSinceStart : 335.5573835372925
Done logging...



********** Iteration 123 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 197.76190185546875
Train_StdReturn : 9.36001968383789
Train_MaxReturn : 200.0
Train_MinReturn : 156.0
Train_AverageEpLen : 197.76190476190476
Actor Loss : 73754.890625
Train_EnvstepsSoFar : 506195
TimeSinceStart : 338.0636456012726
Done logging...



********** Iteration 124 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 196.09524536132812
Train_StdReturn : 12.133796691894531
Train_MaxReturn : 200.0
Train_MinReturn : 154.0
Train_AverageEpLen : 196.0952380952381
Actor Loss : 82144.328125
Train_EnvstepsSoFar : 510313
TimeSinceStart : 340.53045654296875
Done logging...



********** Iteration 125 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 199.85714721679688
Train_StdReturn : 0.6388765573501587
Train_MaxReturn : 200.0
Train_MinReturn : 197.0
Train_AverageEpLen : 199.85714285714286
Actor Loss : 81656.765625
Train_EnvstepsSoFar : 514510
TimeSinceStart : 344.3120217323303
Done logging...



********** Iteration 126 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 197.6666717529297
Train_StdReturn : 5.914738655090332
Train_MaxReturn : 200.0
Train_MinReturn : 178.0
Train_AverageEpLen : 197.66666666666666
Actor Loss : 68628.328125
Train_EnvstepsSoFar : 518661
TimeSinceStart : 346.8195285797119
Done logging...



********** Iteration 127 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 199.42857360839844
Train_StdReturn : 2.5555059909820557
Train_MaxReturn : 200.0
Train_MinReturn : 188.0
Train_AverageEpLen : 199.42857142857142
Actor Loss : 77366.1875
Train_EnvstepsSoFar : 522849
TimeSinceStart : 349.2626175880432
Done logging...



********** Iteration 128 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 78380.09375
Train_EnvstepsSoFar : 526849
TimeSinceStart : 351.6729176044464
Done logging...



********** Iteration 129 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 70842.96875
Train_EnvstepsSoFar : 530849
TimeSinceStart : 354.07485461235046
Done logging...



********** Iteration 130 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 65890.96875
Train_EnvstepsSoFar : 534849
TimeSinceStart : 356.4867079257965
Done logging...



********** Iteration 131 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 70631.3125
Train_EnvstepsSoFar : 538849
TimeSinceStart : 358.90036058425903
Done logging...



********** Iteration 132 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 68834.671875
Train_EnvstepsSoFar : 542849
TimeSinceStart : 361.316908121109
Done logging...



********** Iteration 133 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 198.4761962890625
Train_StdReturn : 6.814682960510254
Train_MaxReturn : 200.0
Train_MinReturn : 168.0
Train_AverageEpLen : 198.47619047619048
Actor Loss : 70755.6640625
Train_EnvstepsSoFar : 547017
TimeSinceStart : 364.6355469226837
Done logging...



********** Iteration 134 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 199.42857360839844
Train_StdReturn : 2.5555059909820557
Train_MaxReturn : 200.0
Train_MinReturn : 188.0
Train_AverageEpLen : 199.42857142857142
Actor Loss : 71690.828125
Train_EnvstepsSoFar : 551205
TimeSinceStart : 367.1465599536896
Done logging...



********** Iteration 135 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 69225.640625
Train_EnvstepsSoFar : 555205
TimeSinceStart : 369.7125678062439
Done logging...



********** Iteration 136 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 66886.1484375
Train_EnvstepsSoFar : 559205
TimeSinceStart : 372.155442237854
Done logging...



********** Iteration 137 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 68778.25
Train_EnvstepsSoFar : 563205
TimeSinceStart : 374.6697292327881
Done logging...



********** Iteration 138 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 66165.75
Train_EnvstepsSoFar : 567205
TimeSinceStart : 377.12653374671936
Done logging...



********** Iteration 139 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 64721.7734375
Train_EnvstepsSoFar : 571205
TimeSinceStart : 379.5367486476898
Done logging...



********** Iteration 140 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 65160.65625
Train_EnvstepsSoFar : 575205
TimeSinceStart : 382.0326352119446
Done logging...



********** Iteration 141 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 65523.3359375
Train_EnvstepsSoFar : 579205
TimeSinceStart : 384.94481229782104
Done logging...



********** Iteration 142 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 65553.2265625
Train_EnvstepsSoFar : 583205
TimeSinceStart : 389.0219917297363
Done logging...



********** Iteration 143 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 62120.66015625
Train_EnvstepsSoFar : 587205
TimeSinceStart : 391.421914100647
Done logging...



********** Iteration 144 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 60665.3359375
Train_EnvstepsSoFar : 591205
TimeSinceStart : 393.90343713760376
Done logging...



********** Iteration 145 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 60803.5
Train_EnvstepsSoFar : 595205
TimeSinceStart : 396.2687420845032
Done logging...



********** Iteration 146 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 60801.3671875
Train_EnvstepsSoFar : 599205
TimeSinceStart : 399.4353883266449
Done logging...



********** Iteration 147 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 62021.04296875
Train_EnvstepsSoFar : 603205
TimeSinceStart : 402.06947803497314
Done logging...



********** Iteration 148 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 59252.91015625
Train_EnvstepsSoFar : 607205
TimeSinceStart : 405.0753927230835
Done logging...



********** Iteration 149 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 58015.3125
Train_EnvstepsSoFar : 611205
TimeSinceStart : 407.99852228164673
Done logging...



********** Iteration 150 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 58524.640625
Train_EnvstepsSoFar : 615205
TimeSinceStart : 410.45405197143555
Done logging...



********** Iteration 151 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 59245.4296875
Train_EnvstepsSoFar : 619205
TimeSinceStart : 413.71405029296875
Done logging...



********** Iteration 152 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 56232.515625
Train_EnvstepsSoFar : 623205
TimeSinceStart : 416.9795777797699
Done logging...



********** Iteration 153 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 54062.1171875
Train_EnvstepsSoFar : 627205
TimeSinceStart : 420.1626241207123
Done logging...



********** Iteration 154 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 57900.40625
Train_EnvstepsSoFar : 631205
TimeSinceStart : 423.10320138931274
Done logging...



********** Iteration 155 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 55772.1484375
Train_EnvstepsSoFar : 635205
TimeSinceStart : 426.3191878795624
Done logging...



********** Iteration 156 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 55529.0859375
Train_EnvstepsSoFar : 639205
TimeSinceStart : 429.2510278224945
Done logging...



********** Iteration 157 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 55114.8125
Train_EnvstepsSoFar : 643205
TimeSinceStart : 432.4943640232086
Done logging...



********** Iteration 158 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 50743.57421875
Train_EnvstepsSoFar : 647205
TimeSinceStart : 435.37765288352966
Done logging...



********** Iteration 159 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 54924.60546875
Train_EnvstepsSoFar : 651205
TimeSinceStart : 438.4497547149658
Done logging...



********** Iteration 160 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 53451.34375
Train_EnvstepsSoFar : 655205
TimeSinceStart : 441.6052579879761
Done logging...



********** Iteration 161 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 50722.5
Train_EnvstepsSoFar : 659205
TimeSinceStart : 444.35569405555725
Done logging...



********** Iteration 162 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 52779.859375
Train_EnvstepsSoFar : 663205
TimeSinceStart : 448.49300837516785
Done logging...



********** Iteration 163 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 50996.4296875
Train_EnvstepsSoFar : 667205
TimeSinceStart : 451.71426796913147
Done logging...



********** Iteration 164 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 51173.49609375
Train_EnvstepsSoFar : 671205
TimeSinceStart : 454.2821249961853
Done logging...



********** Iteration 165 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 50879.7890625
Train_EnvstepsSoFar : 675205
TimeSinceStart : 457.0008897781372
Done logging...



********** Iteration 166 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 48705.8515625
Train_EnvstepsSoFar : 679205
TimeSinceStart : 459.3854742050171
Done logging...



********** Iteration 167 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 52859.046875
Train_EnvstepsSoFar : 683205
TimeSinceStart : 461.9288387298584
Done logging...



********** Iteration 168 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 50435.734375
Train_EnvstepsSoFar : 687205
TimeSinceStart : 464.8334906101227
Done logging...



********** Iteration 169 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 48597.9375
Train_EnvstepsSoFar : 691205
TimeSinceStart : 468.4369683265686
Done logging...



********** Iteration 170 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 48224.0234375
Train_EnvstepsSoFar : 695205
TimeSinceStart : 471.5592999458313
Done logging...



********** Iteration 171 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 51588.078125
Train_EnvstepsSoFar : 699205
TimeSinceStart : 474.7028453350067
Done logging...



********** Iteration 172 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 46297.2109375
Train_EnvstepsSoFar : 703205
TimeSinceStart : 477.8654670715332
Done logging...



********** Iteration 173 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 47198.859375
Train_EnvstepsSoFar : 707205
TimeSinceStart : 480.9853057861328
Done logging...



********** Iteration 174 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 45293.9609375
Train_EnvstepsSoFar : 711205
TimeSinceStart : 483.9369466304779
Done logging...



********** Iteration 175 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 44523.68359375
Train_EnvstepsSoFar : 715205
TimeSinceStart : 486.777379989624
Done logging...



********** Iteration 176 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 49124.0625
Train_EnvstepsSoFar : 719205
TimeSinceStart : 489.9885084629059
Done logging...



********** Iteration 177 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 47965.0546875
Train_EnvstepsSoFar : 723205
TimeSinceStart : 492.8989751338959
Done logging...



********** Iteration 178 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 42831.765625
Train_EnvstepsSoFar : 727205
TimeSinceStart : 496.11456298828125
Done logging...



********** Iteration 179 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 43763.4140625
Train_EnvstepsSoFar : 731205
TimeSinceStart : 499.08692741394043
Done logging...



********** Iteration 180 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 44628.5234375
Train_EnvstepsSoFar : 735205
TimeSinceStart : 502.22481870651245
Done logging...



********** Iteration 181 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 44361.6171875
Train_EnvstepsSoFar : 739205
TimeSinceStart : 505.18767070770264
Done logging...



********** Iteration 182 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 45731.69921875
Train_EnvstepsSoFar : 743205
TimeSinceStart : 508.09059858322144
Done logging...



********** Iteration 183 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 44528.8515625
Train_EnvstepsSoFar : 747205
TimeSinceStart : 510.96315360069275
Done logging...



********** Iteration 184 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 42732.18359375
Train_EnvstepsSoFar : 751205
TimeSinceStart : 514.1115989685059
Done logging...



********** Iteration 185 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 41970.83203125
Train_EnvstepsSoFar : 755205
TimeSinceStart : 517.3236675262451
Done logging...



********** Iteration 186 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 43797.703125
Train_EnvstepsSoFar : 759205
TimeSinceStart : 520.3817756175995
Done logging...



********** Iteration 187 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 45364.09765625
Train_EnvstepsSoFar : 763205
TimeSinceStart : 523.6105372905731
Done logging...



********** Iteration 188 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 46136.4375
Train_EnvstepsSoFar : 767205
TimeSinceStart : 526.3106093406677
Done logging...



********** Iteration 189 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 44322.0546875
Train_EnvstepsSoFar : 771205
TimeSinceStart : 529.5218939781189
Done logging...



********** Iteration 190 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 42177.953125
Train_EnvstepsSoFar : 775205
TimeSinceStart : 532.7263875007629
Done logging...



********** Iteration 191 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 42991.7265625
Train_EnvstepsSoFar : 779205
TimeSinceStart : 535.8518452644348
Done logging...



********** Iteration 192 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 42138.32421875
Train_EnvstepsSoFar : 783205
TimeSinceStart : 539.0652897357941
Done logging...



********** Iteration 193 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 40382.765625
Train_EnvstepsSoFar : 787205
TimeSinceStart : 542.0241601467133
Done logging...



********** Iteration 194 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 39478.1875
Train_EnvstepsSoFar : 791205
TimeSinceStart : 544.6269645690918
Done logging...



********** Iteration 195 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 40644.65625
Train_EnvstepsSoFar : 795205
TimeSinceStart : 547.774683713913
Done logging...



********** Iteration 196 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 39787.57421875
Train_EnvstepsSoFar : 799205
TimeSinceStart : 550.9356038570404
Done logging...



********** Iteration 197 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 41286.34765625
Train_EnvstepsSoFar : 803205
TimeSinceStart : 553.3797640800476
Done logging...



********** Iteration 198 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 42736.703125
Train_EnvstepsSoFar : 807205
TimeSinceStart : 556.2457618713379
Done logging...



********** Iteration 199 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 40055.65625
Train_EnvstepsSoFar : 811205
TimeSinceStart : 559.1129105091095
Done logging...



********** Iteration 200 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 39002.33984375
Train_EnvstepsSoFar : 815205
TimeSinceStart : 562.0419192314148
Done logging...



********** Iteration 201 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 39524.9609375
Train_EnvstepsSoFar : 819205
TimeSinceStart : 564.9374620914459
Done logging...



********** Iteration 202 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 42563.640625
Train_EnvstepsSoFar : 823205
TimeSinceStart : 568.1392004489899
Done logging...



********** Iteration 203 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 44095.3515625
Train_EnvstepsSoFar : 827205
TimeSinceStart : 572.1008205413818
Done logging...



********** Iteration 204 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 40658.98046875
Train_EnvstepsSoFar : 831205
TimeSinceStart : 575.4684171676636
Done logging...



********** Iteration 205 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 43702.2421875
Train_EnvstepsSoFar : 835205
TimeSinceStart : 578.6684985160828
Done logging...



********** Iteration 206 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 41152.6640625
Train_EnvstepsSoFar : 839205
TimeSinceStart : 581.1113338470459
Done logging...



********** Iteration 207 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 41809.1484375
Train_EnvstepsSoFar : 843205
TimeSinceStart : 583.4864103794098
Done logging...



********** Iteration 208 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 40689.2109375
Train_EnvstepsSoFar : 847205
TimeSinceStart : 586.0710983276367
Done logging...



********** Iteration 209 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 40617.7109375
Train_EnvstepsSoFar : 851205
TimeSinceStart : 588.4832377433777
Done logging...



********** Iteration 210 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 39592.015625
Train_EnvstepsSoFar : 855205
TimeSinceStart : 592.1179761886597
Done logging...



********** Iteration 211 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 41942.6484375
Train_EnvstepsSoFar : 859205
TimeSinceStart : 595.1092164516449
Done logging...



********** Iteration 212 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 39025.7109375
Train_EnvstepsSoFar : 863205
TimeSinceStart : 597.5785133838654
Done logging...



********** Iteration 213 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 37432.83984375
Train_EnvstepsSoFar : 867205
TimeSinceStart : 599.9157557487488
Done logging...



********** Iteration 214 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 41953.5859375
Train_EnvstepsSoFar : 871205
TimeSinceStart : 602.3297603130341
Done logging...



********** Iteration 215 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 34890.46484375
Train_EnvstepsSoFar : 875205
TimeSinceStart : 605.2633857727051
Done logging...



********** Iteration 216 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 37059.93359375
Train_EnvstepsSoFar : 879205
TimeSinceStart : 608.7863211631775
Done logging...



********** Iteration 217 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 35244.6640625
Train_EnvstepsSoFar : 883205
TimeSinceStart : 614.831857919693
Done logging...



********** Iteration 218 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 39571.08984375
Train_EnvstepsSoFar : 887205
TimeSinceStart : 617.1712357997894
Done logging...



********** Iteration 219 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 35798.734375
Train_EnvstepsSoFar : 891205
TimeSinceStart : 620.0242402553558
Done logging...



********** Iteration 220 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 36543.62109375
Train_EnvstepsSoFar : 895205
TimeSinceStart : 626.0722641944885
Done logging...



********** Iteration 221 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 35944.8984375
Train_EnvstepsSoFar : 899205
TimeSinceStart : 628.4159297943115
Done logging...



********** Iteration 222 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 34299.3125
Train_EnvstepsSoFar : 903205
TimeSinceStart : 630.7365429401398
Done logging...



********** Iteration 223 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 34213.46875
Train_EnvstepsSoFar : 907205
TimeSinceStart : 633.5970718860626
Done logging...



********** Iteration 224 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 37161.15625
Train_EnvstepsSoFar : 911205
TimeSinceStart : 636.1190557479858
Done logging...



********** Iteration 225 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 37292.9453125
Train_EnvstepsSoFar : 915205
TimeSinceStart : 638.4916744232178
Done logging...



********** Iteration 226 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 34759.4453125
Train_EnvstepsSoFar : 919205
TimeSinceStart : 641.9826774597168
Done logging...



********** Iteration 227 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 33268.36328125
Train_EnvstepsSoFar : 923205
TimeSinceStart : 645.2239847183228
Done logging...



********** Iteration 228 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 34152.359375
Train_EnvstepsSoFar : 927205
TimeSinceStart : 647.5531561374664
Done logging...



********** Iteration 229 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 37210.625
Train_EnvstepsSoFar : 931205
TimeSinceStart : 649.8928506374359
Done logging...



********** Iteration 230 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 34805.984375
Train_EnvstepsSoFar : 935205
TimeSinceStart : 652.2946548461914
Done logging...



********** Iteration 231 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 35045.9375
Train_EnvstepsSoFar : 939205
TimeSinceStart : 654.6740636825562
Done logging...



********** Iteration 232 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 31931.509765625
Train_EnvstepsSoFar : 943205
TimeSinceStart : 657.9039208889008
Done logging...



********** Iteration 233 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 35406.125
Train_EnvstepsSoFar : 947205
TimeSinceStart : 661.1246957778931
Done logging...



********** Iteration 234 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 33360.421875
Train_EnvstepsSoFar : 951205
TimeSinceStart : 663.5599925518036
Done logging...



********** Iteration 235 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 33895.7265625
Train_EnvstepsSoFar : 955205
TimeSinceStart : 665.9664490222931
Done logging...



********** Iteration 236 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 33237.734375
Train_EnvstepsSoFar : 959205
TimeSinceStart : 668.3933918476105
Done logging...



********** Iteration 237 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 32471.08984375
Train_EnvstepsSoFar : 963205
TimeSinceStart : 670.7766501903534
Done logging...



********** Iteration 238 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 32740.89453125
Train_EnvstepsSoFar : 967205
TimeSinceStart : 673.1898312568665
Done logging...



********** Iteration 239 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 30688.830078125
Train_EnvstepsSoFar : 971205
TimeSinceStart : 677.3431231975555
Done logging...



********** Iteration 240 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 30883.234375
Train_EnvstepsSoFar : 975205
TimeSinceStart : 681.1710712909698
Done logging...



********** Iteration 241 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 31845.830078125
Train_EnvstepsSoFar : 979205
TimeSinceStart : 683.5778050422668
Done logging...



********** Iteration 242 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 33773.375
Train_EnvstepsSoFar : 983205
TimeSinceStart : 685.9682404994965
Done logging...



********** Iteration 243 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 33600.9453125
Train_EnvstepsSoFar : 987205
TimeSinceStart : 688.3823754787445
Done logging...



********** Iteration 244 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 30919.98046875
Train_EnvstepsSoFar : 991205
TimeSinceStart : 690.7909853458405
Done logging...



********** Iteration 245 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 31603.12109375
Train_EnvstepsSoFar : 995205
TimeSinceStart : 693.6910171508789
Done logging...



********** Iteration 246 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 32996.3125
Train_EnvstepsSoFar : 999205
TimeSinceStart : 696.1028618812561
Done logging...



********** Iteration 247 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 32155.42578125
Train_EnvstepsSoFar : 1003205
TimeSinceStart : 698.7987909317017
Done logging...



********** Iteration 248 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 31638.6875
Train_EnvstepsSoFar : 1007205
TimeSinceStart : 702.7956538200378
Done logging...



********** Iteration 249 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 35508.11328125
Train_EnvstepsSoFar : 1011205
TimeSinceStart : 705.2391791343689
Done logging...



********** Iteration 250 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 33130.32421875
Train_EnvstepsSoFar : 1015205
TimeSinceStart : 707.6733844280243
Done logging...



********** Iteration 251 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 31592.177734375
Train_EnvstepsSoFar : 1019205
TimeSinceStart : 710.0691735744476
Done logging...



********** Iteration 252 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 32020.544921875
Train_EnvstepsSoFar : 1023205
TimeSinceStart : 712.4949100017548
Done logging...



********** Iteration 253 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 29981.1796875
Train_EnvstepsSoFar : 1027205
TimeSinceStart : 714.865033864975
Done logging...



********** Iteration 254 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 28924.458984375
Train_EnvstepsSoFar : 1031205
TimeSinceStart : 717.3737125396729
Done logging...



********** Iteration 255 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 29119.033203125
Train_EnvstepsSoFar : 1035205
TimeSinceStart : 720.1903345584869
Done logging...



********** Iteration 256 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 29619.427734375
Train_EnvstepsSoFar : 1039205
TimeSinceStart : 722.7633059024811
Done logging...



********** Iteration 257 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 30382.3125
Train_EnvstepsSoFar : 1043205
TimeSinceStart : 725.1404294967651
Done logging...



********** Iteration 258 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 32746.8515625
Train_EnvstepsSoFar : 1047205
TimeSinceStart : 727.5098621845245
Done logging...



********** Iteration 259 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 27950.24609375
Train_EnvstepsSoFar : 1051205
TimeSinceStart : 729.9746112823486
Done logging...



********** Iteration 260 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 28562.38671875
Train_EnvstepsSoFar : 1055205
TimeSinceStart : 732.3336579799652
Done logging...



********** Iteration 261 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 28054.80078125
Train_EnvstepsSoFar : 1059205
TimeSinceStart : 734.8317770957947
Done logging...



********** Iteration 262 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 29950.1875
Train_EnvstepsSoFar : 1063205
TimeSinceStart : 737.2197682857513
Done logging...



********** Iteration 263 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 28298.150390625
Train_EnvstepsSoFar : 1067205
TimeSinceStart : 739.6280105113983
Done logging...



********** Iteration 264 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 30203.1015625
Train_EnvstepsSoFar : 1071205
TimeSinceStart : 741.9839832782745
Done logging...



********** Iteration 265 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 28863.544921875
Train_EnvstepsSoFar : 1075205
TimeSinceStart : 744.3273420333862
Done logging...



********** Iteration 266 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 27762.615234375
Train_EnvstepsSoFar : 1079205
TimeSinceStart : 747.226514339447
Done logging...



********** Iteration 267 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 31113.830078125
Train_EnvstepsSoFar : 1083205
TimeSinceStart : 752.5541086196899
Done logging...



********** Iteration 268 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 29625.81640625
Train_EnvstepsSoFar : 1087205
TimeSinceStart : 755.1860902309418
Done logging...



********** Iteration 269 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 28761.923828125
Train_EnvstepsSoFar : 1091205
TimeSinceStart : 758.4762015342712
Done logging...



********** Iteration 270 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 32223.29296875
Train_EnvstepsSoFar : 1095205
TimeSinceStart : 761.246166229248
Done logging...



********** Iteration 271 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 30397.216796875
Train_EnvstepsSoFar : 1099205
TimeSinceStart : 764.1803624629974
Done logging...



********** Iteration 272 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 29473.5546875
Train_EnvstepsSoFar : 1103205
TimeSinceStart : 767.0980005264282
Done logging...



********** Iteration 273 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 29863.078125
Train_EnvstepsSoFar : 1107205
TimeSinceStart : 770.3174965381622
Done logging...



********** Iteration 274 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 27471.0390625
Train_EnvstepsSoFar : 1111205
TimeSinceStart : 774.1721799373627
Done logging...



********** Iteration 275 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 25790.0078125
Train_EnvstepsSoFar : 1115205
TimeSinceStart : 777.0898547172546
Done logging...



********** Iteration 276 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 26005.55078125
Train_EnvstepsSoFar : 1119205
TimeSinceStart : 779.9551696777344
Done logging...



********** Iteration 277 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 27138.05859375
Train_EnvstepsSoFar : 1123205
TimeSinceStart : 783.1020309925079
Done logging...



********** Iteration 278 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 26378.556640625
Train_EnvstepsSoFar : 1127205
TimeSinceStart : 785.8019959926605
Done logging...



********** Iteration 279 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 25037.1875
Train_EnvstepsSoFar : 1131205
TimeSinceStart : 789.0473175048828
Done logging...



********** Iteration 280 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 27847.36328125
Train_EnvstepsSoFar : 1135205
TimeSinceStart : 794.3088252544403
Done logging...



********** Iteration 281 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 26070.240234375
Train_EnvstepsSoFar : 1139205
TimeSinceStart : 796.687157869339
Done logging...



********** Iteration 282 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 25480.0546875
Train_EnvstepsSoFar : 1143205
TimeSinceStart : 799.4774439334869
Done logging...



********** Iteration 283 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 24338.171875
Train_EnvstepsSoFar : 1147205
TimeSinceStart : 801.8579499721527
Done logging...



********** Iteration 284 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 27545.091796875
Train_EnvstepsSoFar : 1151205
TimeSinceStart : 804.2231206893921
Done logging...



********** Iteration 285 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 25854.673828125
Train_EnvstepsSoFar : 1155205
TimeSinceStart : 810.2684664726257
Done logging...



********** Iteration 286 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 26838.40234375
Train_EnvstepsSoFar : 1159205
TimeSinceStart : 812.660754442215
Done logging...



********** Iteration 287 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 26562.21875
Train_EnvstepsSoFar : 1163205
TimeSinceStart : 815.0299146175385
Done logging...



********** Iteration 288 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 27193.75
Train_EnvstepsSoFar : 1167205
TimeSinceStart : 817.8960485458374
Done logging...



********** Iteration 289 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 24101.939453125
Train_EnvstepsSoFar : 1171205
TimeSinceStart : 820.2880153656006
Done logging...



********** Iteration 290 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 26970.1484375
Train_EnvstepsSoFar : 1175205
TimeSinceStart : 822.7027189731598
Done logging...



********** Iteration 291 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 25673.150390625
Train_EnvstepsSoFar : 1179205
TimeSinceStart : 825.1869628429413
Done logging...



********** Iteration 292 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 25904.544921875
Train_EnvstepsSoFar : 1183205
TimeSinceStart : 827.5827419757843
Done logging...



********** Iteration 293 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 27872.1015625
Train_EnvstepsSoFar : 1187205
TimeSinceStart : 829.9961297512054
Done logging...



********** Iteration 294 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 27200.1328125
Train_EnvstepsSoFar : 1191205
TimeSinceStart : 832.4061710834503
Done logging...



********** Iteration 295 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 26143.21484375
Train_EnvstepsSoFar : 1195205
TimeSinceStart : 834.7858216762543
Done logging...



********** Iteration 296 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 26617.3203125
Train_EnvstepsSoFar : 1199205
TimeSinceStart : 838.6704235076904
Done logging...



********** Iteration 297 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 24269.7109375
Train_EnvstepsSoFar : 1203205
TimeSinceStart : 841.0397567749023
Done logging...



********** Iteration 298 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 24555.423828125
Train_EnvstepsSoFar : 1207205
TimeSinceStart : 843.4505755901337
Done logging...



********** Iteration 299 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 27121.65625
Train_EnvstepsSoFar : 1211205
TimeSinceStart : 845.8609983921051
Done logging...



********** Iteration 300 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 25545.85546875
Train_EnvstepsSoFar : 1215205
TimeSinceStart : 848.9250214099884
Done logging...



********** Iteration 301 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 26316.796875
Train_EnvstepsSoFar : 1219205
TimeSinceStart : 851.3827731609344
Done logging...



********** Iteration 302 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 24660.669921875
Train_EnvstepsSoFar : 1223205
TimeSinceStart : 853.7455415725708
Done logging...



********** Iteration 303 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 26037.82421875
Train_EnvstepsSoFar : 1227205
TimeSinceStart : 856.1257073879242
Done logging...



********** Iteration 304 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 24813.51171875
Train_EnvstepsSoFar : 1231205
TimeSinceStart : 858.535139799118
Done logging...



********** Iteration 305 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 24758.353515625
Train_EnvstepsSoFar : 1235205
TimeSinceStart : 860.9563941955566
Done logging...



********** Iteration 306 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 25367.61328125
Train_EnvstepsSoFar : 1239205
TimeSinceStart : 863.3477208614349
Done logging...



********** Iteration 307 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 24735.78515625
Train_EnvstepsSoFar : 1243205
TimeSinceStart : 865.7709720134735
Done logging...



********** Iteration 308 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 25682.43359375
Train_EnvstepsSoFar : 1247205
TimeSinceStart : 868.3152418136597
Done logging...



********** Iteration 309 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 24297.96484375
Train_EnvstepsSoFar : 1251205
TimeSinceStart : 871.2677781581879
Done logging...



********** Iteration 310 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 26546.80078125
Train_EnvstepsSoFar : 1255205
TimeSinceStart : 873.6422324180603
Done logging...



********** Iteration 311 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 26535.93359375
Train_EnvstepsSoFar : 1259205
TimeSinceStart : 876.0688717365265
Done logging...



********** Iteration 312 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 24673.484375
Train_EnvstepsSoFar : 1263205
TimeSinceStart : 878.4752593040466
Done logging...



********** Iteration 313 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 25279.998046875
Train_EnvstepsSoFar : 1267205
TimeSinceStart : 880.8665614128113
Done logging...



********** Iteration 314 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 23316.060546875
Train_EnvstepsSoFar : 1271205
TimeSinceStart : 883.3483653068542
Done logging...



********** Iteration 315 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 24599.466796875
Train_EnvstepsSoFar : 1275205
TimeSinceStart : 885.8364865779877
Done logging...



********** Iteration 316 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 22392.5546875
Train_EnvstepsSoFar : 1279205
TimeSinceStart : 888.301278591156
Done logging...



********** Iteration 317 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 23559.662109375
Train_EnvstepsSoFar : 1283205
TimeSinceStart : 890.6448645591736
Done logging...



********** Iteration 318 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 22776.333984375
Train_EnvstepsSoFar : 1287205
TimeSinceStart : 893.321759223938
Done logging...



********** Iteration 319 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 21798.0
Train_EnvstepsSoFar : 1291205
TimeSinceStart : 898.5660481452942
Done logging...



********** Iteration 320 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 24775.62109375
Train_EnvstepsSoFar : 1295205
TimeSinceStart : 901.312974691391
Done logging...



********** Iteration 321 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 24186.33984375
Train_EnvstepsSoFar : 1299205
TimeSinceStart : 903.6609988212585
Done logging...



********** Iteration 322 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 24357.25
Train_EnvstepsSoFar : 1303205
TimeSinceStart : 906.0112018585205
Done logging...



********** Iteration 323 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 20550.04296875
Train_EnvstepsSoFar : 1307205
TimeSinceStart : 908.3762362003326
Done logging...



********** Iteration 324 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 23056.759765625
Train_EnvstepsSoFar : 1311205
TimeSinceStart : 911.9222934246063
Done logging...



********** Iteration 325 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 22495.857421875
Train_EnvstepsSoFar : 1315205
TimeSinceStart : 915.1381103992462
Done logging...



********** Iteration 326 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 23478.080078125
Train_EnvstepsSoFar : 1319205
TimeSinceStart : 917.5699560642242
Done logging...



********** Iteration 327 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 21989.64453125
Train_EnvstepsSoFar : 1323205
TimeSinceStart : 919.9214804172516
Done logging...



********** Iteration 328 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 25478.1640625
Train_EnvstepsSoFar : 1327205
TimeSinceStart : 922.2840793132782
Done logging...



********** Iteration 329 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 23491.482421875
Train_EnvstepsSoFar : 1331205
TimeSinceStart : 924.6785621643066
Done logging...



********** Iteration 330 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 23386.2578125
Train_EnvstepsSoFar : 1335205
TimeSinceStart : 927.5395183563232
Done logging...



********** Iteration 331 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 23209.841796875
Train_EnvstepsSoFar : 1339205
TimeSinceStart : 929.9355795383453
Done logging...



********** Iteration 332 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 22156.361328125
Train_EnvstepsSoFar : 1343205
TimeSinceStart : 932.3408868312836
Done logging...



********** Iteration 333 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 24766.998046875
Train_EnvstepsSoFar : 1347205
TimeSinceStart : 934.7464575767517
Done logging...



********** Iteration 334 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 22474.5
Train_EnvstepsSoFar : 1351205
TimeSinceStart : 937.1366035938263
Done logging...



********** Iteration 335 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 21626.546875
Train_EnvstepsSoFar : 1355205
TimeSinceStart : 939.5169079303741
Done logging...



********** Iteration 336 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 21787.32421875
Train_EnvstepsSoFar : 1359205
TimeSinceStart : 941.9052476882935
Done logging...



********** Iteration 337 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 21554.1875
Train_EnvstepsSoFar : 1363205
TimeSinceStart : 944.2826066017151
Done logging...



********** Iteration 338 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 22899.576171875
Train_EnvstepsSoFar : 1367205
TimeSinceStart : 946.6950650215149
Done logging...



********** Iteration 339 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 23539.51953125
Train_EnvstepsSoFar : 1371205
TimeSinceStart : 949.0768580436707
Done logging...



********** Iteration 340 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 24214.2578125
Train_EnvstepsSoFar : 1375205
TimeSinceStart : 951.5005693435669
Done logging...



********** Iteration 341 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 23712.32421875
Train_EnvstepsSoFar : 1379205
TimeSinceStart : 954.504153251648
Done logging...



********** Iteration 342 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 22987.974609375
Train_EnvstepsSoFar : 1383205
TimeSinceStart : 957.4111571311951
Done logging...



********** Iteration 343 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 24996.3046875
Train_EnvstepsSoFar : 1387205
TimeSinceStart : 959.8028800487518
Done logging...



********** Iteration 344 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 20696.642578125
Train_EnvstepsSoFar : 1391205
TimeSinceStart : 962.1878936290741
Done logging...



********** Iteration 345 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 23203.978515625
Train_EnvstepsSoFar : 1395205
TimeSinceStart : 964.5922117233276
Done logging...



********** Iteration 346 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 20753.609375
Train_EnvstepsSoFar : 1399205
TimeSinceStart : 966.9771239757538
Done logging...



********** Iteration 347 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 21517.025390625
Train_EnvstepsSoFar : 1403205
TimeSinceStart : 970.5191552639008
Done logging...



********** Iteration 348 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 20712.7734375
Train_EnvstepsSoFar : 1407205
TimeSinceStart : 975.5333309173584
Done logging...



********** Iteration 349 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 22071.8515625
Train_EnvstepsSoFar : 1411205
TimeSinceStart : 977.9607498645782
Done logging...



********** Iteration 350 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 22480.537109375
Train_EnvstepsSoFar : 1415205
TimeSinceStart : 980.3723123073578
Done logging...



********** Iteration 351 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 22500.19140625
Train_EnvstepsSoFar : 1419205
TimeSinceStart : 986.400582075119
Done logging...



********** Iteration 352 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 20661.10546875
Train_EnvstepsSoFar : 1423205
TimeSinceStart : 988.8091037273407
Done logging...



********** Iteration 353 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 22502.912109375
Train_EnvstepsSoFar : 1427205
TimeSinceStart : 991.605943441391
Done logging...



********** Iteration 354 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 22651.58203125
Train_EnvstepsSoFar : 1431205
TimeSinceStart : 994.0282571315765
Done logging...



********** Iteration 355 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 21247.6796875
Train_EnvstepsSoFar : 1435205
TimeSinceStart : 996.420978307724
Done logging...



********** Iteration 356 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 22286.97265625
Train_EnvstepsSoFar : 1439205
TimeSinceStart : 998.7990980148315
Done logging...



********** Iteration 357 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 22311.30078125
Train_EnvstepsSoFar : 1443205
TimeSinceStart : 1001.188800573349
Done logging...



********** Iteration 358 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 21603.5859375
Train_EnvstepsSoFar : 1447205
TimeSinceStart : 1006.8485555648804
Done logging...



********** Iteration 359 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 20855.775390625
Train_EnvstepsSoFar : 1451205
TimeSinceStart : 1009.8549439907074
Done logging...



********** Iteration 360 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 21145.58984375
Train_EnvstepsSoFar : 1455205
TimeSinceStart : 1012.2375581264496
Done logging...



********** Iteration 361 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 21831.548828125
Train_EnvstepsSoFar : 1459205
TimeSinceStart : 1015.6122152805328
Done logging...



********** Iteration 362 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 20520.8828125
Train_EnvstepsSoFar : 1463205
TimeSinceStart : 1019.3836181163788
Done logging...



********** Iteration 363 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 20228.232421875
Train_EnvstepsSoFar : 1467205
TimeSinceStart : 1022.8464834690094
Done logging...



********** Iteration 364 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 20274.4296875
Train_EnvstepsSoFar : 1471205
TimeSinceStart : 1025.2589790821075
Done logging...



********** Iteration 365 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 20361.88671875
Train_EnvstepsSoFar : 1475205
TimeSinceStart : 1028.4248986244202
Done logging...



********** Iteration 366 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 21180.21875
Train_EnvstepsSoFar : 1479205
TimeSinceStart : 1031.4930577278137
Done logging...



********** Iteration 367 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 19660.8671875
Train_EnvstepsSoFar : 1483205
TimeSinceStart : 1036.113109111786
Done logging...



********** Iteration 368 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 18178.375
Train_EnvstepsSoFar : 1487205
TimeSinceStart : 1038.4927277565002
Done logging...



********** Iteration 369 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 18744.974609375
Train_EnvstepsSoFar : 1491205
TimeSinceStart : 1040.9204001426697
Done logging...



********** Iteration 370 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 18775.240234375
Train_EnvstepsSoFar : 1495205
TimeSinceStart : 1043.381383895874
Done logging...



********** Iteration 371 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 17735.953125
Train_EnvstepsSoFar : 1499205
TimeSinceStart : 1047.2067353725433
Done logging...



********** Iteration 372 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 20036.640625
Train_EnvstepsSoFar : 1503205
TimeSinceStart : 1050.448587179184
Done logging...



********** Iteration 373 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 20375.794921875
Train_EnvstepsSoFar : 1507205
TimeSinceStart : 1052.8663263320923
Done logging...



********** Iteration 374 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 19591.66015625
Train_EnvstepsSoFar : 1511205
TimeSinceStart : 1055.2534964084625
Done logging...



********** Iteration 375 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 18152.75
Train_EnvstepsSoFar : 1515205
TimeSinceStart : 1057.682808637619
Done logging...



********** Iteration 376 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 18973.59375
Train_EnvstepsSoFar : 1519205
TimeSinceStart : 1060.0701594352722
Done logging...



********** Iteration 377 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 18594.052734375
Train_EnvstepsSoFar : 1523205
TimeSinceStart : 1062.8118522167206
Done logging...



********** Iteration 378 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 18638.408203125
Train_EnvstepsSoFar : 1527205
TimeSinceStart : 1065.1901195049286
Done logging...



********** Iteration 379 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 20061.5234375
Train_EnvstepsSoFar : 1531205
TimeSinceStart : 1070.4604682922363
Done logging...



********** Iteration 380 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 19232.31640625
Train_EnvstepsSoFar : 1535205
TimeSinceStart : 1072.8333566188812
Done logging...



********** Iteration 381 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 20186.4921875
Train_EnvstepsSoFar : 1539205
TimeSinceStart : 1075.1975662708282
Done logging...



********** Iteration 382 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 20120.576171875
Train_EnvstepsSoFar : 1543205
TimeSinceStart : 1077.5624854564667
Done logging...



********** Iteration 383 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 18443.3046875
Train_EnvstepsSoFar : 1547205
TimeSinceStart : 1081.2982366085052
Done logging...



********** Iteration 384 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 19774.34375
Train_EnvstepsSoFar : 1551205
TimeSinceStart : 1083.681217432022
Done logging...



********** Iteration 385 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 19579.32421875
Train_EnvstepsSoFar : 1555205
TimeSinceStart : 1087.1772875785828
Done logging...



********** Iteration 386 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 19425.92578125
Train_EnvstepsSoFar : 1559205
TimeSinceStart : 1089.5421524047852
Done logging...



********** Iteration 387 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 19396.232421875
Train_EnvstepsSoFar : 1563205
TimeSinceStart : 1092.2052087783813
Done logging...



********** Iteration 388 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 20164.10546875
Train_EnvstepsSoFar : 1567205
TimeSinceStart : 1094.5815708637238
Done logging...



********** Iteration 389 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 18819.57421875
Train_EnvstepsSoFar : 1571205
TimeSinceStart : 1096.9337406158447
Done logging...



********** Iteration 390 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 19750.7734375
Train_EnvstepsSoFar : 1575205
TimeSinceStart : 1099.3023600578308
Done logging...



********** Iteration 391 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 18626.65625
Train_EnvstepsSoFar : 1579205
TimeSinceStart : 1101.6878640651703
Done logging...



********** Iteration 392 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 19327.2734375
Train_EnvstepsSoFar : 1583205
TimeSinceStart : 1104.0518381595612
Done logging...



********** Iteration 393 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 19226.75390625
Train_EnvstepsSoFar : 1587205
TimeSinceStart : 1106.4283442497253
Done logging...



********** Iteration 394 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 16861.52734375
Train_EnvstepsSoFar : 1591205
TimeSinceStart : 1108.8587007522583
Done logging...



********** Iteration 395 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 18314.603515625
Train_EnvstepsSoFar : 1595205
TimeSinceStart : 1111.3133897781372
Done logging...



********** Iteration 396 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 17817.28515625
Train_EnvstepsSoFar : 1599205
TimeSinceStart : 1114.4342815876007
Done logging...



********** Iteration 397 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 17912.30078125
Train_EnvstepsSoFar : 1603205
TimeSinceStart : 1116.793815612793
Done logging...



********** Iteration 398 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 19772.455078125
Train_EnvstepsSoFar : 1607205
TimeSinceStart : 1119.1414489746094
Done logging...



********** Iteration 399 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 16115.916015625
Train_EnvstepsSoFar : 1611205
TimeSinceStart : 1123.7135622501373
Done logging...



********** Iteration 400 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 16334.896484375
Train_EnvstepsSoFar : 1615205
TimeSinceStart : 1126.0749764442444
Done logging...



********** Iteration 401 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 16856.150390625
Train_EnvstepsSoFar : 1619205
TimeSinceStart : 1128.4749517440796
Done logging...



********** Iteration 402 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 18440.9296875
Train_EnvstepsSoFar : 1623205
TimeSinceStart : 1130.909253835678
Done logging...



********** Iteration 403 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 16859.712890625
Train_EnvstepsSoFar : 1627205
TimeSinceStart : 1133.3267049789429
Done logging...



********** Iteration 404 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 17889.08984375
Train_EnvstepsSoFar : 1631205
TimeSinceStart : 1136.998681306839
Done logging...



********** Iteration 405 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 18106.8203125
Train_EnvstepsSoFar : 1635205
TimeSinceStart : 1140.813461303711
Done logging...



********** Iteration 406 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 17909.53125
Train_EnvstepsSoFar : 1639205
TimeSinceStart : 1143.5059099197388
Done logging...



********** Iteration 407 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 17811.875
Train_EnvstepsSoFar : 1643205
TimeSinceStart : 1145.9331250190735
Done logging...



********** Iteration 408 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 18429.7265625
Train_EnvstepsSoFar : 1647205
TimeSinceStart : 1149.0971994400024
Done logging...



********** Iteration 409 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 16899.53515625
Train_EnvstepsSoFar : 1651205
TimeSinceStart : 1152.3314905166626
Done logging...



********** Iteration 410 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 17521.58984375
Train_EnvstepsSoFar : 1655205
TimeSinceStart : 1155.4939935207367
Done logging...



********** Iteration 411 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 16931.20703125
Train_EnvstepsSoFar : 1659205
TimeSinceStart : 1158.4641206264496
Done logging...



********** Iteration 412 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 17566.95703125
Train_EnvstepsSoFar : 1663205
TimeSinceStart : 1161.6320292949677
Done logging...



********** Iteration 413 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 17589.92578125
Train_EnvstepsSoFar : 1667205
TimeSinceStart : 1164.2999403476715
Done logging...



********** Iteration 414 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 17208.97265625
Train_EnvstepsSoFar : 1671205
TimeSinceStart : 1167.3733432292938
Done logging...



********** Iteration 415 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 17845.046875
Train_EnvstepsSoFar : 1675205
TimeSinceStart : 1170.4438931941986
Done logging...



********** Iteration 416 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 17029.51953125
Train_EnvstepsSoFar : 1679205
TimeSinceStart : 1173.544368982315
Done logging...



********** Iteration 417 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 18746.43359375
Train_EnvstepsSoFar : 1683205
TimeSinceStart : 1176.5194900035858
Done logging...



********** Iteration 418 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 18790.81640625
Train_EnvstepsSoFar : 1687205
TimeSinceStart : 1178.9279243946075
Done logging...



********** Iteration 419 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 19356.62109375
Train_EnvstepsSoFar : 1691205
TimeSinceStart : 1183.707735300064
Done logging...



********** Iteration 420 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 16320.6005859375
Train_EnvstepsSoFar : 1695205
TimeSinceStart : 1186.7817833423615
Done logging...



********** Iteration 421 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 18163.52734375
Train_EnvstepsSoFar : 1699205
TimeSinceStart : 1189.9548201560974
Done logging...



********** Iteration 422 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 18620.150390625
Train_EnvstepsSoFar : 1703205
TimeSinceStart : 1192.3660049438477
Done logging...



********** Iteration 423 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 16697.89453125
Train_EnvstepsSoFar : 1707205
TimeSinceStart : 1195.156284570694
Done logging...



********** Iteration 424 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 17130.9140625
Train_EnvstepsSoFar : 1711205
TimeSinceStart : 1197.961139678955
Done logging...



********** Iteration 425 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15672.93359375
Train_EnvstepsSoFar : 1715205
TimeSinceStart : 1201.4688096046448
Done logging...



********** Iteration 426 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 18733.3671875
Train_EnvstepsSoFar : 1719205
TimeSinceStart : 1204.4173531532288
Done logging...



********** Iteration 427 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 20390.84375
Train_EnvstepsSoFar : 1723205
TimeSinceStart : 1206.9230017662048
Done logging...



********** Iteration 428 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 18231.505859375
Train_EnvstepsSoFar : 1727205
TimeSinceStart : 1209.339536190033
Done logging...



********** Iteration 429 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 20247.375
Train_EnvstepsSoFar : 1731205
TimeSinceStart : 1211.7411451339722
Done logging...



********** Iteration 430 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 18079.712890625
Train_EnvstepsSoFar : 1735205
TimeSinceStart : 1214.15882229805
Done logging...



********** Iteration 431 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 16836.30078125
Train_EnvstepsSoFar : 1739205
TimeSinceStart : 1216.554018497467
Done logging...



********** Iteration 432 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 17796.263671875
Train_EnvstepsSoFar : 1743205
TimeSinceStart : 1218.9582324028015
Done logging...



********** Iteration 433 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 17695.68359375
Train_EnvstepsSoFar : 1747205
TimeSinceStart : 1221.357140302658
Done logging...



********** Iteration 434 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15538.048828125
Train_EnvstepsSoFar : 1751205
TimeSinceStart : 1223.750065088272
Done logging...



********** Iteration 435 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 16981.5234375
Train_EnvstepsSoFar : 1755205
TimeSinceStart : 1226.1353647708893
Done logging...



********** Iteration 436 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 17307.703125
Train_EnvstepsSoFar : 1759205
TimeSinceStart : 1228.5275616645813
Done logging...



********** Iteration 437 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 16710.828125
Train_EnvstepsSoFar : 1763205
TimeSinceStart : 1231.5921158790588
Done logging...



********** Iteration 438 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 16663.265625
Train_EnvstepsSoFar : 1767205
TimeSinceStart : 1234.9461224079132
Done logging...



********** Iteration 439 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 16590.583984375
Train_EnvstepsSoFar : 1771205
TimeSinceStart : 1238.2148535251617
Done logging...



********** Iteration 440 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15998.56640625
Train_EnvstepsSoFar : 1775205
TimeSinceStart : 1240.601547241211
Done logging...



********** Iteration 441 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15955.470703125
Train_EnvstepsSoFar : 1779205
TimeSinceStart : 1244.9149482250214
Done logging...



********** Iteration 442 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 17849.62890625
Train_EnvstepsSoFar : 1783205
TimeSinceStart : 1247.7663569450378
Done logging...



********** Iteration 443 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 18176.421875
Train_EnvstepsSoFar : 1787205
TimeSinceStart : 1250.1744496822357
Done logging...



********** Iteration 444 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15335.22265625
Train_EnvstepsSoFar : 1791205
TimeSinceStart : 1252.5490527153015
Done logging...



********** Iteration 445 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 14239.529296875
Train_EnvstepsSoFar : 1795205
TimeSinceStart : 1254.9529888629913
Done logging...



********** Iteration 446 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15398.5546875
Train_EnvstepsSoFar : 1799205
TimeSinceStart : 1257.3625266551971
Done logging...



********** Iteration 447 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 16597.75
Train_EnvstepsSoFar : 1803205
TimeSinceStart : 1260.0076801776886
Done logging...



********** Iteration 448 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15931.669921875
Train_EnvstepsSoFar : 1807205
TimeSinceStart : 1262.5690398216248
Done logging...



********** Iteration 449 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 17670.05859375
Train_EnvstepsSoFar : 1811205
TimeSinceStart : 1265.0286729335785
Done logging...



********** Iteration 450 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 17006.673828125
Train_EnvstepsSoFar : 1815205
TimeSinceStart : 1267.3901898860931
Done logging...



********** Iteration 451 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 18311.5078125
Train_EnvstepsSoFar : 1819205
TimeSinceStart : 1271.212069272995
Done logging...



********** Iteration 452 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15816.5244140625
Train_EnvstepsSoFar : 1823205
TimeSinceStart : 1273.8891515731812
Done logging...



********** Iteration 453 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15722.7744140625
Train_EnvstepsSoFar : 1827205
TimeSinceStart : 1276.2836608886719
Done logging...



********** Iteration 454 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 17114.888671875
Train_EnvstepsSoFar : 1831205
TimeSinceStart : 1278.9961779117584
Done logging...



********** Iteration 455 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15070.447265625
Train_EnvstepsSoFar : 1835205
TimeSinceStart : 1281.4079353809357
Done logging...



********** Iteration 456 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 16958.908203125
Train_EnvstepsSoFar : 1839205
TimeSinceStart : 1285.2409355640411
Done logging...



********** Iteration 457 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 17171.634765625
Train_EnvstepsSoFar : 1843205
TimeSinceStart : 1289.1846618652344
Done logging...



********** Iteration 458 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 16019.8125
Train_EnvstepsSoFar : 1847205
TimeSinceStart : 1292.999923467636
Done logging...



********** Iteration 459 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15033.2265625
Train_EnvstepsSoFar : 1851205
TimeSinceStart : 1295.386796951294
Done logging...



********** Iteration 460 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 17593.953125
Train_EnvstepsSoFar : 1855205
TimeSinceStart : 1297.7738547325134
Done logging...



********** Iteration 461 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 16083.5546875
Train_EnvstepsSoFar : 1859205
TimeSinceStart : 1303.7750732898712
Done logging...



********** Iteration 462 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15728.275390625
Train_EnvstepsSoFar : 1863205
TimeSinceStart : 1306.2296814918518
Done logging...



********** Iteration 463 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 16683.15625
Train_EnvstepsSoFar : 1867205
TimeSinceStart : 1308.5945391654968
Done logging...



********** Iteration 464 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15001.193359375
Train_EnvstepsSoFar : 1871205
TimeSinceStart : 1310.9795651435852
Done logging...



********** Iteration 465 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 16182.1162109375
Train_EnvstepsSoFar : 1875205
TimeSinceStart : 1313.3666830062866
Done logging...



********** Iteration 466 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 16253.3330078125
Train_EnvstepsSoFar : 1879205
TimeSinceStart : 1315.750330209732
Done logging...



********** Iteration 467 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 14811.6669921875
Train_EnvstepsSoFar : 1883205
TimeSinceStart : 1319.639952659607
Done logging...



********** Iteration 468 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15521.5029296875
Train_EnvstepsSoFar : 1887205
TimeSinceStart : 1322.7599885463715
Done logging...



********** Iteration 469 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15147.1943359375
Train_EnvstepsSoFar : 1891205
TimeSinceStart : 1325.3991115093231
Done logging...



********** Iteration 470 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 16478.52734375
Train_EnvstepsSoFar : 1895205
TimeSinceStart : 1328.2733798027039
Done logging...



********** Iteration 471 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15164.11328125
Train_EnvstepsSoFar : 1899205
TimeSinceStart : 1330.9661619663239
Done logging...



********** Iteration 472 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15571.6630859375
Train_EnvstepsSoFar : 1903205
TimeSinceStart : 1333.3889002799988
Done logging...



********** Iteration 473 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15446.0751953125
Train_EnvstepsSoFar : 1907205
TimeSinceStart : 1336.639238834381
Done logging...



********** Iteration 474 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 13521.5302734375
Train_EnvstepsSoFar : 1911205
TimeSinceStart : 1339.6679282188416
Done logging...



********** Iteration 475 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15627.5361328125
Train_EnvstepsSoFar : 1915205
TimeSinceStart : 1342.6312019824982
Done logging...



********** Iteration 476 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15019.9130859375
Train_EnvstepsSoFar : 1919205
TimeSinceStart : 1345.6628711223602
Done logging...



********** Iteration 477 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 14756.0400390625
Train_EnvstepsSoFar : 1923205
TimeSinceStart : 1348.3712294101715
Done logging...



********** Iteration 478 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 13905.630859375
Train_EnvstepsSoFar : 1927205
TimeSinceStart : 1351.1025559902191
Done logging...



********** Iteration 479 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15903.37109375
Train_EnvstepsSoFar : 1931205
TimeSinceStart : 1353.681387424469
Done logging...



********** Iteration 480 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 14882.869140625
Train_EnvstepsSoFar : 1935205
TimeSinceStart : 1356.8064577579498
Done logging...



********** Iteration 481 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 14400.998046875
Train_EnvstepsSoFar : 1939205
TimeSinceStart : 1359.696328163147
Done logging...



********** Iteration 482 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15415.861328125
Train_EnvstepsSoFar : 1943205
TimeSinceStart : 1362.7637572288513
Done logging...



********** Iteration 483 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 14831.7822265625
Train_EnvstepsSoFar : 1947205
TimeSinceStart : 1365.5482165813446
Done logging...



********** Iteration 484 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 14451.6455078125
Train_EnvstepsSoFar : 1951205
TimeSinceStart : 1367.9669110774994
Done logging...



********** Iteration 485 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15535.634765625
Train_EnvstepsSoFar : 1955205
TimeSinceStart : 1370.3685250282288
Done logging...



********** Iteration 486 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 13160.31640625
Train_EnvstepsSoFar : 1959205
TimeSinceStart : 1372.9672033786774
Done logging...



********** Iteration 487 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 13605.705078125
Train_EnvstepsSoFar : 1963205
TimeSinceStart : 1376.0664510726929
Done logging...



********** Iteration 488 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15583.28125
Train_EnvstepsSoFar : 1967205
TimeSinceStart : 1378.5300514698029
Done logging...



********** Iteration 489 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 14976.73828125
Train_EnvstepsSoFar : 1971205
TimeSinceStart : 1381.5936813354492
Done logging...



********** Iteration 490 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15510.595703125
Train_EnvstepsSoFar : 1975205
TimeSinceStart : 1384.2081508636475
Done logging...



********** Iteration 491 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15005.80078125
Train_EnvstepsSoFar : 1979205
TimeSinceStart : 1386.960366487503
Done logging...



********** Iteration 492 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 14691.99609375
Train_EnvstepsSoFar : 1983205
TimeSinceStart : 1391.8848497867584
Done logging...



********** Iteration 493 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15199.322265625
Train_EnvstepsSoFar : 1987205
TimeSinceStart : 1394.7164504528046
Done logging...



********** Iteration 494 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 12994.0009765625
Train_EnvstepsSoFar : 1991205
TimeSinceStart : 1397.9002137184143
Done logging...



********** Iteration 495 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 15382.8046875
Train_EnvstepsSoFar : 1995205
TimeSinceStart : 1400.3056445121765
Done logging...



********** Iteration 496 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 14596.4443359375
Train_EnvstepsSoFar : 1999205
TimeSinceStart : 1402.793033361435
Done logging...



********** Iteration 497 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 14185.7900390625
Train_EnvstepsSoFar : 2003205
TimeSinceStart : 1405.6596419811249
Done logging...



********** Iteration 498 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 14758.75
Train_EnvstepsSoFar : 2007205
TimeSinceStart : 1408.6371009349823
Done logging...



********** Iteration 499 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : 12187.96875
Train_EnvstepsSoFar : 2011205
TimeSinceStart : 1411.4266538619995
Done logging...


########################
logging outputs to  /home/jaehyun-jeong/UCBerkeley_cs285/hw2/cs285/scripts/../../data/q2_pg_cartpole_lb_rtg_CartPole-v0_17-08-2024_01-57-32
########################
Using GPU id 0
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/envs/registration.py:593: UserWarning: [33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.[0m
  logger.warn(
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/core.py:317: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(

********** Iteration 0 ************
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):

Collecting data for eval...
Eval_AverageReturn : 27.933332443237305
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/tensorboardX/summary.py:153: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
  scalar = float(scalar)
Eval_StdReturn : 6.136955738067627
Eval_MaxReturn : 40.0
Eval_MinReturn : 20.0
Eval_AverageEpLen : 27.933333333333334
Train_AverageReturn : 39.28845977783203
Train_StdReturn : 18.524242401123047
Train_MaxReturn : 136.0
Train_MinReturn : 20.0
Train_AverageEpLen : 39.28846153846154
Actor Loss : 68198.40625
Train_EnvstepsSoFar : 4086
TimeSinceStart : 3.129645347595215
Initial_DataCollection_AverageReturn : 39.28845977783203
Done logging...



********** Iteration 1 ************

Collecting data for eval...
Eval_AverageReturn : 24.176469802856445
Eval_StdReturn : 3.729616165161133
Eval_MaxReturn : 32.0
Eval_MinReturn : 18.0
Eval_AverageEpLen : 24.176470588235293
Train_AverageReturn : 27.108108520507812
Train_StdReturn : 3.9900810718536377
Train_MaxReturn : 36.0
Train_MinReturn : 19.0
Train_AverageEpLen : 27.10810810810811
Actor Loss : 36570.5703125
Train_EnvstepsSoFar : 8098
TimeSinceStart : 5.605705976486206
Done logging...



********** Iteration 2 ************

Collecting data for eval...
Eval_AverageReturn : 22.77777862548828
Eval_StdReturn : 3.1011745929718018
Eval_MaxReturn : 27.0
Eval_MinReturn : 18.0
Eval_AverageEpLen : 22.77777777777778
Train_AverageReturn : 24.40243911743164
Train_StdReturn : 3.719951868057251
Train_MaxReturn : 33.0
Train_MinReturn : 18.0
Train_AverageEpLen : 24.402439024390244
Actor Loss : 30611.35546875
Train_EnvstepsSoFar : 12100
TimeSinceStart : 9.079426765441895
Done logging...



********** Iteration 3 ************

Collecting data for eval...
Eval_AverageReturn : 23.44444465637207
Eval_StdReturn : 3.386611223220825
Eval_MaxReturn : 30.0
Eval_MinReturn : 18.0
Eval_AverageEpLen : 23.444444444444443
Train_AverageReturn : 23.0
Train_StdReturn : 3.9245762825012207
Train_MaxReturn : 32.0
Train_MinReturn : 17.0
Train_AverageEpLen : 23.0
Actor Loss : 26674.38671875
Train_EnvstepsSoFar : 16102
TimeSinceStart : 11.648903369903564
Done logging...



********** Iteration 4 ************

Collecting data for eval...
Eval_AverageReturn : 21.736841201782227
Eval_StdReturn : 4.101888179779053
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.736842105263158
Train_AverageReturn : 23.06321907043457
Train_StdReturn : 4.171816349029541
Train_MaxReturn : 33.0
Train_MinReturn : 16.0
Train_AverageEpLen : 23.063218390804597
Actor Loss : 24486.46875
Train_EnvstepsSoFar : 20115
TimeSinceStart : 14.229131937026978
Done logging...



********** Iteration 5 ************

Collecting data for eval...
Eval_AverageReturn : 20.799999237060547
Eval_StdReturn : 3.340658664703369
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.8
Train_AverageReturn : 21.868852615356445
Train_StdReturn : 3.9261298179626465
Train_MaxReturn : 32.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.868852459016395
Actor Loss : 20886.205078125
Train_EnvstepsSoFar : 24117
TimeSinceStart : 16.79596495628357
Done logging...



********** Iteration 6 ************

Collecting data for eval...
Eval_AverageReturn : 22.263158798217773
Eval_StdReturn : 4.41101598739624
Eval_MaxReturn : 32.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 22.263157894736842
Train_AverageReturn : 22.18231964111328
Train_StdReturn : 4.202724456787109
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 22.18232044198895
Actor Loss : 19078.046875
Train_EnvstepsSoFar : 28132
TimeSinceStart : 19.377420663833618
Done logging...



********** Iteration 7 ************

Collecting data for eval...
Eval_AverageReturn : 21.947368621826172
Eval_StdReturn : 3.034428596496582
Eval_MaxReturn : 28.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 21.94736842105263
Train_AverageReturn : 22.60451889038086
Train_StdReturn : 3.986074924468994
Train_MaxReturn : 32.0
Train_MinReturn : 16.0
Train_AverageEpLen : 22.6045197740113
Actor Loss : 17021.25
Train_EnvstepsSoFar : 32133
TimeSinceStart : 22.358744144439697
Done logging...



********** Iteration 8 ************

Collecting data for eval...
Eval_AverageReturn : 22.5
Eval_StdReturn : 4.645786762237549
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.5
Train_AverageReturn : 22.60451889038086
Train_StdReturn : 4.158115386962891
Train_MaxReturn : 33.0
Train_MinReturn : 16.0
Train_AverageEpLen : 22.6045197740113
Actor Loss : 14934.126953125
Train_EnvstepsSoFar : 36134
TimeSinceStart : 24.901378870010376
Done logging...



********** Iteration 9 ************

Collecting data for eval...
Eval_AverageReturn : 22.77777862548828
Eval_StdReturn : 3.224137306213379
Eval_MaxReturn : 28.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 22.77777777777778
Train_AverageReturn : 22.846590042114258
Train_StdReturn : 3.7514071464538574
Train_MaxReturn : 33.0
Train_MinReturn : 17.0
Train_AverageEpLen : 22.84659090909091
Actor Loss : 13110.388671875
Train_EnvstepsSoFar : 40155
TimeSinceStart : 27.472750186920166
Done logging...



********** Iteration 10 ************

Collecting data for eval...
Eval_AverageReturn : 22.77777862548828
Eval_StdReturn : 3.7201485633850098
Eval_MaxReturn : 31.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 22.77777777777778
Train_AverageReturn : 22.62359619140625
Train_StdReturn : 3.6702423095703125
Train_MaxReturn : 31.0
Train_MinReturn : 17.0
Train_AverageEpLen : 22.623595505617978
Actor Loss : 11078.5068359375
Train_EnvstepsSoFar : 44182
TimeSinceStart : 30.07292628288269
Done logging...



********** Iteration 11 ************

Collecting data for eval...
Eval_AverageReturn : 22.5
Eval_StdReturn : 3.7749171257019043
Eval_MaxReturn : 31.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 22.5
Train_AverageReturn : 22.7401123046875
Train_StdReturn : 3.881030797958374
Train_MaxReturn : 32.0
Train_MinReturn : 16.0
Train_AverageEpLen : 22.740112994350284
Actor Loss : 9506.6884765625
Train_EnvstepsSoFar : 48207
TimeSinceStart : 32.63072156906128
Done logging...



********** Iteration 12 ************

Collecting data for eval...
Eval_AverageReturn : 21.6842098236084
Eval_StdReturn : 2.656721830368042
Eval_MaxReturn : 27.0
Eval_MinReturn : 18.0
Eval_AverageEpLen : 21.68421052631579
Train_AverageReturn : 22.5
Train_StdReturn : 4.082367897033691
Train_MaxReturn : 33.0
Train_MinReturn : 16.0
Train_AverageEpLen : 22.5
Actor Loss : 7842.861328125
Train_EnvstepsSoFar : 52212
TimeSinceStart : 37.96951460838318
Done logging...



********** Iteration 13 ************

Collecting data for eval...
Eval_AverageReturn : 22.88888931274414
Eval_StdReturn : 3.8857131004333496
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.88888888888889
Train_AverageReturn : 22.396648406982422
Train_StdReturn : 3.9016098976135254
Train_MaxReturn : 33.0
Train_MinReturn : 16.0
Train_AverageEpLen : 22.39664804469274
Actor Loss : 6533.1337890625
Train_EnvstepsSoFar : 56221
TimeSinceStart : 40.573880195617676
Done logging...



********** Iteration 14 ************

Collecting data for eval...
Eval_AverageReturn : 21.105262756347656
Eval_StdReturn : 3.823676109313965
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.105263157894736
Train_AverageReturn : 22.093406677246094
Train_StdReturn : 3.764650583267212
Train_MaxReturn : 33.0
Train_MinReturn : 16.0
Train_AverageEpLen : 22.093406593406595
Actor Loss : 5458.53076171875
Train_EnvstepsSoFar : 60242
TimeSinceStart : 43.44814085960388
Done logging...



********** Iteration 15 ************

Collecting data for eval...
Eval_AverageReturn : 22.55555534362793
Eval_StdReturn : 3.608973979949951
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.555555555555557
Train_AverageReturn : 21.842391967773438
Train_StdReturn : 3.892879009246826
Train_MaxReturn : 33.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.842391304347824
Actor Loss : 4528.572265625
Train_EnvstepsSoFar : 64261
TimeSinceStart : 46.82947564125061
Done logging...



********** Iteration 16 ************

Collecting data for eval...
Eval_AverageReturn : 22.5
Eval_StdReturn : 4.20647668838501
Eval_MaxReturn : 32.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.5
Train_AverageReturn : 22.288888931274414
Train_StdReturn : 3.977001667022705
Train_MaxReturn : 32.0
Train_MinReturn : 16.0
Train_AverageEpLen : 22.288888888888888
Actor Loss : 3903.14208984375
Train_EnvstepsSoFar : 68273
TimeSinceStart : 50.02758288383484
Done logging...



********** Iteration 17 ************

Collecting data for eval...
Eval_AverageReturn : 23.05555534362793
Eval_StdReturn : 2.8376872539520264
Eval_MaxReturn : 28.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 23.055555555555557
Train_AverageReturn : 22.266666412353516
Train_StdReturn : 3.78975248336792
Train_MaxReturn : 32.0
Train_MinReturn : 16.0
Train_AverageEpLen : 22.266666666666666
Actor Loss : 3185.40478515625
Train_EnvstepsSoFar : 72281
TimeSinceStart : 53.33843803405762
Done logging...



********** Iteration 18 ************

Collecting data for eval...
Eval_AverageReturn : 23.16666603088379
Eval_StdReturn : 4.126472473144531
Eval_MaxReturn : 31.0
Eval_MinReturn : 18.0
Eval_AverageEpLen : 23.166666666666668
Train_AverageReturn : 22.458101272583008
Train_StdReturn : 3.8552262783050537
Train_MaxReturn : 33.0
Train_MinReturn : 16.0
Train_AverageEpLen : 22.45810055865922
Actor Loss : 2797.9345703125
Train_EnvstepsSoFar : 76301
TimeSinceStart : 56.37850642204285
Done logging...



********** Iteration 19 ************

Collecting data for eval...
Eval_AverageReturn : 22.22222137451172
Eval_StdReturn : 3.9094693660736084
Eval_MaxReturn : 32.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 22.22222222222222
Train_AverageReturn : 22.372222900390625
Train_StdReturn : 3.7535619735717773
Train_MaxReturn : 32.0
Train_MinReturn : 16.0
Train_AverageEpLen : 22.372222222222224
Actor Loss : 2376.916259765625
Train_EnvstepsSoFar : 80328
TimeSinceStart : 59.76164531707764
Done logging...



********** Iteration 20 ************

Collecting data for eval...
Eval_AverageReturn : 23.5
Eval_StdReturn : 3.484090805053711
Eval_MaxReturn : 30.0
Eval_MinReturn : 18.0
Eval_AverageEpLen : 23.5
Train_AverageReturn : 22.299999237060547
Train_StdReturn : 3.7887258529663086
Train_MaxReturn : 32.0
Train_MinReturn : 16.0
Train_AverageEpLen : 22.3
Actor Loss : 2091.579345703125
Train_EnvstepsSoFar : 84342
TimeSinceStart : 63.238369941711426
Done logging...



********** Iteration 21 ************

Collecting data for eval...
Eval_AverageReturn : 21.6842098236084
Eval_StdReturn : 4.657225608825684
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.68421052631579
Train_AverageReturn : 22.22222137451172
Train_StdReturn : 3.8909518718719482
Train_MaxReturn : 33.0
Train_MinReturn : 16.0
Train_AverageEpLen : 22.22222222222222
Actor Loss : 1795.689697265625
Train_EnvstepsSoFar : 88342
TimeSinceStart : 66.28570461273193
Done logging...



********** Iteration 22 ************

Collecting data for eval...
Eval_AverageReturn : 22.052631378173828
Eval_StdReturn : 3.9666197299957275
Eval_MaxReturn : 32.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.05263157894737
Train_AverageReturn : 21.55376434326172
Train_StdReturn : 3.993248701095581
Train_MaxReturn : 32.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.553763440860216
Actor Loss : 1609.159423828125
Train_EnvstepsSoFar : 92351
TimeSinceStart : 69.37578272819519
Done logging...



********** Iteration 23 ************

Collecting data for eval...
Eval_AverageReturn : 22.88888931274414
Eval_StdReturn : 3.6192216873168945
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.88888888888889
Train_AverageReturn : 21.9071044921875
Train_StdReturn : 3.722198486328125
Train_MaxReturn : 32.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.907103825136613
Actor Loss : 1419.9642333984375
Train_EnvstepsSoFar : 96360
TimeSinceStart : 72.36431503295898
Done logging...



********** Iteration 24 ************

Collecting data for eval...
Eval_AverageReturn : 20.75
Eval_StdReturn : 3.7399866580963135
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.75
Train_AverageReturn : 21.994535446166992
Train_StdReturn : 3.860260248184204
Train_MaxReturn : 32.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.994535519125684
Actor Loss : 1250.082763671875
Train_EnvstepsSoFar : 100385
TimeSinceStart : 76.72711277008057
Done logging...



********** Iteration 25 ************

Collecting data for eval...
Eval_AverageReturn : 21.6842098236084
Eval_StdReturn : 4.193386077880859
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.68421052631579
Train_AverageReturn : 21.356382369995117
Train_StdReturn : 3.835113763809204
Train_MaxReturn : 32.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.356382978723403
Actor Loss : 1199.022705078125
Train_EnvstepsSoFar : 104400
TimeSinceStart : 79.872727394104
Done logging...



********** Iteration 26 ************

Collecting data for eval...
Eval_AverageReturn : 21.3157901763916
Eval_StdReturn : 3.1128363609313965
Eval_MaxReturn : 28.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 21.31578947368421
Train_AverageReturn : 21.70270347595215
Train_StdReturn : 4.004489898681641
Train_MaxReturn : 32.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.7027027027027
Actor Loss : 1054.905517578125
Train_EnvstepsSoFar : 108415
TimeSinceStart : 83.25157976150513
Done logging...



********** Iteration 27 ************

Collecting data for eval...
Eval_AverageReturn : 23.52941131591797
Eval_StdReturn : 4.326629638671875
Eval_MaxReturn : 30.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 23.529411764705884
Train_AverageReturn : 20.706186294555664
Train_StdReturn : 3.511580467224121
Train_MaxReturn : 32.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.70618556701031
Actor Loss : 987.705322265625
Train_EnvstepsSoFar : 112432
TimeSinceStart : 86.30484890937805
Done logging...



********** Iteration 28 ************

Collecting data for eval...
Eval_AverageReturn : 21.63157844543457
Eval_StdReturn : 3.2315962314605713
Eval_MaxReturn : 27.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.63157894736842
Train_AverageReturn : 22.076923370361328
Train_StdReturn : 4.123720169067383
Train_MaxReturn : 32.0
Train_MinReturn : 15.0
Train_AverageEpLen : 22.076923076923077
Actor Loss : 885.2691650390625
Train_EnvstepsSoFar : 116450
TimeSinceStart : 89.64953327178955
Done logging...



********** Iteration 29 ************

Collecting data for eval...
Eval_AverageReturn : 22.61111068725586
Eval_StdReturn : 3.0937013626098633
Eval_MaxReturn : 27.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.61111111111111
Train_AverageReturn : 21.586021423339844
Train_StdReturn : 3.912431001663208
Train_MaxReturn : 32.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.586021505376344
Actor Loss : 871.046630859375
Train_EnvstepsSoFar : 120465
TimeSinceStart : 92.80888652801514
Done logging...



********** Iteration 30 ************

Collecting data for eval...
Eval_AverageReturn : 21.63157844543457
Eval_StdReturn : 2.9237775802612305
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.63157894736842
Train_AverageReturn : 21.52688217163086
Train_StdReturn : 3.9651477336883545
Train_MaxReturn : 32.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.526881720430108
Actor Loss : 774.574951171875
Train_EnvstepsSoFar : 124469
TimeSinceStart : 96.04492473602295
Done logging...



********** Iteration 31 ************

Collecting data for eval...
Eval_AverageReturn : 21.157894134521484
Eval_StdReturn : 3.296938896179199
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.157894736842106
Train_AverageReturn : 21.70270347595215
Train_StdReturn : 3.8797104358673096
Train_MaxReturn : 32.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.7027027027027
Actor Loss : 745.2284545898438
Train_EnvstepsSoFar : 128484
TimeSinceStart : 99.40438389778137
Done logging...



********** Iteration 32 ************

Collecting data for eval...
Eval_AverageReturn : 22.27777862548828
Eval_StdReturn : 3.158859968185425
Eval_MaxReturn : 27.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 22.27777777777778
Train_AverageReturn : 21.863388061523438
Train_StdReturn : 3.8279848098754883
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.863387978142075
Actor Loss : 693.908203125
Train_EnvstepsSoFar : 132485
TimeSinceStart : 102.57561659812927
Done logging...



********** Iteration 33 ************

Collecting data for eval...
Eval_AverageReturn : 23.11111068725586
Eval_StdReturn : 3.8857131004333496
Eval_MaxReturn : 30.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 23.11111111111111
Train_AverageReturn : 21.62702751159668
Train_StdReturn : 4.086407661437988
Train_MaxReturn : 32.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.627027027027026
Actor Loss : 649.0263671875
Train_EnvstepsSoFar : 136486
TimeSinceStart : 105.93973565101624
Done logging...



********** Iteration 34 ************

Collecting data for eval...
Eval_AverageReturn : 20.649999618530273
Eval_StdReturn : 3.496784210205078
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.65
Train_AverageReturn : 21.1693115234375
Train_StdReturn : 3.8037729263305664
Train_MaxReturn : 32.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.16931216931217
Actor Loss : 658.7520751953125
Train_EnvstepsSoFar : 140487
TimeSinceStart : 109.22080898284912
Done logging...



********** Iteration 35 ************

Collecting data for eval...
Eval_AverageReturn : 21.3157901763916
Eval_StdReturn : 3.7704200744628906
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.31578947368421
Train_AverageReturn : 21.923498153686523
Train_StdReturn : 3.9150328636169434
Train_MaxReturn : 31.0
Train_MinReturn : 16.0
Train_AverageEpLen : 21.92349726775956
Actor Loss : 600.7706909179688
Train_EnvstepsSoFar : 144499
TimeSinceStart : 113.38435316085815
Done logging...



********** Iteration 36 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 3.499642848968506
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 21.62702751159668
Train_StdReturn : 4.159823417663574
Train_MaxReturn : 32.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.627027027027026
Actor Loss : 609.1043701171875
Train_EnvstepsSoFar : 148500
TimeSinceStart : 116.09918403625488
Done logging...



********** Iteration 37 ************

Collecting data for eval...
Eval_AverageReturn : 21.200000762939453
Eval_StdReturn : 3.17175030708313
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.2
Train_AverageReturn : 21.896175384521484
Train_StdReturn : 4.067079067230225
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.896174863387976
Actor Loss : 566.4444580078125
Train_EnvstepsSoFar : 152507
TimeSinceStart : 119.1261796951294
Done logging...



********** Iteration 38 ************

Collecting data for eval...
Eval_AverageReturn : 22.052631378173828
Eval_StdReturn : 3.619736671447754
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.05263157894737
Train_AverageReturn : 21.543010711669922
Train_StdReturn : 4.129721641540527
Train_MaxReturn : 32.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.543010752688172
Actor Loss : 577.3009643554688
Train_EnvstepsSoFar : 156514
TimeSinceStart : 122.41552901268005
Done logging...



********** Iteration 39 ************

Collecting data for eval...
Eval_AverageReturn : 21.210525512695312
Eval_StdReturn : 3.472886562347412
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.210526315789473
Train_AverageReturn : 21.532258987426758
Train_StdReturn : 4.006920337677002
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.532258064516128
Actor Loss : 508.1951904296875
Train_EnvstepsSoFar : 160519
TimeSinceStart : 125.07638430595398
Done logging...



********** Iteration 40 ************

Collecting data for eval...
Eval_AverageReturn : 22.72222137451172
Eval_StdReturn : 4.793578624725342
Eval_MaxReturn : 32.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 22.72222222222222
Train_AverageReturn : 21.890710830688477
Train_StdReturn : 3.9710798263549805
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.89071038251366
Actor Loss : 485.3179931640625
Train_EnvstepsSoFar : 164525
TimeSinceStart : 128.4426028728485
Done logging...



********** Iteration 41 ************

Collecting data for eval...
Eval_AverageReturn : 21.736841201782227
Eval_StdReturn : 3.4003419876098633
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.736842105263158
Train_AverageReturn : 21.71351432800293
Train_StdReturn : 3.9754762649536133
Train_MaxReturn : 33.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.713513513513515
Actor Loss : 467.2352600097656
Train_EnvstepsSoFar : 168542
TimeSinceStart : 131.51769423484802
Done logging...



********** Iteration 42 ************

Collecting data for eval...
Eval_AverageReturn : 21.473684310913086
Eval_StdReturn : 3.439223051071167
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.473684210526315
Train_AverageReturn : 21.7608699798584
Train_StdReturn : 3.996927261352539
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.76086956521739
Actor Loss : 490.2445068359375
Train_EnvstepsSoFar : 172546
TimeSinceStart : 134.8653848171234
Done logging...



********** Iteration 43 ************

Collecting data for eval...
Eval_AverageReturn : 20.450000762939453
Eval_StdReturn : 3.201171636581421
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.45
Train_AverageReturn : 21.72432518005371
Train_StdReturn : 4.126997947692871
Train_MaxReturn : 32.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.724324324324325
Actor Loss : 461.6705322265625
Train_EnvstepsSoFar : 176565
TimeSinceStart : 138.2326467037201
Done logging...



********** Iteration 44 ************

Collecting data for eval...
Eval_AverageReturn : 20.75
Eval_StdReturn : 3.284433126449585
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.75
Train_AverageReturn : 21.28191566467285
Train_StdReturn : 3.9800424575805664
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.28191489361702
Actor Loss : 424.7889404296875
Train_EnvstepsSoFar : 180566
TimeSinceStart : 142.00852036476135
Done logging...



********** Iteration 45 ************

Collecting data for eval...
Eval_AverageReturn : 21.210525512695312
Eval_StdReturn : 4.359851837158203
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.210526315789473
Train_AverageReturn : 21.174602508544922
Train_StdReturn : 3.844351053237915
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.174603174603174
Actor Loss : 433.69476318359375
Train_EnvstepsSoFar : 184568
TimeSinceStart : 144.54796528816223
Done logging...



********** Iteration 46 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 3.1060426235198975
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 21.179893493652344
Train_StdReturn : 3.419430732727051
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.17989417989418
Actor Loss : 401.3984680175781
Train_EnvstepsSoFar : 188571
TimeSinceStart : 147.43787693977356
Done logging...



********** Iteration 47 ************

Collecting data for eval...
Eval_AverageReturn : 21.6842098236084
Eval_StdReturn : 4.496228218078613
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.68421052631579
Train_AverageReturn : 21.20105743408203
Train_StdReturn : 3.861599922180176
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.201058201058203
Actor Loss : 390.0370788574219
Train_EnvstepsSoFar : 192578
TimeSinceStart : 149.97455859184265
Done logging...



********** Iteration 48 ************

Collecting data for eval...
Eval_AverageReturn : 21.157894134521484
Eval_StdReturn : 3.84246563911438
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.157894736842106
Train_AverageReturn : 21.48128318786621
Train_StdReturn : 4.1770219802856445
Train_MaxReturn : 32.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.481283422459892
Actor Loss : 392.14508056640625
Train_EnvstepsSoFar : 196595
TimeSinceStart : 152.8988709449768
Done logging...



********** Iteration 49 ************

Collecting data for eval...
Eval_AverageReturn : 21.105262756347656
Eval_StdReturn : 3.837416172027588
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.105263157894736
Train_AverageReturn : 21.01047134399414
Train_StdReturn : 3.908628463745117
Train_MaxReturn : 32.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.01047120418848
Actor Loss : 399.2492980957031
Train_EnvstepsSoFar : 200608
TimeSinceStart : 155.6697130203247
Done logging...



********** Iteration 50 ************

Collecting data for eval...
Eval_AverageReturn : 21.473684310913086
Eval_StdReturn : 4.20986795425415
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.473684210526315
Train_AverageReturn : 21.276596069335938
Train_StdReturn : 3.986424446105957
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.27659574468085
Actor Loss : 374.03155517578125
Train_EnvstepsSoFar : 204608
TimeSinceStart : 158.18687987327576
Done logging...



********** Iteration 51 ************

Collecting data for eval...
Eval_AverageReturn : 22.44444465637207
Eval_StdReturn : 4.424957275390625
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.444444444444443
Train_AverageReturn : 21.259260177612305
Train_StdReturn : 3.964322566986084
Train_MaxReturn : 32.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.25925925925926
Actor Loss : 402.85968017578125
Train_EnvstepsSoFar : 208626
TimeSinceStart : 160.73473167419434
Done logging...



********** Iteration 52 ************

Collecting data for eval...
Eval_AverageReturn : 21.526315689086914
Eval_StdReturn : 3.760856866836548
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.526315789473685
Train_AverageReturn : 21.292552947998047
Train_StdReturn : 3.872234582901001
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.29255319148936
Actor Loss : 329.374755859375
Train_EnvstepsSoFar : 212629
TimeSinceStart : 163.27004265785217
Done logging...



********** Iteration 53 ************

Collecting data for eval...
Eval_AverageReturn : 20.649999618530273
Eval_StdReturn : 4.373499393463135
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.65
Train_AverageReturn : 21.264551162719727
Train_StdReturn : 3.842654228210449
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.264550264550266
Actor Loss : 299.96038818359375
Train_EnvstepsSoFar : 216648
TimeSinceStart : 165.83257913589478
Done logging...



********** Iteration 54 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 3.773592472076416
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 21.64324378967285
Train_StdReturn : 3.6275627613067627
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.643243243243244
Actor Loss : 334.0067138671875
Train_EnvstepsSoFar : 220652
TimeSinceStart : 168.39299654960632
Done logging...



********** Iteration 55 ************

Collecting data for eval...
Eval_AverageReturn : 21.3157901763916
Eval_StdReturn : 4.243293762207031
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.31578947368421
Train_AverageReturn : 20.86458396911621
Train_StdReturn : 4.186087608337402
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.864583333333332
Actor Loss : 366.3419494628906
Train_EnvstepsSoFar : 224658
TimeSinceStart : 170.91831636428833
Done logging...



********** Iteration 56 ************

Collecting data for eval...
Eval_AverageReturn : 22.27777862548828
Eval_StdReturn : 4.024998664855957
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 22.27777777777778
Train_AverageReturn : 20.86979103088379
Train_StdReturn : 4.1115593910217285
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.869791666666668
Actor Loss : 329.88641357421875
Train_EnvstepsSoFar : 228665
TimeSinceStart : 175.9471538066864
Done logging...



********** Iteration 57 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 3.7469985485076904
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 21.287233352661133
Train_StdReturn : 3.836061716079712
Train_MaxReturn : 32.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.28723404255319
Actor Loss : 334.6063232421875
Train_EnvstepsSoFar : 232667
TimeSinceStart : 178.4562132358551
Done logging...



********** Iteration 58 ************

Collecting data for eval...
Eval_AverageReturn : 21.105262756347656
Eval_StdReturn : 4.063894271850586
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.105263157894736
Train_AverageReturn : 20.69072151184082
Train_StdReturn : 3.6983160972595215
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.690721649484537
Actor Loss : 311.864013671875
Train_EnvstepsSoFar : 236681
TimeSinceStart : 182.93133449554443
Done logging...



********** Iteration 59 ************

Collecting data for eval...
Eval_AverageReturn : 20.450000762939453
Eval_StdReturn : 3.667083263397217
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.45
Train_AverageReturn : 20.968585968017578
Train_StdReturn : 3.6537375450134277
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.968586387434556
Actor Loss : 294.3121643066406
Train_EnvstepsSoFar : 240686
TimeSinceStart : 185.55145716667175
Done logging...



********** Iteration 60 ************

Collecting data for eval...
Eval_AverageReturn : 23.22222137451172
Eval_StdReturn : 3.359158992767334
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 23.22222222222222
Train_AverageReturn : 20.7668399810791
Train_StdReturn : 3.8592514991760254
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.76683937823834
Actor Loss : 318.74530029296875
Train_EnvstepsSoFar : 244694
TimeSinceStart : 188.6246953010559
Done logging...



********** Iteration 61 ************

Collecting data for eval...
Eval_AverageReturn : 21.578947067260742
Eval_StdReturn : 3.2657036781311035
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.57894736842105
Train_AverageReturn : 21.152631759643555
Train_StdReturn : 3.9166135787963867
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.152631578947368
Actor Loss : 299.9226379394531
Train_EnvstepsSoFar : 248713
TimeSinceStart : 192.52984023094177
Done logging...



********** Iteration 62 ************

Collecting data for eval...
Eval_AverageReturn : 20.5
Eval_StdReturn : 4.043513298034668
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.5
Train_AverageReturn : 20.548717498779297
Train_StdReturn : 3.837926149368286
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.54871794871795
Actor Loss : 358.62451171875
Train_EnvstepsSoFar : 252720
TimeSinceStart : 195.8431851863861
Done logging...



********** Iteration 63 ************

Collecting data for eval...
Eval_AverageReturn : 20.0
Eval_StdReturn : 2.880972146987915
Eval_MaxReturn : 25.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.0
Train_AverageReturn : 20.75129508972168
Train_StdReturn : 3.6802666187286377
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.751295336787564
Actor Loss : 271.6570739746094
Train_EnvstepsSoFar : 256725
TimeSinceStart : 199.19594740867615
Done logging...



********** Iteration 64 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 3.6038174629211426
Eval_MaxReturn : 27.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 20.9375
Train_StdReturn : 3.8952763080596924
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.9375
Actor Loss : 275.9888610839844
Train_EnvstepsSoFar : 260745
TimeSinceStart : 202.1554000377655
Done logging...



********** Iteration 65 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 4.054626941680908
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.90625
Train_StdReturn : 3.831280469894409
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.90625
Actor Loss : 254.77279663085938
Train_EnvstepsSoFar : 264759
TimeSinceStart : 205.16795444488525
Done logging...



********** Iteration 66 ************

Collecting data for eval...
Eval_AverageReturn : 21.263158798217773
Eval_StdReturn : 4.101888179779053
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.263157894736842
Train_AverageReturn : 20.68041229248047
Train_StdReturn : 3.952153205871582
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.68041237113402
Actor Loss : 299.0999450683594
Train_EnvstepsSoFar : 268771
TimeSinceStart : 208.0944323539734
Done logging...



********** Iteration 67 ************

Collecting data for eval...
Eval_AverageReturn : 20.100000381469727
Eval_StdReturn : 4.1940436363220215
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.1
Train_AverageReturn : 20.78238296508789
Train_StdReturn : 3.979780673980713
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.78238341968912
Actor Loss : 266.8175048828125
Train_EnvstepsSoFar : 272782
TimeSinceStart : 210.97581958770752
Done logging...



********** Iteration 68 ************

Collecting data for eval...
Eval_AverageReturn : 20.75
Eval_StdReturn : 3.845451831817627
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.75
Train_AverageReturn : 20.049999237060547
Train_StdReturn : 3.63283634185791
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.05
Actor Loss : 237.71705627441406
Train_EnvstepsSoFar : 276792
TimeSinceStart : 214.17145895957947
Done logging...



********** Iteration 69 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 3.699662208557129
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 20.217172622680664
Train_StdReturn : 3.96427321434021
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.217171717171716
Actor Loss : 255.55532836914062
Train_EnvstepsSoFar : 280795
TimeSinceStart : 217.3705313205719
Done logging...



********** Iteration 70 ************

Collecting data for eval...
Eval_AverageReturn : 21.263158798217773
Eval_StdReturn : 3.809159517288208
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.263157894736842
Train_AverageReturn : 20.558975219726562
Train_StdReturn : 3.7866649627685547
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.55897435897436
Actor Loss : 218.72616577148438
Train_EnvstepsSoFar : 284804
TimeSinceStart : 219.97418308258057
Done logging...



********** Iteration 71 ************

Collecting data for eval...
Eval_AverageReturn : 21.105262756347656
Eval_StdReturn : 4.733917713165283
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.105263157894736
Train_AverageReturn : 20.5230770111084
Train_StdReturn : 3.8661227226257324
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.523076923076925
Actor Loss : 240.718017578125
Train_EnvstepsSoFar : 288806
TimeSinceStart : 223.25304007530212
Done logging...



********** Iteration 72 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 3.2465364933013916
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 20.4489803314209
Train_StdReturn : 4.018128395080566
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.448979591836736
Actor Loss : 275.7707214355469
Train_EnvstepsSoFar : 292814
TimeSinceStart : 226.34165024757385
Done logging...



********** Iteration 73 ************

Collecting data for eval...
Eval_AverageReturn : 20.5
Eval_StdReturn : 4.5880279541015625
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.5
Train_AverageReturn : 20.74611473083496
Train_StdReturn : 3.812006950378418
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.746113989637305
Actor Loss : 240.03587341308594
Train_EnvstepsSoFar : 296818
TimeSinceStart : 229.46564602851868
Done logging...



********** Iteration 74 ************

Collecting data for eval...
Eval_AverageReturn : 21.6842098236084
Eval_StdReturn : 4.142877578735352
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.68421052631579
Train_AverageReturn : 20.37055778503418
Train_StdReturn : 3.8367373943328857
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.370558375634516
Actor Loss : 206.88125610351562
Train_EnvstepsSoFar : 300831
TimeSinceStart : 232.67616081237793
Done logging...



********** Iteration 75 ************

Collecting data for eval...
Eval_AverageReturn : 20.095237731933594
Eval_StdReturn : 3.037930727005005
Eval_MaxReturn : 26.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.095238095238095
Train_AverageReturn : 20.564102172851562
Train_StdReturn : 3.947052478790283
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.564102564102566
Actor Loss : 230.861083984375
Train_EnvstepsSoFar : 304841
TimeSinceStart : 235.5102255344391
Done logging...



********** Iteration 76 ************

Collecting data for eval...
Eval_AverageReturn : 20.0
Eval_StdReturn : 3.3094382286071777
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.0
Train_AverageReturn : 20.62371063232422
Train_StdReturn : 4.069962024688721
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.623711340206185
Actor Loss : 226.38723754882812
Train_EnvstepsSoFar : 308842
TimeSinceStart : 238.16374397277832
Done logging...



********** Iteration 77 ************

Collecting data for eval...
Eval_AverageReturn : 20.649999618530273
Eval_StdReturn : 3.52526593208313
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.65
Train_AverageReturn : 20.61855697631836
Train_StdReturn : 4.0840229988098145
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.61855670103093
Actor Loss : 249.77548217773438
Train_EnvstepsSoFar : 312842
TimeSinceStart : 240.89778423309326
Done logging...



********** Iteration 78 ************

Collecting data for eval...
Eval_AverageReturn : 20.5
Eval_StdReturn : 3.681032419204712
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.5
Train_AverageReturn : 20.48469352722168
Train_StdReturn : 4.041212558746338
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.48469387755102
Actor Loss : 206.19210815429688
Train_EnvstepsSoFar : 316857
TimeSinceStart : 244.12929940223694
Done logging...



********** Iteration 79 ************

Collecting data for eval...
Eval_AverageReturn : 19.5238094329834
Eval_StdReturn : 2.83882999420166
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.523809523809526
Train_AverageReturn : 20.98952865600586
Train_StdReturn : 4.117374420166016
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.98952879581152
Actor Loss : 215.85366821289062
Train_EnvstepsSoFar : 320866
TimeSinceStart : 247.1901240348816
Done logging...



********** Iteration 80 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 3.9166314601898193
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.958114624023438
Train_StdReturn : 4.034968376159668
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.958115183246072
Actor Loss : 203.45556640625
Train_EnvstepsSoFar : 324869
TimeSinceStart : 250.20843768119812
Done logging...



********** Iteration 81 ************

Collecting data for eval...
Eval_AverageReturn : 21.105262756347656
Eval_StdReturn : 3.3070056438446045
Eval_MaxReturn : 27.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.105263157894736
Train_AverageReturn : 20.26262664794922
Train_StdReturn : 3.988837480545044
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.262626262626263
Actor Loss : 223.75408935546875
Train_EnvstepsSoFar : 328881
TimeSinceStart : 253.1376440525055
Done logging...



********** Iteration 82 ************

Collecting data for eval...
Eval_AverageReturn : 21.526315689086914
Eval_StdReturn : 4.333084583282471
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.526315789473685
Train_AverageReturn : 21.06842041015625
Train_StdReturn : 3.9696946144104004
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.068421052631578
Actor Loss : 212.52040100097656
Train_EnvstepsSoFar : 332884
TimeSinceStart : 256.2929003238678
Done logging...



********** Iteration 83 ************

Collecting data for eval...
Eval_AverageReturn : 21.105262756347656
Eval_StdReturn : 3.5376877784729004
Eval_MaxReturn : 27.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.105263157894736
Train_AverageReturn : 20.97382164001465
Train_StdReturn : 4.301995754241943
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.973821989528794
Actor Loss : 219.4279022216797
Train_EnvstepsSoFar : 336890
TimeSinceStart : 259.61232829093933
Done logging...



********** Iteration 84 ************

Collecting data for eval...
Eval_AverageReturn : 19.761905670166016
Eval_StdReturn : 4.1392974853515625
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.761904761904763
Train_AverageReturn : 21.121051788330078
Train_StdReturn : 4.022447109222412
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.121052631578948
Actor Loss : 199.78785705566406
Train_EnvstepsSoFar : 340903
TimeSinceStart : 262.9429461956024
Done logging...



********** Iteration 85 ************

Collecting data for eval...
Eval_AverageReturn : 20.299999237060547
Eval_StdReturn : 4.255584239959717
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.3
Train_AverageReturn : 20.569231033325195
Train_StdReturn : 4.062218189239502
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.56923076923077
Actor Loss : 205.56277465820312
Train_EnvstepsSoFar : 344914
TimeSinceStart : 265.9373743534088
Done logging...



********** Iteration 86 ************

Collecting data for eval...
Eval_AverageReturn : 19.761905670166016
Eval_StdReturn : 3.220540761947632
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.761904761904763
Train_AverageReturn : 20.489795684814453
Train_StdReturn : 4.1496124267578125
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.489795918367346
Actor Loss : 256.74420166015625
Train_EnvstepsSoFar : 348930
TimeSinceStart : 268.8823399543762
Done logging...



********** Iteration 87 ************

Collecting data for eval...
Eval_AverageReturn : 20.049999237060547
Eval_StdReturn : 4.067861557006836
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.05
Train_AverageReturn : 20.29292869567871
Train_StdReturn : 3.5837807655334473
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.292929292929294
Actor Loss : 205.9340057373047
Train_EnvstepsSoFar : 352948
TimeSinceStart : 272.0240070819855
Done logging...



********** Iteration 88 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 3.773592472076416
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.90104103088379
Train_StdReturn : 3.9522671699523926
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.901041666666668
Actor Loss : 185.12954711914062
Train_EnvstepsSoFar : 356961
TimeSinceStart : 275.36306166648865
Done logging...



********** Iteration 89 ************

Collecting data for eval...
Eval_AverageReturn : 20.100000381469727
Eval_StdReturn : 4.2649736404418945
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.1
Train_AverageReturn : 20.73575210571289
Train_StdReturn : 3.915905714035034
Train_MaxReturn : 29.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.735751295336787
Actor Loss : 167.97344970703125
Train_EnvstepsSoFar : 360963
TimeSinceStart : 278.6850411891937
Done logging...



********** Iteration 90 ************

Collecting data for eval...
Eval_AverageReturn : 21.157894134521484
Eval_StdReturn : 4.196027755737305
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.157894736842106
Train_AverageReturn : 20.74093246459961
Train_StdReturn : 4.039344787597656
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.740932642487046
Actor Loss : 170.848388671875
Train_EnvstepsSoFar : 364966
TimeSinceStart : 284.3570439815521
Done logging...



********** Iteration 91 ************

Collecting data for eval...
Eval_AverageReturn : 20.700000762939453
Eval_StdReturn : 4.026164531707764
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.7
Train_AverageReturn : 20.61855697631836
Train_StdReturn : 3.8353841304779053
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.61855670103093
Actor Loss : 156.51959228515625
Train_EnvstepsSoFar : 368966
TimeSinceStart : 287.72788882255554
Done logging...



********** Iteration 92 ************

Collecting data for eval...
Eval_AverageReturn : 20.450000762939453
Eval_StdReturn : 4.283398151397705
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.45
Train_AverageReturn : 20.558975219726562
Train_StdReturn : 4.153510570526123
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.55897435897436
Actor Loss : 180.52752685546875
Train_EnvstepsSoFar : 372975
TimeSinceStart : 290.6313199996948
Done logging...



********** Iteration 93 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 3.4680685997009277
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 20.558975219726562
Train_StdReturn : 3.859102964401245
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.55897435897436
Actor Loss : 150.4815216064453
Train_EnvstepsSoFar : 376984
TimeSinceStart : 293.6591875553131
Done logging...



********** Iteration 94 ************

Collecting data for eval...
Eval_AverageReturn : 21.052631378173828
Eval_StdReturn : 2.781019926071167
Eval_MaxReturn : 28.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 21.05263157894737
Train_AverageReturn : 20.664947509765625
Train_StdReturn : 4.1994242668151855
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.664948453608247
Actor Loss : 145.45375061035156
Train_EnvstepsSoFar : 380993
TimeSinceStart : 296.33342957496643
Done logging...



********** Iteration 95 ************

Collecting data for eval...
Eval_AverageReturn : 20.5
Eval_StdReturn : 4.376071453094482
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.5
Train_AverageReturn : 20.345178604125977
Train_StdReturn : 3.720247507095337
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.34517766497462
Actor Loss : 116.77791595458984
Train_EnvstepsSoFar : 385001
TimeSinceStart : 299.5512421131134
Done logging...



********** Iteration 96 ************

Collecting data for eval...
Eval_AverageReturn : 20.047618865966797
Eval_StdReturn : 4.017535209655762
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.047619047619047
Train_AverageReturn : 20.34010124206543
Train_StdReturn : 3.9400413036346436
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.34010152284264
Actor Loss : 140.91937255859375
Train_EnvstepsSoFar : 389008
TimeSinceStart : 302.6156373023987
Done logging...



********** Iteration 97 ************

Collecting data for eval...
Eval_AverageReturn : 21.200000762939453
Eval_StdReturn : 4.489988803863525
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.2
Train_AverageReturn : 20.62886619567871
Train_StdReturn : 4.112639427185059
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.628865979381445
Actor Loss : 145.13348388671875
Train_EnvstepsSoFar : 393010
TimeSinceStart : 305.9392669200897
Done logging...



********** Iteration 98 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 4.282522201538086
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 20.0049991607666
Train_StdReturn : 3.86716628074646
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.005
Actor Loss : 178.7681427001953
Train_EnvstepsSoFar : 397011
TimeSinceStart : 309.00291419029236
Done logging...



********** Iteration 99 ************

Collecting data for eval...
Eval_AverageReturn : 19.809524536132812
Eval_StdReturn : 4.360199451446533
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.80952380952381
Train_AverageReturn : 20.185930252075195
Train_StdReturn : 4.132309436798096
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.185929648241206
Actor Loss : 151.27389526367188
Train_EnvstepsSoFar : 401028
TimeSinceStart : 312.1030628681183
Done logging...



********** Iteration 100 ************

Collecting data for eval...
Eval_AverageReturn : 21.421052932739258
Eval_StdReturn : 4.4875946044921875
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.42105263157895
Train_AverageReturn : 20.190954208374023
Train_StdReturn : 3.779569149017334
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.190954773869347
Actor Loss : 123.48296356201172
Train_EnvstepsSoFar : 405046
TimeSinceStart : 315.3659472465515
Done logging...



********** Iteration 101 ************

Collecting data for eval...
Eval_AverageReturn : 20.100000381469727
Eval_StdReturn : 3.2388269901275635
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.1
Train_AverageReturn : 20.26262664794922
Train_StdReturn : 4.218970775604248
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.262626262626263
Actor Loss : 112.98251342773438
Train_EnvstepsSoFar : 409058
TimeSinceStart : 317.99793910980225
Done logging...



********** Iteration 102 ************

Collecting data for eval...
Eval_AverageReturn : 20.049999237060547
Eval_StdReturn : 4.488596439361572
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.05
Train_AverageReturn : 20.282827377319336
Train_StdReturn : 3.8822059631347656
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.282828282828284
Actor Loss : 107.09856414794922
Train_EnvstepsSoFar : 413074
TimeSinceStart : 320.8375754356384
Done logging...



********** Iteration 103 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 3.726593494415283
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 19.920398712158203
Train_StdReturn : 3.952910900115967
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.920398009950247
Actor Loss : 159.19227600097656
Train_EnvstepsSoFar : 417078
TimeSinceStart : 323.87296199798584
Done logging...



********** Iteration 104 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 3.9417526721954346
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 20.433673858642578
Train_StdReturn : 3.956483840942383
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.433673469387756
Actor Loss : 130.08395385742188
Train_EnvstepsSoFar : 421083
TimeSinceStart : 327.0378305912018
Done logging...



********** Iteration 105 ************

Collecting data for eval...
Eval_AverageReturn : 19.66666603088379
Eval_StdReturn : 3.454925298690796
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.666666666666668
Train_AverageReturn : 20.100000381469727
Train_StdReturn : 4.070626258850098
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.1
Actor Loss : 118.11827087402344
Train_EnvstepsSoFar : 425103
TimeSinceStart : 329.66510367393494
Done logging...



********** Iteration 106 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 4.114304065704346
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 20.2020206451416
Train_StdReturn : 3.8137969970703125
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.2020202020202
Actor Loss : 109.80050659179688
Train_EnvstepsSoFar : 429103
TimeSinceStart : 332.7820909023285
Done logging...



********** Iteration 107 ************

Collecting data for eval...
Eval_AverageReturn : 21.578947067260742
Eval_StdReturn : 3.8568568229675293
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.57894736842105
Train_AverageReturn : 21.417112350463867
Train_StdReturn : 4.127296447753906
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.41711229946524
Actor Loss : 110.42829132080078
Train_EnvstepsSoFar : 433108
TimeSinceStart : 335.8222246170044
Done logging...



********** Iteration 108 ************

Collecting data for eval...
Eval_AverageReturn : 22.052631378173828
Eval_StdReturn : 3.203183889389038
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.05263157894737
Train_AverageReturn : 20.308080673217773
Train_StdReturn : 4.041581153869629
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.30808080808081
Actor Loss : 129.89593505859375
Train_EnvstepsSoFar : 437129
TimeSinceStart : 339.38978385925293
Done logging...



********** Iteration 109 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 4.699734210968018
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 20.517948150634766
Train_StdReturn : 3.8555235862731934
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.51794871794872
Actor Loss : 102.39176940917969
Train_EnvstepsSoFar : 441130
TimeSinceStart : 343.342476606369
Done logging...



********** Iteration 110 ************

Collecting data for eval...
Eval_AverageReturn : 20.5
Eval_StdReturn : 4.364630699157715
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.5
Train_AverageReturn : 20.045000076293945
Train_StdReturn : 3.914456844329834
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.045
Actor Loss : 79.0132827758789
Train_EnvstepsSoFar : 445139
TimeSinceStart : 346.2171862125397
Done logging...



********** Iteration 111 ************

Collecting data for eval...
Eval_AverageReturn : 20.049999237060547
Eval_StdReturn : 3.9048047065734863
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.05
Train_AverageReturn : 20.538461685180664
Train_StdReturn : 4.063888072967529
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.53846153846154
Actor Loss : 83.09934997558594
Train_EnvstepsSoFar : 449144
TimeSinceStart : 349.3155632019043
Done logging...



********** Iteration 112 ************

Collecting data for eval...
Eval_AverageReturn : 21.105262756347656
Eval_StdReturn : 4.399697780609131
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.105263157894736
Train_AverageReturn : 20.83854103088379
Train_StdReturn : 3.9237489700317383
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.838541666666668
Actor Loss : 97.83585357666016
Train_EnvstepsSoFar : 453145
TimeSinceStart : 352.38409781455994
Done logging...



********** Iteration 113 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 3.48425030708313
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.479591369628906
Train_StdReturn : 4.209390640258789
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.479591836734695
Actor Loss : 66.23845672607422
Train_EnvstepsSoFar : 457159
TimeSinceStart : 358.58277702331543
Done logging...



********** Iteration 114 ************

Collecting data for eval...
Eval_AverageReturn : 20.75
Eval_StdReturn : 4.133702754974365
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.75
Train_AverageReturn : 20.059999465942383
Train_StdReturn : 4.282102108001709
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.06
Actor Loss : 90.15998077392578
Train_EnvstepsSoFar : 461171
TimeSinceStart : 361.7839376926422
Done logging...



********** Iteration 115 ************

Collecting data for eval...
Eval_AverageReturn : 20.700000762939453
Eval_StdReturn : 4.290687561035156
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.7
Train_AverageReturn : 20.63401985168457
Train_StdReturn : 3.970909357070923
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.6340206185567
Actor Loss : 63.15984344482422
Train_EnvstepsSoFar : 465174
TimeSinceStart : 364.425137758255
Done logging...



********** Iteration 116 ************

Collecting data for eval...
Eval_AverageReturn : 20.299999237060547
Eval_StdReturn : 4.4732537269592285
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.3
Train_AverageReturn : 20.564102172851562
Train_StdReturn : 4.074906826019287
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.564102564102566
Actor Loss : 61.8894157409668
Train_EnvstepsSoFar : 469184
TimeSinceStart : 370.5773460865021
Done logging...



********** Iteration 117 ************

Collecting data for eval...
Eval_AverageReturn : 21.63157844543457
Eval_StdReturn : 3.936476230621338
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.63157894736842
Train_AverageReturn : 20.459182739257812
Train_StdReturn : 4.111130714416504
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.459183673469386
Actor Loss : 66.38294219970703
Train_EnvstepsSoFar : 473194
TimeSinceStart : 373.11864590644836
Done logging...



********** Iteration 118 ************

Collecting data for eval...
Eval_AverageReturn : 19.904762268066406
Eval_StdReturn : 4.219058513641357
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.904761904761905
Train_AverageReturn : 20.963350296020508
Train_StdReturn : 4.013552665710449
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.963350785340314
Actor Loss : 52.47992706298828
Train_EnvstepsSoFar : 477198
TimeSinceStart : 375.77490520477295
Done logging...



********** Iteration 119 ************

Collecting data for eval...
Eval_AverageReturn : 21.63157844543457
Eval_StdReturn : 4.119409084320068
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.63157894736842
Train_AverageReturn : 20.324872970581055
Train_StdReturn : 3.7329702377319336
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.3248730964467
Actor Loss : 51.894622802734375
Train_EnvstepsSoFar : 481202
TimeSinceStart : 378.42066502571106
Done logging...



********** Iteration 120 ************

Collecting data for eval...
Eval_AverageReturn : 20.649999618530273
Eval_StdReturn : 3.1507935523986816
Eval_MaxReturn : 27.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.65
Train_AverageReturn : 20.31313133239746
Train_StdReturn : 4.276188373565674
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.31313131313131
Actor Loss : 57.11028289794922
Train_EnvstepsSoFar : 485224
TimeSinceStart : 381.2023994922638
Done logging...



********** Iteration 121 ************

Collecting data for eval...
Eval_AverageReturn : 19.761905670166016
Eval_StdReturn : 3.8035666942596436
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.761904761904763
Train_AverageReturn : 20.701030731201172
Train_StdReturn : 4.023551940917969
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.701030927835053
Actor Loss : 57.97662353515625
Train_EnvstepsSoFar : 489240
TimeSinceStart : 384.83670353889465
Done logging...



********** Iteration 122 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 4.035777568817139
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 20.90625
Train_StdReturn : 4.083957672119141
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.90625
Actor Loss : 50.86903381347656
Train_EnvstepsSoFar : 493254
TimeSinceStart : 389.3588547706604
Done logging...



********** Iteration 123 ************

Collecting data for eval...
Eval_AverageReturn : 20.049999237060547
Eval_StdReturn : 4.030818939208984
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.05
Train_AverageReturn : 19.871286392211914
Train_StdReturn : 3.974331855773926
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.871287128712872
Actor Loss : 51.84087371826172
Train_EnvstepsSoFar : 497268
TimeSinceStart : 392.33325576782227
Done logging...



********** Iteration 124 ************

Collecting data for eval...
Eval_AverageReturn : 20.299999237060547
Eval_StdReturn : 3.861346960067749
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.3
Train_AverageReturn : 19.995025634765625
Train_StdReturn : 4.219709396362305
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.99502487562189
Actor Loss : 49.692054748535156
Train_EnvstepsSoFar : 501287
TimeSinceStart : 394.9148573875427
Done logging...



********** Iteration 125 ************

Collecting data for eval...
Eval_AverageReturn : 19.619047164916992
Eval_StdReturn : 4.358638763427734
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.61904761904762
Train_AverageReturn : 20.68556785583496
Train_StdReturn : 3.915222644805908
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.685567010309278
Actor Loss : 49.10047149658203
Train_EnvstepsSoFar : 505300
TimeSinceStart : 397.4553575515747
Done logging...



********** Iteration 126 ************

Collecting data for eval...
Eval_AverageReturn : 21.473684310913086
Eval_StdReturn : 3.6759305000305176
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.473684210526315
Train_AverageReturn : 20.543590545654297
Train_StdReturn : 4.039788722991943
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.543589743589745
Actor Loss : 46.935489654541016
Train_EnvstepsSoFar : 509306
TimeSinceStart : 400.2852816581726
Done logging...



********** Iteration 127 ************

Collecting data for eval...
Eval_AverageReturn : 18.954545974731445
Eval_StdReturn : 4.183053016662598
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 18.954545454545453
Train_AverageReturn : 20.443878173828125
Train_StdReturn : 3.8824453353881836
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.443877551020407
Actor Loss : 44.22831344604492
Train_EnvstepsSoFar : 513313
TimeSinceStart : 403.61045360565186
Done logging...



********** Iteration 128 ************

Collecting data for eval...
Eval_AverageReturn : 21.049999237060547
Eval_StdReturn : 4.067861557006836
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.05
Train_AverageReturn : 19.806930541992188
Train_StdReturn : 3.934784173965454
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.806930693069308
Actor Loss : 45.13786315917969
Train_EnvstepsSoFar : 517314
TimeSinceStart : 406.51821184158325
Done logging...



********** Iteration 129 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 3.5693135261535645
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 19.995025634765625
Train_StdReturn : 3.784621238708496
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.99502487562189
Actor Loss : 42.80595397949219
Train_EnvstepsSoFar : 521333
TimeSinceStart : 410.3369836807251
Done logging...



********** Iteration 130 ************

Collecting data for eval...
Eval_AverageReturn : 21.263158798217773
Eval_StdReturn : 4.12747049331665
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.263157894736842
Train_AverageReturn : 20.35025405883789
Train_StdReturn : 3.9327032566070557
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.3502538071066
Actor Loss : 44.17786407470703
Train_EnvstepsSoFar : 525342
TimeSinceStart : 412.8786828517914
Done logging...



********** Iteration 131 ************

Collecting data for eval...
Eval_AverageReturn : 19.571428298950195
Eval_StdReturn : 3.7742414474487305
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.571428571428573
Train_AverageReturn : 20.155778884887695
Train_StdReturn : 4.080946445465088
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.155778894472363
Actor Loss : 35.97319793701172
Train_EnvstepsSoFar : 529353
TimeSinceStart : 415.3889994621277
Done logging...



********** Iteration 132 ************

Collecting data for eval...
Eval_AverageReturn : 22.66666603088379
Eval_StdReturn : 4.678556442260742
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 22.666666666666668
Train_AverageReturn : 21.395721435546875
Train_StdReturn : 4.143622875213623
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.39572192513369
Actor Loss : 27.588359832763672
Train_EnvstepsSoFar : 533354
TimeSinceStart : 417.88709473609924
Done logging...



********** Iteration 133 ************

Collecting data for eval...
Eval_AverageReturn : 19.809524536132812
Eval_StdReturn : 3.724041223526001
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.80952380952381
Train_AverageReturn : 20.26262664794922
Train_StdReturn : 4.194960594177246
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.262626262626263
Actor Loss : 39.8668212890625
Train_EnvstepsSoFar : 537366
TimeSinceStart : 421.01777029037476
Done logging...



********** Iteration 134 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 3.397057294845581
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.512821197509766
Train_StdReturn : 3.828850030899048
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.512820512820515
Actor Loss : 24.79166030883789
Train_EnvstepsSoFar : 541366
TimeSinceStart : 423.90933561325073
Done logging...



********** Iteration 135 ************

Collecting data for eval...
Eval_AverageReturn : 21.157894134521484
Eval_StdReturn : 3.8833401203155518
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.157894736842106
Train_AverageReturn : 21.036649703979492
Train_StdReturn : 4.268932819366455
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.036649214659686
Actor Loss : 45.362152099609375
Train_EnvstepsSoFar : 545384
TimeSinceStart : 426.4336235523224
Done logging...



********** Iteration 136 ************

Collecting data for eval...
Eval_AverageReturn : 20.190475463867188
Eval_StdReturn : 4.583812713623047
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.19047619047619
Train_AverageReturn : 20.443878173828125
Train_StdReturn : 4.312051296234131
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.443877551020407
Actor Loss : 35.28763961791992
Train_EnvstepsSoFar : 549391
TimeSinceStart : 429.33024168014526
Done logging...



********** Iteration 137 ************

Collecting data for eval...
Eval_AverageReturn : 19.952381134033203
Eval_StdReturn : 3.760397434234619
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.952380952380953
Train_AverageReturn : 20.049999237060547
Train_StdReturn : 3.6806929111480713
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.05
Actor Loss : 23.18711280822754
Train_EnvstepsSoFar : 553401
TimeSinceStart : 431.8419532775879
Done logging...



********** Iteration 138 ************

Collecting data for eval...
Eval_AverageReturn : 22.94444465637207
Eval_StdReturn : 3.658661365509033
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 22.944444444444443
Train_AverageReturn : 20.185930252075195
Train_StdReturn : 3.813570499420166
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.185929648241206
Actor Loss : 23.324602127075195
Train_EnvstepsSoFar : 557418
TimeSinceStart : 434.3506352901459
Done logging...



********** Iteration 139 ************

Collecting data for eval...
Eval_AverageReturn : 20.75
Eval_StdReturn : 4.2529401779174805
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.75
Train_AverageReturn : 20.644329071044922
Train_StdReturn : 3.9077365398406982
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.644329896907216
Actor Loss : 23.57294464111328
Train_EnvstepsSoFar : 561423
TimeSinceStart : 436.91580414772034
Done logging...



********** Iteration 140 ************

Collecting data for eval...
Eval_AverageReturn : 20.649999618530273
Eval_StdReturn : 3.9657909870147705
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.65
Train_AverageReturn : 20.140703201293945
Train_StdReturn : 4.1758222579956055
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.14070351758794
Actor Loss : 23.49583625793457
Train_EnvstepsSoFar : 565431
TimeSinceStart : 439.49345564842224
Done logging...



********** Iteration 141 ************

Collecting data for eval...
Eval_AverageReturn : 19.428571701049805
Eval_StdReturn : 3.0327014923095703
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.428571428571427
Train_AverageReturn : 20.489795684814453
Train_StdReturn : 4.132363319396973
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.489795918367346
Actor Loss : 20.061656951904297
Train_EnvstepsSoFar : 569447
TimeSinceStart : 441.9817454814911
Done logging...



********** Iteration 142 ************

Collecting data for eval...
Eval_AverageReturn : 22.94444465637207
Eval_StdReturn : 4.364912986755371
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.944444444444443
Train_AverageReturn : 20.88541603088379
Train_StdReturn : 4.155492782592773
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.885416666666668
Actor Loss : 17.795988082885742
Train_EnvstepsSoFar : 573457
TimeSinceStart : 445.5016372203827
Done logging...



********** Iteration 143 ************

Collecting data for eval...
Eval_AverageReturn : 22.61111068725586
Eval_StdReturn : 3.182223081588745
Eval_MaxReturn : 28.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 22.61111111111111
Train_AverageReturn : 20.86458396911621
Train_StdReturn : 4.036602973937988
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.864583333333332
Actor Loss : 16.63694190979004
Train_EnvstepsSoFar : 577463
TimeSinceStart : 448.02110958099365
Done logging...



********** Iteration 144 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 4.1763834953308105
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 20.084999084472656
Train_StdReturn : 4.212810516357422
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.085
Actor Loss : 34.93474197387695
Train_EnvstepsSoFar : 581480
TimeSinceStart : 450.52367424964905
Done logging...



********** Iteration 145 ************

Collecting data for eval...
Eval_AverageReturn : 20.700000762939453
Eval_StdReturn : 4.616275787353516
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.7
Train_AverageReturn : 19.595121383666992
Train_StdReturn : 3.8020503520965576
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.59512195121951
Actor Loss : 23.89173698425293
Train_EnvstepsSoFar : 585497
TimeSinceStart : 453.07246708869934
Done logging...



********** Iteration 146 ************

Collecting data for eval...
Eval_AverageReturn : 19.33333396911621
Eval_StdReturn : 4.015841484069824
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.333333333333332
Train_AverageReturn : 20.558975219726562
Train_StdReturn : 4.201386451721191
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.55897435897436
Actor Loss : 56.64570617675781
Train_EnvstepsSoFar : 589506
TimeSinceStart : 455.607280254364
Done logging...



********** Iteration 147 ************

Collecting data for eval...
Eval_AverageReturn : 21.473684310913086
Eval_StdReturn : 4.044078350067139
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.473684210526315
Train_AverageReturn : 20.020000457763672
Train_StdReturn : 4.15687370300293
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.02
Actor Loss : 24.21249008178711
Train_EnvstepsSoFar : 593510
TimeSinceStart : 460.0424573421478
Done logging...



********** Iteration 148 ************

Collecting data for eval...
Eval_AverageReturn : 21.578947067260742
Eval_StdReturn : 4.55742073059082
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.57894736842105
Train_AverageReturn : 20.958114624023438
Train_StdReturn : 4.104438304901123
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.958115183246072
Actor Loss : 28.409076690673828
Train_EnvstepsSoFar : 597513
TimeSinceStart : 462.52849102020264
Done logging...



********** Iteration 149 ************

Collecting data for eval...
Eval_AverageReturn : 21.25
Eval_StdReturn : 4.470737934112549
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.25
Train_AverageReturn : 20.512821197509766
Train_StdReturn : 4.252732276916504
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.512820512820515
Actor Loss : 42.43180465698242
Train_EnvstepsSoFar : 601513
TimeSinceStart : 465.014995098114
Done logging...



********** Iteration 150 ************

Collecting data for eval...
Eval_AverageReturn : 20.0
Eval_StdReturn : 4.171330451965332
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.0
Train_AverageReturn : 20.55384635925293
Train_StdReturn : 3.8284928798675537
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.553846153846155
Actor Loss : 16.48433494567871
Train_EnvstepsSoFar : 605521
TimeSinceStart : 467.94233202934265
Done logging...



********** Iteration 151 ************

Collecting data for eval...
Eval_AverageReturn : 18.636363983154297
Eval_StdReturn : 2.837179183959961
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 18.636363636363637
Train_AverageReturn : 19.920398712158203
Train_StdReturn : 4.033890247344971
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.920398009950247
Actor Loss : 24.885536193847656
Train_EnvstepsSoFar : 609525
TimeSinceStart : 470.44439601898193
Done logging...



********** Iteration 152 ************

Collecting data for eval...
Eval_AverageReturn : 19.761905670166016
Eval_StdReturn : 2.9423794746398926
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.761904761904763
Train_AverageReturn : 20.80310821533203
Train_StdReturn : 4.395309925079346
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.803108808290155
Actor Loss : 26.82003402709961
Train_EnvstepsSoFar : 613540
TimeSinceStart : 473.32456827163696
Done logging...



********** Iteration 153 ************

Collecting data for eval...
Eval_AverageReturn : 20.299999237060547
Eval_StdReturn : 4.439594745635986
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.3
Train_AverageReturn : 20.53333282470703
Train_StdReturn : 3.875321865081787
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.533333333333335
Actor Loss : 22.866886138916016
Train_EnvstepsSoFar : 617544
TimeSinceStart : 475.8376703262329
Done logging...



********** Iteration 154 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 4.4877610206604
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.7668399810791
Train_StdReturn : 4.351468086242676
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.76683937823834
Actor Loss : 36.00828170776367
Train_EnvstepsSoFar : 621552
TimeSinceStart : 478.7158031463623
Done logging...



********** Iteration 155 ************

Collecting data for eval...
Eval_AverageReturn : 20.299999237060547
Eval_StdReturn : 3.6619668006896973
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.3
Train_AverageReturn : 19.763545989990234
Train_StdReturn : 3.8395469188690186
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.763546798029555
Actor Loss : 23.165714263916016
Train_EnvstepsSoFar : 625564
TimeSinceStart : 481.19902205467224
Done logging...



********** Iteration 156 ************

Collecting data for eval...
Eval_AverageReturn : 21.526315689086914
Eval_StdReturn : 5.154134273529053
Eval_MaxReturn : 32.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.526315789473685
Train_AverageReturn : 20.620512008666992
Train_StdReturn : 3.8363430500030518
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.620512820512822
Actor Loss : 17.786678314208984
Train_EnvstepsSoFar : 629585
TimeSinceStart : 483.68460631370544
Done logging...



********** Iteration 157 ************

Collecting data for eval...
Eval_AverageReturn : 18.909090042114258
Eval_StdReturn : 2.858942985534668
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 18.90909090909091
Train_AverageReturn : 20.345178604125977
Train_StdReturn : 4.130195617675781
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.34517766497462
Actor Loss : 19.722240447998047
Train_EnvstepsSoFar : 633593
TimeSinceStart : 486.1830689907074
Done logging...



********** Iteration 158 ************

Collecting data for eval...
Eval_AverageReturn : 21.263158798217773
Eval_StdReturn : 4.253074645996094
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.263157894736842
Train_AverageReturn : 20.58974266052246
Train_StdReturn : 4.022487640380859
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.58974358974359
Actor Loss : 11.751108169555664
Train_EnvstepsSoFar : 637608
TimeSinceStart : 488.6698796749115
Done logging...



********** Iteration 159 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 3.7613162994384766
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 20.014925003051758
Train_StdReturn : 4.020442485809326
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.01492537313433
Actor Loss : 30.09913444519043
Train_EnvstepsSoFar : 641631
TimeSinceStart : 492.4428265094757
Done logging...



********** Iteration 160 ************

Collecting data for eval...
Eval_AverageReturn : 21.842105865478516
Eval_StdReturn : 4.636958599090576
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.842105263157894
Train_AverageReturn : 20.35025405883789
Train_StdReturn : 3.9979896545410156
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.3502538071066
Actor Loss : 11.886787414550781
Train_EnvstepsSoFar : 645640
TimeSinceStart : 494.9529402256012
Done logging...



********** Iteration 161 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 4.165032863616943
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 20.247474670410156
Train_StdReturn : 3.8144288063049316
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.247474747474747
Actor Loss : 12.082392692565918
Train_EnvstepsSoFar : 649649
TimeSinceStart : 497.439017534256
Done logging...



********** Iteration 162 ************

Collecting data for eval...
Eval_AverageReturn : 19.227272033691406
Eval_StdReturn : 3.654783010482788
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.227272727272727
Train_AverageReturn : 20.721649169921875
Train_StdReturn : 4.299945831298828
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.721649484536083
Actor Loss : 18.266010284423828
Train_EnvstepsSoFar : 653669
TimeSinceStart : 499.98445534706116
Done logging...



********** Iteration 163 ************

Collecting data for eval...
Eval_AverageReturn : 21.25
Eval_StdReturn : 4.097255229949951
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.25
Train_AverageReturn : 20.464284896850586
Train_StdReturn : 3.9723212718963623
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.464285714285715
Actor Loss : 9.93498420715332
Train_EnvstepsSoFar : 657680
TimeSinceStart : 502.46374797821045
Done logging...



********** Iteration 164 ************

Collecting data for eval...
Eval_AverageReturn : 19.33333396911621
Eval_StdReturn : 3.8462514877319336
Eval_MaxReturn : 26.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.333333333333332
Train_AverageReturn : 20.094999313354492
Train_StdReturn : 4.0244221687316895
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.095
Actor Loss : 29.448930740356445
Train_EnvstepsSoFar : 661699
TimeSinceStart : 504.95239663124084
Done logging...



********** Iteration 165 ************

Collecting data for eval...
Eval_AverageReturn : 20.700000762939453
Eval_StdReturn : 3.318132162094116
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.7
Train_AverageReturn : 20.345178604125977
Train_StdReturn : 3.896196126937866
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.34517766497462
Actor Loss : 12.047948837280273
Train_EnvstepsSoFar : 665707
TimeSinceStart : 507.4252841472626
Done logging...



********** Iteration 166 ************

Collecting data for eval...
Eval_AverageReturn : 19.095237731933594
Eval_StdReturn : 2.6886842250823975
Eval_MaxReturn : 24.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.095238095238095
Train_AverageReturn : 20.505102157592773
Train_StdReturn : 4.268414497375488
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.505102040816325
Actor Loss : 16.493806838989258
Train_EnvstepsSoFar : 669726
TimeSinceStart : 509.95219445228577
Done logging...



********** Iteration 167 ************

Collecting data for eval...
Eval_AverageReturn : 20.350000381469727
Eval_StdReturn : 4.138538360595703
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.35
Train_AverageReturn : 20.90104103088379
Train_StdReturn : 4.390520095825195
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.901041666666668
Actor Loss : 15.14793586730957
Train_EnvstepsSoFar : 673739
TimeSinceStart : 512.4221205711365
Done logging...



********** Iteration 168 ************

Collecting data for eval...
Eval_AverageReturn : 19.047618865966797
Eval_StdReturn : 2.7856125831604004
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.047619047619047
Train_AverageReturn : 20.314720153808594
Train_StdReturn : 4.262031078338623
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.314720812182742
Actor Loss : 45.92991638183594
Train_EnvstepsSoFar : 677741
TimeSinceStart : 514.8731002807617
Done logging...



********** Iteration 169 ************

Collecting data for eval...
Eval_AverageReturn : 20.799999237060547
Eval_StdReturn : 3.9446165561676025
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.8
Train_AverageReturn : 20.165828704833984
Train_StdReturn : 4.135595798492432
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.165829145728644
Actor Loss : 13.829048156738281
Train_EnvstepsSoFar : 681754
TimeSinceStart : 517.3999354839325
Done logging...



********** Iteration 170 ************

Collecting data for eval...
Eval_AverageReturn : 20.649999618530273
Eval_StdReturn : 4.028337001800537
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.65
Train_AverageReturn : 20.494897842407227
Train_StdReturn : 3.989140033721924
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.494897959183675
Actor Loss : 17.091869354248047
Train_EnvstepsSoFar : 685771
TimeSinceStart : 521.4839816093445
Done logging...



********** Iteration 171 ************

Collecting data for eval...
Eval_AverageReturn : 20.5
Eval_StdReturn : 3.612478494644165
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.5
Train_AverageReturn : 20.25757598876953
Train_StdReturn : 4.169310092926025
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.257575757575758
Actor Loss : 13.820978164672852
Train_EnvstepsSoFar : 689782
TimeSinceStart : 523.9459965229034
Done logging...



********** Iteration 172 ************

Collecting data for eval...
Eval_AverageReturn : 19.904762268066406
Eval_StdReturn : 3.6632635593414307
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.904761904761905
Train_AverageReturn : 20.38071060180664
Train_StdReturn : 4.146092891693115
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.380710659898476
Actor Loss : 16.643165588378906
Train_EnvstepsSoFar : 693797
TimeSinceStart : 527.0497260093689
Done logging...



********** Iteration 173 ************

Collecting data for eval...
Eval_AverageReturn : 20.899999618530273
Eval_StdReturn : 3.9357337951660156
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.9
Train_AverageReturn : 20.62371063232422
Train_StdReturn : 4.011279582977295
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.623711340206185
Actor Loss : 15.063802719116211
Train_EnvstepsSoFar : 697798
TimeSinceStart : 529.5655198097229
Done logging...



********** Iteration 174 ************

Collecting data for eval...
Eval_AverageReturn : 21.3157901763916
Eval_StdReturn : 4.588918209075928
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.31578947368421
Train_AverageReturn : 20.639175415039062
Train_StdReturn : 3.978513240814209
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.63917525773196
Actor Loss : 14.316581726074219
Train_EnvstepsSoFar : 701802
TimeSinceStart : 532.0463027954102
Done logging...



********** Iteration 175 ************

Collecting data for eval...
Eval_AverageReturn : 20.700000762939453
Eval_StdReturn : 4.561798095703125
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.7
Train_AverageReturn : 20.777202606201172
Train_StdReturn : 4.0804219245910645
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.77720207253886
Actor Loss : 19.2586669921875
Train_EnvstepsSoFar : 705812
TimeSinceStart : 534.5840594768524
Done logging...



********** Iteration 176 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 4.09145450592041
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.62886619567871
Train_StdReturn : 4.005973815917969
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.628865979381445
Actor Loss : 14.30453872680664
Train_EnvstepsSoFar : 709814
TimeSinceStart : 537.0732181072235
Done logging...



********** Iteration 177 ************

Collecting data for eval...
Eval_AverageReturn : 19.238094329833984
Eval_StdReturn : 2.792929172515869
Eval_MaxReturn : 24.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.238095238095237
Train_AverageReturn : 20.323232650756836
Train_StdReturn : 4.023487091064453
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.32323232323232
Actor Loss : 17.51019287109375
Train_EnvstepsSoFar : 713838
TimeSinceStart : 539.6919052600861
Done logging...



********** Iteration 178 ************

Collecting data for eval...
Eval_AverageReturn : 21.473684310913086
Eval_StdReturn : 4.271920680999756
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.473684210526315
Train_AverageReturn : 20.267677307128906
Train_StdReturn : 4.087930679321289
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.267676767676768
Actor Loss : 10.267403602600098
Train_EnvstepsSoFar : 717851
TimeSinceStart : 542.2936272621155
Done logging...



********** Iteration 179 ************

Collecting data for eval...
Eval_AverageReturn : 19.090909957885742
Eval_StdReturn : 3.4629087448120117
Eval_MaxReturn : 26.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.09090909090909
Train_AverageReturn : 20.428571701049805
Train_StdReturn : 4.177197456359863
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.428571428571427
Actor Loss : 19.155872344970703
Train_EnvstepsSoFar : 721855
TimeSinceStart : 544.9247317314148
Done logging...



********** Iteration 180 ************

Collecting data for eval...
Eval_AverageReturn : 19.761905670166016
Eval_StdReturn : 3.7531542778015137
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.761904761904763
Train_AverageReturn : 19.724138259887695
Train_StdReturn : 3.9532687664031982
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.724137931034484
Actor Loss : 11.521903991699219
Train_EnvstepsSoFar : 725859
TimeSinceStart : 547.783239364624
Done logging...



********** Iteration 181 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 4.673328399658203
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.34010124206543
Train_StdReturn : 4.007741928100586
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.34010152284264
Actor Loss : 9.244022369384766
Train_EnvstepsSoFar : 729866
TimeSinceStart : 550.314302444458
Done logging...



********** Iteration 182 ************

Collecting data for eval...
Eval_AverageReturn : 19.428571701049805
Eval_StdReturn : 3.2743072509765625
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.428571428571427
Train_AverageReturn : 19.91044807434082
Train_StdReturn : 3.948920249938965
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.91044776119403
Actor Loss : 13.297648429870605
Train_EnvstepsSoFar : 733868
TimeSinceStart : 552.8601868152618
Done logging...



********** Iteration 183 ************

Collecting data for eval...
Eval_AverageReturn : 20.950000762939453
Eval_StdReturn : 4.477443218231201
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.95
Train_AverageReturn : 20.777202606201172
Train_StdReturn : 4.002214431762695
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.77720207253886
Actor Loss : 24.620018005371094
Train_EnvstepsSoFar : 737878
TimeSinceStart : 555.4410963058472
Done logging...



********** Iteration 184 ************

Collecting data for eval...
Eval_AverageReturn : 20.047618865966797
Eval_StdReturn : 3.565391778945923
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.047619047619047
Train_AverageReturn : 20.267677307128906
Train_StdReturn : 4.080511569976807
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.267676767676768
Actor Loss : 8.745309829711914
Train_EnvstepsSoFar : 741891
TimeSinceStart : 558.1553704738617
Done logging...



********** Iteration 185 ************

Collecting data for eval...
Eval_AverageReturn : 19.428571701049805
Eval_StdReturn : 4.089142799377441
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.428571428571427
Train_AverageReturn : 21.073684692382812
Train_StdReturn : 4.081388473510742
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.073684210526316
Actor Loss : 12.819730758666992
Train_EnvstepsSoFar : 745895
TimeSinceStart : 560.6555869579315
Done logging...



********** Iteration 186 ************

Collecting data for eval...
Eval_AverageReturn : 20.049999237060547
Eval_StdReturn : 4.005932807922363
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.05
Train_AverageReturn : 20.48469352722168
Train_StdReturn : 4.15451192855835
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.48469387755102
Actor Loss : 11.15048599243164
Train_EnvstepsSoFar : 749910
TimeSinceStart : 563.1540112495422
Done logging...



********** Iteration 187 ************

Collecting data for eval...
Eval_AverageReturn : 21.842105865478516
Eval_StdReturn : 3.312864303588867
Eval_MaxReturn : 27.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 21.842105263157894
Train_AverageReturn : 20.86979103088379
Train_StdReturn : 4.466160297393799
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.869791666666668
Actor Loss : 24.83518409729004
Train_EnvstepsSoFar : 753917
TimeSinceStart : 565.6674461364746
Done logging...



********** Iteration 188 ************

Collecting data for eval...
Eval_AverageReturn : 19.190475463867188
Eval_StdReturn : 4.204522132873535
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.19047619047619
Train_AverageReturn : 20.63401985168457
Train_StdReturn : 4.0467729568481445
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.6340206185567
Actor Loss : 11.108354568481445
Train_EnvstepsSoFar : 757920
TimeSinceStart : 568.2113409042358
Done logging...



********** Iteration 189 ************

Collecting data for eval...
Eval_AverageReturn : 19.4761905670166
Eval_StdReturn : 3.4588608741760254
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.476190476190474
Train_AverageReturn : 21.29787254333496
Train_StdReturn : 4.3315510749816895
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.29787234042553
Actor Loss : 12.584648132324219
Train_EnvstepsSoFar : 761924
TimeSinceStart : 570.685112953186
Done logging...



********** Iteration 190 ************

Collecting data for eval...
Eval_AverageReturn : 22.157894134521484
Eval_StdReturn : 3.645663022994995
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 22.157894736842106
Train_AverageReturn : 19.9601993560791
Train_StdReturn : 3.981100559234619
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.960199004975124
Actor Loss : 9.38487434387207
Train_EnvstepsSoFar : 765936
TimeSinceStart : 573.2234182357788
Done logging...



********** Iteration 191 ************

Collecting data for eval...
Eval_AverageReturn : 19.619047164916992
Eval_StdReturn : 3.3018925189971924
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.61904761904762
Train_AverageReturn : 21.532258987426758
Train_StdReturn : 4.269362449645996
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.532258064516128
Actor Loss : 12.376741409301758
Train_EnvstepsSoFar : 769941
TimeSinceStart : 575.7562310695648
Done logging...



********** Iteration 192 ************

Collecting data for eval...
Eval_AverageReturn : 20.75
Eval_StdReturn : 4.2646803855896
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.75
Train_AverageReturn : 20.304569244384766
Train_StdReturn : 4.223289489746094
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.304568527918782
Actor Loss : 14.739654541015625
Train_EnvstepsSoFar : 773941
TimeSinceStart : 578.2953517436981
Done logging...



********** Iteration 193 ************

Collecting data for eval...
Eval_AverageReturn : 20.700000762939453
Eval_StdReturn : 4.325506210327148
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.7
Train_AverageReturn : 20.664947509765625
Train_StdReturn : 3.9619462490081787
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.664948453608247
Actor Loss : 13.089021682739258
Train_EnvstepsSoFar : 777950
TimeSinceStart : 580.8567855358124
Done logging...



********** Iteration 194 ************

Collecting data for eval...
Eval_AverageReturn : 21.6842098236084
Eval_StdReturn : 4.091745376586914
Eval_MaxReturn : 29.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 21.68421052631579
Train_AverageReturn : 20.58461570739746
Train_StdReturn : 4.090861797332764
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.584615384615386
Actor Loss : 21.079608917236328
Train_EnvstepsSoFar : 781964
TimeSinceStart : 583.3875226974487
Done logging...



********** Iteration 195 ************

Collecting data for eval...
Eval_AverageReturn : 21.36842155456543
Eval_StdReturn : 4.028980731964111
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.36842105263158
Train_AverageReturn : 20.170854568481445
Train_StdReturn : 4.175900459289551
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.170854271356784
Actor Loss : 12.264081954956055
Train_EnvstepsSoFar : 785978
TimeSinceStart : 585.946380853653
Done logging...



********** Iteration 196 ************

Collecting data for eval...
Eval_AverageReturn : 21.105262756347656
Eval_StdReturn : 3.6258537769317627
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.105263157894736
Train_AverageReturn : 20.73056983947754
Train_StdReturn : 3.9307408332824707
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.730569948186528
Actor Loss : 8.904170989990234
Train_EnvstepsSoFar : 789979
TimeSinceStart : 588.3988230228424
Done logging...



********** Iteration 197 ************

Collecting data for eval...
Eval_AverageReturn : 20.100000381469727
Eval_StdReturn : 3.923008680343628
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.1
Train_AverageReturn : 20.512821197509766
Train_StdReturn : 4.050145626068115
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.512820512820515
Actor Loss : 11.842208862304688
Train_EnvstepsSoFar : 793979
TimeSinceStart : 590.9583508968353
Done logging...



********** Iteration 198 ************

Collecting data for eval...
Eval_AverageReturn : 20.899999618530273
Eval_StdReturn : 4.8155999183654785
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.9
Train_AverageReturn : 20.52820587158203
Train_StdReturn : 4.004225254058838
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.52820512820513
Actor Loss : 8.192749977111816
Train_EnvstepsSoFar : 797982
TimeSinceStart : 593.4672286510468
Done logging...



********** Iteration 199 ************

Collecting data for eval...
Eval_AverageReturn : 20.799999237060547
Eval_StdReturn : 4.556313991546631
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.8
Train_AverageReturn : 20.075000762939453
Train_StdReturn : 4.084039211273193
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.075
Actor Loss : 10.161592483520508
Train_EnvstepsSoFar : 801997
TimeSinceStart : 596.7851028442383
Done logging...



********** Iteration 200 ************

Collecting data for eval...
Eval_AverageReturn : 20.899999618530273
Eval_StdReturn : 3.6180102825164795
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.9
Train_AverageReturn : 20.88541603088379
Train_StdReturn : 4.329813480377197
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.885416666666668
Actor Loss : 12.398799896240234
Train_EnvstepsSoFar : 806007
TimeSinceStart : 599.7085077762604
Done logging...



********** Iteration 201 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 4.431704521179199
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 20.73575210571289
Train_StdReturn : 3.9540908336639404
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.735751295336787
Actor Loss : 8.24903678894043
Train_EnvstepsSoFar : 810009
TimeSinceStart : 602.763956785202
Done logging...



********** Iteration 202 ************

Collecting data for eval...
Eval_AverageReturn : 20.049999237060547
Eval_StdReturn : 4.352872848510742
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.05
Train_AverageReturn : 20.646154403686523
Train_StdReturn : 4.1980366706848145
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.646153846153847
Actor Loss : 7.446718692779541
Train_EnvstepsSoFar : 814035
TimeSinceStart : 605.7188546657562
Done logging...



********** Iteration 203 ************

Collecting data for eval...
Eval_AverageReturn : 21.157894134521484
Eval_StdReturn : 3.773357391357422
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.157894736842106
Train_AverageReturn : 20.659793853759766
Train_StdReturn : 4.311066150665283
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.65979381443299
Actor Loss : 21.699081420898438
Train_EnvstepsSoFar : 818043
TimeSinceStart : 608.3304462432861
Done logging...



********** Iteration 204 ************

Collecting data for eval...
Eval_AverageReturn : 19.14285659790039
Eval_StdReturn : 3.5360147953033447
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.142857142857142
Train_AverageReturn : 19.91044807434082
Train_StdReturn : 4.050912380218506
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.91044776119403
Actor Loss : 10.09290885925293
Train_EnvstepsSoFar : 822045
TimeSinceStart : 611.4896802902222
Done logging...



********** Iteration 205 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 2.9563491344451904
Eval_MaxReturn : 27.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 20.83333396911621
Train_StdReturn : 4.12731409072876
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.833333333333332
Actor Loss : 7.358686923980713
Train_EnvstepsSoFar : 826045
TimeSinceStart : 614.7288718223572
Done logging...



********** Iteration 206 ************

Collecting data for eval...
Eval_AverageReturn : 19.14285659790039
Eval_StdReturn : 3.4817306995391846
Eval_MaxReturn : 26.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.142857142857142
Train_AverageReturn : 20.145729064941406
Train_StdReturn : 3.9025657176971436
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.14572864321608
Actor Loss : 13.064292907714844
Train_EnvstepsSoFar : 830054
TimeSinceStart : 617.672548532486
Done logging...



********** Iteration 207 ************

Collecting data for eval...
Eval_AverageReturn : 21.052631378173828
Eval_StdReturn : 4.536097049713135
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.05263157894737
Train_AverageReturn : 20.020000457763672
Train_StdReturn : 4.002449035644531
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.02
Actor Loss : 9.405344009399414
Train_EnvstepsSoFar : 834058
TimeSinceStart : 620.8934464454651
Done logging...



********** Iteration 208 ************

Collecting data for eval...
Eval_AverageReturn : 19.66666603088379
Eval_StdReturn : 4.29100227355957
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.666666666666668
Train_AverageReturn : 20.27777862548828
Train_StdReturn : 4.193382740020752
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.27777777777778
Actor Loss : 26.938196182250977
Train_EnvstepsSoFar : 838073
TimeSinceStart : 624.2032358646393
Done logging...



********** Iteration 209 ************

Collecting data for eval...
Eval_AverageReturn : 21.6842098236084
Eval_StdReturn : 4.588918209075928
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.68421052631579
Train_AverageReturn : 20.375635147094727
Train_StdReturn : 4.049317359924316
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.375634517766496
Actor Loss : 9.49974536895752
Train_EnvstepsSoFar : 842087
TimeSinceStart : 626.8790848255157
Done logging...



********** Iteration 210 ************

Collecting data for eval...
Eval_AverageReturn : 20.100000381469727
Eval_StdReturn : 3.740320920944214
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.1
Train_AverageReturn : 20.48469352722168
Train_StdReturn : 4.2106242179870605
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.48469387755102
Actor Loss : 10.184587478637695
Train_EnvstepsSoFar : 846102
TimeSinceStart : 629.8961882591248
Done logging...



********** Iteration 211 ************

Collecting data for eval...
Eval_AverageReturn : 19.238094329833984
Eval_StdReturn : 3.8533196449279785
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.238095238095237
Train_AverageReturn : 20.479591369628906
Train_StdReturn : 3.992926597595215
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.479591836734695
Actor Loss : 6.654975891113281
Train_EnvstepsSoFar : 850116
TimeSinceStart : 632.8741736412048
Done logging...



********** Iteration 212 ************

Collecting data for eval...
Eval_AverageReturn : 21.842105865478516
Eval_StdReturn : 4.836953639984131
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.842105263157894
Train_AverageReturn : 19.970149993896484
Train_StdReturn : 3.971177816390991
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.970149253731343
Actor Loss : 6.29527473449707
Train_EnvstepsSoFar : 854130
TimeSinceStart : 638.2576992511749
Done logging...



********** Iteration 213 ************

Collecting data for eval...
Eval_AverageReturn : 19.571428298950195
Eval_StdReturn : 3.645890235900879
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.571428571428573
Train_AverageReturn : 20.045000076293945
Train_StdReturn : 3.913179636001587
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.045
Actor Loss : 5.928508758544922
Train_EnvstepsSoFar : 858139
TimeSinceStart : 641.3471336364746
Done logging...



********** Iteration 214 ************

Collecting data for eval...
Eval_AverageReturn : 20.850000381469727
Eval_StdReturn : 3.8245913982391357
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.85
Train_AverageReturn : 20.272727966308594
Train_StdReturn : 4.220723628997803
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.272727272727273
Actor Loss : 17.890419006347656
Train_EnvstepsSoFar : 862153
TimeSinceStart : 643.8486564159393
Done logging...



********** Iteration 215 ************

Collecting data for eval...
Eval_AverageReturn : 19.66666603088379
Eval_StdReturn : 4.268749237060547
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.666666666666668
Train_AverageReturn : 20.512821197509766
Train_StdReturn : 4.166236400604248
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.512820512820515
Actor Loss : 7.323592662811279
Train_EnvstepsSoFar : 866153
TimeSinceStart : 648.504855632782
Done logging...



********** Iteration 216 ************

Collecting data for eval...
Eval_AverageReturn : 21.6842098236084
Eval_StdReturn : 5.161116123199463
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.68421052631579
Train_AverageReturn : 20.125627517700195
Train_StdReturn : 3.8890769481658936
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.12562814070352
Actor Loss : 8.45414924621582
Train_EnvstepsSoFar : 870158
TimeSinceStart : 651.0269801616669
Done logging...



********** Iteration 217 ************

Collecting data for eval...
Eval_AverageReturn : 19.380952835083008
Eval_StdReturn : 3.538579225540161
Eval_MaxReturn : 25.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.38095238095238
Train_AverageReturn : 21.136842727661133
Train_StdReturn : 3.9989748001098633
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.13684210526316
Actor Loss : 9.391450881958008
Train_EnvstepsSoFar : 874174
TimeSinceStart : 653.6143946647644
Done logging...



********** Iteration 218 ************

Collecting data for eval...
Eval_AverageReturn : 19.14285659790039
Eval_StdReturn : 3.6159136295318604
Eval_MaxReturn : 26.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.142857142857142
Train_AverageReturn : 20.564102172851562
Train_StdReturn : 4.4433465003967285
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.564102564102566
Actor Loss : 7.851379871368408
Train_EnvstepsSoFar : 878184
TimeSinceStart : 656.216198682785
Done logging...



********** Iteration 219 ************

Collecting data for eval...
Eval_AverageReturn : 19.952381134033203
Eval_StdReturn : 3.415318489074707
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.952380952380953
Train_AverageReturn : 20.489795684814453
Train_StdReturn : 4.164340496063232
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.489795918367346
Actor Loss : 8.665986061096191
Train_EnvstepsSoFar : 882200
TimeSinceStart : 658.730081319809
Done logging...



********** Iteration 220 ************

Collecting data for eval...
Eval_AverageReturn : 20.5
Eval_StdReturn : 4.769696235656738
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.5
Train_AverageReturn : 20.282827377319336
Train_StdReturn : 4.331096172332764
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.282828282828284
Actor Loss : 6.874578475952148
Train_EnvstepsSoFar : 886216
TimeSinceStart : 661.3089604377747
Done logging...



********** Iteration 221 ************

Collecting data for eval...
Eval_AverageReturn : 20.950000762939453
Eval_StdReturn : 4.177020072937012
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.95
Train_AverageReturn : 20.32994842529297
Train_StdReturn : 4.116053104400635
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.32994923857868
Actor Loss : 7.224950790405273
Train_EnvstepsSoFar : 890221
TimeSinceStart : 663.8824615478516
Done logging...



********** Iteration 222 ************

Collecting data for eval...
Eval_AverageReturn : 19.285715103149414
Eval_StdReturn : 3.6793227195739746
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.285714285714285
Train_AverageReturn : 20.160804748535156
Train_StdReturn : 3.9103357791900635
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.160804020100503
Actor Loss : 6.981540203094482
Train_EnvstepsSoFar : 894233
TimeSinceStart : 666.6619300842285
Done logging...



********** Iteration 223 ************

Collecting data for eval...
Eval_AverageReturn : 19.428571701049805
Eval_StdReturn : 3.786837339401245
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.428571428571427
Train_AverageReturn : 19.905471801757812
Train_StdReturn : 3.803117513656616
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 19.90547263681592
Actor Loss : 10.166112899780273
Train_EnvstepsSoFar : 898234
TimeSinceStart : 671.6791887283325
Done logging...



********** Iteration 224 ************

Collecting data for eval...
Eval_AverageReturn : 21.36842155456543
Eval_StdReturn : 3.497525930404663
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.36842105263158
Train_AverageReturn : 19.905471801757812
Train_StdReturn : 3.9076428413391113
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.90547263681592
Actor Loss : 5.40484619140625
Train_EnvstepsSoFar : 902235
TimeSinceStart : 674.1964662075043
Done logging...



********** Iteration 225 ************

Collecting data for eval...
Eval_AverageReturn : 21.473684310913086
Eval_StdReturn : 4.271920680999756
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.473684210526315
Train_AverageReturn : 20.701030731201172
Train_StdReturn : 4.176924705505371
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.701030927835053
Actor Loss : 9.097207069396973
Train_EnvstepsSoFar : 906251
TimeSinceStart : 676.7217524051666
Done logging...



********** Iteration 226 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 3.679673910140991
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 20.454082489013672
Train_StdReturn : 4.04350471496582
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.45408163265306
Actor Loss : 5.905759811401367
Train_EnvstepsSoFar : 910260
TimeSinceStart : 679.2371914386749
Done logging...



********** Iteration 227 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 3.547886610031128
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 20.474489212036133
Train_StdReturn : 4.1433939933776855
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.474489795918366
Actor Loss : 7.218515396118164
Train_EnvstepsSoFar : 914273
TimeSinceStart : 681.7848045825958
Done logging...



********** Iteration 228 ************

Collecting data for eval...
Eval_AverageReturn : 21.63157844543457
Eval_StdReturn : 3.2800917625427246
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.63157894736842
Train_AverageReturn : 20.548717498779297
Train_StdReturn : 4.228285312652588
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.54871794871795
Actor Loss : 6.341959476470947
Train_EnvstepsSoFar : 918280
TimeSinceStart : 684.3353178501129
Done logging...



********** Iteration 229 ************

Collecting data for eval...
Eval_AverageReturn : 22.0
Eval_StdReturn : 4.757266044616699
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.0
Train_AverageReturn : 20.304569244384766
Train_StdReturn : 4.214867115020752
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.304568527918782
Actor Loss : 11.759851455688477
Train_EnvstepsSoFar : 922280
TimeSinceStart : 690.3337619304657
Done logging...



********** Iteration 230 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 4.2646803855896
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 20.72538948059082
Train_StdReturn : 4.18388557434082
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.72538860103627
Actor Loss : 7.59654426574707
Train_EnvstepsSoFar : 926280
TimeSinceStart : 692.8612353801727
Done logging...



********** Iteration 231 ************

Collecting data for eval...
Eval_AverageReturn : 20.299999237060547
Eval_StdReturn : 3.7429935932159424
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.3
Train_AverageReturn : 20.175878524780273
Train_StdReturn : 4.378364086151123
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.175879396984925
Actor Loss : 5.297895431518555
Train_EnvstepsSoFar : 930295
TimeSinceStart : 695.4010615348816
Done logging...



********** Iteration 232 ************

Collecting data for eval...
Eval_AverageReturn : 19.761905670166016
Eval_StdReturn : 4.286243438720703
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.761904761904763
Train_AverageReturn : 20.797927856445312
Train_StdReturn : 4.227420330047607
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.797927461139896
Actor Loss : 6.644753456115723
Train_EnvstepsSoFar : 934309
TimeSinceStart : 697.9456822872162
Done logging...



********** Iteration 233 ************

Collecting data for eval...
Eval_AverageReturn : 20.350000381469727
Eval_StdReturn : 4.2104034423828125
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.35
Train_AverageReturn : 20.74611473083496
Train_StdReturn : 4.167826175689697
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.746113989637305
Actor Loss : 12.878551483154297
Train_EnvstepsSoFar : 938313
TimeSinceStart : 700.4948098659515
Done logging...



********** Iteration 234 ************

Collecting data for eval...
Eval_AverageReturn : 20.0
Eval_StdReturn : 4.3424811363220215
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.0
Train_AverageReturn : 20.69072151184082
Train_StdReturn : 4.327711582183838
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.690721649484537
Actor Loss : 6.524650573730469
Train_EnvstepsSoFar : 942327
TimeSinceStart : 703.0262293815613
Done logging...



********** Iteration 235 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 3.7067506313323975
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 21.01047134399414
Train_StdReturn : 4.131338119506836
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.01047120418848
Actor Loss : 8.038671493530273
Train_EnvstepsSoFar : 946340
TimeSinceStart : 705.5607266426086
Done logging...



********** Iteration 236 ************

Collecting data for eval...
Eval_AverageReturn : 20.200000762939453
Eval_StdReturn : 3.906404972076416
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.2
Train_AverageReturn : 20.644329071044922
Train_StdReturn : 4.522828102111816
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.644329896907216
Actor Loss : 11.544798851013184
Train_EnvstepsSoFar : 950345
TimeSinceStart : 708.1086118221283
Done logging...



********** Iteration 237 ************

Collecting data for eval...
Eval_AverageReturn : 21.105262756347656
Eval_StdReturn : 3.9722025394439697
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.105263157894736
Train_AverageReturn : 20.68556785583496
Train_StdReturn : 4.063807487487793
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.685567010309278
Actor Loss : 4.434439659118652
Train_EnvstepsSoFar : 954358
TimeSinceStart : 710.6417660713196
Done logging...



********** Iteration 238 ************

Collecting data for eval...
Eval_AverageReturn : 19.761905670166016
Eval_StdReturn : 3.6891703605651855
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.761904761904763
Train_AverageReturn : 20.160804748535156
Train_StdReturn : 4.096115589141846
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.160804020100503
Actor Loss : 5.713888168334961
Train_EnvstepsSoFar : 958370
TimeSinceStart : 715.2876970767975
Done logging...



********** Iteration 239 ************

Collecting data for eval...
Eval_AverageReturn : 20.0
Eval_StdReturn : 3.8340578079223633
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.0
Train_AverageReturn : 20.105527877807617
Train_StdReturn : 4.291386604309082
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.105527638190956
Actor Loss : 14.232841491699219
Train_EnvstepsSoFar : 962371
TimeSinceStart : 717.8122832775116
Done logging...



********** Iteration 240 ************

Collecting data for eval...
Eval_AverageReturn : 20.0
Eval_StdReturn : 3.532165050506592
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.0
Train_AverageReturn : 20.454082489013672
Train_StdReturn : 4.295576095581055
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.45408163265306
Actor Loss : 12.561424255371094
Train_EnvstepsSoFar : 966380
TimeSinceStart : 720.3468146324158
Done logging...



********** Iteration 241 ************

Collecting data for eval...
Eval_AverageReturn : 19.85714340209961
Eval_StdReturn : 3.2701494693756104
Eval_MaxReturn : 26.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 19.857142857142858
Train_AverageReturn : 20.130653381347656
Train_StdReturn : 4.066410541534424
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.13065326633166
Actor Loss : 6.2830400466918945
Train_EnvstepsSoFar : 970386
TimeSinceStart : 723.1166460514069
Done logging...



********** Iteration 242 ************

Collecting data for eval...
Eval_AverageReturn : 20.75
Eval_StdReturn : 3.6861226558685303
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.75
Train_AverageReturn : 20.40816307067871
Train_StdReturn : 3.7343873977661133
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.408163265306122
Actor Loss : 6.940471649169922
Train_EnvstepsSoFar : 974386
TimeSinceStart : 725.6454973220825
Done logging...



********** Iteration 243 ************

Collecting data for eval...
Eval_AverageReturn : 20.299999237060547
Eval_StdReturn : 4.680811882019043
Eval_MaxReturn : 32.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.3
Train_AverageReturn : 20.231155395507812
Train_StdReturn : 3.969334125518799
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.231155778894472
Actor Loss : 7.1786088943481445
Train_EnvstepsSoFar : 978412
TimeSinceStart : 728.1632709503174
Done logging...



********** Iteration 244 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 4.14578104019165
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 20.72538948059082
Train_StdReturn : 4.323957443237305
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.72538860103627
Actor Loss : 6.706263065338135
Train_EnvstepsSoFar : 982412
TimeSinceStart : 734.2640047073364
Done logging...



********** Iteration 245 ************

Collecting data for eval...
Eval_AverageReturn : 22.55555534362793
Eval_StdReturn : 3.4516055583953857
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 22.555555555555557
Train_AverageReturn : 20.579486846923828
Train_StdReturn : 3.9752554893493652
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.57948717948718
Actor Loss : 7.241144180297852
Train_EnvstepsSoFar : 986425
TimeSinceStart : 736.7930333614349
Done logging...



********** Iteration 246 ************

Collecting data for eval...
Eval_AverageReturn : 19.761905670166016
Eval_StdReturn : 3.584420680999756
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.761904761904763
Train_AverageReturn : 20.74093246459961
Train_StdReturn : 4.136935234069824
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.740932642487046
Actor Loss : 5.08110237121582
Train_EnvstepsSoFar : 990428
TimeSinceStart : 739.3379416465759
Done logging...



********** Iteration 247 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 3.853245258331299
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 20.479591369628906
Train_StdReturn : 3.8814830780029297
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.479591836734695
Actor Loss : 7.944625377655029
Train_EnvstepsSoFar : 994442
TimeSinceStart : 741.8596382141113
Done logging...



********** Iteration 248 ************

Collecting data for eval...
Eval_AverageReturn : 20.049999237060547
Eval_StdReturn : 3.667083263397217
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.05
Train_AverageReturn : 20.252525329589844
Train_StdReturn : 3.415187120437622
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.252525252525253
Actor Loss : 7.448934555053711
Train_EnvstepsSoFar : 998452
TimeSinceStart : 744.4017162322998
Done logging...



********** Iteration 249 ************

Collecting data for eval...
Eval_AverageReturn : 18.954545974731445
Eval_StdReturn : 3.8668434619903564
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 18.954545454545453
Train_AverageReturn : 20.324872970581055
Train_StdReturn : 4.101014137268066
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.3248730964467
Actor Loss : 5.7897210121154785
Train_EnvstepsSoFar : 1002456
TimeSinceStart : 746.9297182559967
Done logging...



********** Iteration 250 ************

Collecting data for eval...
Eval_AverageReturn : 20.899999618530273
Eval_StdReturn : 5.195189476013184
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.9
Train_AverageReturn : 20.32994842529297
Train_StdReturn : 4.195449352264404
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.32994923857868
Actor Loss : 7.381758689880371
Train_EnvstepsSoFar : 1006461
TimeSinceStart : 749.4799427986145
Done logging...



********** Iteration 251 ************

Collecting data for eval...
Eval_AverageReturn : 20.047618865966797
Eval_StdReturn : 3.860375165939331
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.047619047619047
Train_AverageReturn : 20.217172622680664
Train_StdReturn : 4.061187267303467
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.217171717171716
Actor Loss : 5.149206161499023
Train_EnvstepsSoFar : 1010464
TimeSinceStart : 754.875185251236
Done logging...



********** Iteration 252 ************

Collecting data for eval...
Eval_AverageReturn : 19.045454025268555
Eval_StdReturn : 3.5863029956817627
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.045454545454547
Train_AverageReturn : 20.454082489013672
Train_StdReturn : 4.21040153503418
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.45408163265306
Actor Loss : 8.924396514892578
Train_EnvstepsSoFar : 1014473
TimeSinceStart : 757.404176235199
Done logging...



********** Iteration 253 ************

Collecting data for eval...
Eval_AverageReturn : 17.60869598388672
Eval_StdReturn : 2.298187017440796
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 17.608695652173914
Train_AverageReturn : 20.91666603088379
Train_StdReturn : 4.55216646194458
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.916666666666668
Actor Loss : 8.184762001037598
Train_EnvstepsSoFar : 1018489
TimeSinceStart : 759.9537601470947
Done logging...



********** Iteration 254 ************

Collecting data for eval...
Eval_AverageReturn : 20.799999237060547
Eval_StdReturn : 3.3852620124816895
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.8
Train_AverageReturn : 20.90104103088379
Train_StdReturn : 3.8858182430267334
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.901041666666668
Actor Loss : 5.983915328979492
Train_EnvstepsSoFar : 1022502
TimeSinceStart : 762.4978754520416
Done logging...



********** Iteration 255 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 3.5205905437469482
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 20.175878524780273
Train_StdReturn : 4.25142240524292
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.175879396984925
Actor Loss : 5.724795341491699
Train_EnvstepsSoFar : 1026517
TimeSinceStart : 765.2922072410583
Done logging...



********** Iteration 256 ************

Collecting data for eval...
Eval_AverageReturn : 19.85714340209961
Eval_StdReturn : 3.536015033721924
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.857142857142858
Train_AverageReturn : 20.564102172851562
Train_StdReturn : 4.015322208404541
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.564102564102566
Actor Loss : 8.031637191772461
Train_EnvstepsSoFar : 1030527
TimeSinceStart : 767.8578190803528
Done logging...



********** Iteration 257 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 4.176122665405273
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 19.816831588745117
Train_StdReturn : 4.096740245819092
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.816831683168317
Actor Loss : 3.944190502166748
Train_EnvstepsSoFar : 1034530
TimeSinceStart : 771.8520066738129
Done logging...



********** Iteration 258 ************

Collecting data for eval...
Eval_AverageReturn : 19.380952835083008
Eval_StdReturn : 3.169440269470215
Eval_MaxReturn : 27.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 19.38095238095238
Train_AverageReturn : 20.287878036499023
Train_StdReturn : 3.8720643520355225
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.28787878787879
Actor Loss : 6.086643695831299
Train_EnvstepsSoFar : 1038547
TimeSinceStart : 774.3908007144928
Done logging...



********** Iteration 259 ************

Collecting data for eval...
Eval_AverageReturn : 19.4761905670166
Eval_StdReturn : 3.672537088394165
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.476190476190474
Train_AverageReturn : 20.150753021240234
Train_StdReturn : 4.230469226837158
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.150753768844222
Actor Loss : 5.270033836364746
Train_EnvstepsSoFar : 1042557
TimeSinceStart : 776.9177846908569
Done logging...



********** Iteration 260 ************

Collecting data for eval...
Eval_AverageReturn : 20.14285659790039
Eval_StdReturn : 3.4953808784484863
Eval_MaxReturn : 25.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.142857142857142
Train_AverageReturn : 20.479591369628906
Train_StdReturn : 3.9839720726013184
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.479591836734695
Actor Loss : 4.868476390838623
Train_EnvstepsSoFar : 1046571
TimeSinceStart : 779.4527881145477
Done logging...



********** Iteration 261 ************

Collecting data for eval...
Eval_AverageReturn : 19.809524536132812
Eval_StdReturn : 4.227112770080566
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.80952380952381
Train_AverageReturn : 20.91145896911621
Train_StdReturn : 4.23618745803833
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.911458333333332
Actor Loss : 10.022520065307617
Train_EnvstepsSoFar : 1050586
TimeSinceStart : 781.9519681930542
Done logging...



********** Iteration 262 ************

Collecting data for eval...
Eval_AverageReturn : 21.421052932739258
Eval_StdReturn : 4.196687698364258
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.42105263157895
Train_AverageReturn : 20.62371063232422
Train_StdReturn : 4.062355995178223
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.623711340206185
Actor Loss : 5.066587448120117
Train_EnvstepsSoFar : 1054587
TimeSinceStart : 784.4728920459747
Done logging...



********** Iteration 263 ************

Collecting data for eval...
Eval_AverageReturn : 22.22222137451172
Eval_StdReturn : 4.649439334869385
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 22.22222222222222
Train_AverageReturn : 20.797927856445312
Train_StdReturn : 4.221287727355957
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.797927461139896
Actor Loss : 7.498069763183594
Train_EnvstepsSoFar : 1058601
TimeSinceStart : 787.0560302734375
Done logging...



********** Iteration 264 ************

Collecting data for eval...
Eval_AverageReturn : 19.238094329833984
Eval_StdReturn : 3.8035669326782227
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.238095238095237
Train_AverageReturn : 20.324872970581055
Train_StdReturn : 3.9355263710021973
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.3248730964467
Actor Loss : 6.478945732116699
Train_EnvstepsSoFar : 1062605
TimeSinceStart : 789.5538597106934
Done logging...



********** Iteration 265 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 4.329838275909424
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 20.27777862548828
Train_StdReturn : 3.927192449569702
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.27777777777778
Actor Loss : 6.012945175170898
Train_EnvstepsSoFar : 1066620
TimeSinceStart : 792.0661697387695
Done logging...



********** Iteration 266 ************

Collecting data for eval...
Eval_AverageReturn : 19.619047164916992
Eval_StdReturn : 3.6576883792877197
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.61904761904762
Train_AverageReturn : 20.72538948059082
Train_StdReturn : 4.1577982902526855
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.72538860103627
Actor Loss : 7.772924423217773
Train_EnvstepsSoFar : 1070620
TimeSinceStart : 794.5918371677399
Done logging...



********** Iteration 267 ************

Collecting data for eval...
Eval_AverageReturn : 21.6842098236084
Eval_StdReturn : 3.642622470855713
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.68421052631579
Train_AverageReturn : 19.9601993560791
Train_StdReturn : 4.061517715454102
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.960199004975124
Actor Loss : 6.471475124359131
Train_EnvstepsSoFar : 1074632
TimeSinceStart : 797.114405632019
Done logging...



********** Iteration 268 ************

Collecting data for eval...
Eval_AverageReturn : 21.36842155456543
Eval_StdReturn : 4.462835311889648
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.36842105263158
Train_AverageReturn : 20.22222137451172
Train_StdReturn : 4.0652642250061035
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.22222222222222
Actor Loss : 5.187991619110107
Train_EnvstepsSoFar : 1078636
TimeSinceStart : 799.9155449867249
Done logging...



********** Iteration 269 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 3.268068552017212
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 20.345178604125977
Train_StdReturn : 4.054531574249268
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.34517766497462
Actor Loss : 4.423546314239502
Train_EnvstepsSoFar : 1082644
TimeSinceStart : 802.4099595546722
Done logging...



********** Iteration 270 ************

Collecting data for eval...
Eval_AverageReturn : 21.473684310913086
Eval_StdReturn : 4.488211631774902
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.473684210526315
Train_AverageReturn : 20.520408630371094
Train_StdReturn : 4.189953327178955
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.520408163265305
Actor Loss : 7.3373823165893555
Train_EnvstepsSoFar : 1086666
TimeSinceStart : 804.9713952541351
Done logging...



********** Iteration 271 ************

Collecting data for eval...
Eval_AverageReturn : 20.5
Eval_StdReturn : 5.113707065582275
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.5
Train_AverageReturn : 20.73056983947754
Train_StdReturn : 4.103574752807617
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.730569948186528
Actor Loss : 5.298241138458252
Train_EnvstepsSoFar : 1090667
TimeSinceStart : 807.5060756206512
Done logging...



********** Iteration 272 ************

Collecting data for eval...
Eval_AverageReturn : 19.571428298950195
Eval_StdReturn : 3.6848654747009277
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.571428571428573
Train_AverageReturn : 20.252525329589844
Train_StdReturn : 4.003390789031982
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.252525252525253
Actor Loss : 4.633973121643066
Train_EnvstepsSoFar : 1094677
TimeSinceStart : 810.210419178009
Done logging...



********** Iteration 273 ************

Collecting data for eval...
Eval_AverageReturn : 19.5238094329834
Eval_StdReturn : 3.672536849975586
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.523809523809526
Train_AverageReturn : 20.34010124206543
Train_StdReturn : 3.7916641235351562
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.34010152284264
Actor Loss : 3.972668170928955
Train_EnvstepsSoFar : 1098684
TimeSinceStart : 812.7205817699432
Done logging...



********** Iteration 274 ************

Collecting data for eval...
Eval_AverageReturn : 21.526315689086914
Eval_StdReturn : 4.464696884155273
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.526315789473685
Train_AverageReturn : 19.841583251953125
Train_StdReturn : 4.147604942321777
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.84158415841584
Actor Loss : 13.437625885009766
Train_EnvstepsSoFar : 1102692
TimeSinceStart : 815.2045438289642
Done logging...



********** Iteration 275 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 4.608687400817871
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.88020896911621
Train_StdReturn : 3.9661619663238525
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.880208333333332
Actor Loss : 8.710318565368652
Train_EnvstepsSoFar : 1106701
TimeSinceStart : 818.9374310970306
Done logging...



********** Iteration 276 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 4.40908145904541
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.91666603088379
Train_StdReturn : 4.230757236480713
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.916666666666668
Actor Loss : 6.576436519622803
Train_EnvstepsSoFar : 1110717
TimeSinceStart : 821.4394640922546
Done logging...



********** Iteration 277 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 4.282522678375244
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.2020206451416
Train_StdReturn : 3.8611762523651123
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.2020202020202
Actor Loss : 5.115046501159668
Train_EnvstepsSoFar : 1114717
TimeSinceStart : 825.0201234817505
Done logging...



********** Iteration 278 ************

Collecting data for eval...
Eval_AverageReturn : 22.72222137451172
Eval_StdReturn : 4.36915397644043
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.72222222222222
Train_AverageReturn : 20.52820587158203
Train_StdReturn : 3.862107276916504
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.52820512820513
Actor Loss : 5.192582130432129
Train_EnvstepsSoFar : 1118720
TimeSinceStart : 827.5014841556549
Done logging...



********** Iteration 279 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 4.521061897277832
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 20.74093246459961
Train_StdReturn : 4.202791213989258
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.740932642487046
Actor Loss : 6.4066057205200195
Train_EnvstepsSoFar : 1122723
TimeSinceStart : 829.9788596630096
Done logging...



********** Iteration 280 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 4.872371196746826
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 20.22222137451172
Train_StdReturn : 4.129361629486084
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.22222222222222
Actor Loss : 5.768327236175537
Train_EnvstepsSoFar : 1126727
TimeSinceStart : 832.4747786521912
Done logging...



********** Iteration 281 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 3.6121323108673096
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 20.726804733276367
Train_StdReturn : 4.262350559234619
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.72680412371134
Actor Loss : 7.417612075805664
Train_EnvstepsSoFar : 1130748
TimeSinceStart : 834.9724371433258
Done logging...



********** Iteration 282 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 3.4985711574554443
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.72538948059082
Train_StdReturn : 3.967775344848633
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.72538860103627
Actor Loss : 6.555507183074951
Train_EnvstepsSoFar : 1134748
TimeSinceStart : 837.6613733768463
Done logging...



********** Iteration 283 ************

Collecting data for eval...
Eval_AverageReturn : 21.210525512695312
Eval_StdReturn : 4.840388298034668
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.210526315789473
Train_AverageReturn : 20.73711395263672
Train_StdReturn : 4.068734645843506
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.737113402061855
Actor Loss : 4.553624153137207
Train_EnvstepsSoFar : 1138771
TimeSinceStart : 840.1222817897797
Done logging...



********** Iteration 284 ************

Collecting data for eval...
Eval_AverageReturn : 21.421052932739258
Eval_StdReturn : 5.081605434417725
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.42105263157895
Train_AverageReturn : 21.17368507385254
Train_StdReturn : 4.148092746734619
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 21.173684210526314
Actor Loss : 4.3256096839904785
Train_EnvstepsSoFar : 1142794
TimeSinceStart : 842.8985900878906
Done logging...



********** Iteration 285 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 3.720215082168579
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 21.02617835998535
Train_StdReturn : 4.2959065437316895
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.026178010471206
Actor Loss : 11.775673866271973
Train_EnvstepsSoFar : 1146810
TimeSinceStart : 845.419891834259
Done logging...



********** Iteration 286 ************

Collecting data for eval...
Eval_AverageReturn : 19.047618865966797
Eval_StdReturn : 2.768465042114258
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.047619047619047
Train_AverageReturn : 19.866336822509766
Train_StdReturn : 4.0206098556518555
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.866336633663366
Actor Loss : 3.3396568298339844
Train_EnvstepsSoFar : 1150823
TimeSinceStart : 847.9208602905273
Done logging...



********** Iteration 287 ************

Collecting data for eval...
Eval_AverageReturn : 20.5
Eval_StdReturn : 3.570714235305786
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.5
Train_AverageReturn : 20.464284896850586
Train_StdReturn : 3.988983631134033
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.464285714285715
Actor Loss : 3.710388660430908
Train_EnvstepsSoFar : 1154834
TimeSinceStart : 850.4690985679626
Done logging...



********** Iteration 288 ************

Collecting data for eval...
Eval_AverageReturn : 18.727272033691406
Eval_StdReturn : 3.2359042167663574
Eval_MaxReturn : 25.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 18.727272727272727
Train_AverageReturn : 20.010000228881836
Train_StdReturn : 3.94460391998291
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.01
Actor Loss : 5.525717735290527
Train_EnvstepsSoFar : 1158836
TimeSinceStart : 855.3293669223785
Done logging...



********** Iteration 289 ************

Collecting data for eval...
Eval_AverageReturn : 19.85714340209961
Eval_StdReturn : 3.8456618785858154
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.857142857142858
Train_AverageReturn : 20.31979751586914
Train_StdReturn : 3.872887134552002
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.31979695431472
Actor Loss : 3.821390390396118
Train_EnvstepsSoFar : 1162839
TimeSinceStart : 857.8414452075958
Done logging...



********** Iteration 290 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 3.144439458847046
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 19.930347442626953
Train_StdReturn : 3.8691437244415283
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.930348258706466
Actor Loss : 5.725072860717773
Train_EnvstepsSoFar : 1166845
TimeSinceStart : 860.3601763248444
Done logging...



********** Iteration 291 ************

Collecting data for eval...
Eval_AverageReturn : 18.954545974731445
Eval_StdReturn : 3.309453248977661
Eval_MaxReturn : 26.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 18.954545454545453
Train_AverageReturn : 20.474489212036133
Train_StdReturn : 4.390895366668701
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.474489795918366
Actor Loss : 5.742832660675049
Train_EnvstepsSoFar : 1170858
TimeSinceStart : 862.8951444625854
Done logging...



********** Iteration 292 ************

Collecting data for eval...
Eval_AverageReturn : 21.789474487304688
Eval_StdReturn : 4.455379962921143
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.789473684210527
Train_AverageReturn : 20.711339950561523
Train_StdReturn : 4.3196001052856445
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.711340206185568
Actor Loss : 4.143380165100098
Train_EnvstepsSoFar : 1174876
TimeSinceStart : 865.4418635368347
Done logging...



********** Iteration 293 ************

Collecting data for eval...
Eval_AverageReturn : 21.842105865478516
Eval_StdReturn : 5.392618179321289
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.842105263157894
Train_AverageReturn : 20.538461685180664
Train_StdReturn : 3.856703519821167
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.53846153846154
Actor Loss : 3.943006753921509
Train_EnvstepsSoFar : 1178881
TimeSinceStart : 868.770947933197
Done logging...



********** Iteration 294 ************

Collecting data for eval...
Eval_AverageReturn : 22.27777862548828
Eval_StdReturn : 5.465096950531006
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 22.27777777777778
Train_AverageReturn : 20.548717498779297
Train_StdReturn : 4.190518379211426
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.54871794871795
Actor Loss : 6.429947376251221
Train_EnvstepsSoFar : 1182888
TimeSinceStart : 871.758823633194
Done logging...



********** Iteration 295 ************

Collecting data for eval...
Eval_AverageReturn : 19.428571701049805
Eval_StdReturn : 3.458205223083496
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.428571428571427
Train_AverageReturn : 20.706186294555664
Train_StdReturn : 4.250077724456787
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.70618556701031
Actor Loss : 5.322940349578857
Train_EnvstepsSoFar : 1186905
TimeSinceStart : 874.9352860450745
Done logging...



********** Iteration 296 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 3.4420199394226074
Eval_MaxReturn : 26.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 20.045000076293945
Train_StdReturn : 3.942457914352417
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.045
Actor Loss : 2.6953301429748535
Train_EnvstepsSoFar : 1190914
TimeSinceStart : 877.840913772583
Done logging...



********** Iteration 297 ************

Collecting data for eval...
Eval_AverageReturn : 21.105262756347656
Eval_StdReturn : 3.8783440589904785
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.105263157894736
Train_AverageReturn : 20.35025405883789
Train_StdReturn : 4.303718566894531
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.3502538071066
Actor Loss : 3.9463679790496826
Train_EnvstepsSoFar : 1194923
TimeSinceStart : 880.5814671516418
Done logging...



********** Iteration 298 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 3.9556922912597656
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 20.35025405883789
Train_StdReturn : 4.186534404754639
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.3502538071066
Actor Loss : 6.609205722808838
Train_EnvstepsSoFar : 1198932
TimeSinceStart : 883.8989617824554
Done logging...



********** Iteration 299 ************

Collecting data for eval...
Eval_AverageReturn : 19.4761905670166
Eval_StdReturn : 4.2830681800842285
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.476190476190474
Train_AverageReturn : 20.58461570739746
Train_StdReturn : 4.211920738220215
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.584615384615386
Actor Loss : 3.827694892883301
Train_EnvstepsSoFar : 1202946
TimeSinceStart : 889.0952363014221
Done logging...



********** Iteration 300 ************

Collecting data for eval...
Eval_AverageReturn : 21.789474487304688
Eval_StdReturn : 3.188448905944824
Eval_MaxReturn : 27.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 21.789473684210527
Train_AverageReturn : 20.86979103088379
Train_StdReturn : 4.0835957527160645
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.869791666666668
Actor Loss : 4.1973748207092285
Train_EnvstepsSoFar : 1206953
TimeSinceStart : 891.780999660492
Done logging...



********** Iteration 301 ************

Collecting data for eval...
Eval_AverageReturn : 22.0
Eval_StdReturn : 4.230216979980469
Eval_MaxReturn : 30.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 22.0
Train_AverageReturn : 20.24242401123047
Train_StdReturn : 4.25711727142334
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.242424242424242
Actor Loss : 2.9245080947875977
Train_EnvstepsSoFar : 1210961
TimeSinceStart : 894.3149516582489
Done logging...



********** Iteration 302 ************

Collecting data for eval...
Eval_AverageReturn : 21.6842098236084
Eval_StdReturn : 4.193386077880859
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.68421052631579
Train_AverageReturn : 20.308080673217773
Train_StdReturn : 4.286581516265869
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.30808080808081
Actor Loss : 4.194367408752441
Train_EnvstepsSoFar : 1214982
TimeSinceStart : 896.8349294662476
Done logging...



********** Iteration 303 ************

Collecting data for eval...
Eval_AverageReturn : 19.571428298950195
Eval_StdReturn : 4.030496120452881
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.571428571428573
Train_AverageReturn : 20.416244506835938
Train_StdReturn : 4.021432399749756
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.416243654822335
Actor Loss : 4.593851089477539
Train_EnvstepsSoFar : 1219004
TimeSinceStart : 899.3751747608185
Done logging...



********** Iteration 304 ************

Collecting data for eval...
Eval_AverageReturn : 18.727272033691406
Eval_StdReturn : 3.6949820518493652
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 18.727272727272727
Train_AverageReturn : 20.32994842529297
Train_StdReturn : 4.060177803039551
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.32994923857868
Actor Loss : 4.067501068115234
Train_EnvstepsSoFar : 1223009
TimeSinceStart : 901.9036009311676
Done logging...



********** Iteration 305 ************

Collecting data for eval...
Eval_AverageReturn : 21.263158798217773
Eval_StdReturn : 4.326686859130859
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.263157894736842
Train_AverageReturn : 19.886138916015625
Train_StdReturn : 4.238193511962891
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.886138613861387
Actor Loss : 3.22756290435791
Train_EnvstepsSoFar : 1227026
TimeSinceStart : 904.4463984966278
Done logging...



********** Iteration 306 ************

Collecting data for eval...
Eval_AverageReturn : 20.649999618530273
Eval_StdReturn : 4.126439094543457
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.65
Train_AverageReturn : 20.88541603088379
Train_StdReturn : 4.199131488800049
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.885416666666668
Actor Loss : 5.735307693481445
Train_EnvstepsSoFar : 1231036
TimeSinceStart : 907.4988851547241
Done logging...



********** Iteration 307 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 3.992492914199829
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 20.170854568481445
Train_StdReturn : 3.920177698135376
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.170854271356784
Actor Loss : 4.035527229309082
Train_EnvstepsSoFar : 1235050
TimeSinceStart : 910.1962385177612
Done logging...



********** Iteration 308 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 3.440929889678955
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.74093246459961
Train_StdReturn : 4.19909143447876
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.740932642487046
Actor Loss : 4.120242118835449
Train_EnvstepsSoFar : 1239053
TimeSinceStart : 913.4921977519989
Done logging...



********** Iteration 309 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 4.211887836456299
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 20.870466232299805
Train_StdReturn : 4.074285507202148
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.870466321243523
Actor Loss : 3.9114365577697754
Train_EnvstepsSoFar : 1243081
TimeSinceStart : 916.571671962738
Done logging...



********** Iteration 310 ************

Collecting data for eval...
Eval_AverageReturn : 20.049999237060547
Eval_StdReturn : 3.9556922912597656
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.05
Train_AverageReturn : 20.859375
Train_StdReturn : 3.9072601795196533
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.859375
Actor Loss : 4.813905715942383
Train_EnvstepsSoFar : 1247086
TimeSinceStart : 919.9014945030212
Done logging...



********** Iteration 311 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 4.14578104019165
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 20.479591369628906
Train_StdReturn : 4.374624252319336
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.479591836734695
Actor Loss : 5.322053909301758
Train_EnvstepsSoFar : 1251100
TimeSinceStart : 923.2460327148438
Done logging...



********** Iteration 312 ************

Collecting data for eval...
Eval_AverageReturn : 20.350000381469727
Eval_StdReturn : 4.015905857086182
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.35
Train_AverageReturn : 20.68556785583496
Train_StdReturn : 4.156611442565918
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.685567010309278
Actor Loss : 3.8314151763916016
Train_EnvstepsSoFar : 1255113
TimeSinceStart : 926.3538677692413
Done logging...



********** Iteration 313 ************

Collecting data for eval...
Eval_AverageReturn : 20.5
Eval_StdReturn : 4.092676162719727
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.5
Train_AverageReturn : 20.505102157592773
Train_StdReturn : 4.378166198730469
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.505102040816325
Actor Loss : 3.4506797790527344
Train_EnvstepsSoFar : 1259132
TimeSinceStart : 929.2253880500793
Done logging...



********** Iteration 314 ************

Collecting data for eval...
Eval_AverageReturn : 20.299999237060547
Eval_StdReturn : 3.8483762741088867
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.3
Train_AverageReturn : 20.25757598876953
Train_StdReturn : 3.936275005340576
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.257575757575758
Actor Loss : 5.594196319580078
Train_EnvstepsSoFar : 1263143
TimeSinceStart : 932.4894032478333
Done logging...



********** Iteration 315 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 2.2284493446350098
Eval_MaxReturn : 23.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 20.335025787353516
Train_StdReturn : 4.171384334564209
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.33502538071066
Actor Loss : 3.6805129051208496
Train_EnvstepsSoFar : 1267149
TimeSinceStart : 935.5394675731659
Done logging...



********** Iteration 316 ************

Collecting data for eval...
Eval_AverageReturn : 22.27777862548828
Eval_StdReturn : 4.14736270904541
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 22.27777777777778
Train_AverageReturn : 20.48469352722168
Train_StdReturn : 4.119982719421387
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.48469387755102
Actor Loss : 4.662972927093506
Train_EnvstepsSoFar : 1271164
TimeSinceStart : 938.099091053009
Done logging...



********** Iteration 317 ************

Collecting data for eval...
Eval_AverageReturn : 21.421052932739258
Eval_StdReturn : 4.648890972137451
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.42105263157895
Train_AverageReturn : 20.639175415039062
Train_StdReturn : 4.235795974731445
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.63917525773196
Actor Loss : 3.649226188659668
Train_EnvstepsSoFar : 1275168
TimeSinceStart : 942.7840876579285
Done logging...



********** Iteration 318 ************

Collecting data for eval...
Eval_AverageReturn : 21.736841201782227
Eval_StdReturn : 4.089036464691162
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.736842105263158
Train_AverageReturn : 20.324872970581055
Train_StdReturn : 4.0323615074157715
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.3248730964467
Actor Loss : 3.28425669670105
Train_EnvstepsSoFar : 1279172
TimeSinceStart : 945.314056634903
Done logging...



********** Iteration 319 ************

Collecting data for eval...
Eval_AverageReturn : 20.0
Eval_StdReturn : 3.391165018081665
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.0
Train_AverageReturn : 20.574359893798828
Train_StdReturn : 4.192589282989502
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.574358974358976
Actor Loss : 4.171651363372803
Train_EnvstepsSoFar : 1283184
TimeSinceStart : 947.8697674274445
Done logging...



********** Iteration 320 ************

Collecting data for eval...
Eval_AverageReturn : 21.3157901763916
Eval_StdReturn : 3.2614595890045166
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.31578947368421
Train_AverageReturn : 20.72538948059082
Train_StdReturn : 4.231907844543457
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.72538860103627
Actor Loss : 4.724939346313477
Train_EnvstepsSoFar : 1287184
TimeSinceStart : 950.6991829872131
Done logging...



********** Iteration 321 ************

Collecting data for eval...
Eval_AverageReturn : 20.850000381469727
Eval_StdReturn : 4.7986979484558105
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.85
Train_AverageReturn : 20.20707130432129
Train_StdReturn : 4.103774070739746
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.207070707070706
Actor Loss : 8.695266723632812
Train_EnvstepsSoFar : 1291185
TimeSinceStart : 953.7409157752991
Done logging...



********** Iteration 322 ************

Collecting data for eval...
Eval_AverageReturn : 19.227272033691406
Eval_StdReturn : 3.450057029724121
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.227272727272727
Train_AverageReturn : 20.2020206451416
Train_StdReturn : 4.056370258331299
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.2020202020202
Actor Loss : 3.764967203140259
Train_EnvstepsSoFar : 1295185
TimeSinceStart : 956.9058012962341
Done logging...



********** Iteration 323 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 4.077682971954346
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 20.22222137451172
Train_StdReturn : 4.000140190124512
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.22222222222222
Actor Loss : 3.708472967147827
Train_EnvstepsSoFar : 1299189
TimeSinceStart : 959.5135471820831
Done logging...



********** Iteration 324 ************

Collecting data for eval...
Eval_AverageReturn : 20.299999237060547
Eval_StdReturn : 4.428318023681641
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.3
Train_AverageReturn : 20.726804733276367
Train_StdReturn : 4.084494590759277
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.72680412371134
Actor Loss : 4.062222957611084
Train_EnvstepsSoFar : 1303210
TimeSinceStart : 962.1246919631958
Done logging...



********** Iteration 325 ************

Collecting data for eval...
Eval_AverageReturn : 21.526315689086914
Eval_StdReturn : 4.405360698699951
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.526315789473685
Train_AverageReturn : 20.517948150634766
Train_StdReturn : 4.08040189743042
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.51794871794872
Actor Loss : 4.2667317390441895
Train_EnvstepsSoFar : 1307211
TimeSinceStart : 964.7508914470673
Done logging...



********** Iteration 326 ************

Collecting data for eval...
Eval_AverageReturn : 19.14285659790039
Eval_StdReturn : 2.474358320236206
Eval_MaxReturn : 23.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.142857142857142
Train_AverageReturn : 20.787565231323242
Train_StdReturn : 3.958522081375122
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.787564766839377
Actor Loss : 3.7925169467926025
Train_EnvstepsSoFar : 1311223
TimeSinceStart : 967.2159593105316
Done logging...



********** Iteration 327 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 3.6249139308929443
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 20.20707130432129
Train_StdReturn : 3.903190851211548
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.207070707070706
Actor Loss : 4.909024238586426
Train_EnvstepsSoFar : 1315224
TimeSinceStart : 969.6797835826874
Done logging...



********** Iteration 328 ************

Collecting data for eval...
Eval_AverageReturn : 21.578947067260742
Eval_StdReturn : 4.5689544677734375
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.57894736842105
Train_AverageReturn : 20.130653381347656
Train_StdReturn : 4.174944877624512
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.13065326633166
Actor Loss : 4.112736701965332
Train_EnvstepsSoFar : 1319230
TimeSinceStart : 972.148252248764
Done logging...



********** Iteration 329 ************

Collecting data for eval...
Eval_AverageReturn : 18.5
Eval_StdReturn : 3.271780014038086
Eval_MaxReturn : 25.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 18.5
Train_AverageReturn : 20.83333396911621
Train_StdReturn : 4.25040864944458
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.833333333333332
Actor Loss : 5.2209153175354
Train_EnvstepsSoFar : 1323230
TimeSinceStart : 974.59144282341
Done logging...



********** Iteration 330 ************

Collecting data for eval...
Eval_AverageReturn : 20.049999237060547
Eval_StdReturn : 4.455053329467773
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.05
Train_AverageReturn : 20.512821197509766
Train_StdReturn : 4.027289867401123
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.512820512820515
Actor Loss : 6.000888824462891
Train_EnvstepsSoFar : 1327230
TimeSinceStart : 977.0597689151764
Done logging...



********** Iteration 331 ************

Collecting data for eval...
Eval_AverageReturn : 19.238094329833984
Eval_StdReturn : 4.104640483856201
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.238095238095237
Train_AverageReturn : 20.706186294555664
Train_StdReturn : 3.9155073165893555
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.70618556701031
Actor Loss : 3.169309616088867
Train_EnvstepsSoFar : 1331247
TimeSinceStart : 979.5091345310211
Done logging...



********** Iteration 332 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 3.8141186237335205
Eval_MaxReturn : 26.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 20.065000534057617
Train_StdReturn : 4.063345432281494
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.065
Actor Loss : 4.9330902099609375
Train_EnvstepsSoFar : 1335260
TimeSinceStart : 981.9672996997833
Done logging...



********** Iteration 333 ************

Collecting data for eval...
Eval_AverageReturn : 21.100000381469727
Eval_StdReturn : 4.085339546203613
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.1
Train_AverageReturn : 20.232322692871094
Train_StdReturn : 4.069666862487793
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.232323232323232
Actor Loss : 5.431726455688477
Train_EnvstepsSoFar : 1339266
TimeSinceStart : 984.6801590919495
Done logging...



********** Iteration 334 ************

Collecting data for eval...
Eval_AverageReturn : 20.899999618530273
Eval_StdReturn : 4.369210243225098
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.9
Train_AverageReturn : 20.42346954345703
Train_StdReturn : 3.9148149490356445
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.4234693877551
Actor Loss : 3.1889688968658447
Train_EnvstepsSoFar : 1343269
TimeSinceStart : 987.1555948257446
Done logging...



********** Iteration 335 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 4.222262382507324
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 20.63401985168457
Train_StdReturn : 3.9799857139587402
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.6340206185567
Actor Loss : 4.099745273590088
Train_EnvstepsSoFar : 1347272
TimeSinceStart : 989.6750099658966
Done logging...



********** Iteration 336 ************

Collecting data for eval...
Eval_AverageReturn : 21.052631378173828
Eval_StdReturn : 4.524478912353516
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.05263157894737
Train_AverageReturn : 20.579486846923828
Train_StdReturn : 4.02142858505249
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.57948717948718
Actor Loss : 4.915139198303223
Train_EnvstepsSoFar : 1351285
TimeSinceStart : 992.1946725845337
Done logging...



********** Iteration 337 ************

Collecting data for eval...
Eval_AverageReturn : 20.899999618530273
Eval_StdReturn : 4.8569536209106445
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.9
Train_AverageReturn : 20.37055778503418
Train_StdReturn : 4.061675071716309
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.370558375634516
Actor Loss : 4.100066184997559
Train_EnvstepsSoFar : 1355298
TimeSinceStart : 995.1494827270508
Done logging...



********** Iteration 338 ************

Collecting data for eval...
Eval_AverageReturn : 20.700000762939453
Eval_StdReturn : 4.00124979019165
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.7
Train_AverageReturn : 20.84375
Train_StdReturn : 4.304378032684326
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.84375
Actor Loss : 6.053992748260498
Train_EnvstepsSoFar : 1359300
TimeSinceStart : 997.671183347702
Done logging...



********** Iteration 339 ************

Collecting data for eval...
Eval_AverageReturn : 22.72222137451172
Eval_StdReturn : 4.066195964813232
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 22.72222222222222
Train_AverageReturn : 20.630769729614258
Train_StdReturn : 4.06449031829834
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.630769230769232
Actor Loss : 2.7086362838745117
Train_EnvstepsSoFar : 1363323
TimeSinceStart : 1000.154762506485
Done logging...



********** Iteration 340 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 4.12795352935791
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.58461570739746
Train_StdReturn : 4.008551120758057
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.584615384615386
Actor Loss : 3.865478992462158
Train_EnvstepsSoFar : 1367337
TimeSinceStart : 1002.7828409671783
Done logging...



********** Iteration 341 ************

Collecting data for eval...
Eval_AverageReturn : 20.5
Eval_StdReturn : 3.9937450885772705
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.5
Train_AverageReturn : 20.43877601623535
Train_StdReturn : 4.083481788635254
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.43877551020408
Actor Loss : 4.290152549743652
Train_EnvstepsSoFar : 1371343
TimeSinceStart : 1005.4170372486115
Done logging...



********** Iteration 342 ************

Collecting data for eval...
Eval_AverageReturn : 20.200000762939453
Eval_StdReturn : 4.296510219573975
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.2
Train_AverageReturn : 20.62886619567871
Train_StdReturn : 4.243417263031006
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.628865979381445
Actor Loss : 6.312255859375
Train_EnvstepsSoFar : 1375345
TimeSinceStart : 1007.9729664325714
Done logging...



********** Iteration 343 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 3.9420807361602783
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 20.74093246459961
Train_StdReturn : 4.185495853424072
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.740932642487046
Actor Loss : 2.946629762649536
Train_EnvstepsSoFar : 1379348
TimeSinceStart : 1010.5316181182861
Done logging...



********** Iteration 344 ************

Collecting data for eval...
Eval_AverageReturn : 21.842105865478516
Eval_StdReturn : 4.343938827514648
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.842105263157894
Train_AverageReturn : 20.05500030517578
Train_StdReturn : 4.315318584442139
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.055
Actor Loss : 4.335981369018555
Train_EnvstepsSoFar : 1383359
TimeSinceStart : 1013.3920512199402
Done logging...



********** Iteration 345 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 4.294181823730469
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 20.474489212036133
Train_StdReturn : 4.12982702255249
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.474489795918366
Actor Loss : 4.2488250732421875
Train_EnvstepsSoFar : 1387372
TimeSinceStart : 1015.90061211586
Done logging...



********** Iteration 346 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 4.2529401779174805
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 20.345178604125977
Train_StdReturn : 4.130195617675781
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.34517766497462
Actor Loss : 3.9745309352874756
Train_EnvstepsSoFar : 1391380
TimeSinceStart : 1018.3991007804871
Done logging...



********** Iteration 347 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 4.8121161460876465
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 20.659793853759766
Train_StdReturn : 4.050930023193359
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.65979381443299
Actor Loss : 3.4826364517211914
Train_EnvstepsSoFar : 1395388
TimeSinceStart : 1021.983608007431
Done logging...



********** Iteration 348 ************

Collecting data for eval...
Eval_AverageReturn : 19.238094329833984
Eval_StdReturn : 3.4490132331848145
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.238095238095237
Train_AverageReturn : 20.968585968017578
Train_StdReturn : 4.1489362716674805
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.968586387434556
Actor Loss : 5.0100626945495605
Train_EnvstepsSoFar : 1399393
TimeSinceStart : 1024.49196267128
Done logging...



********** Iteration 349 ************

Collecting data for eval...
Eval_AverageReturn : 19.238094329833984
Eval_StdReturn : 3.08459734916687
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.238095238095237
Train_AverageReturn : 20.42346954345703
Train_StdReturn : 4.256958484649658
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.4234693877551
Actor Loss : 3.620746612548828
Train_EnvstepsSoFar : 1403396
TimeSinceStart : 1026.9265372753143
Done logging...



********** Iteration 350 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 4.066939830780029
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 20.74611473083496
Train_StdReturn : 4.2855095863342285
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.746113989637305
Actor Loss : 3.720621109008789
Train_EnvstepsSoFar : 1407400
TimeSinceStart : 1029.3570370674133
Done logging...



********** Iteration 351 ************

Collecting data for eval...
Eval_AverageReturn : 21.100000381469727
Eval_StdReturn : 4.311612129211426
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.1
Train_AverageReturn : 20.98952865600586
Train_StdReturn : 4.289265155792236
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.98952879581152
Actor Loss : 3.8094184398651123
Train_EnvstepsSoFar : 1411409
TimeSinceStart : 1031.8812081813812
Done logging...



********** Iteration 352 ************

Collecting data for eval...
Eval_AverageReturn : 19.904762268066406
Eval_StdReturn : 3.0222156047821045
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.904761904761905
Train_AverageReturn : 20.232322692871094
Train_StdReturn : 3.953845500946045
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.232323232323232
Actor Loss : 2.972954750061035
Train_EnvstepsSoFar : 1415415
TimeSinceStart : 1034.4000930786133
Done logging...



********** Iteration 353 ************

Collecting data for eval...
Eval_AverageReturn : 21.105262756347656
Eval_StdReturn : 4.20394229888916
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.105263157894736
Train_AverageReturn : 20.32994842529297
Train_StdReturn : 4.251935005187988
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.32994923857868
Actor Loss : 3.2062876224517822
Train_EnvstepsSoFar : 1419420
TimeSinceStart : 1037.8053550720215
Done logging...



********** Iteration 354 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 3.144439458847046
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 19.63725471496582
Train_StdReturn : 3.9064781665802
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.637254901960784
Actor Loss : 3.4682345390319824
Train_EnvstepsSoFar : 1423426
TimeSinceStart : 1042.00878572464
Done logging...



********** Iteration 355 ************

Collecting data for eval...
Eval_AverageReturn : 19.136363983154297
Eval_StdReturn : 3.0939157009124756
Eval_MaxReturn : 26.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.136363636363637
Train_AverageReturn : 20.664947509765625
Train_StdReturn : 4.062160015106201
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.664948453608247
Actor Loss : 3.6442997455596924
Train_EnvstepsSoFar : 1427435
TimeSinceStart : 1044.8901126384735
Done logging...



********** Iteration 356 ************

Collecting data for eval...
Eval_AverageReturn : 21.63157844543457
Eval_StdReturn : 3.7305359840393066
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.63157894736842
Train_AverageReturn : 20.72538948059082
Train_StdReturn : 4.110170364379883
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.72538860103627
Actor Loss : 16.722654342651367
Train_EnvstepsSoFar : 1431435
TimeSinceStart : 1047.400582075119
Done logging...



********** Iteration 357 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 4.684015274047852
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 19.886138916015625
Train_StdReturn : 4.087157726287842
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.886138613861387
Actor Loss : 4.91270637512207
Train_EnvstepsSoFar : 1435452
TimeSinceStart : 1049.904893875122
Done logging...



********** Iteration 358 ************

Collecting data for eval...
Eval_AverageReturn : 20.190475463867188
Eval_StdReturn : 4.0073628425598145
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.19047619047619
Train_AverageReturn : 20.395938873291016
Train_StdReturn : 4.1034321784973145
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.395939086294415
Actor Loss : 3.9062204360961914
Train_EnvstepsSoFar : 1439470
TimeSinceStart : 1053.3744661808014
Done logging...



********** Iteration 359 ************

Collecting data for eval...
Eval_AverageReturn : 21.421052932739258
Eval_StdReturn : 3.4991095066070557
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.42105263157895
Train_AverageReturn : 20.267677307128906
Train_StdReturn : 4.186807632446289
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.267676767676768
Actor Loss : 3.508610725402832
Train_EnvstepsSoFar : 1443483
TimeSinceStart : 1055.9273319244385
Done logging...



********** Iteration 360 ************

Collecting data for eval...
Eval_AverageReturn : 20.299999237060547
Eval_StdReturn : 3.782855987548828
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.3
Train_AverageReturn : 20.045000076293945
Train_StdReturn : 3.805650472640991
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.045
Actor Loss : 3.0140180587768555
Train_EnvstepsSoFar : 1447492
TimeSinceStart : 1058.4606642723083
Done logging...



********** Iteration 361 ************

Collecting data for eval...
Eval_AverageReturn : 20.350000381469727
Eval_StdReturn : 3.6915442943573
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.35
Train_AverageReturn : 20.345178604125977
Train_StdReturn : 4.103067874908447
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.34517766497462
Actor Loss : 3.4977405071258545
Train_EnvstepsSoFar : 1451500
TimeSinceStart : 1061.0133218765259
Done logging...



********** Iteration 362 ************

Collecting data for eval...
Eval_AverageReturn : 19.904762268066406
Eval_StdReturn : 4.471121788024902
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.904761904761905
Train_AverageReturn : 20.494897842407227
Train_StdReturn : 4.232403755187988
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.494897959183675
Actor Loss : 3.486748218536377
Train_EnvstepsSoFar : 1455517
TimeSinceStart : 1063.540986776352
Done logging...



********** Iteration 363 ************

Collecting data for eval...
Eval_AverageReturn : 20.047618865966797
Eval_StdReturn : 3.2289788722991943
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.047619047619047
Train_AverageReturn : 20.520408630371094
Train_StdReturn : 4.100098609924316
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.520408163265305
Actor Loss : 3.4355854988098145
Train_EnvstepsSoFar : 1459539
TimeSinceStart : 1066.0715379714966
Done logging...



********** Iteration 364 ************

Collecting data for eval...
Eval_AverageReturn : 21.200000762939453
Eval_StdReturn : 3.264965534210205
Eval_MaxReturn : 28.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 21.2
Train_AverageReturn : 20.418367385864258
Train_StdReturn : 3.7537014484405518
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.418367346938776
Actor Loss : 2.4138636589050293
Train_EnvstepsSoFar : 1463541
TimeSinceStart : 1072.1708824634552
Done logging...



********** Iteration 365 ************

Collecting data for eval...
Eval_AverageReturn : 21.6842098236084
Eval_StdReturn : 4.193386077880859
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.68421052631579
Train_AverageReturn : 20.40816307067871
Train_StdReturn : 4.303146839141846
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.408163265306122
Actor Loss : 2.972750425338745
Train_EnvstepsSoFar : 1467541
TimeSinceStart : 1074.635540485382
Done logging...



********** Iteration 366 ************

Collecting data for eval...
Eval_AverageReturn : 21.052631378173828
Eval_StdReturn : 2.163663625717163
Eval_MaxReturn : 25.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 21.05263157894737
Train_AverageReturn : 20.335025787353516
Train_StdReturn : 3.84330677986145
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.33502538071066
Actor Loss : 3.6388347148895264
Train_EnvstepsSoFar : 1471547
TimeSinceStart : 1077.1180515289307
Done logging...



********** Iteration 367 ************

Collecting data for eval...
Eval_AverageReturn : 21.894737243652344
Eval_StdReturn : 4.399698257446289
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.894736842105264
Train_AverageReturn : 20.135679244995117
Train_StdReturn : 3.992037773132324
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.1356783919598
Actor Loss : 3.5912976264953613
Train_EnvstepsSoFar : 1475554
TimeSinceStart : 1080.909004688263
Done logging...



********** Iteration 368 ************

Collecting data for eval...
Eval_AverageReturn : 21.052631378173828
Eval_StdReturn : 4.627989292144775
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.05263157894737
Train_AverageReturn : 20.155778884887695
Train_StdReturn : 4.088327884674072
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.155778894472363
Actor Loss : 2.4531893730163574
Train_EnvstepsSoFar : 1479565
TimeSinceStart : 1083.4431583881378
Done logging...



********** Iteration 369 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 4.952524662017822
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 19.93532371520996
Train_StdReturn : 4.047085285186768
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.935323383084576
Actor Loss : 3.9443085193634033
Train_EnvstepsSoFar : 1483572
TimeSinceStart : 1085.9015200138092
Done logging...



********** Iteration 370 ************

Collecting data for eval...
Eval_AverageReturn : 22.263158798217773
Eval_StdReturn : 3.5517542362213135
Eval_MaxReturn : 28.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 22.263157894736842
Train_AverageReturn : 20.649484634399414
Train_StdReturn : 4.051323413848877
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.649484536082475
Actor Loss : 3.827634334564209
Train_EnvstepsSoFar : 1487578
TimeSinceStart : 1088.4056959152222
Done logging...



********** Iteration 371 ************

Collecting data for eval...
Eval_AverageReturn : 19.66666603088379
Eval_StdReturn : 4.528568744659424
Eval_MaxReturn : 32.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.666666666666668
Train_AverageReturn : 20.267677307128906
Train_StdReturn : 4.030698776245117
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.267676767676768
Actor Loss : 3.2176308631896973
Train_EnvstepsSoFar : 1491591
TimeSinceStart : 1090.9729561805725
Done logging...



********** Iteration 372 ************

Collecting data for eval...
Eval_AverageReturn : 19.809524536132812
Eval_StdReturn : 4.381987571716309
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.80952380952381
Train_AverageReturn : 20.20707130432129
Train_StdReturn : 4.070409297943115
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.207070707070706
Actor Loss : 2.6219840049743652
Train_EnvstepsSoFar : 1495592
TimeSinceStart : 1093.5177037715912
Done logging...



********** Iteration 373 ************

Collecting data for eval...
Eval_AverageReturn : 21.3157901763916
Eval_StdReturn : 4.657225608825684
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.31578947368421
Train_AverageReturn : 20.594871520996094
Train_StdReturn : 4.1218581199646
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.594871794871796
Actor Loss : 3.576165199279785
Train_EnvstepsSoFar : 1499608
TimeSinceStart : 1096.0356998443604
Done logging...



********** Iteration 374 ************

Collecting data for eval...
Eval_AverageReturn : 20.5
Eval_StdReturn : 3.91790771484375
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.5
Train_AverageReturn : 20.62886619567871
Train_StdReturn : 4.143855571746826
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.628865979381445
Actor Loss : 6.08183479309082
Train_EnvstepsSoFar : 1503610
TimeSinceStart : 1098.6109580993652
Done logging...



********** Iteration 375 ************

Collecting data for eval...
Eval_AverageReturn : 19.66666603088379
Eval_StdReturn : 3.4960293769836426
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.666666666666668
Train_AverageReturn : 20.130653381347656
Train_StdReturn : 3.93068265914917
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.13065326633166
Actor Loss : 2.6656689643859863
Train_EnvstepsSoFar : 1507616
TimeSinceStart : 1101.155579328537
Done logging...



********** Iteration 376 ************

Collecting data for eval...
Eval_AverageReturn : 20.899999618530273
Eval_StdReturn : 4.241462230682373
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.9
Train_AverageReturn : 20.0
Train_StdReturn : 4.220189571380615
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.0
Actor Loss : 2.846414089202881
Train_EnvstepsSoFar : 1511616
TimeSinceStart : 1103.6394999027252
Done logging...



********** Iteration 377 ************

Collecting data for eval...
Eval_AverageReturn : 19.761905670166016
Eval_StdReturn : 4.1736674308776855
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.761904761904763
Train_AverageReturn : 20.23737335205078
Train_StdReturn : 3.9413912296295166
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.237373737373737
Actor Loss : 2.5485525131225586
Train_EnvstepsSoFar : 1515623
TimeSinceStart : 1106.1177282333374
Done logging...



********** Iteration 378 ************

Collecting data for eval...
Eval_AverageReturn : 21.105262756347656
Eval_StdReturn : 3.2750208377838135
Eval_MaxReturn : 26.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.105263157894736
Train_AverageReturn : 20.947643280029297
Train_StdReturn : 3.974708318710327
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.94764397905759
Actor Loss : 2.9920310974121094
Train_EnvstepsSoFar : 1519624
TimeSinceStart : 1109.072504043579
Done logging...



********** Iteration 379 ************

Collecting data for eval...
Eval_AverageReturn : 21.894737243652344
Eval_StdReturn : 4.587107181549072
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.894736842105264
Train_AverageReturn : 20.829015731811523
Train_StdReturn : 4.318509101867676
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.82901554404145
Actor Loss : 4.292698860168457
Train_EnvstepsSoFar : 1523644
TimeSinceStart : 1111.6727139949799
Done logging...



********** Iteration 380 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 4.841487407684326
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.413265228271484
Train_StdReturn : 4.044096946716309
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.413265306122447
Actor Loss : 3.360283851623535
Train_EnvstepsSoFar : 1527645
TimeSinceStart : 1114.1764922142029
Done logging...



********** Iteration 381 ************

Collecting data for eval...
Eval_AverageReturn : 21.0
Eval_StdReturn : 3.3763885498046875
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.0
Train_AverageReturn : 20.272727966308594
Train_StdReturn : 4.086978912353516
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.272727272727273
Actor Loss : 2.9632325172424316
Train_EnvstepsSoFar : 1531659
TimeSinceStart : 1116.690214395523
Done logging...



********** Iteration 382 ************

Collecting data for eval...
Eval_AverageReturn : 21.578947067260742
Eval_StdReturn : 2.815666675567627
Eval_MaxReturn : 27.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.57894736842105
Train_AverageReturn : 20.190954208374023
Train_StdReturn : 4.177436351776123
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.190954773869347
Actor Loss : 3.0595898628234863
Train_EnvstepsSoFar : 1535677
TimeSinceStart : 1119.2282860279083
Done logging...



********** Iteration 383 ************

Collecting data for eval...
Eval_AverageReturn : 21.200000762939453
Eval_StdReturn : 4.456455707550049
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.2
Train_AverageReturn : 20.42346954345703
Train_StdReturn : 4.018992900848389
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.4234693877551
Actor Loss : 3.9293882846832275
Train_EnvstepsSoFar : 1539680
TimeSinceStart : 1121.772711277008
Done logging...



********** Iteration 384 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 4.2529401779174805
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 20.517948150634766
Train_StdReturn : 3.912299633026123
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.51794871794872
Actor Loss : 2.4294228553771973
Train_EnvstepsSoFar : 1543681
TimeSinceStart : 1124.310719013214
Done logging...



********** Iteration 385 ************

Collecting data for eval...
Eval_AverageReturn : 18.086956024169922
Eval_StdReturn : 3.1472978591918945
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 18.08695652173913
Train_AverageReturn : 20.211055755615234
Train_StdReturn : 4.055603504180908
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.21105527638191
Actor Loss : 3.181413173675537
Train_EnvstepsSoFar : 1547703
TimeSinceStart : 1126.8572373390198
Done logging...



********** Iteration 386 ************

Collecting data for eval...
Eval_AverageReturn : 20.799999237060547
Eval_StdReturn : 3.6687874794006348
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.8
Train_AverageReturn : 19.846534729003906
Train_StdReturn : 3.7721245288848877
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.846534653465348
Actor Loss : 3.0703420639038086
Train_EnvstepsSoFar : 1551712
TimeSinceStart : 1129.454191684723
Done logging...



********** Iteration 387 ************

Collecting data for eval...
Eval_AverageReturn : 18.863636016845703
Eval_StdReturn : 3.2793493270874023
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 18.863636363636363
Train_AverageReturn : 20.180904388427734
Train_StdReturn : 3.968144178390503
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.180904522613066
Actor Loss : 2.5700924396514893
Train_EnvstepsSoFar : 1555728
TimeSinceStart : 1133.5881743431091
Done logging...



********** Iteration 388 ************

Collecting data for eval...
Eval_AverageReturn : 19.85714340209961
Eval_StdReturn : 3.8580243587493896
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.857142857142858
Train_AverageReturn : 20.97905731201172
Train_StdReturn : 4.1703996658325195
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.979057591623036
Actor Loss : 4.399165630340576
Train_EnvstepsSoFar : 1559735
TimeSinceStart : 1136.287314414978
Done logging...



********** Iteration 389 ************

Collecting data for eval...
Eval_AverageReturn : 20.0
Eval_StdReturn : 3.3316662311553955
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.0
Train_AverageReturn : 21.164020538330078
Train_StdReturn : 4.353382110595703
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.164021164021165
Actor Loss : 5.764773368835449
Train_EnvstepsSoFar : 1563735
TimeSinceStart : 1138.8167793750763
Done logging...



********** Iteration 390 ************

Collecting data for eval...
Eval_AverageReturn : 21.157894134521484
Eval_StdReturn : 4.404102802276611
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.157894736842106
Train_AverageReturn : 19.920398712158203
Train_StdReturn : 3.955427408218384
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.920398009950247
Actor Loss : 2.7238731384277344
Train_EnvstepsSoFar : 1567739
TimeSinceStart : 1141.6546680927277
Done logging...



********** Iteration 391 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 3.97334885597229
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 20.538461685180664
Train_StdReturn : 3.8166046142578125
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.53846153846154
Actor Loss : 2.665332794189453
Train_EnvstepsSoFar : 1571744
TimeSinceStart : 1144.1689057350159
Done logging...



********** Iteration 392 ************

Collecting data for eval...
Eval_AverageReturn : 22.210525512695312
Eval_StdReturn : 4.020721435546875
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.210526315789473
Train_AverageReturn : 20.140703201293945
Train_StdReturn : 4.061128616333008
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.14070351758794
Actor Loss : 6.008581638336182
Train_EnvstepsSoFar : 1575752
TimeSinceStart : 1146.6255099773407
Done logging...



********** Iteration 393 ************

Collecting data for eval...
Eval_AverageReturn : 18.772727966308594
Eval_StdReturn : 3.528221607208252
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 18.772727272727273
Train_AverageReturn : 20.711339950561523
Train_StdReturn : 3.967545509338379
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.711340206185568
Actor Loss : 3.43118953704834
Train_EnvstepsSoFar : 1579770
TimeSinceStart : 1150.6658947467804
Done logging...



********** Iteration 394 ************

Collecting data for eval...
Eval_AverageReturn : 18.81818199157715
Eval_StdReturn : 3.1281185150146484
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 18.818181818181817
Train_AverageReturn : 20.335025787353516
Train_StdReturn : 3.8419857025146484
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.33502538071066
Actor Loss : 1.9340863227844238
Train_EnvstepsSoFar : 1583776
TimeSinceStart : 1153.500858783722
Done logging...



********** Iteration 395 ************

Collecting data for eval...
Eval_AverageReturn : 20.950000762939453
Eval_StdReturn : 4.080134868621826
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.95
Train_AverageReturn : 20.75129508972168
Train_StdReturn : 4.118743896484375
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.751295336787564
Actor Loss : 4.049036979675293
Train_EnvstepsSoFar : 1587781
TimeSinceStart : 1155.9998772144318
Done logging...



********** Iteration 396 ************

Collecting data for eval...
Eval_AverageReturn : 20.049999237060547
Eval_StdReturn : 2.8892037868499756
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.05
Train_AverageReturn : 20.130653381347656
Train_StdReturn : 3.965050220489502
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.13065326633166
Actor Loss : 1.9126451015472412
Train_EnvstepsSoFar : 1591787
TimeSinceStart : 1158.4668455123901
Done logging...



********** Iteration 397 ************

Collecting data for eval...
Eval_AverageReturn : 19.380952835083008
Eval_StdReturn : 3.565391778945923
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.38095238095238
Train_AverageReturn : 20.55384635925293
Train_StdReturn : 4.148638725280762
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.553846153846155
Actor Loss : 3.863959789276123
Train_EnvstepsSoFar : 1595795
TimeSinceStart : 1161.0373187065125
Done logging...



********** Iteration 398 ************

Collecting data for eval...
Eval_AverageReturn : 20.100000381469727
Eval_StdReturn : 3.562302589416504
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.1
Train_AverageReturn : 20.140703201293945
Train_StdReturn : 4.145628452301025
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.14070351758794
Actor Loss : 3.2917819023132324
Train_EnvstepsSoFar : 1599803
TimeSinceStart : 1163.5032515525818
Done logging...



********** Iteration 399 ************

Collecting data for eval...
Eval_AverageReturn : 19.904762268066406
Eval_StdReturn : 4.534574031829834
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.904761904761905
Train_AverageReturn : 20.4489803314209
Train_StdReturn : 4.300266742706299
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.448979591836736
Actor Loss : 2.2268683910369873
Train_EnvstepsSoFar : 1603811
TimeSinceStart : 1166.0050613880157
Done logging...



********** Iteration 400 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 3.831484079360962
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 20.73575210571289
Train_StdReturn : 4.236238479614258
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.735751295336787
Actor Loss : 3.3718948364257812
Train_EnvstepsSoFar : 1607813
TimeSinceStart : 1168.4909245967865
Done logging...



********** Iteration 401 ************

Collecting data for eval...
Eval_AverageReturn : 20.100000381469727
Eval_StdReturn : 4.2059478759765625
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.1
Train_AverageReturn : 20.30964469909668
Train_StdReturn : 4.178814888000488
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.309644670050762
Actor Loss : 3.6236026287078857
Train_EnvstepsSoFar : 1611814
TimeSinceStart : 1170.975037574768
Done logging...



********** Iteration 402 ************

Collecting data for eval...
Eval_AverageReturn : 20.649999618530273
Eval_StdReturn : 3.636962890625
Eval_MaxReturn : 27.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.65
Train_AverageReturn : 20.53333282470703
Train_StdReturn : 4.089093208312988
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.533333333333335
Actor Loss : 2.8044075965881348
Train_EnvstepsSoFar : 1615818
TimeSinceStart : 1173.4562516212463
Done logging...



********** Iteration 403 ************

Collecting data for eval...
Eval_AverageReturn : 21.6842098236084
Eval_StdReturn : 4.14287805557251
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.68421052631579
Train_AverageReturn : 20.30964469909668
Train_StdReturn : 3.9309470653533936
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.309644670050762
Actor Loss : 2.986740827560425
Train_EnvstepsSoFar : 1619819
TimeSinceStart : 1175.9537818431854
Done logging...



********** Iteration 404 ************

Collecting data for eval...
Eval_AverageReturn : 22.27777862548828
Eval_StdReturn : 4.5068535804748535
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.27777777777778
Train_AverageReturn : 20.625640869140625
Train_StdReturn : 4.1901421546936035
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.625641025641027
Actor Loss : 3.276174545288086
Train_EnvstepsSoFar : 1623841
TimeSinceStart : 1178.4438033103943
Done logging...



********** Iteration 405 ************

Collecting data for eval...
Eval_AverageReturn : 21.263158798217773
Eval_StdReturn : 4.350947856903076
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.263157894736842
Train_AverageReturn : 20.375635147094727
Train_StdReturn : 4.038019180297852
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.375634517766496
Actor Loss : 3.3462932109832764
Train_EnvstepsSoFar : 1627855
TimeSinceStart : 1180.933729171753
Done logging...



********** Iteration 406 ************

Collecting data for eval...
Eval_AverageReturn : 20.100000381469727
Eval_StdReturn : 3.910243034362793
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.1
Train_AverageReturn : 20.304569244384766
Train_StdReturn : 4.3207244873046875
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.304568527918782
Actor Loss : 3.3900866508483887
Train_EnvstepsSoFar : 1631855
TimeSinceStart : 1183.4196124076843
Done logging...



********** Iteration 407 ************

Collecting data for eval...
Eval_AverageReturn : 19.952381134033203
Eval_StdReturn : 3.7981975078582764
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.952380952380953
Train_AverageReturn : 21.136842727661133
Train_StdReturn : 4.241674423217773
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.13684210526316
Actor Loss : 4.385043621063232
Train_EnvstepsSoFar : 1635871
TimeSinceStart : 1187.4854266643524
Done logging...



********** Iteration 408 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 4.532107830047607
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.105527877807617
Train_StdReturn : 4.009275436401367
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.105527638190956
Actor Loss : 2.535208225250244
Train_EnvstepsSoFar : 1639872
TimeSinceStart : 1189.9447588920593
Done logging...



********** Iteration 409 ************

Collecting data for eval...
Eval_AverageReturn : 20.75
Eval_StdReturn : 4.958578586578369
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.75
Train_AverageReturn : 20.79274559020996
Train_StdReturn : 4.231457233428955
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.792746113989637
Actor Loss : 4.316402435302734
Train_EnvstepsSoFar : 1643885
TimeSinceStart : 1192.4369714260101
Done logging...



********** Iteration 410 ************

Collecting data for eval...
Eval_AverageReturn : 20.5
Eval_StdReturn : 4.068169116973877
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.5
Train_AverageReturn : 21.031414031982422
Train_StdReturn : 4.180365085601807
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.031413612565444
Actor Loss : 3.2849836349487305
Train_EnvstepsSoFar : 1647902
TimeSinceStart : 1194.9512627124786
Done logging...



********** Iteration 411 ************

Collecting data for eval...
Eval_AverageReturn : 19.4761905670166
Eval_StdReturn : 3.033449172973633
Eval_MaxReturn : 27.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 19.476190476190474
Train_AverageReturn : 20.418367385864258
Train_StdReturn : 4.055541515350342
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.418367346938776
Actor Loss : 2.45350980758667
Train_EnvstepsSoFar : 1651904
TimeSinceStart : 1197.4656918048859
Done logging...



********** Iteration 412 ************

Collecting data for eval...
Eval_AverageReturn : 20.75
Eval_StdReturn : 4.311322212219238
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.75
Train_AverageReturn : 20.303030014038086
Train_StdReturn : 4.048829555511475
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.303030303030305
Actor Loss : 3.028608798980713
Train_EnvstepsSoFar : 1655924
TimeSinceStart : 1199.992146730423
Done logging...



********** Iteration 413 ************

Collecting data for eval...
Eval_AverageReturn : 19.66666603088379
Eval_StdReturn : 3.629683494567871
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.666666666666668
Train_AverageReturn : 20.155778884887695
Train_StdReturn : 4.046321868896484
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.155778894472363
Actor Loss : 2.7332205772399902
Train_EnvstepsSoFar : 1659935
TimeSinceStart : 1202.5202586650848
Done logging...



********** Iteration 414 ************

Collecting data for eval...
Eval_AverageReturn : 21.63157844543457
Eval_StdReturn : 4.498075485229492
Eval_MaxReturn : 31.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.63157894736842
Train_AverageReturn : 20.77202033996582
Train_StdReturn : 3.985705614089966
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.7720207253886
Actor Loss : 2.7145676612854004
Train_EnvstepsSoFar : 1663944
TimeSinceStart : 1205.0428783893585
Done logging...



********** Iteration 415 ************

Collecting data for eval...
Eval_AverageReturn : 22.157894134521484
Eval_StdReturn : 4.307437419891357
Eval_MaxReturn : 30.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.157894736842106
Train_AverageReturn : 20.875
Train_StdReturn : 4.212456703186035
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.875
Actor Loss : 3.557103157043457
Train_EnvstepsSoFar : 1667952
TimeSinceStart : 1207.913801908493
Done logging...



********** Iteration 416 ************

Collecting data for eval...
Eval_AverageReturn : 21.421052932739258
Eval_StdReturn : 4.246556282043457
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.42105263157895
Train_AverageReturn : 20.517948150634766
Train_StdReturn : 3.978588342666626
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.51794871794872
Actor Loss : 3.7409720420837402
Train_EnvstepsSoFar : 1671953
TimeSinceStart : 1210.8457708358765
Done logging...



********** Iteration 417 ************

Collecting data for eval...
Eval_AverageReturn : 22.22222137451172
Eval_StdReturn : 3.808696746826172
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 22.22222222222222
Train_AverageReturn : 20.454082489013672
Train_StdReturn : 4.057360649108887
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.45408163265306
Actor Loss : 2.759611129760742
Train_EnvstepsSoFar : 1675962
TimeSinceStart : 1215.9201707839966
Done logging...



********** Iteration 418 ************

Collecting data for eval...
Eval_AverageReturn : 20.899999618530273
Eval_StdReturn : 4.938623428344727
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.9
Train_AverageReturn : 20.05500030517578
Train_StdReturn : 3.883551597595215
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.055
Actor Loss : 2.532946825027466
Train_EnvstepsSoFar : 1679973
TimeSinceStart : 1218.9975216388702
Done logging...



********** Iteration 419 ************

Collecting data for eval...
Eval_AverageReturn : 20.5
Eval_StdReturn : 3.853569746017456
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.5
Train_AverageReturn : 20.201005935668945
Train_StdReturn : 4.187777996063232
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.201005025125628
Actor Loss : 2.306061267852783
Train_EnvstepsSoFar : 1683993
TimeSinceStart : 1222.0919878482819
Done logging...



********** Iteration 420 ************

Collecting data for eval...
Eval_AverageReturn : 21.157894134521484
Eval_StdReturn : 4.4869771003723145
Eval_MaxReturn : 32.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.157894736842106
Train_AverageReturn : 20.150753021240234
Train_StdReturn : 3.983304977416992
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.150753768844222
Actor Loss : 3.6508255004882812
Train_EnvstepsSoFar : 1688003
TimeSinceStart : 1224.6580874919891
Done logging...



********** Iteration 421 ************

Collecting data for eval...
Eval_AverageReturn : 21.3157901763916
Eval_StdReturn : 4.389612674713135
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.31578947368421
Train_AverageReturn : 21.06842041015625
Train_StdReturn : 4.329890251159668
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.068421052631578
Actor Loss : 3.867539167404175
Train_EnvstepsSoFar : 1692006
TimeSinceStart : 1227.246459722519
Done logging...



********** Iteration 422 ************

Collecting data for eval...
Eval_AverageReturn : 20.649999618530273
Eval_StdReturn : 3.03767991065979
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.65
Train_AverageReturn : 20.73056983947754
Train_StdReturn : 4.0553107261657715
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.730569948186528
Actor Loss : 4.695725440979004
Train_EnvstepsSoFar : 1696007
TimeSinceStart : 1229.8037025928497
Done logging...



********** Iteration 423 ************

Collecting data for eval...
Eval_AverageReturn : 20.5
Eval_StdReturn : 3.681032419204712
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.5
Train_AverageReturn : 20.625640869140625
Train_StdReturn : 3.840186834335327
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.625641025641027
Actor Loss : 3.390864849090576
Train_EnvstepsSoFar : 1700029
TimeSinceStart : 1232.475494146347
Done logging...



********** Iteration 424 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 4.269367694854736
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 19.97512435913086
Train_StdReturn : 4.035215377807617
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.975124378109452
Actor Loss : 1.8575248718261719
Train_EnvstepsSoFar : 1704044
TimeSinceStart : 1235.8083209991455
Done logging...



********** Iteration 425 ************

Collecting data for eval...
Eval_AverageReturn : 19.4761905670166
Eval_StdReturn : 4.56298828125
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.476190476190474
Train_AverageReturn : 20.75129508972168
Train_StdReturn : 4.495283603668213
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.751295336787564
Actor Loss : 2.607694149017334
Train_EnvstepsSoFar : 1708049
TimeSinceStart : 1238.264161348343
Done logging...



********** Iteration 426 ************

Collecting data for eval...
Eval_AverageReturn : 19.85714340209961
Eval_StdReturn : 3.4953808784484863
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.857142857142858
Train_AverageReturn : 20.365482330322266
Train_StdReturn : 4.12106466293335
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.365482233502537
Actor Loss : 3.3028855323791504
Train_EnvstepsSoFar : 1712061
TimeSinceStart : 1240.7233338356018
Done logging...



********** Iteration 427 ************

Collecting data for eval...
Eval_AverageReturn : 18.863636016845703
Eval_StdReturn : 3.4548447132110596
Eval_MaxReturn : 26.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 18.863636363636363
Train_AverageReturn : 20.040000915527344
Train_StdReturn : 3.889524459838867
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.04
Actor Loss : 1.258840799331665
Train_EnvstepsSoFar : 1716069
TimeSinceStart : 1244.4804904460907
Done logging...



********** Iteration 428 ************

Collecting data for eval...
Eval_AverageReturn : 20.200000762939453
Eval_StdReturn : 3.749666690826416
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.2
Train_AverageReturn : 20.165828704833984
Train_StdReturn : 3.897897720336914
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.165829145728644
Actor Loss : 1.9508659839630127
Train_EnvstepsSoFar : 1720082
TimeSinceStart : 1246.944828748703
Done logging...



********** Iteration 429 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 3.8245913982391357
Eval_MaxReturn : 27.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 20.247474670410156
Train_StdReturn : 4.086732864379883
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.247474747474747
Actor Loss : 3.1180968284606934
Train_EnvstepsSoFar : 1724091
TimeSinceStart : 1249.4189853668213
Done logging...



********** Iteration 430 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 3.8919789791107178
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 20.304569244384766
Train_StdReturn : 3.9021835327148438
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.304568527918782
Actor Loss : 1.98042631149292
Train_EnvstepsSoFar : 1728091
TimeSinceStart : 1252.6008064746857
Done logging...



********** Iteration 431 ************

Collecting data for eval...
Eval_AverageReturn : 19.14285659790039
Eval_StdReturn : 3.783242702484131
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.142857142857142
Train_AverageReturn : 20.145729064941406
Train_StdReturn : 3.5107691287994385
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.14572864321608
Actor Loss : 2.791423797607422
Train_EnvstepsSoFar : 1732100
TimeSinceStart : 1258.345297574997
Done logging...



********** Iteration 432 ************

Collecting data for eval...
Eval_AverageReturn : 20.700000762939453
Eval_StdReturn : 4.1243181228637695
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.7
Train_AverageReturn : 20.287878036499023
Train_StdReturn : 4.02805233001709
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.28787878787879
Actor Loss : 3.386101007461548
Train_EnvstepsSoFar : 1736117
TimeSinceStart : 1260.8204746246338
Done logging...



********** Iteration 433 ************

Collecting data for eval...
Eval_AverageReturn : 19.4761905670166
Eval_StdReturn : 3.3893253803253174
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.476190476190474
Train_AverageReturn : 21.078947067260742
Train_StdReturn : 4.424700736999512
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.07894736842105
Actor Loss : 3.880871057510376
Train_EnvstepsSoFar : 1740122
TimeSinceStart : 1263.277884721756
Done logging...



********** Iteration 434 ************

Collecting data for eval...
Eval_AverageReturn : 19.095237731933594
Eval_StdReturn : 3.890216827392578
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.095238095238095
Train_AverageReturn : 20.711339950561523
Train_StdReturn : 4.1242523193359375
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.711340206185568
Actor Loss : 2.2716755867004395
Train_EnvstepsSoFar : 1744140
TimeSinceStart : 1266.8036456108093
Done logging...



********** Iteration 435 ************

Collecting data for eval...
Eval_AverageReturn : 20.047618865966797
Eval_StdReturn : 3.670684337615967
Eval_MaxReturn : 25.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.047619047619047
Train_AverageReturn : 20.58461570739746
Train_StdReturn : 4.087098598480225
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.584615384615386
Actor Loss : 5.620035171508789
Train_EnvstepsSoFar : 1748154
TimeSinceStart : 1269.272982597351
Done logging...



********** Iteration 436 ************

Collecting data for eval...
Eval_AverageReturn : 21.3157901763916
Eval_StdReturn : 3.784353494644165
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.31578947368421
Train_AverageReturn : 20.22222137451172
Train_StdReturn : 4.003925800323486
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.22222222222222
Actor Loss : 2.6487982273101807
Train_EnvstepsSoFar : 1752158
TimeSinceStart : 1271.7753684520721
Done logging...



********** Iteration 437 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 4.554118633270264
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.474489212036133
Train_StdReturn : 3.891954183578491
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.474489795918366
Actor Loss : 2.12559175491333
Train_EnvstepsSoFar : 1756171
TimeSinceStart : 1274.3099365234375
Done logging...



********** Iteration 438 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 4.459540367126465
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 20.247474670410156
Train_StdReturn : 3.848700523376465
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.247474747474747
Actor Loss : 3.49475359916687
Train_EnvstepsSoFar : 1760180
TimeSinceStart : 1277.6067447662354
Done logging...



********** Iteration 439 ************

Collecting data for eval...
Eval_AverageReturn : 20.799999237060547
Eval_StdReturn : 4.057092666625977
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.8
Train_AverageReturn : 20.777202606201172
Train_StdReturn : 4.13340950012207
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.77720207253886
Actor Loss : 3.337691068649292
Train_EnvstepsSoFar : 1764190
TimeSinceStart : 1280.550534248352
Done logging...



********** Iteration 440 ************

Collecting data for eval...
Eval_AverageReturn : 21.049999237060547
Eval_StdReturn : 5.31483793258667
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.05
Train_AverageReturn : 19.753694534301758
Train_StdReturn : 3.835076093673706
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.753694581280786
Actor Loss : 2.810384750366211
Train_EnvstepsSoFar : 1768200
TimeSinceStart : 1283.040676355362
Done logging...



********** Iteration 441 ************

Collecting data for eval...
Eval_AverageReturn : 21.210525512695312
Eval_StdReturn : 4.685688495635986
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.210526315789473
Train_AverageReturn : 20.155778884887695
Train_StdReturn : 4.236815929412842
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.155778894472363
Actor Loss : 3.7051315307617188
Train_EnvstepsSoFar : 1772211
TimeSinceStart : 1286.0775790214539
Done logging...



********** Iteration 442 ************

Collecting data for eval...
Eval_AverageReturn : 21.210525512695312
Eval_StdReturn : 3.9944558143615723
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.210526315789473
Train_AverageReturn : 20.85416603088379
Train_StdReturn : 4.143215179443359
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.854166666666668
Actor Loss : 2.6339335441589355
Train_EnvstepsSoFar : 1776215
TimeSinceStart : 1288.750487089157
Done logging...



********** Iteration 443 ************

Collecting data for eval...
Eval_AverageReturn : 20.238094329833984
Eval_StdReturn : 3.828523874282837
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.238095238095237
Train_AverageReturn : 20.58461570739746
Train_StdReturn : 3.9725687503814697
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.584615384615386
Actor Loss : 2.1183836460113525
Train_EnvstepsSoFar : 1780229
TimeSinceStart : 1291.2267620563507
Done logging...



********** Iteration 444 ************

Collecting data for eval...
Eval_AverageReturn : 21.149999618530273
Eval_StdReturn : 3.7586567401885986
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.15
Train_AverageReturn : 20.639175415039062
Train_StdReturn : 4.250373840332031
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.63917525773196
Actor Loss : 5.888431549072266
Train_EnvstepsSoFar : 1784233
TimeSinceStart : 1293.7668750286102
Done logging...



********** Iteration 445 ************

Collecting data for eval...
Eval_AverageReturn : 21.421052932739258
Eval_StdReturn : 4.693957805633545
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.42105263157895
Train_AverageReturn : 20.385786056518555
Train_StdReturn : 3.8583288192749023
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.385786802030456
Actor Loss : 2.9880871772766113
Train_EnvstepsSoFar : 1788249
TimeSinceStart : 1296.2306244373322
Done logging...



********** Iteration 446 ************

Collecting data for eval...
Eval_AverageReturn : 21.157894134521484
Eval_StdReturn : 4.738011360168457
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.157894736842106
Train_AverageReturn : 20.375635147094727
Train_StdReturn : 4.2043023109436035
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.375634517766496
Actor Loss : 4.10162353515625
Train_EnvstepsSoFar : 1792263
TimeSinceStart : 1298.7102794647217
Done logging...



********** Iteration 447 ************

Collecting data for eval...
Eval_AverageReturn : 20.14285659790039
Eval_StdReturn : 4.693315505981445
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.142857142857142
Train_AverageReturn : 20.05500030517578
Train_StdReturn : 3.918159246444702
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.055
Actor Loss : 2.3889331817626953
Train_EnvstepsSoFar : 1796274
TimeSinceStart : 1301.1831634044647
Done logging...



********** Iteration 448 ************

Collecting data for eval...
Eval_AverageReturn : 19.428571701049805
Eval_StdReturn : 3.5128531455993652
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.428571428571427
Train_AverageReturn : 20.395938873291016
Train_StdReturn : 4.110847473144531
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.395939086294415
Actor Loss : 3.6072232723236084
Train_EnvstepsSoFar : 1800292
TimeSinceStart : 1303.710658788681
Done logging...



********** Iteration 449 ************

Collecting data for eval...
Eval_AverageReturn : 20.149999618530273
Eval_StdReturn : 4.809106349945068
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.15
Train_AverageReturn : 20.31818199157715
Train_StdReturn : 3.990490436553955
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.318181818181817
Actor Loss : 3.7567977905273438
Train_EnvstepsSoFar : 1804315
TimeSinceStart : 1306.2689790725708
Done logging...



********** Iteration 450 ************

Collecting data for eval...
Eval_AverageReturn : 19.4761905670166
Eval_StdReturn : 4.204521656036377
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.476190476190474
Train_AverageReturn : 20.084999084472656
Train_StdReturn : 4.013449192047119
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.085
Actor Loss : 3.997002124786377
Train_EnvstepsSoFar : 1808332
TimeSinceStart : 1308.8081378936768
Done logging...



********** Iteration 451 ************

Collecting data for eval...
Eval_AverageReturn : 19.14285659790039
Eval_StdReturn : 3.2991445064544678
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.142857142857142
Train_AverageReturn : 20.459182739257812
Train_StdReturn : 4.2080302238464355
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.459183673469386
Actor Loss : 1.97893226146698
Train_EnvstepsSoFar : 1812342
TimeSinceStart : 1311.7353374958038
Done logging...



********** Iteration 452 ************

Collecting data for eval...
Eval_AverageReturn : 20.850000381469727
Eval_StdReturn : 4.32752799987793
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.85
Train_AverageReturn : 20.4489803314209
Train_StdReturn : 4.135763645172119
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.448979591836736
Actor Loss : 3.371857166290283
Train_EnvstepsSoFar : 1816350
TimeSinceStart : 1314.86625623703
Done logging...



********** Iteration 453 ************

Collecting data for eval...
Eval_AverageReturn : 19.238094329833984
Eval_StdReturn : 3.974978446960449
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.238095238095237
Train_AverageReturn : 20.217172622680664
Train_StdReturn : 4.127795219421387
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.217171717171716
Actor Loss : 3.4185397624969482
Train_EnvstepsSoFar : 1820353
TimeSinceStart : 1318.1969528198242
Done logging...



********** Iteration 454 ************

Collecting data for eval...
Eval_AverageReturn : 19.761905670166016
Eval_StdReturn : 2.61688232421875
Eval_MaxReturn : 26.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 19.761904761904763
Train_AverageReturn : 20.324872970581055
Train_StdReturn : 4.018490314483643
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.3248730964467
Actor Loss : 2.419321060180664
Train_EnvstepsSoFar : 1824357
TimeSinceStart : 1320.9928131103516
Done logging...



********** Iteration 455 ************

Collecting data for eval...
Eval_AverageReturn : 18.727272033691406
Eval_StdReturn : 3.632952928543091
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 18.727272727272727
Train_AverageReturn : 20.615385055541992
Train_StdReturn : 4.115108966827393
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.615384615384617
Actor Loss : 3.497929096221924
Train_EnvstepsSoFar : 1828377
TimeSinceStart : 1324.3426864147186
Done logging...



********** Iteration 456 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 3.8141188621520996
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 20.558975219726562
Train_StdReturn : 3.8524532318115234
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.55897435897436
Actor Loss : 2.4141721725463867
Train_EnvstepsSoFar : 1832386
TimeSinceStart : 1327.3664090633392
Done logging...



********** Iteration 457 ************

Collecting data for eval...
Eval_AverageReturn : 20.600000381469727
Eval_StdReturn : 3.66606068611145
Eval_MaxReturn : 28.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.6
Train_AverageReturn : 20.574359893798828
Train_StdReturn : 4.081020355224609
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.574358974358976
Actor Loss : 3.5675759315490723
Train_EnvstepsSoFar : 1836398
TimeSinceStart : 1330.6536672115326
Done logging...



********** Iteration 458 ************

Collecting data for eval...
Eval_AverageReturn : 21.3157901763916
Eval_StdReturn : 4.899544715881348
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.31578947368421
Train_AverageReturn : 20.43877601623535
Train_StdReturn : 4.048346519470215
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.43877551020408
Actor Loss : 2.636730909347534
Train_EnvstepsSoFar : 1840404
TimeSinceStart : 1333.656095981598
Done logging...



********** Iteration 459 ************

Collecting data for eval...
Eval_AverageReturn : 21.473684310913086
Eval_StdReturn : 4.004844665527344
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.473684210526315
Train_AverageReturn : 20.564102172851562
Train_StdReturn : 4.329948425292969
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.564102564102566
Actor Loss : 2.381101608276367
Train_EnvstepsSoFar : 1844414
TimeSinceStart : 1336.5904159545898
Done logging...



********** Iteration 460 ************

Collecting data for eval...
Eval_AverageReturn : 22.27777862548828
Eval_StdReturn : 4.531440258026123
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 22.27777777777778
Train_AverageReturn : 21.00523567199707
Train_StdReturn : 4.130713939666748
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.005235602094242
Actor Loss : 2.5283043384552
Train_EnvstepsSoFar : 1848426
TimeSinceStart : 1339.402438402176
Done logging...



********** Iteration 461 ************

Collecting data for eval...
Eval_AverageReturn : 20.700000762939453
Eval_StdReturn : 2.984962224960327
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.7
Train_AverageReturn : 20.30964469909668
Train_StdReturn : 3.91412353515625
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.309644670050762
Actor Loss : 2.323665142059326
Train_EnvstepsSoFar : 1852427
TimeSinceStart : 1342.7369327545166
Done logging...



********** Iteration 462 ************

Collecting data for eval...
Eval_AverageReturn : 20.649999618530273
Eval_StdReturn : 3.3507461547851562
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.65
Train_AverageReturn : 20.211055755615234
Train_StdReturn : 4.081540584564209
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.21105527638191
Actor Loss : 2.1547024250030518
Train_EnvstepsSoFar : 1856449
TimeSinceStart : 1345.6449964046478
Done logging...



********** Iteration 463 ************

Collecting data for eval...
Eval_AverageReturn : 21.3157901763916
Eval_StdReturn : 3.961029052734375
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.31578947368421
Train_AverageReturn : 20.232322692871094
Train_StdReturn : 4.151981830596924
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.232323232323232
Actor Loss : 5.8323750495910645
Train_EnvstepsSoFar : 1860455
TimeSinceStart : 1348.891933441162
Done logging...



********** Iteration 464 ************

Collecting data for eval...
Eval_AverageReturn : 21.842105865478516
Eval_StdReturn : 4.659604072570801
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.842105263157894
Train_AverageReturn : 20.93229103088379
Train_StdReturn : 3.847428560256958
Train_MaxReturn : 31.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.932291666666668
Actor Loss : 3.4603843688964844
Train_EnvstepsSoFar : 1864474
TimeSinceStart : 1352.228043794632
Done logging...



********** Iteration 465 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 2.962348699569702
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 20.43877601623535
Train_StdReturn : 3.9937868118286133
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.43877551020408
Actor Loss : 2.436548948287964
Train_EnvstepsSoFar : 1868480
TimeSinceStart : 1354.981820821762
Done logging...



********** Iteration 466 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 4.25910758972168
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 21.285715103149414
Train_StdReturn : 4.189033031463623
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.285714285714285
Actor Loss : 2.495734691619873
Train_EnvstepsSoFar : 1872503
TimeSinceStart : 1357.529793024063
Done logging...



********** Iteration 467 ************

Collecting data for eval...
Eval_AverageReturn : 19.952381134033203
Eval_StdReturn : 3.884967088699341
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.952380952380953
Train_AverageReturn : 20.31818199157715
Train_StdReturn : 3.9536166191101074
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.318181818181817
Actor Loss : 1.9276224374771118
Train_EnvstepsSoFar : 1876526
TimeSinceStart : 1360.1380610466003
Done logging...



********** Iteration 468 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 4.4370598793029785
Eval_MaxReturn : 31.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 20.58461570739746
Train_StdReturn : 4.156769752502441
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.584615384615386
Actor Loss : 2.8075432777404785
Train_EnvstepsSoFar : 1880540
TimeSinceStart : 1362.6416149139404
Done logging...



********** Iteration 469 ************

Collecting data for eval...
Eval_AverageReturn : 20.200000762939453
Eval_StdReturn : 3.6000001430511475
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.2
Train_AverageReturn : 20.059999465942383
Train_StdReturn : 3.819214344024658
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.06
Actor Loss : 1.5099329948425293
Train_EnvstepsSoFar : 1884552
TimeSinceStart : 1365.1785793304443
Done logging...



********** Iteration 470 ************

Collecting data for eval...
Eval_AverageReturn : 21.149999618530273
Eval_StdReturn : 4.040729999542236
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.15
Train_AverageReturn : 20.010000228881836
Train_StdReturn : 3.9166183471679688
Train_MaxReturn : 29.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.01
Actor Loss : 1.1320818662643433
Train_EnvstepsSoFar : 1888554
TimeSinceStart : 1367.716572523117
Done logging...



********** Iteration 471 ************

Collecting data for eval...
Eval_AverageReturn : 20.399999618530273
Eval_StdReturn : 3.7868192195892334
Eval_MaxReturn : 28.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.4
Train_AverageReturn : 20.175878524780273
Train_StdReturn : 4.301948070526123
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.175879396984925
Actor Loss : 3.8264362812042236
Train_EnvstepsSoFar : 1892569
TimeSinceStart : 1370.2237346172333
Done logging...



********** Iteration 472 ************

Collecting data for eval...
Eval_AverageReturn : 21.6842098236084
Eval_StdReturn : 3.7982356548309326
Eval_MaxReturn : 29.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 21.68421052631579
Train_AverageReturn : 20.2979793548584
Train_StdReturn : 4.072213649749756
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.2979797979798
Actor Loss : 3.776489734649658
Train_EnvstepsSoFar : 1896588
TimeSinceStart : 1375.1165752410889
Done logging...



********** Iteration 473 ************

Collecting data for eval...
Eval_AverageReturn : 20.75
Eval_StdReturn : 3.8584322929382324
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.75
Train_AverageReturn : 20.654638290405273
Train_StdReturn : 3.85955810546875
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.65463917525773
Actor Loss : 2.344587802886963
Train_EnvstepsSoFar : 1900595
TimeSinceStart : 1377.6791353225708
Done logging...



********** Iteration 474 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 4.57886266708374
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 20.030000686645508
Train_StdReturn : 3.935619354248047
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.03
Actor Loss : 2.6136417388916016
Train_EnvstepsSoFar : 1904601
TimeSinceStart : 1380.213514328003
Done logging...



********** Iteration 475 ************

Collecting data for eval...
Eval_AverageReturn : 21.3157901763916
Eval_StdReturn : 4.218413829803467
Eval_MaxReturn : 30.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.31578947368421
Train_AverageReturn : 20.96354103088379
Train_StdReturn : 4.352169513702393
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.963541666666668
Actor Loss : 2.9122984409332275
Train_EnvstepsSoFar : 1908626
TimeSinceStart : 1382.695951461792
Done logging...



********** Iteration 476 ************

Collecting data for eval...
Eval_AverageReturn : 19.761905670166016
Eval_StdReturn : 3.5038042068481445
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.761904761904763
Train_AverageReturn : 20.345178604125977
Train_StdReturn : 4.074513912200928
Train_MaxReturn : 30.0
Train_MinReturn : 15.0
Train_AverageEpLen : 20.34517766497462
Actor Loss : 2.310884475708008
Train_EnvstepsSoFar : 1912634
TimeSinceStart : 1385.4693706035614
Done logging...



********** Iteration 477 ************

Collecting data for eval...
Eval_AverageReturn : 19.047618865966797
Eval_StdReturn : 3.644646406173706
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.047619047619047
Train_AverageReturn : 20.787565231323242
Train_StdReturn : 4.4595417976379395
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.787564766839377
Actor Loss : 2.6171188354492188
Train_EnvstepsSoFar : 1916646
TimeSinceStart : 1387.9463937282562
Done logging...



********** Iteration 478 ************

Collecting data for eval...
Eval_AverageReturn : 19.66666603088379
Eval_StdReturn : 3.5231661796569824
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.666666666666668
Train_AverageReturn : 21.089473724365234
Train_StdReturn : 4.20117712020874
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.089473684210525
Actor Loss : 2.6682636737823486
Train_EnvstepsSoFar : 1920653
TimeSinceStart : 1390.4885022640228
Done logging...



********** Iteration 479 ************

Collecting data for eval...
Eval_AverageReturn : 18.590909957885742
Eval_StdReturn : 3.6138508319854736
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 18.59090909090909
Train_AverageReturn : 20.742267608642578
Train_StdReturn : 4.172266006469727
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.742268041237114
Actor Loss : 2.632089614868164
Train_EnvstepsSoFar : 1924677
TimeSinceStart : 1393.034200668335
Done logging...



********** Iteration 480 ************

Collecting data for eval...
Eval_AverageReturn : 20.25
Eval_StdReturn : 4.3344550132751465
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.25
Train_AverageReturn : 20.510204315185547
Train_StdReturn : 3.991687536239624
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.510204081632654
Actor Loss : 2.108783006668091
Train_EnvstepsSoFar : 1928697
TimeSinceStart : 1396.6561739444733
Done logging...



********** Iteration 481 ************

Collecting data for eval...
Eval_AverageReturn : 20.799999237060547
Eval_StdReturn : 4.545327186584473
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.8
Train_AverageReturn : 21.105262756347656
Train_StdReturn : 4.237610340118408
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.105263157894736
Actor Loss : 3.7390451431274414
Train_EnvstepsSoFar : 1932707
TimeSinceStart : 1399.1440680027008
Done logging...



********** Iteration 482 ************

Collecting data for eval...
Eval_AverageReturn : 22.22222137451172
Eval_StdReturn : 3.895232915878296
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 22.22222222222222
Train_AverageReturn : 20.175878524780273
Train_StdReturn : 3.7556283473968506
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.175879396984925
Actor Loss : 2.115060329437256
Train_EnvstepsSoFar : 1936722
TimeSinceStart : 1401.733149766922
Done logging...



********** Iteration 483 ************

Collecting data for eval...
Eval_AverageReturn : 21.263158798217773
Eval_StdReturn : 3.6683871746063232
Eval_MaxReturn : 30.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.263157894736842
Train_AverageReturn : 19.985074996948242
Train_StdReturn : 4.021679401397705
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.98507462686567
Actor Loss : 1.9477336406707764
Train_EnvstepsSoFar : 1940739
TimeSinceStart : 1404.2735350131989
Done logging...



********** Iteration 484 ************

Collecting data for eval...
Eval_AverageReturn : 21.100000381469727
Eval_StdReturn : 4.537620544433594
Eval_MaxReturn : 31.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.1
Train_AverageReturn : 20.489795684814453
Train_StdReturn : 4.140997409820557
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.489795918367346
Actor Loss : 2.9379963874816895
Train_EnvstepsSoFar : 1944755
TimeSinceStart : 1406.800433397293
Done logging...



********** Iteration 485 ************

Collecting data for eval...
Eval_AverageReturn : 19.095237731933594
Eval_StdReturn : 3.6762399673461914
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.095238095238095
Train_AverageReturn : 20.73711395263672
Train_StdReturn : 4.131593704223633
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.737113402061855
Actor Loss : 2.2704129219055176
Train_EnvstepsSoFar : 1948778
TimeSinceStart : 1409.3406960964203
Done logging...



********** Iteration 486 ************

Collecting data for eval...
Eval_AverageReturn : 18.68181800842285
Eval_StdReturn : 3.2105844020843506
Eval_MaxReturn : 25.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 18.681818181818183
Train_AverageReturn : 19.915422439575195
Train_StdReturn : 4.085870742797852
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.915422885572138
Actor Loss : 3.257049560546875
Train_EnvstepsSoFar : 1952781
TimeSinceStart : 1411.8897948265076
Done logging...



********** Iteration 487 ************

Collecting data for eval...
Eval_AverageReturn : 19.714284896850586
Eval_StdReturn : 4.0490193367004395
Eval_MaxReturn : 27.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.714285714285715
Train_AverageReturn : 20.579486846923828
Train_StdReturn : 4.154403209686279
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.57948717948718
Actor Loss : 2.776597499847412
Train_EnvstepsSoFar : 1956794
TimeSinceStart : 1414.4279494285583
Done logging...



********** Iteration 488 ************

Collecting data for eval...
Eval_AverageReturn : 19.809524536132812
Eval_StdReturn : 3.43121600151062
Eval_MaxReturn : 26.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.80952380952381
Train_AverageReturn : 20.433673858642578
Train_StdReturn : 4.31663703918457
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.433673469387756
Actor Loss : 2.082871198654175
Train_EnvstepsSoFar : 1960799
TimeSinceStart : 1416.9748303890228
Done logging...



********** Iteration 489 ************

Collecting data for eval...
Eval_AverageReturn : 19.190475463867188
Eval_StdReturn : 3.445066452026367
Eval_MaxReturn : 27.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 19.19047619047619
Train_AverageReturn : 20.27777862548828
Train_StdReturn : 3.956660747528076
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.27777777777778
Actor Loss : 2.998331308364868
Train_EnvstepsSoFar : 1964814
TimeSinceStart : 1419.5212993621826
Done logging...



********** Iteration 490 ************

Collecting data for eval...
Eval_AverageReturn : 20.450000762939453
Eval_StdReturn : 3.5982635021209717
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 20.45
Train_AverageReturn : 20.664947509765625
Train_StdReturn : 4.243382453918457
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.664948453608247
Actor Loss : 2.9666194915771484
Train_EnvstepsSoFar : 1968823
TimeSinceStart : 1422.0064084529877
Done logging...



********** Iteration 491 ************

Collecting data for eval...
Eval_AverageReturn : 19.5238094329834
Eval_StdReturn : 3.216313123703003
Eval_MaxReturn : 25.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 19.523809523809526
Train_AverageReturn : 19.79310417175293
Train_StdReturn : 4.090907096862793
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 19.79310344827586
Actor Loss : 3.8006222248077393
Train_EnvstepsSoFar : 1972841
TimeSinceStart : 1424.5134460926056
Done logging...



********** Iteration 492 ************

Collecting data for eval...
Eval_AverageReturn : 18.363636016845703
Eval_StdReturn : 3.1844143867492676
Eval_MaxReturn : 26.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 18.363636363636363
Train_AverageReturn : 20.41116714477539
Train_StdReturn : 3.638273239135742
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.411167512690355
Actor Loss : 2.447988748550415
Train_EnvstepsSoFar : 1976862
TimeSinceStart : 1427.0354754924774
Done logging...



********** Iteration 493 ************

Collecting data for eval...
Eval_AverageReturn : 21.105262756347656
Eval_StdReturn : 3.9854307174682617
Eval_MaxReturn : 28.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.105263157894736
Train_AverageReturn : 20.543590545654297
Train_StdReturn : 4.1635661125183105
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.543589743589745
Actor Loss : 2.055037498474121
Train_EnvstepsSoFar : 1980868
TimeSinceStart : 1429.5750303268433
Done logging...



********** Iteration 494 ************

Collecting data for eval...
Eval_AverageReturn : 20.200000762939453
Eval_StdReturn : 3.7762415409088135
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 20.2
Train_AverageReturn : 21.01570701599121
Train_StdReturn : 4.215995788574219
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.015706806282722
Actor Loss : 3.2780027389526367
Train_EnvstepsSoFar : 1984882
TimeSinceStart : 1432.1367123126984
Done logging...



********** Iteration 495 ************

Collecting data for eval...
Eval_AverageReturn : 20.299999237060547
Eval_StdReturn : 3.5930490493774414
Eval_MaxReturn : 28.0
Eval_MinReturn : 17.0
Eval_AverageEpLen : 20.3
Train_AverageReturn : 20.385786056518555
Train_StdReturn : 4.1376566886901855
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.385786802030456
Actor Loss : 2.7984609603881836
Train_EnvstepsSoFar : 1988898
TimeSinceStart : 1434.6864619255066
Done logging...



********** Iteration 496 ************

Collecting data for eval...
Eval_AverageReturn : 18.590909957885742
Eval_StdReturn : 2.979613780975342
Eval_MaxReturn : 26.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 18.59090909090909
Train_AverageReturn : 20.512821197509766
Train_StdReturn : 4.048879623413086
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.512820512820515
Actor Loss : 2.802255630493164
Train_EnvstepsSoFar : 1992898
TimeSinceStart : 1438.924367427826
Done logging...



********** Iteration 497 ************

Collecting data for eval...
Eval_AverageReturn : 21.736841201782227
Eval_StdReturn : 4.446667671203613
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 21.736842105263158
Train_AverageReturn : 20.135679244995117
Train_StdReturn : 4.1451897621154785
Train_MaxReturn : 32.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.1356783919598
Actor Loss : 3.9611003398895264
Train_EnvstepsSoFar : 1996905
TimeSinceStart : 1441.3868021965027
Done logging...



********** Iteration 498 ************

Collecting data for eval...
Eval_AverageReturn : 21.105262756347656
Eval_StdReturn : 4.3636627197265625
Eval_MaxReturn : 29.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 21.105263157894736
Train_AverageReturn : 20.2020206451416
Train_StdReturn : 4.228282928466797
Train_MaxReturn : 30.0
Train_MinReturn : 14.0
Train_AverageEpLen : 20.2020202020202
Actor Loss : 2.8789758682250977
Train_EnvstepsSoFar : 2000905
TimeSinceStart : 1443.9051070213318
Done logging...



********** Iteration 499 ************

Collecting data for eval...
Eval_AverageReturn : 20.549999237060547
Eval_StdReturn : 4.295055389404297
Eval_MaxReturn : 29.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 20.55
Train_AverageReturn : 21.238094329833984
Train_StdReturn : 4.153334617614746
Train_MaxReturn : 31.0
Train_MinReturn : 14.0
Train_AverageEpLen : 21.238095238095237
Actor Loss : 2.309095859527588
Train_EnvstepsSoFar : 2004919
TimeSinceStart : 1446.4260540008545
Done logging...


########################
logging outputs to  /home/jaehyun-jeong/UCBerkeley_cs285/hw2/cs285/scripts/../../data/q2_pg_cartpole_lb_na_CartPole-v0_17-08-2024_02-21-44
########################
Using GPU id 0
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/envs/registration.py:593: UserWarning: [33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.[0m
  logger.warn(
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/core.py:317: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(

********** Iteration 0 ************
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/tensorboardX/summary.py:153: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
  scalar = float(scalar)
Eval_StdReturn : 0.8769631385803223
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 36.581817626953125
Train_StdReturn : 14.573563575744629
Train_MaxReturn : 97.0
Train_MinReturn : 20.0
Train_AverageEpLen : 36.58181818181818
Actor Loss : -0.1208038330078125
Train_EnvstepsSoFar : 4024
TimeSinceStart : 3.1096339225769043
Initial_DataCollection_AverageReturn : 36.581817626953125
Done logging...



********** Iteration 1 ************

Collecting data for eval...
Eval_AverageReturn : 21.894737243652344
Eval_StdReturn : 4.241334915161133
Eval_MaxReturn : 29.0
Eval_MinReturn : 16.0
Eval_AverageEpLen : 21.894736842105264
Train_AverageReturn : 9.384075164794922
Train_StdReturn : 0.8724399209022522
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.38407494145199
Actor Loss : 31.738401412963867
Train_EnvstepsSoFar : 8031
TimeSinceStart : 5.76830530166626
Done logging...



********** Iteration 2 ************

Collecting data for eval...
Eval_AverageReturn : 52.5
Eval_StdReturn : 16.286497116088867
Eval_MaxReturn : 89.0
Eval_MinReturn : 39.0
Eval_AverageEpLen : 52.5
Train_AverageReturn : 22.327777862548828
Train_StdReturn : 4.2880072593688965
Train_MaxReturn : 32.0
Train_MinReturn : 16.0
Train_AverageEpLen : 22.32777777777778
Actor Loss : 1.8608932495117188
Train_EnvstepsSoFar : 12050
TimeSinceStart : 8.275452852249146
Done logging...



********** Iteration 3 ************

Collecting data for eval...
Eval_AverageReturn : 88.5999984741211
Eval_StdReturn : 34.971988677978516
Eval_MaxReturn : 152.0
Eval_MinReturn : 56.0
Eval_AverageEpLen : 88.6
Train_AverageReturn : 65.67213439941406
Train_StdReturn : 22.391977310180664
Train_MaxReturn : 173.0
Train_MinReturn : 42.0
Train_AverageEpLen : 65.67213114754098
Actor Loss : 0.4041023254394531
Train_EnvstepsSoFar : 16056
TimeSinceStart : 10.69095492362976
Done logging...



********** Iteration 4 ************

Collecting data for eval...
Eval_AverageReturn : 58.28571319580078
Eval_StdReturn : 10.402119636535645
Eval_MaxReturn : 73.0
Eval_MinReturn : 46.0
Eval_AverageEpLen : 58.285714285714285
Train_AverageReturn : 104.53845977783203
Train_StdReturn : 45.62941360473633
Train_MaxReturn : 200.0
Train_MinReturn : 52.0
Train_AverageEpLen : 104.53846153846153
Actor Loss : -0.13002777099609375
Train_EnvstepsSoFar : 20133
TimeSinceStart : 13.827023267745972
Done logging...



********** Iteration 5 ************

Collecting data for eval...
Eval_AverageReturn : 45.29999923706055
Eval_StdReturn : 14.567429542541504
Eval_MaxReturn : 78.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 45.3
Train_AverageReturn : 63.60317611694336
Train_StdReturn : 19.85306167602539
Train_MaxReturn : 120.0
Train_MinReturn : 41.0
Train_AverageEpLen : 63.6031746031746
Actor Loss : -2.58154296875
Train_EnvstepsSoFar : 24140
TimeSinceStart : 16.747446298599243
Done logging...



********** Iteration 6 ************

Collecting data for eval...
Eval_AverageReturn : 41.29999923706055
Eval_StdReturn : 10.218120574951172
Eval_MaxReturn : 58.0
Eval_MinReturn : 26.0
Eval_AverageEpLen : 41.3
Train_AverageReturn : 49.5
Train_StdReturn : 20.61508560180664
Train_MaxReturn : 112.0
Train_MinReturn : 28.0
Train_AverageEpLen : 49.5
Actor Loss : -0.40143585205078125
Train_EnvstepsSoFar : 28199
TimeSinceStart : 19.219359159469604
Done logging...



********** Iteration 7 ************

Collecting data for eval...
Eval_AverageReturn : 38.0
Eval_StdReturn : 7.862453937530518
Eval_MaxReturn : 52.0
Eval_MinReturn : 26.0
Eval_AverageEpLen : 38.0
Train_AverageReturn : 40.979591369628906
Train_StdReturn : 11.907792091369629
Train_MaxReturn : 69.0
Train_MinReturn : 25.0
Train_AverageEpLen : 40.97959183673469
Actor Loss : 1.9849281311035156
Train_EnvstepsSoFar : 32215
TimeSinceStart : 21.642972469329834
Done logging...



********** Iteration 8 ************

Collecting data for eval...
Eval_AverageReturn : 34.83333206176758
Eval_StdReturn : 7.8616509437561035
Eval_MaxReturn : 48.0
Eval_MinReturn : 24.0
Eval_AverageEpLen : 34.833333333333336
Train_AverageReturn : 36.32432556152344
Train_StdReturn : 8.259488105773926
Train_MaxReturn : 61.0
Train_MinReturn : 24.0
Train_AverageEpLen : 36.32432432432432
Actor Loss : 3.0110950469970703
Train_EnvstepsSoFar : 36247
TimeSinceStart : 24.066375732421875
Done logging...



********** Iteration 9 ************

Collecting data for eval...
Eval_AverageReturn : 37.181819915771484
Eval_StdReturn : 4.4275617599487305
Eval_MaxReturn : 45.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 37.18181818181818
Train_AverageReturn : 35.92856979370117
Train_StdReturn : 7.618954658508301
Train_MaxReturn : 58.0
Train_MinReturn : 23.0
Train_AverageEpLen : 35.92857142857143
Actor Loss : 2.74713134765625
Train_EnvstepsSoFar : 40271
TimeSinceStart : 26.472535133361816
Done logging...



********** Iteration 10 ************

Collecting data for eval...
Eval_AverageReturn : 37.818180084228516
Eval_StdReturn : 5.765385627746582
Eval_MaxReturn : 46.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 37.81818181818182
Train_AverageReturn : 33.70588302612305
Train_StdReturn : 7.20218563079834
Train_MaxReturn : 55.0
Train_MinReturn : 23.0
Train_AverageEpLen : 33.705882352941174
Actor Loss : 2.69482421875
Train_EnvstepsSoFar : 44282
TimeSinceStart : 28.87774968147278
Done logging...



********** Iteration 11 ************

Collecting data for eval...
Eval_AverageReturn : 37.54545593261719
Eval_StdReturn : 7.088577747344971
Eval_MaxReturn : 48.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 37.54545454545455
Train_AverageReturn : 34.482757568359375
Train_StdReturn : 7.278312683105469
Train_MaxReturn : 55.0
Train_MinReturn : 23.0
Train_AverageEpLen : 34.48275862068966
Actor Loss : 4.09017276763916
Train_EnvstepsSoFar : 48282
TimeSinceStart : 31.288590908050537
Done logging...



********** Iteration 12 ************

Collecting data for eval...
Eval_AverageReturn : 37.90909194946289
Eval_StdReturn : 9.346409797668457
Eval_MaxReturn : 52.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 37.90909090909091
Train_AverageReturn : 36.62727355957031
Train_StdReturn : 8.858338356018066
Train_MaxReturn : 60.0
Train_MinReturn : 23.0
Train_AverageEpLen : 36.627272727272725
Actor Loss : 3.3089065551757812
Train_EnvstepsSoFar : 52311
TimeSinceStart : 33.73854112625122
Done logging...



********** Iteration 13 ************

Collecting data for eval...
Eval_AverageReturn : 44.45454406738281
Eval_StdReturn : 20.042518615722656
Eval_MaxReturn : 90.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 44.45454545454545
Train_AverageReturn : 36.5
Train_StdReturn : 10.565595626831055
Train_MaxReturn : 72.0
Train_MinReturn : 23.0
Train_AverageEpLen : 36.5
Actor Loss : 3.1636734008789062
Train_EnvstepsSoFar : 56326
TimeSinceStart : 36.227200746536255
Done logging...



********** Iteration 14 ************

Collecting data for eval...
Eval_AverageReturn : 42.70000076293945
Eval_StdReturn : 20.34723663330078
Eval_MaxReturn : 101.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 42.7
Train_AverageReturn : 44.05434799194336
Train_StdReturn : 16.084941864013672
Train_MaxReturn : 92.0
Train_MinReturn : 25.0
Train_AverageEpLen : 44.05434782608695
Actor Loss : 1.4538288116455078
Train_EnvstepsSoFar : 60379
TimeSinceStart : 38.70225501060486
Done logging...



********** Iteration 15 ************

Collecting data for eval...
Eval_AverageReturn : 47.44444274902344
Eval_StdReturn : 16.43242835998535
Eval_MaxReturn : 79.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 47.44444444444444
Train_AverageReturn : 46.5
Train_StdReturn : 24.657655715942383
Train_MaxReturn : 168.0
Train_MinReturn : 26.0
Train_AverageEpLen : 46.5
Actor Loss : -5.640061855316162
Train_EnvstepsSoFar : 64471
TimeSinceStart : 41.46584129333496
Done logging...



********** Iteration 16 ************

Collecting data for eval...
Eval_AverageReturn : 49.66666793823242
Eval_StdReturn : 12.156388282775879
Eval_MaxReturn : 71.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 49.666666666666664
Train_AverageReturn : 50.23749923706055
Train_StdReturn : 18.769819259643555
Train_MaxReturn : 129.0
Train_MinReturn : 28.0
Train_AverageEpLen : 50.2375
Actor Loss : -9.975067138671875
Train_EnvstepsSoFar : 68490
TimeSinceStart : 43.96781349182129
Done logging...



********** Iteration 17 ************

Collecting data for eval...
Eval_AverageReturn : 46.77777862548828
Eval_StdReturn : 9.964133262634277
Eval_MaxReturn : 67.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 46.77777777777778
Train_AverageReturn : 49.085365295410156
Train_StdReturn : 13.978382110595703
Train_MaxReturn : 102.0
Train_MinReturn : 32.0
Train_AverageEpLen : 49.08536585365854
Actor Loss : -11.796356201171875
Train_EnvstepsSoFar : 72515
TimeSinceStart : 46.401625633239746
Done logging...



********** Iteration 18 ************

Collecting data for eval...
Eval_AverageReturn : 55.0
Eval_StdReturn : 13.304134368896484
Eval_MaxReturn : 72.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 55.0
Train_AverageReturn : 52.31168746948242
Train_StdReturn : 16.303340911865234
Train_MaxReturn : 105.0
Train_MinReturn : 30.0
Train_AverageEpLen : 52.311688311688314
Actor Loss : -13.156517028808594
Train_EnvstepsSoFar : 76543
TimeSinceStart : 48.82856822013855
Done logging...



********** Iteration 19 ************

Collecting data for eval...
Eval_AverageReturn : 44.099998474121094
Eval_StdReturn : 12.119818687438965
Eval_MaxReturn : 66.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 44.1
Train_AverageReturn : 51.94805145263672
Train_StdReturn : 16.867626190185547
Train_MaxReturn : 116.0
Train_MinReturn : 29.0
Train_AverageEpLen : 51.94805194805195
Actor Loss : -15.516777038574219
Train_EnvstepsSoFar : 80543
TimeSinceStart : 51.22607398033142
Done logging...



********** Iteration 20 ************

Collecting data for eval...
Eval_AverageReturn : 39.727272033691406
Eval_StdReturn : 3.7195041179656982
Eval_MaxReturn : 46.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 39.72727272727273
Train_AverageReturn : 50.4375
Train_StdReturn : 19.25282096862793
Train_MaxReturn : 126.0
Train_MinReturn : 28.0
Train_AverageEpLen : 50.4375
Actor Loss : -17.30652618408203
Train_EnvstepsSoFar : 84578
TimeSinceStart : 54.30973958969116
Done logging...



********** Iteration 21 ************

Collecting data for eval...
Eval_AverageReturn : 42.599998474121094
Eval_StdReturn : 12.02663803100586
Eval_MaxReturn : 72.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 42.6
Train_AverageReturn : 43.83695602416992
Train_StdReturn : 14.201406478881836
Train_MaxReturn : 97.0
Train_MinReturn : 27.0
Train_AverageEpLen : 43.83695652173913
Actor Loss : -16.09105682373047
Train_EnvstepsSoFar : 88611
TimeSinceStart : 56.752053022384644
Done logging...



********** Iteration 22 ************

Collecting data for eval...
Eval_AverageReturn : 44.099998474121094
Eval_StdReturn : 14.916098594665527
Eval_MaxReturn : 82.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 44.1
Train_AverageReturn : 47.670589447021484
Train_StdReturn : 22.83567237854004
Train_MaxReturn : 130.0
Train_MinReturn : 26.0
Train_AverageEpLen : 47.67058823529412
Actor Loss : -18.99476432800293
Train_EnvstepsSoFar : 92663
TimeSinceStart : 59.24774885177612
Done logging...



********** Iteration 23 ************

Collecting data for eval...
Eval_AverageReturn : 43.79999923706055
Eval_StdReturn : 27.282960891723633
Eval_MaxReturn : 110.0
Eval_MinReturn : 25.0
Eval_AverageEpLen : 43.8
Train_AverageReturn : 47.904762268066406
Train_StdReturn : 22.692886352539062
Train_MaxReturn : 117.0
Train_MinReturn : 23.0
Train_AverageEpLen : 47.904761904761905
Actor Loss : -9.238327026367188
Train_EnvstepsSoFar : 96687
TimeSinceStart : 61.701563358306885
Done logging...



********** Iteration 24 ************

Collecting data for eval...
Eval_AverageReturn : 53.77777862548828
Eval_StdReturn : 29.798500061035156
Eval_MaxReturn : 112.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 53.77777777777778
Train_AverageReturn : 42.421051025390625
Train_StdReturn : 18.269662857055664
Train_MaxReturn : 121.0
Train_MinReturn : 25.0
Train_AverageEpLen : 42.421052631578945
Actor Loss : -21.351417541503906
Train_EnvstepsSoFar : 100717
TimeSinceStart : 64.21361041069031
Done logging...



********** Iteration 25 ************

Collecting data for eval...
Eval_AverageReturn : 62.71428680419922
Eval_StdReturn : 30.202714920043945
Eval_MaxReturn : 113.0
Eval_MinReturn : 25.0
Eval_AverageEpLen : 62.714285714285715
Train_AverageReturn : 46.75581359863281
Train_StdReturn : 25.376209259033203
Train_MaxReturn : 141.0
Train_MinReturn : 23.0
Train_AverageEpLen : 46.75581395348837
Actor Loss : -17.030488967895508
Train_EnvstepsSoFar : 104738
TimeSinceStart : 66.67277431488037
Done logging...



********** Iteration 26 ************

Collecting data for eval...
Eval_AverageReturn : 40.5
Eval_StdReturn : 16.72273826599121
Eval_MaxReturn : 82.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 40.5
Train_AverageReturn : 42.18947219848633
Train_StdReturn : 18.096988677978516
Train_MaxReturn : 113.0
Train_MinReturn : 24.0
Train_AverageEpLen : 42.189473684210526
Actor Loss : -33.3997802734375
Train_EnvstepsSoFar : 108746
TimeSinceStart : 69.11686325073242
Done logging...



********** Iteration 27 ************

Collecting data for eval...
Eval_AverageReturn : 51.25
Eval_StdReturn : 20.6866512298584
Eval_MaxReturn : 90.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 51.25
Train_AverageReturn : 46.08045959472656
Train_StdReturn : 18.55728530883789
Train_MaxReturn : 110.0
Train_MinReturn : 24.0
Train_AverageEpLen : 46.08045977011494
Actor Loss : -36.520015716552734
Train_EnvstepsSoFar : 112755
TimeSinceStart : 71.582763671875
Done logging...



********** Iteration 28 ************

Collecting data for eval...
Eval_AverageReturn : 84.19999694824219
Eval_StdReturn : 15.223666191101074
Eval_MaxReturn : 107.0
Eval_MinReturn : 59.0
Eval_AverageEpLen : 84.2
Train_AverageReturn : 48.33734893798828
Train_StdReturn : 14.03719425201416
Train_MaxReturn : 95.0
Train_MinReturn : 26.0
Train_AverageEpLen : 48.33734939759036
Actor Loss : -38.144161224365234
Train_EnvstepsSoFar : 116767
TimeSinceStart : 74.03656888008118
Done logging...



********** Iteration 29 ************

Collecting data for eval...
Eval_AverageReturn : 64.0
Eval_StdReturn : 16.124515533447266
Eval_MaxReturn : 93.0
Eval_MinReturn : 43.0
Eval_AverageEpLen : 64.0
Train_AverageReturn : 61.04545593261719
Train_StdReturn : 23.728534698486328
Train_MaxReturn : 142.0
Train_MinReturn : 32.0
Train_AverageEpLen : 61.04545454545455
Actor Loss : -30.369338989257812
Train_EnvstepsSoFar : 120796
TimeSinceStart : 76.49697780609131
Done logging...



********** Iteration 30 ************

Collecting data for eval...
Eval_AverageReturn : 58.0
Eval_StdReturn : 12.359207153320312
Eval_MaxReturn : 77.0
Eval_MinReturn : 42.0
Eval_AverageEpLen : 58.0
Train_AverageReturn : 65.0
Train_StdReturn : 24.87492561340332
Train_MaxReturn : 139.0
Train_MinReturn : 33.0
Train_AverageEpLen : 65.0
Actor Loss : -19.894580841064453
Train_EnvstepsSoFar : 124891
TimeSinceStart : 78.99734711647034
Done logging...



********** Iteration 31 ************

Collecting data for eval...
Eval_AverageReturn : 61.14285659790039
Eval_StdReturn : 18.58900260925293
Eval_MaxReturn : 86.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 61.142857142857146
Train_AverageReturn : 60.787879943847656
Train_StdReturn : 20.747045516967773
Train_MaxReturn : 135.0
Train_MinReturn : 32.0
Train_AverageEpLen : 60.78787878787879
Actor Loss : -28.001846313476562
Train_EnvstepsSoFar : 128903
TimeSinceStart : 81.39250087738037
Done logging...



********** Iteration 32 ************

Collecting data for eval...
Eval_AverageReturn : 51.25
Eval_StdReturn : 14.60094165802002
Eval_MaxReturn : 76.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 51.25
Train_AverageReturn : 59.80596923828125
Train_StdReturn : 20.73589324951172
Train_MaxReturn : 124.0
Train_MinReturn : 35.0
Train_AverageEpLen : 59.80597014925373
Actor Loss : -33.811546325683594
Train_EnvstepsSoFar : 132910
TimeSinceStart : 84.78906607627869
Done logging...



********** Iteration 33 ************

Collecting data for eval...
Eval_AverageReturn : 40.20000076293945
Eval_StdReturn : 10.693923950195312
Eval_MaxReturn : 66.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 40.2
Train_AverageReturn : 54.10810852050781
Train_StdReturn : 17.707509994506836
Train_MaxReturn : 117.0
Train_MinReturn : 34.0
Train_AverageEpLen : 54.108108108108105
Actor Loss : -43.17668914794922
Train_EnvstepsSoFar : 136914
TimeSinceStart : 88.02725172042847
Done logging...



********** Iteration 34 ************

Collecting data for eval...
Eval_AverageReturn : 40.599998474121094
Eval_StdReturn : 25.016794204711914
Eval_MaxReturn : 113.0
Eval_MinReturn : 26.0
Eval_AverageEpLen : 40.6
Train_AverageReturn : 47.188236236572266
Train_StdReturn : 15.680256843566895
Train_MaxReturn : 108.0
Train_MinReturn : 26.0
Train_AverageEpLen : 47.188235294117646
Actor Loss : -62.84563446044922
Train_EnvstepsSoFar : 140925
TimeSinceStart : 90.50825905799866
Done logging...



********** Iteration 35 ************

Collecting data for eval...
Eval_AverageReturn : 33.91666793823242
Eval_StdReturn : 8.52895450592041
Eval_MaxReturn : 48.0
Eval_MinReturn : 23.0
Eval_AverageEpLen : 33.916666666666664
Train_AverageReturn : 42.2315788269043
Train_StdReturn : 19.142927169799805
Train_MaxReturn : 115.0
Train_MinReturn : 23.0
Train_AverageEpLen : 42.23157894736842
Actor Loss : -94.91388702392578
Train_EnvstepsSoFar : 144937
TimeSinceStart : 93.07055425643921
Done logging...



********** Iteration 36 ************

Collecting data for eval...
Eval_AverageReturn : 40.20000076293945
Eval_StdReturn : 16.141870498657227
Eval_MaxReturn : 71.0
Eval_MinReturn : 23.0
Eval_AverageEpLen : 40.2
Train_AverageReturn : 44.83516311645508
Train_StdReturn : 22.026588439941406
Train_MaxReturn : 116.0
Train_MinReturn : 20.0
Train_AverageEpLen : 44.83516483516483
Actor Loss : -115.16846466064453
Train_EnvstepsSoFar : 149017
TimeSinceStart : 95.54778409004211
Done logging...



********** Iteration 37 ************

Collecting data for eval...
Eval_AverageReturn : 35.91666793823242
Eval_StdReturn : 12.62575626373291
Eval_MaxReturn : 74.0
Eval_MinReturn : 25.0
Eval_AverageEpLen : 35.916666666666664
Train_AverageReturn : 41.04081726074219
Train_StdReturn : 17.142213821411133
Train_MaxReturn : 102.0
Train_MinReturn : 23.0
Train_AverageEpLen : 41.04081632653061
Actor Loss : -109.28620910644531
Train_EnvstepsSoFar : 153039
TimeSinceStart : 98.19562268257141
Done logging...



********** Iteration 38 ************

Collecting data for eval...
Eval_AverageReturn : 49.33333206176758
Eval_StdReturn : 9.752492904663086
Eval_MaxReturn : 65.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 49.333333333333336
Train_AverageReturn : 43.96703338623047
Train_StdReturn : 17.897417068481445
Train_MaxReturn : 93.0
Train_MinReturn : 23.0
Train_AverageEpLen : 43.967032967032964
Actor Loss : -123.93966674804688
Train_EnvstepsSoFar : 157040
TimeSinceStart : 100.62064480781555
Done logging...



********** Iteration 39 ************

Collecting data for eval...
Eval_AverageReturn : 52.0
Eval_StdReturn : 16.61324691772461
Eval_MaxReturn : 80.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 52.0
Train_AverageReturn : 52.48051834106445
Train_StdReturn : 16.03940773010254
Train_MaxReturn : 107.0
Train_MinReturn : 27.0
Train_AverageEpLen : 52.48051948051948
Actor Loss : -80.31951904296875
Train_EnvstepsSoFar : 161081
TimeSinceStart : 103.23294949531555
Done logging...



********** Iteration 40 ************

Collecting data for eval...
Eval_AverageReturn : 55.625
Eval_StdReturn : 14.704910278320312
Eval_MaxReturn : 75.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 55.625
Train_AverageReturn : 54.9315071105957
Train_StdReturn : 19.985151290893555
Train_MaxReturn : 128.0
Train_MinReturn : 29.0
Train_AverageEpLen : 54.93150684931507
Actor Loss : -81.90933227539062
Train_EnvstepsSoFar : 165091
TimeSinceStart : 106.67607975006104
Done logging...



********** Iteration 41 ************

Collecting data for eval...
Eval_AverageReturn : 47.55555725097656
Eval_StdReturn : 9.190709114074707
Eval_MaxReturn : 61.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 47.55555555555556
Train_AverageReturn : 54.253334045410156
Train_StdReturn : 16.39845085144043
Train_MaxReturn : 121.0
Train_MinReturn : 33.0
Train_AverageEpLen : 54.25333333333333
Actor Loss : -55.45917510986328
Train_EnvstepsSoFar : 169160
TimeSinceStart : 109.58563232421875
Done logging...



********** Iteration 42 ************

Collecting data for eval...
Eval_AverageReturn : 53.0
Eval_StdReturn : 13.610657691955566
Eval_MaxReturn : 78.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 53.0
Train_AverageReturn : 52.272727966308594
Train_StdReturn : 13.429600715637207
Train_MaxReturn : 95.0
Train_MinReturn : 32.0
Train_AverageEpLen : 52.27272727272727
Actor Loss : -19.445192337036133
Train_EnvstepsSoFar : 173185
TimeSinceStart : 112.01718044281006
Done logging...



********** Iteration 43 ************

Collecting data for eval...
Eval_AverageReturn : 42.20000076293945
Eval_StdReturn : 15.753094673156738
Eval_MaxReturn : 67.0
Eval_MinReturn : 22.0
Eval_AverageEpLen : 42.2
Train_AverageReturn : 54.77027130126953
Train_StdReturn : 17.584964752197266
Train_MaxReturn : 99.0
Train_MinReturn : 26.0
Train_AverageEpLen : 54.770270270270274
Actor Loss : -92.55717468261719
Train_EnvstepsSoFar : 177238
TimeSinceStart : 114.62496042251587
Done logging...



********** Iteration 44 ************

Collecting data for eval...
Eval_AverageReturn : 57.57143020629883
Eval_StdReturn : 14.57843017578125
Eval_MaxReturn : 80.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 57.57142857142857
Train_AverageReturn : 47.2470588684082
Train_StdReturn : 18.13926887512207
Train_MaxReturn : 101.0
Train_MinReturn : 20.0
Train_AverageEpLen : 47.247058823529414
Actor Loss : -166.1129150390625
Train_EnvstepsSoFar : 181254
TimeSinceStart : 117.05941581726074
Done logging...



********** Iteration 45 ************

Collecting data for eval...
Eval_AverageReturn : 52.875
Eval_StdReturn : 16.120153427124023
Eval_MaxReturn : 80.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 52.875
Train_AverageReturn : 57.271427154541016
Train_StdReturn : 14.61791706085205
Train_MaxReturn : 94.0
Train_MinReturn : 29.0
Train_AverageEpLen : 57.27142857142857
Actor Loss : -76.0999755859375
Train_EnvstepsSoFar : 185263
TimeSinceStart : 119.49160361289978
Done logging...



********** Iteration 46 ************

Collecting data for eval...
Eval_AverageReturn : 53.0
Eval_StdReturn : 23.371397018432617
Eval_MaxReturn : 107.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 53.0
Train_AverageReturn : 54.82191848754883
Train_StdReturn : 18.620464324951172
Train_MaxReturn : 133.0
Train_MinReturn : 30.0
Train_AverageEpLen : 54.821917808219176
Actor Loss : 73.20719909667969
Train_EnvstepsSoFar : 189265
TimeSinceStart : 121.96309208869934
Done logging...



********** Iteration 47 ************

Collecting data for eval...
Eval_AverageReturn : 46.22222137451172
Eval_StdReturn : 12.13606071472168
Eval_MaxReturn : 77.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 46.22222222222222
Train_AverageReturn : 52.2337646484375
Train_StdReturn : 18.94413948059082
Train_MaxReturn : 135.0
Train_MinReturn : 31.0
Train_AverageEpLen : 52.23376623376623
Actor Loss : 120.94007110595703
Train_EnvstepsSoFar : 193287
TimeSinceStart : 124.38200497627258
Done logging...



********** Iteration 48 ************

Collecting data for eval...
Eval_AverageReturn : 51.25
Eval_StdReturn : 17.027551651000977
Eval_MaxReturn : 91.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 51.25
Train_AverageReturn : 51.075950622558594
Train_StdReturn : 22.162673950195312
Train_MaxReturn : 138.0
Train_MinReturn : 31.0
Train_AverageEpLen : 51.075949367088604
Actor Loss : 55.455291748046875
Train_EnvstepsSoFar : 197322
TimeSinceStart : 126.88244724273682
Done logging...



********** Iteration 49 ************

Collecting data for eval...
Eval_AverageReturn : 54.875
Eval_StdReturn : 18.884103775024414
Eval_MaxReturn : 88.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 54.875
Train_AverageReturn : 56.135135650634766
Train_StdReturn : 26.528579711914062
Train_MaxReturn : 167.0
Train_MinReturn : 31.0
Train_AverageEpLen : 56.13513513513514
Actor Loss : 91.09815979003906
Train_EnvstepsSoFar : 201476
TimeSinceStart : 129.7099425792694
Done logging...



********** Iteration 50 ************

Collecting data for eval...
Eval_AverageReturn : 52.875
Eval_StdReturn : 10.385537147521973
Eval_MaxReturn : 69.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 52.875
Train_AverageReturn : 52.181819915771484
Train_StdReturn : 18.504283905029297
Train_MaxReturn : 135.0
Train_MinReturn : 33.0
Train_AverageEpLen : 52.18181818181818
Actor Loss : -9.296788215637207
Train_EnvstepsSoFar : 205494
TimeSinceStart : 132.08421683311462
Done logging...



********** Iteration 51 ************

Collecting data for eval...
Eval_AverageReturn : 73.5
Eval_StdReturn : 37.061885833740234
Eval_MaxReturn : 154.0
Eval_MinReturn : 43.0
Eval_AverageEpLen : 73.5
Train_AverageReturn : 55.27397155761719
Train_StdReturn : 22.870248794555664
Train_MaxReturn : 188.0
Train_MinReturn : 36.0
Train_AverageEpLen : 55.273972602739725
Actor Loss : -30.355144500732422
Train_EnvstepsSoFar : 209529
TimeSinceStart : 134.47653222084045
Done logging...



********** Iteration 52 ************

Collecting data for eval...
Eval_AverageReturn : 57.28571319580078
Eval_StdReturn : 24.98407745361328
Eval_MaxReturn : 115.0
Eval_MinReturn : 37.0
Eval_AverageEpLen : 57.285714285714285
Train_AverageReturn : 57.507041931152344
Train_StdReturn : 24.631866455078125
Train_MaxReturn : 199.0
Train_MinReturn : 32.0
Train_AverageEpLen : 57.50704225352113
Actor Loss : -47.59010314941406
Train_EnvstepsSoFar : 213612
TimeSinceStart : 136.99225664138794
Done logging...



********** Iteration 53 ************

Collecting data for eval...
Eval_AverageReturn : 64.14286041259766
Eval_StdReturn : 20.385068893432617
Eval_MaxReturn : 92.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 64.14285714285714
Train_AverageReturn : 56.507041931152344
Train_StdReturn : 17.650657653808594
Train_MaxReturn : 117.0
Train_MinReturn : 33.0
Train_AverageEpLen : 56.50704225352113
Actor Loss : -68.81745910644531
Train_EnvstepsSoFar : 217624
TimeSinceStart : 139.38681745529175
Done logging...



********** Iteration 54 ************

Collecting data for eval...
Eval_AverageReturn : 52.75
Eval_StdReturn : 15.722197532653809
Eval_MaxReturn : 92.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 52.75
Train_AverageReturn : 57.371429443359375
Train_StdReturn : 14.708765029907227
Train_MaxReturn : 100.0
Train_MinReturn : 36.0
Train_AverageEpLen : 57.371428571428574
Actor Loss : -96.73340606689453
Train_EnvstepsSoFar : 221640
TimeSinceStart : 141.90988874435425
Done logging...



********** Iteration 55 ************

Collecting data for eval...
Eval_AverageReturn : 52.75
Eval_StdReturn : 12.152674674987793
Eval_MaxReturn : 68.0
Eval_MinReturn : 36.0
Eval_AverageEpLen : 52.75
Train_AverageReturn : 54.18918991088867
Train_StdReturn : 19.091299057006836
Train_MaxReturn : 117.0
Train_MinReturn : 31.0
Train_AverageEpLen : 54.189189189189186
Actor Loss : -160.27508544921875
Train_EnvstepsSoFar : 225650
TimeSinceStart : 144.27695393562317
Done logging...



********** Iteration 56 ************

Collecting data for eval...
Eval_AverageReturn : 51.5
Eval_StdReturn : 15.612495422363281
Eval_MaxReturn : 71.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 51.5
Train_AverageReturn : 51.61538314819336
Train_StdReturn : 20.213748931884766
Train_MaxReturn : 110.0
Train_MinReturn : 30.0
Train_AverageEpLen : 51.61538461538461
Actor Loss : -179.6476287841797
Train_EnvstepsSoFar : 229676
TimeSinceStart : 146.6639585494995
Done logging...



********** Iteration 57 ************

Collecting data for eval...
Eval_AverageReturn : 51.875
Eval_StdReturn : 23.507644653320312
Eval_MaxReturn : 106.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 51.875
Train_AverageReturn : 50.64556884765625
Train_StdReturn : 26.207082748413086
Train_MaxReturn : 159.0
Train_MinReturn : 27.0
Train_AverageEpLen : 50.64556962025316
Actor Loss : -194.55967712402344
Train_EnvstepsSoFar : 233677
TimeSinceStart : 149.2561957836151
Done logging...



********** Iteration 58 ************

Collecting data for eval...
Eval_AverageReturn : 42.6363639831543
Eval_StdReturn : 14.467975616455078
Eval_MaxReturn : 73.0
Eval_MinReturn : 26.0
Eval_AverageEpLen : 42.63636363636363
Train_AverageReturn : 44.36263656616211
Train_StdReturn : 18.27838134765625
Train_MaxReturn : 149.0
Train_MinReturn : 25.0
Train_AverageEpLen : 44.362637362637365
Actor Loss : -230.03353881835938
Train_EnvstepsSoFar : 237714
TimeSinceStart : 151.71282839775085
Done logging...



********** Iteration 59 ************

Collecting data for eval...
Eval_AverageReturn : 69.33333587646484
Eval_StdReturn : 15.786773681640625
Eval_MaxReturn : 89.0
Eval_MinReturn : 42.0
Eval_AverageEpLen : 69.33333333333333
Train_AverageReturn : 50.23749923706055
Train_StdReturn : 24.107698440551758
Train_MaxReturn : 146.0
Train_MinReturn : 21.0
Train_AverageEpLen : 50.2375
Actor Loss : -312.84722900390625
Train_EnvstepsSoFar : 241733
TimeSinceStart : 154.16028785705566
Done logging...



********** Iteration 60 ************

Collecting data for eval...
Eval_AverageReturn : 47.66666793823242
Eval_StdReturn : 9.40449047088623
Eval_MaxReturn : 65.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 47.666666666666664
Train_AverageReturn : 60.60606002807617
Train_StdReturn : 18.415143966674805
Train_MaxReturn : 107.0
Train_MinReturn : 21.0
Train_AverageEpLen : 60.60606060606061
Actor Loss : -126.56840515136719
Train_EnvstepsSoFar : 245733
TimeSinceStart : 156.58514547348022
Done logging...



********** Iteration 61 ************

Collecting data for eval...
Eval_AverageReturn : 60.0
Eval_StdReturn : 24.750179290771484
Eval_MaxReturn : 107.0
Eval_MinReturn : 38.0
Eval_AverageEpLen : 60.0
Train_AverageReturn : 49.378047943115234
Train_StdReturn : 11.31332015991211
Train_MaxReturn : 89.0
Train_MinReturn : 33.0
Train_AverageEpLen : 49.3780487804878
Actor Loss : 50.4703369140625
Train_EnvstepsSoFar : 249782
TimeSinceStart : 159.09427642822266
Done logging...



********** Iteration 62 ************

Collecting data for eval...
Eval_AverageReturn : 47.22222137451172
Eval_StdReturn : 15.61180305480957
Eval_MaxReturn : 77.0
Eval_MinReturn : 29.0
Eval_AverageEpLen : 47.22222222222222
Train_AverageReturn : 48.9878044128418
Train_StdReturn : 19.59062385559082
Train_MaxReturn : 119.0
Train_MinReturn : 29.0
Train_AverageEpLen : 48.98780487804878
Actor Loss : 95.49517822265625
Train_EnvstepsSoFar : 253799
TimeSinceStart : 161.5225601196289
Done logging...



********** Iteration 63 ************

Collecting data for eval...
Eval_AverageReturn : 44.66666793823242
Eval_StdReturn : 11.547004699707031
Eval_MaxReturn : 63.0
Eval_MinReturn : 31.0
Eval_AverageEpLen : 44.666666666666664
Train_AverageReturn : 44.46666717529297
Train_StdReturn : 15.373281478881836
Train_MaxReturn : 92.0
Train_MinReturn : 28.0
Train_AverageEpLen : 44.46666666666667
Actor Loss : 73.87493133544922
Train_EnvstepsSoFar : 257801
TimeSinceStart : 163.8877763748169
Done logging...



********** Iteration 64 ************

Collecting data for eval...
Eval_AverageReturn : 46.11111068725586
Eval_StdReturn : 19.028892517089844
Eval_MaxReturn : 77.0
Eval_MinReturn : 28.0
Eval_AverageEpLen : 46.111111111111114
Train_AverageReturn : 48.349395751953125
Train_StdReturn : 16.796035766601562
Train_MaxReturn : 99.0
Train_MinReturn : 28.0
Train_AverageEpLen : 48.34939759036145
Actor Loss : 72.8996810913086
Train_EnvstepsSoFar : 261814
TimeSinceStart : 166.73356771469116
Done logging...



********** Iteration 65 ************

Collecting data for eval...
Eval_AverageReturn : 42.5
Eval_StdReturn : 13.1320219039917
Eval_MaxReturn : 70.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 42.5
Train_AverageReturn : 45.2696647644043
Train_StdReturn : 15.104701042175293
Train_MaxReturn : 92.0
Train_MinReturn : 28.0
Train_AverageEpLen : 45.26966292134831
Actor Loss : 65.72453308105469
Train_EnvstepsSoFar : 265843
TimeSinceStart : 169.56479620933533
Done logging...



********** Iteration 66 ************

Collecting data for eval...
Eval_AverageReturn : 50.5
Eval_StdReturn : 18.72164535522461
Eval_MaxReturn : 88.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 50.5
Train_AverageReturn : 43.75
Train_StdReturn : 14.44225788116455
Train_MaxReturn : 88.0
Train_MinReturn : 28.0
Train_AverageEpLen : 43.75
Actor Loss : 14.636175155639648
Train_EnvstepsSoFar : 269868
TimeSinceStart : 171.96166014671326
Done logging...



********** Iteration 67 ************

Collecting data for eval...
Eval_AverageReturn : 55.875
Eval_StdReturn : 16.442607879638672
Eval_MaxReturn : 87.0
Eval_MinReturn : 35.0
Eval_AverageEpLen : 55.875
Train_AverageReturn : 47.77381134033203
Train_StdReturn : 15.977179527282715
Train_MaxReturn : 94.0
Train_MinReturn : 29.0
Train_AverageEpLen : 47.773809523809526
Actor Loss : 21.682960510253906
Train_EnvstepsSoFar : 273881
TimeSinceStart : 174.3810474872589
Done logging...



********** Iteration 68 ************

Collecting data for eval...
Eval_AverageReturn : 47.66666793823242
Eval_StdReturn : 11.518101692199707
Eval_MaxReturn : 69.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 47.666666666666664
Train_AverageReturn : 51.61538314819336
Train_StdReturn : 19.014318466186523
Train_MaxReturn : 103.0
Train_MinReturn : 29.0
Train_AverageEpLen : 51.61538461538461
Actor Loss : -1.5807571411132812
Train_EnvstepsSoFar : 277907
TimeSinceStart : 176.8077266216278
Done logging...



********** Iteration 69 ************

Collecting data for eval...
Eval_AverageReturn : 54.75
Eval_StdReturn : 16.40693473815918
Eval_MaxReturn : 90.0
Eval_MinReturn : 33.0
Eval_AverageEpLen : 54.75
Train_AverageReturn : 63.873016357421875
Train_StdReturn : 30.226390838623047
Train_MaxReturn : 200.0
Train_MinReturn : 34.0
Train_AverageEpLen : 63.87301587301587
Actor Loss : 43.62005615234375
Train_EnvstepsSoFar : 281931
TimeSinceStart : 179.22022080421448
Done logging...



********** Iteration 70 ************

Collecting data for eval...
Eval_AverageReturn : 60.14285659790039
Eval_StdReturn : 27.76651954650879
Eval_MaxReturn : 127.0
Eval_MinReturn : 39.0
Eval_AverageEpLen : 60.142857142857146
Train_AverageReturn : 61.58461380004883
Train_StdReturn : 25.556509017944336
Train_MaxReturn : 151.0
Train_MinReturn : 36.0
Train_AverageEpLen : 61.58461538461538
Actor Loss : -15.279342651367188
Train_EnvstepsSoFar : 285934
TimeSinceStart : 181.60311698913574
Done logging...



********** Iteration 71 ************

Collecting data for eval...
Eval_AverageReturn : 61.85714340209961
Eval_StdReturn : 8.609439849853516
Eval_MaxReturn : 78.0
Eval_MinReturn : 48.0
Eval_AverageEpLen : 61.857142857142854
Train_AverageReturn : 64.44444274902344
Train_StdReturn : 25.907514572143555
Train_MaxReturn : 134.0
Train_MinReturn : 36.0
Train_AverageEpLen : 64.44444444444444
Actor Loss : -49.23402404785156
Train_EnvstepsSoFar : 289994
TimeSinceStart : 184.08086371421814
Done logging...



********** Iteration 72 ************

Collecting data for eval...
Eval_AverageReturn : 68.83333587646484
Eval_StdReturn : 22.13155174255371
Eval_MaxReturn : 104.0
Eval_MinReturn : 41.0
Eval_AverageEpLen : 68.83333333333333
Train_AverageReturn : 58.9420280456543
Train_StdReturn : 18.100271224975586
Train_MaxReturn : 126.0
Train_MinReturn : 39.0
Train_AverageEpLen : 58.94202898550725
Actor Loss : -51.82368850708008
Train_EnvstepsSoFar : 294061
TimeSinceStart : 186.53401374816895
Done logging...



********** Iteration 73 ************

Collecting data for eval...
Eval_AverageReturn : 57.28571319580078
Eval_StdReturn : 15.90789794921875
Eval_MaxReturn : 85.0
Eval_MinReturn : 39.0
Eval_AverageEpLen : 57.285714285714285
Train_AverageReturn : 65.6229476928711
Train_StdReturn : 22.288837432861328
Train_MaxReturn : 144.0
Train_MinReturn : 40.0
Train_AverageEpLen : 65.62295081967213
Actor Loss : -51.34673309326172
Train_EnvstepsSoFar : 298064
TimeSinceStart : 188.94753336906433
Done logging...



********** Iteration 74 ************

Collecting data for eval...
Eval_AverageReturn : 81.5999984741211
Eval_StdReturn : 35.29645919799805
Eval_MaxReturn : 150.0
Eval_MinReturn : 48.0
Eval_AverageEpLen : 81.6
Train_AverageReturn : 67.88135528564453
Train_StdReturn : 21.408920288085938
Train_MaxReturn : 152.0
Train_MinReturn : 41.0
Train_AverageEpLen : 67.88135593220339
Actor Loss : -100.92898559570312
Train_EnvstepsSoFar : 302069
TimeSinceStart : 191.37440466880798
Done logging...



********** Iteration 75 ************

Collecting data for eval...
Eval_AverageReturn : 90.5999984741211
Eval_StdReturn : 25.6171817779541
Eval_MaxReturn : 118.0
Eval_MinReturn : 49.0
Eval_AverageEpLen : 90.6
Train_AverageReturn : 65.83606719970703
Train_StdReturn : 23.408124923706055
Train_MaxReturn : 169.0
Train_MinReturn : 43.0
Train_AverageEpLen : 65.8360655737705
Actor Loss : -37.10146713256836
Train_EnvstepsSoFar : 306085
TimeSinceStart : 193.81257820129395
Done logging...



********** Iteration 76 ************

Collecting data for eval...
Eval_AverageReturn : 63.14285659790039
Eval_StdReturn : 13.819537162780762
Eval_MaxReturn : 85.0
Eval_MinReturn : 41.0
Eval_AverageEpLen : 63.142857142857146
Train_AverageReturn : 66.03278350830078
Train_StdReturn : 19.671037673950195
Train_MaxReturn : 119.0
Train_MinReturn : 39.0
Train_AverageEpLen : 66.0327868852459
Actor Loss : -162.52423095703125
Train_EnvstepsSoFar : 310113
TimeSinceStart : 196.26759815216064
Done logging...



********** Iteration 77 ************

Collecting data for eval...
Eval_AverageReturn : 59.28571319580078
Eval_StdReturn : 36.49154281616211
Eval_MaxReturn : 147.0
Eval_MinReturn : 32.0
Eval_AverageEpLen : 59.285714285714285
Train_AverageReturn : 67.7966079711914
Train_StdReturn : 25.02864646911621
Train_MaxReturn : 200.0
Train_MinReturn : 41.0
Train_AverageEpLen : 67.79661016949153
Actor Loss : -183.49258422851562
Train_EnvstepsSoFar : 314113
TimeSinceStart : 198.68912720680237
Done logging...



********** Iteration 78 ************

Collecting data for eval...
Eval_AverageReturn : 50.25
Eval_StdReturn : 16.7014217376709
Eval_MaxReturn : 85.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 50.25
Train_AverageReturn : 56.38028335571289
Train_StdReturn : 20.372148513793945
Train_MaxReturn : 121.0
Train_MinReturn : 30.0
Train_AverageEpLen : 56.38028169014085
Actor Loss : -194.29298400878906
Train_EnvstepsSoFar : 318116
TimeSinceStart : 201.10318088531494
Done logging...



********** Iteration 79 ************

Collecting data for eval...
Eval_AverageReturn : 36.08333206176758
Eval_StdReturn : 11.063892364501953
Eval_MaxReturn : 64.0
Eval_MinReturn : 24.0
Eval_AverageEpLen : 36.083333333333336
Train_AverageReturn : 50.712501525878906
Train_StdReturn : 20.22633934020996
Train_MaxReturn : 114.0
Train_MinReturn : 22.0
Train_AverageEpLen : 50.7125
Actor Loss : -310.225341796875
Train_EnvstepsSoFar : 322173
TimeSinceStart : 203.56853342056274
Done logging...



********** Iteration 80 ************

Collecting data for eval...
Eval_AverageReturn : 73.66666412353516
Eval_StdReturn : 28.128673553466797
Eval_MaxReturn : 116.0
Eval_MinReturn : 34.0
Eval_AverageEpLen : 73.66666666666667
Train_AverageReturn : 47.77381134033203
Train_StdReturn : 22.03911590576172
Train_MaxReturn : 120.0
Train_MinReturn : 18.0
Train_AverageEpLen : 47.773809523809526
Actor Loss : -232.75787353515625
Train_EnvstepsSoFar : 326186
TimeSinceStart : 206.01455926895142
Done logging...



********** Iteration 81 ************

Collecting data for eval...
Eval_AverageReturn : 89.80000305175781
Eval_StdReturn : 31.313894271850586
Eval_MaxReturn : 127.0
Eval_MinReturn : 49.0
Eval_AverageEpLen : 89.8
Train_AverageReturn : 55.73611068725586
Train_StdReturn : 22.744958877563477
Train_MaxReturn : 115.0
Train_MinReturn : 24.0
Train_AverageEpLen : 55.736111111111114
Actor Loss : -213.4903564453125
Train_EnvstepsSoFar : 330199
TimeSinceStart : 208.4329640865326
Done logging...



********** Iteration 82 ************

Collecting data for eval...
Eval_AverageReturn : 91.19999694824219
Eval_StdReturn : 28.237564086914062
Eval_MaxReturn : 143.0
Eval_MinReturn : 58.0
Eval_AverageEpLen : 91.2
Train_AverageReturn : 67.30000305175781
Train_StdReturn : 26.35039520263672
Train_MaxReturn : 139.0
Train_MinReturn : 31.0
Train_AverageEpLen : 67.3
Actor Loss : -144.32989501953125
Train_EnvstepsSoFar : 334237
TimeSinceStart : 210.87649154663086
Done logging...



********** Iteration 83 ************

Collecting data for eval...
Eval_AverageReturn : 69.66666412353516
Eval_StdReturn : 9.893881797790527
Eval_MaxReturn : 86.0
Eval_MinReturn : 56.0
Eval_AverageEpLen : 69.66666666666667
Train_AverageReturn : 88.71739196777344
Train_StdReturn : 29.155256271362305
Train_MaxReturn : 155.0
Train_MinReturn : 50.0
Train_AverageEpLen : 88.71739130434783
Actor Loss : 22.634654998779297
Train_EnvstepsSoFar : 338318
TimeSinceStart : 213.33768963813782
Done logging...



********** Iteration 84 ************

Collecting data for eval...
Eval_AverageReturn : 56.25
Eval_StdReturn : 4.763139724731445
Eval_MaxReturn : 65.0
Eval_MinReturn : 50.0
Eval_AverageEpLen : 56.25
Train_AverageReturn : 75.11111450195312
Train_StdReturn : 27.855892181396484
Train_MaxReturn : 200.0
Train_MinReturn : 44.0
Train_AverageEpLen : 75.11111111111111
Actor Loss : 44.1001091003418
Train_EnvstepsSoFar : 342374
TimeSinceStart : 215.78519463539124
Done logging...



********** Iteration 85 ************

Collecting data for eval...
Eval_AverageReturn : 60.71428680419922
Eval_StdReturn : 5.469768524169922
Eval_MaxReturn : 70.0
Eval_MinReturn : 54.0
Eval_AverageEpLen : 60.714285714285715
Train_AverageReturn : 63.74603271484375
Train_StdReturn : 16.53372573852539
Train_MaxReturn : 114.0
Train_MinReturn : 44.0
Train_AverageEpLen : 63.74603174603175
Actor Loss : 144.21673583984375
Train_EnvstepsSoFar : 346390
TimeSinceStart : 218.19044971466064
Done logging...



********** Iteration 86 ************

Collecting data for eval...
Eval_AverageReturn : 57.42856979370117
Eval_StdReturn : 10.167977333068848
Eval_MaxReturn : 74.0
Eval_MinReturn : 44.0
Eval_AverageEpLen : 57.42857142857143
Train_AverageReturn : 67.25
Train_StdReturn : 24.91159439086914
Train_MaxReturn : 152.0
Train_MinReturn : 40.0
Train_AverageEpLen : 67.25
Actor Loss : 54.164310455322266
Train_EnvstepsSoFar : 350425
TimeSinceStart : 220.58228468894958
Done logging...



********** Iteration 87 ************

Collecting data for eval...
Eval_AverageReturn : 81.0
Eval_StdReturn : 29.7657527923584
Eval_MaxReturn : 121.0
Eval_MinReturn : 50.0
Eval_AverageEpLen : 81.0
Train_AverageReturn : 65.43548583984375
Train_StdReturn : 22.26861000061035
Train_MaxReturn : 131.0
Train_MinReturn : 41.0
Train_AverageEpLen : 65.43548387096774
Actor Loss : 119.58332824707031
Train_EnvstepsSoFar : 354482
TimeSinceStart : 223.8713414669037
Done logging...



********** Iteration 88 ************

Collecting data for eval...
Eval_AverageReturn : 70.16666412353516
Eval_StdReturn : 27.4190731048584
Eval_MaxReturn : 116.0
Eval_MinReturn : 41.0
Eval_AverageEpLen : 70.16666666666667
Train_AverageReturn : 61.0
Train_StdReturn : 22.581838607788086
Train_MaxReturn : 132.0
Train_MinReturn : 37.0
Train_AverageEpLen : 61.0
Actor Loss : 60.33998107910156
Train_EnvstepsSoFar : 358508
TimeSinceStart : 226.28520274162292
Done logging...



********** Iteration 89 ************

Collecting data for eval...
Eval_AverageReturn : 54.25
Eval_StdReturn : 8.496322631835938
Eval_MaxReturn : 68.0
Eval_MinReturn : 40.0
Eval_AverageEpLen : 54.25
Train_AverageReturn : 71.52631378173828
Train_StdReturn : 24.775556564331055
Train_MaxReturn : 142.0
Train_MinReturn : 42.0
Train_AverageEpLen : 71.52631578947368
Actor Loss : 20.209518432617188
Train_EnvstepsSoFar : 362585
TimeSinceStart : 228.73496198654175
Done logging...



********** Iteration 90 ************

Collecting data for eval...
Eval_AverageReturn : 69.0
Eval_StdReturn : 19.928443908691406
Eval_MaxReturn : 98.0
Eval_MinReturn : 46.0
Eval_AverageEpLen : 69.0
Train_AverageReturn : 64.14286041259766
Train_StdReturn : 28.852035522460938
Train_MaxReturn : 182.0
Train_MinReturn : 36.0
Train_AverageEpLen : 64.14285714285714
Actor Loss : 35.319976806640625
Train_EnvstepsSoFar : 366626
TimeSinceStart : 231.18994736671448
Done logging...



********** Iteration 91 ************

Collecting data for eval...
Eval_AverageReturn : 58.0
Eval_StdReturn : 18.322507858276367
Eval_MaxReturn : 95.0
Eval_MinReturn : 42.0
Eval_AverageEpLen : 58.0
Train_AverageReturn : 62.875
Train_StdReturn : 28.714923858642578
Train_MaxReturn : 141.0
Train_MinReturn : 38.0
Train_AverageEpLen : 62.875
Actor Loss : 25.66745376586914
Train_EnvstepsSoFar : 370650
TimeSinceStart : 233.58086013793945
Done logging...



********** Iteration 92 ************

Collecting data for eval...
Eval_AverageReturn : 75.83333587646484
Eval_StdReturn : 23.39099884033203
Eval_MaxReturn : 114.0
Eval_MinReturn : 51.0
Eval_AverageEpLen : 75.83333333333333
Train_AverageReturn : 66.26229858398438
Train_StdReturn : 30.148757934570312
Train_MaxReturn : 199.0
Train_MinReturn : 38.0
Train_AverageEpLen : 66.26229508196721
Actor Loss : 45.597110748291016
Train_EnvstepsSoFar : 374692
TimeSinceStart : 236.0143699645996
Done logging...



********** Iteration 93 ************

Collecting data for eval...
Eval_AverageReturn : 54.75
Eval_StdReturn : 10.096409797668457
Eval_MaxReturn : 76.0
Eval_MinReturn : 44.0
Eval_AverageEpLen : 54.75
Train_AverageReturn : 62.523075103759766
Train_StdReturn : 25.296463012695312
Train_MaxReturn : 154.0
Train_MinReturn : 37.0
Train_AverageEpLen : 62.52307692307692
Actor Loss : -5.016756534576416
Train_EnvstepsSoFar : 378756
TimeSinceStart : 238.4648358821869
Done logging...



********** Iteration 94 ************

Collecting data for eval...
Eval_AverageReturn : 87.16666412353516
Eval_StdReturn : 39.65020751953125
Eval_MaxReturn : 156.0
Eval_MinReturn : 48.0
Eval_AverageEpLen : 87.16666666666667
Train_AverageReturn : 65.58064270019531
Train_StdReturn : 24.593172073364258
Train_MaxReturn : 122.0
Train_MinReturn : 40.0
Train_AverageEpLen : 65.58064516129032
Actor Loss : 6.800498962402344
Train_EnvstepsSoFar : 382822
TimeSinceStart : 243.0423822402954
Done logging...



********** Iteration 95 ************

Collecting data for eval...
Eval_AverageReturn : 69.83333587646484
Eval_StdReturn : 32.03340148925781
Eval_MaxReturn : 118.0
Eval_MinReturn : 44.0
Eval_AverageEpLen : 69.83333333333333
Train_AverageReturn : 63.092308044433594
Train_StdReturn : 28.109521865844727
Train_MaxReturn : 200.0
Train_MinReturn : 42.0
Train_AverageEpLen : 63.09230769230769
Actor Loss : -0.7775037288665771
Train_EnvstepsSoFar : 386923
TimeSinceStart : 245.90461134910583
Done logging...



********** Iteration 96 ************

Collecting data for eval...
Eval_AverageReturn : 61.42856979370117
Eval_StdReturn : 22.28296661376953
Eval_MaxReturn : 112.0
Eval_MinReturn : 44.0
Eval_AverageEpLen : 61.42857142857143
Train_AverageReturn : 62.123077392578125
Train_StdReturn : 26.17133331298828
Train_MaxReturn : 194.0
Train_MinReturn : 40.0
Train_AverageEpLen : 62.12307692307692
Actor Loss : 2.1748085021972656
Train_EnvstepsSoFar : 390961
TimeSinceStart : 248.32316732406616
Done logging...



********** Iteration 97 ************

Collecting data for eval...
Eval_AverageReturn : 102.5
Eval_StdReturn : 51.45143508911133
Eval_MaxReturn : 180.0
Eval_MinReturn : 53.0
Eval_AverageEpLen : 102.5
Train_AverageReturn : 71.42105102539062
Train_StdReturn : 31.134653091430664
Train_MaxReturn : 150.0
Train_MinReturn : 40.0
Train_AverageEpLen : 71.42105263157895
Actor Loss : -4.735231876373291
Train_EnvstepsSoFar : 395032
TimeSinceStart : 252.19808268547058
Done logging...



********** Iteration 98 ************

Collecting data for eval...
Eval_AverageReturn : 61.28571319580078
Eval_StdReturn : 9.467452049255371
Eval_MaxReturn : 71.0
Eval_MinReturn : 44.0
Eval_AverageEpLen : 61.285714285714285
Train_AverageReturn : 70.7368392944336
Train_StdReturn : 28.72832489013672
Train_MaxReturn : 156.0
Train_MinReturn : 42.0
Train_AverageEpLen : 70.73684210526316
Actor Loss : -7.203639507293701
Train_EnvstepsSoFar : 399064
TimeSinceStart : 254.60686254501343
Done logging...



********** Iteration 99 ************

Collecting data for eval...
Eval_AverageReturn : 70.42857360839844
Eval_StdReturn : 30.93244743347168
Eval_MaxReturn : 145.0
Eval_MinReturn : 50.0
Eval_AverageEpLen : 70.42857142857143
Train_AverageReturn : 73.98181915283203
Train_StdReturn : 28.27494239807129
Train_MaxReturn : 172.0
Train_MinReturn : 41.0
Train_AverageEpLen : 73.98181818181818
Actor Loss : -14.549187660217285
Train_EnvstepsSoFar : 403133
TimeSinceStart : 257.1158974170685
Done logging...



********** Iteration 100 ************

Collecting data for eval...
Eval_AverageReturn : 82.5999984741211
Eval_StdReturn : 21.66656494140625
Eval_MaxReturn : 125.0
Eval_MinReturn : 65.0
Eval_AverageEpLen : 82.6
Train_AverageReturn : 77.92308044433594
Train_StdReturn : 30.677507400512695
Train_MaxReturn : 183.0
Train_MinReturn : 46.0
Train_AverageEpLen : 77.92307692307692
Actor Loss : -32.558109283447266
Train_EnvstepsSoFar : 407185
TimeSinceStart : 259.54433250427246
Done logging...



********** Iteration 101 ************

Collecting data for eval...
Eval_AverageReturn : 99.19999694824219
Eval_StdReturn : 32.99333190917969
Eval_MaxReturn : 164.0
Eval_MinReturn : 77.0
Eval_AverageEpLen : 99.2
Train_AverageReturn : 71.12281036376953
Train_StdReturn : 27.759029388427734
Train_MaxReturn : 166.0
Train_MinReturn : 46.0
Train_AverageEpLen : 71.12280701754386
Actor Loss : -24.66546630859375
Train_EnvstepsSoFar : 411239
TimeSinceStart : 262.03262758255005
Done logging...



********** Iteration 102 ************

Collecting data for eval...
Eval_AverageReturn : 95.0
Eval_StdReturn : 45.166358947753906
Eval_MaxReturn : 173.0
Eval_MinReturn : 55.0
Eval_AverageEpLen : 95.0
Train_AverageReturn : 74.25926208496094
Train_StdReturn : 20.117420196533203
Train_MaxReturn : 140.0
Train_MinReturn : 48.0
Train_AverageEpLen : 74.25925925925925
Actor Loss : -16.82730484008789
Train_EnvstepsSoFar : 415249
TimeSinceStart : 264.47505354881287
Done logging...



********** Iteration 103 ************

Collecting data for eval...
Eval_AverageReturn : 72.0
Eval_StdReturn : 13.051180839538574
Eval_MaxReturn : 93.0
Eval_MinReturn : 55.0
Eval_AverageEpLen : 72.0
Train_AverageReturn : 87.41304016113281
Train_StdReturn : 32.01465606689453
Train_MaxReturn : 200.0
Train_MinReturn : 49.0
Train_AverageEpLen : 87.41304347826087
Actor Loss : -14.48978328704834
Train_EnvstepsSoFar : 419270
TimeSinceStart : 266.8765597343445
Done logging...



********** Iteration 104 ************

Collecting data for eval...
Eval_AverageReturn : 123.0
Eval_StdReturn : 46.16817092895508
Eval_MaxReturn : 200.0
Eval_MinReturn : 81.0
Eval_AverageEpLen : 123.0
Train_AverageReturn : 81.7755126953125
Train_StdReturn : 25.275836944580078
Train_MaxReturn : 161.0
Train_MinReturn : 48.0
Train_AverageEpLen : 81.77551020408163
Actor Loss : 5.649684906005859
Train_EnvstepsSoFar : 423277
TimeSinceStart : 269.30683612823486
Done logging...



********** Iteration 105 ************

Collecting data for eval...
Eval_AverageReturn : 81.4000015258789
Eval_StdReturn : 27.236740112304688
Eval_MaxReturn : 126.0
Eval_MinReturn : 52.0
Eval_AverageEpLen : 81.4
Train_AverageReturn : 93.90697479248047
Train_StdReturn : 37.46739196777344
Train_MaxReturn : 200.0
Train_MinReturn : 53.0
Train_AverageEpLen : 93.90697674418605
Actor Loss : 65.03057861328125
Train_EnvstepsSoFar : 427315
TimeSinceStart : 272.0316090583801
Done logging...



********** Iteration 106 ************

Collecting data for eval...
Eval_AverageReturn : 84.0
Eval_StdReturn : 16.832508087158203
Eval_MaxReturn : 107.0
Eval_MinReturn : 55.0
Eval_AverageEpLen : 84.0
Train_AverageReturn : 93.4186019897461
Train_StdReturn : 41.804771423339844
Train_MaxReturn : 200.0
Train_MinReturn : 55.0
Train_AverageEpLen : 93.4186046511628
Actor Loss : 173.54917907714844
Train_EnvstepsSoFar : 431332
TimeSinceStart : 274.50588822364807
Done logging...



********** Iteration 107 ************

Collecting data for eval...
Eval_AverageReturn : 114.0
Eval_StdReturn : 32.38518142700195
Eval_MaxReturn : 174.0
Eval_MinReturn : 81.0
Eval_AverageEpLen : 114.0
Train_AverageReturn : 112.0810775756836
Train_StdReturn : 47.94387435913086
Train_MaxReturn : 200.0
Train_MinReturn : 55.0
Train_AverageEpLen : 112.08108108108108
Actor Loss : 142.38168334960938
Train_EnvstepsSoFar : 435479
TimeSinceStart : 277.083678483963
Done logging...



********** Iteration 108 ************

Collecting data for eval...
Eval_AverageReturn : 134.6666717529297
Eval_StdReturn : 46.226497650146484
Eval_MaxReturn : 200.0
Eval_MinReturn : 100.0
Eval_AverageEpLen : 134.66666666666666
Train_AverageReturn : 126.7272720336914
Train_StdReturn : 54.191734313964844
Train_MaxReturn : 200.0
Train_MinReturn : 58.0
Train_AverageEpLen : 126.72727272727273
Actor Loss : 94.96463012695312
Train_EnvstepsSoFar : 439661
TimeSinceStart : 279.6850028038025
Done logging...



********** Iteration 109 ************

Collecting data for eval...
Eval_AverageReturn : 136.0
Eval_StdReturn : 64.06246948242188
Eval_MaxReturn : 200.0
Eval_MinReturn : 68.0
Eval_AverageEpLen : 136.0
Train_AverageReturn : 148.5357208251953
Train_StdReturn : 56.207191467285156
Train_MaxReturn : 200.0
Train_MinReturn : 64.0
Train_AverageEpLen : 148.53571428571428
Actor Loss : 86.79714965820312
Train_EnvstepsSoFar : 443820
TimeSinceStart : 282.94966101646423
Done logging...



********** Iteration 110 ************

Collecting data for eval...
Eval_AverageReturn : 137.5
Eval_StdReturn : 62.535987854003906
Eval_MaxReturn : 200.0
Eval_MinReturn : 72.0
Eval_AverageEpLen : 137.5
Train_AverageReturn : 155.65383911132812
Train_StdReturn : 50.27153015136719
Train_MaxReturn : 200.0
Train_MinReturn : 68.0
Train_AverageEpLen : 155.65384615384616
Actor Loss : 98.70368957519531
Train_EnvstepsSoFar : 447867
TimeSinceStart : 285.47654032707214
Done logging...



********** Iteration 111 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 149.64285278320312
Train_StdReturn : 54.856441497802734
Train_MaxReturn : 200.0
Train_MinReturn : 70.0
Train_AverageEpLen : 149.64285714285714
Actor Loss : 93.07015228271484
Train_EnvstepsSoFar : 452057
TimeSinceStart : 287.9801232814789
Done logging...



********** Iteration 112 ************

Collecting data for eval...
Eval_AverageReturn : 135.6666717529297
Eval_StdReturn : 41.49163055419922
Eval_MaxReturn : 194.0
Eval_MinReturn : 101.0
Eval_AverageEpLen : 135.66666666666666
Train_AverageReturn : 152.22222900390625
Train_StdReturn : 50.5879020690918
Train_MaxReturn : 200.0
Train_MinReturn : 64.0
Train_AverageEpLen : 152.22222222222223
Actor Loss : 107.15091705322266
Train_EnvstepsSoFar : 456167
TimeSinceStart : 290.5960032939911
Done logging...



********** Iteration 113 ************

Collecting data for eval...
Eval_AverageReturn : 88.4000015258789
Eval_StdReturn : 13.04760456085205
Eval_MaxReturn : 112.0
Eval_MinReturn : 76.0
Eval_AverageEpLen : 88.4
Train_AverageReturn : 135.8000030517578
Train_StdReturn : 49.27568817138672
Train_MaxReturn : 200.0
Train_MinReturn : 68.0
Train_AverageEpLen : 135.8
Actor Loss : 102.29742431640625
Train_EnvstepsSoFar : 460241
TimeSinceStart : 293.38931155204773
Done logging...



********** Iteration 114 ************

Collecting data for eval...
Eval_AverageReturn : 94.4000015258789
Eval_StdReturn : 14.374978065490723
Eval_MaxReturn : 110.0
Eval_MinReturn : 69.0
Eval_AverageEpLen : 94.4
Train_AverageReturn : 111.52777862548828
Train_StdReturn : 37.968177795410156
Train_MaxReturn : 200.0
Train_MinReturn : 64.0
Train_AverageEpLen : 111.52777777777777
Actor Loss : 86.47909545898438
Train_EnvstepsSoFar : 464256
TimeSinceStart : 295.8780746459961
Done logging...



********** Iteration 115 ************

Collecting data for eval...
Eval_AverageReturn : 116.19999694824219
Eval_StdReturn : 44.11077117919922
Eval_MaxReturn : 200.0
Eval_MinReturn : 73.0
Eval_AverageEpLen : 116.2
Train_AverageReturn : 109.27027130126953
Train_StdReturn : 41.13566970825195
Train_MaxReturn : 200.0
Train_MinReturn : 66.0
Train_AverageEpLen : 109.27027027027027
Actor Loss : 138.03955078125
Train_EnvstepsSoFar : 468299
TimeSinceStart : 298.4542541503906
Done logging...



********** Iteration 116 ************

Collecting data for eval...
Eval_AverageReturn : 124.75
Eval_StdReturn : 44.650726318359375
Eval_MaxReturn : 200.0
Eval_MinReturn : 88.0
Eval_AverageEpLen : 124.75
Train_AverageReturn : 113.25
Train_StdReturn : 47.47243118286133
Train_MaxReturn : 200.0
Train_MinReturn : 60.0
Train_AverageEpLen : 113.25
Actor Loss : 180.57608032226562
Train_EnvstepsSoFar : 472376
TimeSinceStart : 300.9667229652405
Done logging...



********** Iteration 117 ************

Collecting data for eval...
Eval_AverageReturn : 119.25
Eval_StdReturn : 47.26190185546875
Eval_MaxReturn : 200.0
Eval_MinReturn : 86.0
Eval_AverageEpLen : 119.25
Train_AverageReturn : 108.43243408203125
Train_StdReturn : 37.073734283447266
Train_MaxReturn : 200.0
Train_MinReturn : 63.0
Train_AverageEpLen : 108.43243243243244
Actor Loss : 135.19952392578125
Train_EnvstepsSoFar : 476388
TimeSinceStart : 303.88324189186096
Done logging...



********** Iteration 118 ************

Collecting data for eval...
Eval_AverageReturn : 137.5
Eval_StdReturn : 61.09214401245117
Eval_MaxReturn : 200.0
Eval_MinReturn : 72.0
Eval_AverageEpLen : 137.5
Train_AverageReturn : 102.42500305175781
Train_StdReturn : 32.60512924194336
Train_MaxReturn : 200.0
Train_MinReturn : 56.0
Train_AverageEpLen : 102.425
Actor Loss : 66.81318664550781
Train_EnvstepsSoFar : 480485
TimeSinceStart : 306.46737599372864
Done logging...



********** Iteration 119 ************

Collecting data for eval...
Eval_AverageReturn : 158.0
Eval_StdReturn : 17.568912506103516
Eval_MaxReturn : 180.0
Eval_MinReturn : 137.0
Eval_AverageEpLen : 158.0
Train_AverageReturn : 129.74192810058594
Train_StdReturn : 45.43408203125
Train_MaxReturn : 200.0
Train_MinReturn : 70.0
Train_AverageEpLen : 129.74193548387098
Actor Loss : 122.74693298339844
Train_EnvstepsSoFar : 484507
TimeSinceStart : 308.95884346961975
Done logging...



********** Iteration 120 ************

Collecting data for eval...
Eval_AverageReturn : 107.25
Eval_StdReturn : 17.69710350036621
Eval_MaxReturn : 130.0
Eval_MinReturn : 89.0
Eval_AverageEpLen : 107.25
Train_AverageReturn : 132.4193572998047
Train_StdReturn : 47.38433837890625
Train_MaxReturn : 200.0
Train_MinReturn : 76.0
Train_AverageEpLen : 132.41935483870967
Actor Loss : 142.5289764404297
Train_EnvstepsSoFar : 488612
TimeSinceStart : 311.8049683570862
Done logging...



********** Iteration 121 ************

Collecting data for eval...
Eval_AverageReturn : 145.0
Eval_StdReturn : 39.149288177490234
Eval_MaxReturn : 200.0
Eval_MinReturn : 112.0
Eval_AverageEpLen : 145.0
Train_AverageReturn : 150.3333282470703
Train_StdReturn : 45.299007415771484
Train_MaxReturn : 200.0
Train_MinReturn : 86.0
Train_AverageEpLen : 150.33333333333334
Actor Loss : 132.2718505859375
Train_EnvstepsSoFar : 492671
TimeSinceStart : 315.61192417144775
Done logging...



********** Iteration 122 ************

Collecting data for eval...
Eval_AverageReturn : 161.6666717529297
Eval_StdReturn : 46.64999771118164
Eval_MaxReturn : 200.0
Eval_MinReturn : 96.0
Eval_AverageEpLen : 161.66666666666666
Train_AverageReturn : 141.89654541015625
Train_StdReturn : 44.90475845336914
Train_MaxReturn : 200.0
Train_MinReturn : 77.0
Train_AverageEpLen : 141.89655172413794
Actor Loss : 96.29306030273438
Train_EnvstepsSoFar : 496786
TimeSinceStart : 318.293598651886
Done logging...



********** Iteration 123 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 165.1199951171875
Train_StdReturn : 41.188655853271484
Train_MaxReturn : 200.0
Train_MinReturn : 91.0
Train_AverageEpLen : 165.12
Actor Loss : 91.83824157714844
Train_EnvstepsSoFar : 500914
TimeSinceStart : 320.8925220966339
Done logging...



********** Iteration 124 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 154.8148193359375
Train_StdReturn : 44.670841217041016
Train_MaxReturn : 200.0
Train_MinReturn : 88.0
Train_AverageEpLen : 154.8148148148148
Actor Loss : 90.67152404785156
Train_EnvstepsSoFar : 505094
TimeSinceStart : 323.62422347068787
Done logging...



********** Iteration 125 ************

Collecting data for eval...
Eval_AverageReturn : 176.3333282470703
Eval_StdReturn : 33.46971893310547
Eval_MaxReturn : 200.0
Eval_MinReturn : 129.0
Eval_AverageEpLen : 176.33333333333334
Train_AverageReturn : 167.7083282470703
Train_StdReturn : 39.08481979370117
Train_MaxReturn : 200.0
Train_MinReturn : 93.0
Train_AverageEpLen : 167.70833333333334
Actor Loss : 84.43510437011719
Train_EnvstepsSoFar : 509119
TimeSinceStart : 326.22746872901917
Done logging...



********** Iteration 126 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 176.13043212890625
Train_StdReturn : 32.4523811340332
Train_MaxReturn : 200.0
Train_MinReturn : 104.0
Train_AverageEpLen : 176.1304347826087
Actor Loss : 45.51332092285156
Train_EnvstepsSoFar : 513170
TimeSinceStart : 328.6828501224518
Done logging...



********** Iteration 127 ************

Collecting data for eval...
Eval_AverageReturn : 189.3333282470703
Eval_StdReturn : 15.084944725036621
Eval_MaxReturn : 200.0
Eval_MinReturn : 168.0
Eval_AverageEpLen : 189.33333333333334
Train_AverageReturn : 174.43478393554688
Train_StdReturn : 33.90629959106445
Train_MaxReturn : 200.0
Train_MinReturn : 105.0
Train_AverageEpLen : 174.43478260869566
Actor Loss : 28.759201049804688
Train_EnvstepsSoFar : 517182
TimeSinceStart : 331.2584562301636
Done logging...



********** Iteration 128 ************

Collecting data for eval...
Eval_AverageReturn : 189.6666717529297
Eval_StdReturn : 7.3181657791137695
Eval_MaxReturn : 200.0
Eval_MinReturn : 184.0
Eval_AverageEpLen : 189.66666666666666
Train_AverageReturn : 172.5833282470703
Train_StdReturn : 31.018699645996094
Train_MaxReturn : 200.0
Train_MinReturn : 119.0
Train_AverageEpLen : 172.58333333333334
Actor Loss : 70.96527099609375
Train_EnvstepsSoFar : 521324
TimeSinceStart : 337.62425446510315
Done logging...



********** Iteration 129 ************

Collecting data for eval...
Eval_AverageReturn : 151.3333282470703
Eval_StdReturn : 36.26139450073242
Eval_MaxReturn : 200.0
Eval_MinReturn : 113.0
Eval_AverageEpLen : 151.33333333333334
Train_AverageReturn : 172.875
Train_StdReturn : 31.993896484375
Train_MaxReturn : 200.0
Train_MinReturn : 101.0
Train_AverageEpLen : 172.875
Actor Loss : 58.67963409423828
Train_EnvstepsSoFar : 525473
TimeSinceStart : 340.32756304740906
Done logging...



********** Iteration 130 ************

Collecting data for eval...
Eval_AverageReturn : 194.0
Eval_StdReturn : 8.485280990600586
Eval_MaxReturn : 200.0
Eval_MinReturn : 182.0
Eval_AverageEpLen : 194.0
Train_AverageReturn : 169.0833282470703
Train_StdReturn : 35.86887741088867
Train_MaxReturn : 200.0
Train_MinReturn : 91.0
Train_AverageEpLen : 169.08333333333334
Actor Loss : -24.473615646362305
Train_EnvstepsSoFar : 529531
TimeSinceStart : 343.34743785858154
Done logging...



********** Iteration 131 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 190.8095245361328
Train_StdReturn : 21.905900955200195
Train_MaxReturn : 200.0
Train_MinReturn : 120.0
Train_AverageEpLen : 190.8095238095238
Actor Loss : 29.33554458618164
Train_EnvstepsSoFar : 533538
TimeSinceStart : 345.8499071598053
Done logging...



********** Iteration 132 ************

Collecting data for eval...
Eval_AverageReturn : 171.3333282470703
Eval_StdReturn : 23.683094024658203
Eval_MaxReturn : 200.0
Eval_MinReturn : 142.0
Eval_AverageEpLen : 171.33333333333334
Train_AverageReturn : 183.9545440673828
Train_StdReturn : 17.442052841186523
Train_MaxReturn : 200.0
Train_MinReturn : 148.0
Train_AverageEpLen : 183.95454545454547
Actor Loss : 20.44116973876953
Train_EnvstepsSoFar : 537585
TimeSinceStart : 348.4788193702698
Done logging...



********** Iteration 133 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 191.2857208251953
Train_StdReturn : 13.122655868530273
Train_MaxReturn : 200.0
Train_MinReturn : 148.0
Train_AverageEpLen : 191.28571428571428
Actor Loss : -8.447469711303711
Train_EnvstepsSoFar : 541602
TimeSinceStart : 350.93702840805054
Done logging...



********** Iteration 134 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 191.6666717529297
Train_StdReturn : 15.661092758178711
Train_MaxReturn : 200.0
Train_MinReturn : 156.0
Train_AverageEpLen : 191.66666666666666
Actor Loss : -100.44734191894531
Train_EnvstepsSoFar : 545627
TimeSinceStart : 353.39377617836
Done logging...



********** Iteration 135 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 195.8095245361328
Train_StdReturn : 8.95820426940918
Train_MaxReturn : 200.0
Train_MinReturn : 173.0
Train_AverageEpLen : 195.8095238095238
Actor Loss : -9.965574264526367
Train_EnvstepsSoFar : 549739
TimeSinceStart : 356.2856078147888
Done logging...



********** Iteration 136 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 199.0
Train_StdReturn : 4.047338962554932
Train_MaxReturn : 200.0
Train_MinReturn : 181.0
Train_AverageEpLen : 199.0
Actor Loss : -16.729570388793945
Train_EnvstepsSoFar : 553918
TimeSinceStart : 358.7966628074646
Done logging...



********** Iteration 137 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 193.3333282470703
Train_StdReturn : 14.277298927307129
Train_MaxReturn : 200.0
Train_MinReturn : 156.0
Train_AverageEpLen : 193.33333333333334
Actor Loss : -40.910335540771484
Train_EnvstepsSoFar : 557978
TimeSinceStart : 361.24442768096924
Done logging...



********** Iteration 138 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 199.6666717529297
Train_StdReturn : 1.1268723011016846
Train_MaxReturn : 200.0
Train_MinReturn : 195.0
Train_AverageEpLen : 199.66666666666666
Actor Loss : -89.60154724121094
Train_EnvstepsSoFar : 562171
TimeSinceStart : 363.7736530303955
Done logging...



********** Iteration 139 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 195.85714721679688
Train_StdReturn : 10.269166946411133
Train_MaxReturn : 200.0
Train_MinReturn : 163.0
Train_AverageEpLen : 195.85714285714286
Actor Loss : -126.95753479003906
Train_EnvstepsSoFar : 566284
TimeSinceStart : 366.27516317367554
Done logging...



********** Iteration 140 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 198.76190185546875
Train_StdReturn : 5.536930561065674
Train_MaxReturn : 200.0
Train_MinReturn : 174.0
Train_AverageEpLen : 198.76190476190476
Actor Loss : -85.02194213867188
Train_EnvstepsSoFar : 570458
TimeSinceStart : 368.80994606018066
Done logging...



********** Iteration 141 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 199.23809814453125
Train_StdReturn : 3.407341480255127
Train_MaxReturn : 200.0
Train_MinReturn : 184.0
Train_AverageEpLen : 199.23809523809524
Actor Loss : -108.8062973022461
Train_EnvstepsSoFar : 574642
TimeSinceStart : 371.3390910625458
Done logging...



********** Iteration 142 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 196.23809814453125
Train_StdReturn : 11.604205131530762
Train_MaxReturn : 200.0
Train_MinReturn : 159.0
Train_AverageEpLen : 196.23809523809524
Actor Loss : -133.54196166992188
Train_EnvstepsSoFar : 578763
TimeSinceStart : 373.8270511627197
Done logging...



********** Iteration 143 ************

Collecting data for eval...
Eval_AverageReturn : 131.75
Eval_StdReturn : 65.37727355957031
Eval_MaxReturn : 200.0
Eval_MinReturn : 48.0
Eval_AverageEpLen : 131.75
Train_AverageReturn : 159.15383911132812
Train_StdReturn : 38.88908767700195
Train_MaxReturn : 200.0
Train_MinReturn : 88.0
Train_AverageEpLen : 159.15384615384616
Actor Loss : -238.78170776367188
Train_EnvstepsSoFar : 582901
TimeSinceStart : 376.4030544757843
Done logging...



********** Iteration 144 ************

Collecting data for eval...
Eval_AverageReturn : 83.16666412353516
Eval_StdReturn : 83.70865631103516
Eval_MaxReturn : 200.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 83.16666666666667
Train_AverageReturn : 84.44898223876953
Train_StdReturn : 67.29134368896484
Train_MaxReturn : 200.0
Train_MinReturn : 10.0
Train_AverageEpLen : 84.44897959183673
Actor Loss : -132.68081665039062
Train_EnvstepsSoFar : 587039
TimeSinceStart : 378.961772441864
Done logging...



********** Iteration 145 ************

Collecting data for eval...
Eval_AverageReturn : 101.0
Eval_StdReturn : 81.09561920166016
Eval_MaxReturn : 200.0
Eval_MinReturn : 10.0
Eval_AverageEpLen : 101.0
Train_AverageReturn : 76.66666412353516
Train_StdReturn : 76.62873840332031
Train_MaxReturn : 200.0
Train_MinReturn : 9.0
Train_AverageEpLen : 76.66666666666667
Actor Loss : 95.06800842285156
Train_EnvstepsSoFar : 591179
TimeSinceStart : 381.48327589035034
Done logging...



********** Iteration 146 ************

Collecting data for eval...
Eval_AverageReturn : 115.5
Eval_StdReturn : 51.01225280761719
Eval_MaxReturn : 200.0
Eval_MinReturn : 63.0
Eval_AverageEpLen : 115.5
Train_AverageReturn : 93.16278839111328
Train_StdReturn : 78.8221206665039
Train_MaxReturn : 200.0
Train_MinReturn : 9.0
Train_AverageEpLen : 93.16279069767442
Actor Loss : -4.8184814453125
Train_EnvstepsSoFar : 595185
TimeSinceStart : 383.9458656311035
Done logging...



********** Iteration 147 ************

Collecting data for eval...
Eval_AverageReturn : 172.3333282470703
Eval_StdReturn : 13.960260391235352
Eval_MaxReturn : 192.0
Eval_MinReturn : 161.0
Eval_AverageEpLen : 172.33333333333334
Train_AverageReturn : 122.85294342041016
Train_StdReturn : 72.03068542480469
Train_MaxReturn : 200.0
Train_MinReturn : 21.0
Train_AverageEpLen : 122.8529411764706
Actor Loss : -163.87612915039062
Train_EnvstepsSoFar : 599362
TimeSinceStart : 386.9208610057831
Done logging...



********** Iteration 148 ************

Collecting data for eval...
Eval_AverageReturn : 175.3333282470703
Eval_StdReturn : 34.88393783569336
Eval_MaxReturn : 200.0
Eval_MinReturn : 126.0
Eval_AverageEpLen : 175.33333333333334
Train_AverageReturn : 186.4545440673828
Train_StdReturn : 24.551851272583008
Train_MaxReturn : 200.0
Train_MinReturn : 112.0
Train_AverageEpLen : 186.45454545454547
Actor Loss : -166.90406799316406
Train_EnvstepsSoFar : 603464
TimeSinceStart : 389.7153310775757
Done logging...



********** Iteration 149 ************

Collecting data for eval...
Eval_AverageReturn : 186.6666717529297
Eval_StdReturn : 9.977753639221191
Eval_MaxReturn : 200.0
Eval_MinReturn : 176.0
Eval_AverageEpLen : 186.66666666666666
Train_AverageReturn : 187.59091186523438
Train_StdReturn : 20.80135154724121
Train_MaxReturn : 200.0
Train_MinReturn : 144.0
Train_AverageEpLen : 187.5909090909091
Actor Loss : -228.58944702148438
Train_EnvstepsSoFar : 607591
TimeSinceStart : 392.2797966003418
Done logging...



********** Iteration 150 ************

Collecting data for eval...
Eval_AverageReturn : 150.6666717529297
Eval_StdReturn : 35.0364875793457
Eval_MaxReturn : 200.0
Eval_MinReturn : 122.0
Eval_AverageEpLen : 150.66666666666666
Train_AverageReturn : 181.9130401611328
Train_StdReturn : 30.796546936035156
Train_MaxReturn : 200.0
Train_MinReturn : 96.0
Train_AverageEpLen : 181.91304347826087
Actor Loss : -178.0467529296875
Train_EnvstepsSoFar : 611775
TimeSinceStart : 394.8022389411926
Done logging...



********** Iteration 151 ************

Collecting data for eval...
Eval_AverageReturn : 182.0
Eval_StdReturn : 25.45584487915039
Eval_MaxReturn : 200.0
Eval_MinReturn : 146.0
Eval_AverageEpLen : 182.0
Train_AverageReturn : 161.1199951171875
Train_StdReturn : 33.32304763793945
Train_MaxReturn : 200.0
Train_MinReturn : 95.0
Train_AverageEpLen : 161.12
Actor Loss : -162.99151611328125
Train_EnvstepsSoFar : 615803
TimeSinceStart : 397.2717308998108
Done logging...



********** Iteration 152 ************

Collecting data for eval...
Eval_AverageReturn : 151.6666717529297
Eval_StdReturn : 40.45024490356445
Eval_MaxReturn : 200.0
Eval_MinReturn : 101.0
Eval_AverageEpLen : 151.66666666666666
Train_AverageReturn : 161.9600067138672
Train_StdReturn : 36.01386260986328
Train_MaxReturn : 200.0
Train_MinReturn : 96.0
Train_AverageEpLen : 161.96
Actor Loss : -240.17306518554688
Train_EnvstepsSoFar : 619852
TimeSinceStart : 400.0486419200897
Done logging...



********** Iteration 153 ************

Collecting data for eval...
Eval_AverageReturn : 155.0
Eval_StdReturn : 31.885211944580078
Eval_MaxReturn : 200.0
Eval_MinReturn : 130.0
Eval_AverageEpLen : 155.0
Train_AverageReturn : 151.59259033203125
Train_StdReturn : 28.075637817382812
Train_MaxReturn : 200.0
Train_MinReturn : 107.0
Train_AverageEpLen : 151.59259259259258
Actor Loss : -165.81430053710938
Train_EnvstepsSoFar : 623945
TimeSinceStart : 402.72071623802185
Done logging...



********** Iteration 154 ************

Collecting data for eval...
Eval_AverageReturn : 134.3333282470703
Eval_StdReturn : 9.03081226348877
Eval_MaxReturn : 146.0
Eval_MinReturn : 124.0
Eval_AverageEpLen : 134.33333333333334
Train_AverageReturn : 145.67857360839844
Train_StdReturn : 33.74489974975586
Train_MaxReturn : 200.0
Train_MinReturn : 101.0
Train_AverageEpLen : 145.67857142857142
Actor Loss : -226.60537719726562
Train_EnvstepsSoFar : 628024
TimeSinceStart : 405.1772403717041
Done logging...



********** Iteration 155 ************

Collecting data for eval...
Eval_AverageReturn : 138.3333282470703
Eval_StdReturn : 45.404354095458984
Eval_MaxReturn : 200.0
Eval_MinReturn : 92.0
Eval_AverageEpLen : 138.33333333333334
Train_AverageReturn : 151.37037658691406
Train_StdReturn : 37.86735916137695
Train_MaxReturn : 200.0
Train_MinReturn : 94.0
Train_AverageEpLen : 151.37037037037038
Actor Loss : -240.01475524902344
Train_EnvstepsSoFar : 632111
TimeSinceStart : 408.2926924228668
Done logging...



********** Iteration 156 ************

Collecting data for eval...
Eval_AverageReturn : 101.5
Eval_StdReturn : 13.275918006896973
Eval_MaxReturn : 118.0
Eval_MinReturn : 87.0
Eval_AverageEpLen : 101.5
Train_AverageReturn : 134.5
Train_StdReturn : 31.5592041015625
Train_MaxReturn : 200.0
Train_MinReturn : 84.0
Train_AverageEpLen : 134.5
Actor Loss : -259.21563720703125
Train_EnvstepsSoFar : 636146
TimeSinceStart : 410.76186895370483
Done logging...



********** Iteration 157 ************

Collecting data for eval...
Eval_AverageReturn : 91.19999694824219
Eval_StdReturn : 18.755266189575195
Eval_MaxReturn : 126.0
Eval_MinReturn : 72.0
Eval_AverageEpLen : 91.2
Train_AverageReturn : 127.25
Train_StdReturn : 38.47970199584961
Train_MaxReturn : 200.0
Train_MinReturn : 64.0
Train_AverageEpLen : 127.25
Actor Loss : -220.94912719726562
Train_EnvstepsSoFar : 640218
TimeSinceStart : 413.2367899417877
Done logging...



********** Iteration 158 ************

Collecting data for eval...
Eval_AverageReturn : 91.19999694824219
Eval_StdReturn : 17.713272094726562
Eval_MaxReturn : 111.0
Eval_MinReturn : 64.0
Eval_AverageEpLen : 91.2
Train_AverageReturn : 105.7631607055664
Train_StdReturn : 36.591941833496094
Train_MaxReturn : 200.0
Train_MinReturn : 50.0
Train_AverageEpLen : 105.76315789473684
Actor Loss : -195.06613159179688
Train_EnvstepsSoFar : 644237
TimeSinceStart : 415.70015811920166
Done logging...



********** Iteration 159 ************

Collecting data for eval...
Eval_AverageReturn : 65.14286041259766
Eval_StdReturn : 13.973735809326172
Eval_MaxReturn : 95.0
Eval_MinReturn : 50.0
Eval_AverageEpLen : 65.14285714285714
Train_AverageReturn : 87.0434799194336
Train_StdReturn : 29.235145568847656
Train_MaxReturn : 200.0
Train_MinReturn : 50.0
Train_AverageEpLen : 87.04347826086956
Actor Loss : -162.95480346679688
Train_EnvstepsSoFar : 648241
TimeSinceStart : 418.1432058811188
Done logging...



********** Iteration 160 ************

Collecting data for eval...
Eval_AverageReturn : 54.625
Eval_StdReturn : 10.221759796142578
Eval_MaxReturn : 70.0
Eval_MinReturn : 39.0
Eval_AverageEpLen : 54.625
Train_AverageReturn : 78.4313735961914
Train_StdReturn : 38.38517761230469
Train_MaxReturn : 200.0
Train_MinReturn : 46.0
Train_AverageEpLen : 78.43137254901961
Actor Loss : -230.151611328125
Train_EnvstepsSoFar : 652241
TimeSinceStart : 420.5858724117279
Done logging...



********** Iteration 161 ************

Collecting data for eval...
Eval_AverageReturn : 40.6363639831543
Eval_StdReturn : 16.64207649230957
Eval_MaxReturn : 69.0
Eval_MinReturn : 11.0
Eval_AverageEpLen : 40.63636363636363
Train_AverageReturn : 63.70769119262695
Train_StdReturn : 31.68582534790039
Train_MaxReturn : 200.0
Train_MinReturn : 38.0
Train_AverageEpLen : 63.707692307692305
Actor Loss : -230.80999755859375
Train_EnvstepsSoFar : 656382
TimeSinceStart : 423.095942735672
Done logging...



********** Iteration 162 ************

Collecting data for eval...
Eval_AverageReturn : 37.09090805053711
Eval_StdReturn : 16.762807846069336
Eval_MaxReturn : 59.0
Eval_MinReturn : 11.0
Eval_AverageEpLen : 37.09090909090909
Train_AverageReturn : 43.07526779174805
Train_StdReturn : 14.463329315185547
Train_MaxReturn : 88.0
Train_MinReturn : 12.0
Train_AverageEpLen : 43.075268817204304
Actor Loss : -236.81468200683594
Train_EnvstepsSoFar : 660388
TimeSinceStart : 425.5459358692169
Done logging...



********** Iteration 163 ************

Collecting data for eval...
Eval_AverageReturn : 41.099998474121094
Eval_StdReturn : 13.494072914123535
Eval_MaxReturn : 60.0
Eval_MinReturn : 14.0
Eval_AverageEpLen : 41.1
Train_AverageReturn : 42.081634521484375
Train_StdReturn : 23.186321258544922
Train_MaxReturn : 180.0
Train_MinReturn : 11.0
Train_AverageEpLen : 42.08163265306123
Actor Loss : -228.48876953125
Train_EnvstepsSoFar : 664512
TimeSinceStart : 428.04522490501404
Done logging...



********** Iteration 164 ************

Collecting data for eval...
Eval_AverageReturn : 44.900001525878906
Eval_StdReturn : 18.592741012573242
Eval_MaxReturn : 75.0
Eval_MinReturn : 15.0
Eval_AverageEpLen : 44.9
Train_AverageReturn : 44.120880126953125
Train_StdReturn : 24.299793243408203
Train_MaxReturn : 200.0
Train_MinReturn : 11.0
Train_AverageEpLen : 44.120879120879124
Actor Loss : -259.9500732421875
Train_EnvstepsSoFar : 668527
TimeSinceStart : 430.6127562522888
Done logging...



********** Iteration 165 ************

Collecting data for eval...
Eval_AverageReturn : 74.83333587646484
Eval_StdReturn : 10.853827476501465
Eval_MaxReturn : 85.0
Eval_MinReturn : 53.0
Eval_AverageEpLen : 74.83333333333333
Train_AverageReturn : 54.10810852050781
Train_StdReturn : 15.075994491577148
Train_MaxReturn : 88.0
Train_MinReturn : 13.0
Train_AverageEpLen : 54.108108108108105
Actor Loss : -215.30841064453125
Train_EnvstepsSoFar : 672531
TimeSinceStart : 433.07041025161743
Done logging...



********** Iteration 166 ************

Collecting data for eval...
Eval_AverageReturn : 77.16666412353516
Eval_StdReturn : 8.394773483276367
Eval_MaxReturn : 89.0
Eval_MinReturn : 64.0
Eval_AverageEpLen : 77.16666666666667
Train_AverageReturn : 70.59648895263672
Train_StdReturn : 16.41122817993164
Train_MaxReturn : 147.0
Train_MinReturn : 50.0
Train_AverageEpLen : 70.59649122807018
Actor Loss : -108.50926208496094
Train_EnvstepsSoFar : 676555
TimeSinceStart : 436.12286734580994
Done logging...



********** Iteration 167 ************

Collecting data for eval...
Eval_AverageReturn : 91.19999694824219
Eval_StdReturn : 10.361466407775879
Eval_MaxReturn : 105.0
Eval_MinReturn : 77.0
Eval_AverageEpLen : 91.2
Train_AverageReturn : 85.7021255493164
Train_StdReturn : 20.538408279418945
Train_MaxReturn : 188.0
Train_MinReturn : 59.0
Train_AverageEpLen : 85.70212765957447
Actor Loss : -81.30986022949219
Train_EnvstepsSoFar : 680583
TimeSinceStart : 439.69321489334106
Done logging...



********** Iteration 168 ************

Collecting data for eval...
Eval_AverageReturn : 131.75
Eval_StdReturn : 40.33221435546875
Eval_MaxReturn : 200.0
Eval_MinReturn : 95.0
Eval_AverageEpLen : 131.75
Train_AverageReturn : 103.0
Train_StdReturn : 29.596431732177734
Train_MaxReturn : 193.0
Train_MinReturn : 69.0
Train_AverageEpLen : 103.0
Actor Loss : -90.05937194824219
Train_EnvstepsSoFar : 684600
TimeSinceStart : 442.9514081478119
Done logging...



********** Iteration 169 ************

Collecting data for eval...
Eval_AverageReturn : 165.6666717529297
Eval_StdReturn : 31.982633590698242
Eval_MaxReturn : 200.0
Eval_MinReturn : 123.0
Eval_AverageEpLen : 165.66666666666666
Train_AverageReturn : 119.5882339477539
Train_StdReturn : 29.64507484436035
Train_MaxReturn : 200.0
Train_MinReturn : 86.0
Train_AverageEpLen : 119.58823529411765
Actor Loss : -148.39639282226562
Train_EnvstepsSoFar : 688666
TimeSinceStart : 445.8153336048126
Done logging...



********** Iteration 170 ************

Collecting data for eval...
Eval_AverageReturn : 144.6666717529297
Eval_StdReturn : 40.14418411254883
Eval_MaxReturn : 200.0
Eval_MinReturn : 106.0
Eval_AverageEpLen : 144.66666666666666
Train_AverageReturn : 130.77420043945312
Train_StdReturn : 33.40630340576172
Train_MaxReturn : 200.0
Train_MinReturn : 90.0
Train_AverageEpLen : 130.7741935483871
Actor Loss : -189.16903686523438
Train_EnvstepsSoFar : 692720
TimeSinceStart : 448.96609687805176
Done logging...



********** Iteration 171 ************

Collecting data for eval...
Eval_AverageReturn : 152.6666717529297
Eval_StdReturn : 19.0671329498291
Eval_MaxReturn : 178.0
Eval_MinReturn : 132.0
Eval_AverageEpLen : 152.66666666666666
Train_AverageReturn : 141.7586212158203
Train_StdReturn : 24.603975296020508
Train_MaxReturn : 200.0
Train_MinReturn : 110.0
Train_AverageEpLen : 141.75862068965517
Actor Loss : -188.39735412597656
Train_EnvstepsSoFar : 696831
TimeSinceStart : 452.22202801704407
Done logging...



********** Iteration 172 ************

Collecting data for eval...
Eval_AverageReturn : 188.6666717529297
Eval_StdReturn : 16.027753829956055
Eval_MaxReturn : 200.0
Eval_MinReturn : 166.0
Eval_AverageEpLen : 188.66666666666666
Train_AverageReturn : 167.5416717529297
Train_StdReturn : 28.642885208129883
Train_MaxReturn : 200.0
Train_MinReturn : 120.0
Train_AverageEpLen : 167.54166666666666
Actor Loss : -219.46597290039062
Train_EnvstepsSoFar : 700852
TimeSinceStart : 455.62393856048584
Done logging...



********** Iteration 173 ************

Collecting data for eval...
Eval_AverageReturn : 169.6666717529297
Eval_StdReturn : 12.036980628967285
Eval_MaxReturn : 181.0
Eval_MinReturn : 153.0
Eval_AverageEpLen : 169.66666666666666
Train_AverageReturn : 168.625
Train_StdReturn : 23.685108184814453
Train_MaxReturn : 200.0
Train_MinReturn : 130.0
Train_AverageEpLen : 168.625
Actor Loss : -241.35470581054688
Train_EnvstepsSoFar : 704899
TimeSinceStart : 458.83057856559753
Done logging...



********** Iteration 174 ************

Collecting data for eval...
Eval_AverageReturn : 177.0
Eval_StdReturn : 20.607440948486328
Eval_MaxReturn : 200.0
Eval_MinReturn : 150.0
Eval_AverageEpLen : 177.0
Train_AverageReturn : 169.3333282470703
Train_StdReturn : 24.786869049072266
Train_MaxReturn : 200.0
Train_MinReturn : 132.0
Train_AverageEpLen : 169.33333333333334
Actor Loss : -279.69195556640625
Train_EnvstepsSoFar : 708963
TimeSinceStart : 461.538188457489
Done logging...



********** Iteration 175 ************

Collecting data for eval...
Eval_AverageReturn : 169.6666717529297
Eval_StdReturn : 42.89781188964844
Eval_MaxReturn : 200.0
Eval_MinReturn : 109.0
Eval_AverageEpLen : 169.66666666666666
Train_AverageReturn : 155.53846740722656
Train_StdReturn : 24.665815353393555
Train_MaxReturn : 200.0
Train_MinReturn : 121.0
Train_AverageEpLen : 155.53846153846155
Actor Loss : -228.2253875732422
Train_EnvstepsSoFar : 713007
TimeSinceStart : 464.7229301929474
Done logging...



********** Iteration 176 ************

Collecting data for eval...
Eval_AverageReturn : 128.0
Eval_StdReturn : 41.575233459472656
Eval_MaxReturn : 200.0
Eval_MinReturn : 103.0
Eval_AverageEpLen : 128.0
Train_AverageReturn : 155.76922607421875
Train_StdReturn : 36.108070373535156
Train_MaxReturn : 200.0
Train_MinReturn : 99.0
Train_AverageEpLen : 155.76923076923077
Actor Loss : -259.94207763671875
Train_EnvstepsSoFar : 717057
TimeSinceStart : 468.1020429134369
Done logging...



********** Iteration 177 ************

Collecting data for eval...
Eval_AverageReturn : 109.75
Eval_StdReturn : 11.121488571166992
Eval_MaxReturn : 128.0
Eval_MinReturn : 99.0
Eval_AverageEpLen : 109.75
Train_AverageReturn : 144.2142791748047
Train_StdReturn : 39.8589973449707
Train_MaxReturn : 200.0
Train_MinReturn : 98.0
Train_AverageEpLen : 144.21428571428572
Actor Loss : -257.9261779785156
Train_EnvstepsSoFar : 721095
TimeSinceStart : 471.40869784355164
Done logging...



********** Iteration 178 ************

Collecting data for eval...
Eval_AverageReturn : 116.5
Eval_StdReturn : 48.3864631652832
Eval_MaxReturn : 200.0
Eval_MinReturn : 82.0
Eval_AverageEpLen : 116.5
Train_AverageReturn : 135.19354248046875
Train_StdReturn : 39.11061477661133
Train_MaxReturn : 200.0
Train_MinReturn : 79.0
Train_AverageEpLen : 135.19354838709677
Actor Loss : -218.4658660888672
Train_EnvstepsSoFar : 725286
TimeSinceStart : 474.3060142993927
Done logging...



********** Iteration 179 ************

Collecting data for eval...
Eval_AverageReturn : 124.0
Eval_StdReturn : 44.90545654296875
Eval_MaxReturn : 200.0
Eval_MinReturn : 85.0
Eval_AverageEpLen : 124.0
Train_AverageReturn : 134.7096710205078
Train_StdReturn : 41.924041748046875
Train_MaxReturn : 200.0
Train_MinReturn : 81.0
Train_AverageEpLen : 134.70967741935485
Actor Loss : -209.10943603515625
Train_EnvstepsSoFar : 729462
TimeSinceStart : 477.4348862171173
Done logging...



********** Iteration 180 ************

Collecting data for eval...
Eval_AverageReturn : 156.0
Eval_StdReturn : 62.22539520263672
Eval_MaxReturn : 200.0
Eval_MinReturn : 68.0
Eval_AverageEpLen : 156.0
Train_AverageReturn : 119.79412078857422
Train_StdReturn : 40.81938552856445
Train_MaxReturn : 200.0
Train_MinReturn : 67.0
Train_AverageEpLen : 119.79411764705883
Actor Loss : -209.4412841796875
Train_EnvstepsSoFar : 733535
TimeSinceStart : 480.5532488822937
Done logging...



********** Iteration 181 ************

Collecting data for eval...
Eval_AverageReturn : 109.75
Eval_StdReturn : 28.908260345458984
Eval_MaxReturn : 147.0
Eval_MinReturn : 67.0
Eval_AverageEpLen : 109.75
Train_AverageReturn : 126.28125
Train_StdReturn : 47.8338508605957
Train_MaxReturn : 200.0
Train_MinReturn : 60.0
Train_AverageEpLen : 126.28125
Actor Loss : -238.01780700683594
Train_EnvstepsSoFar : 737576
TimeSinceStart : 483.5920033454895
Done logging...



********** Iteration 182 ************

Collecting data for eval...
Eval_AverageReturn : 90.5999984741211
Eval_StdReturn : 13.937002182006836
Eval_MaxReturn : 104.0
Eval_MinReturn : 64.0
Eval_AverageEpLen : 90.6
Train_AverageReturn : 109.0540542602539
Train_StdReturn : 46.99738311767578
Train_MaxReturn : 200.0
Train_MinReturn : 60.0
Train_AverageEpLen : 109.05405405405405
Actor Loss : -223.26824951171875
Train_EnvstepsSoFar : 741611
TimeSinceStart : 486.911169052124
Done logging...



********** Iteration 183 ************

Collecting data for eval...
Eval_AverageReturn : 71.83333587646484
Eval_StdReturn : 17.276348114013672
Eval_MaxReturn : 103.0
Eval_MinReturn : 50.0
Eval_AverageEpLen : 71.83333333333333
Train_AverageReturn : 108.29729461669922
Train_StdReturn : 47.427249908447266
Train_MaxReturn : 200.0
Train_MinReturn : 53.0
Train_AverageEpLen : 108.29729729729729
Actor Loss : -227.49447631835938
Train_EnvstepsSoFar : 745618
TimeSinceStart : 490.11449933052063
Done logging...



********** Iteration 184 ************

Collecting data for eval...
Eval_AverageReturn : 109.0
Eval_StdReturn : 62.02015686035156
Eval_MaxReturn : 193.0
Eval_MinReturn : 46.0
Eval_AverageEpLen : 109.0
Train_AverageReturn : 120.23529052734375
Train_StdReturn : 51.73579025268555
Train_MaxReturn : 200.0
Train_MinReturn : 46.0
Train_AverageEpLen : 120.23529411764706
Actor Loss : -211.103271484375
Train_EnvstepsSoFar : 749706
TimeSinceStart : 493.3923041820526
Done logging...



********** Iteration 185 ************

Collecting data for eval...
Eval_AverageReturn : 104.75
Eval_StdReturn : 38.8675651550293
Eval_MaxReturn : 150.0
Eval_MinReturn : 54.0
Eval_AverageEpLen : 104.75
Train_AverageReturn : 107.60526275634766
Train_StdReturn : 46.4228515625
Train_MaxReturn : 200.0
Train_MinReturn : 38.0
Train_AverageEpLen : 107.60526315789474
Actor Loss : -188.50753784179688
Train_EnvstepsSoFar : 753795
TimeSinceStart : 497.1938056945801
Done logging...



********** Iteration 186 ************

Collecting data for eval...
Eval_AverageReturn : 81.4000015258789
Eval_StdReturn : 39.07735824584961
Eval_MaxReturn : 145.0
Eval_MinReturn : 36.0
Eval_AverageEpLen : 81.4
Train_AverageReturn : 97.20930480957031
Train_StdReturn : 49.49491882324219
Train_MaxReturn : 200.0
Train_MinReturn : 36.0
Train_AverageEpLen : 97.20930232558139
Actor Loss : -151.9632568359375
Train_EnvstepsSoFar : 757975
TimeSinceStart : 500.2965474128723
Done logging...



********** Iteration 187 ************

Collecting data for eval...
Eval_AverageReturn : 84.5999984741211
Eval_StdReturn : 25.491960525512695
Eval_MaxReturn : 111.0
Eval_MinReturn : 51.0
Eval_AverageEpLen : 84.6
Train_AverageReturn : 109.0540542602539
Train_StdReturn : 50.61457443237305
Train_MaxReturn : 200.0
Train_MinReturn : 36.0
Train_AverageEpLen : 109.05405405405405
Actor Loss : -132.16082763671875
Train_EnvstepsSoFar : 762010
TimeSinceStart : 503.6952576637268
Done logging...



********** Iteration 188 ************

Collecting data for eval...
Eval_AverageReturn : 101.0
Eval_StdReturn : 31.730112075805664
Eval_MaxReturn : 144.0
Eval_MinReturn : 57.0
Eval_AverageEpLen : 101.0
Train_AverageReturn : 108.29729461669922
Train_StdReturn : 50.1963005065918
Train_MaxReturn : 200.0
Train_MinReturn : 34.0
Train_AverageEpLen : 108.29729729729729
Actor Loss : -136.44400024414062
Train_EnvstepsSoFar : 766017
TimeSinceStart : 506.81981229782104
Done logging...



********** Iteration 189 ************

Collecting data for eval...
Eval_AverageReturn : 151.3333282470703
Eval_StdReturn : 51.54501724243164
Eval_MaxReturn : 200.0
Eval_MinReturn : 80.0
Eval_AverageEpLen : 151.33333333333334
Train_AverageReturn : 90.84782409667969
Train_StdReturn : 46.5827751159668
Train_MaxReturn : 200.0
Train_MinReturn : 29.0
Train_AverageEpLen : 90.84782608695652
Actor Loss : -167.20248413085938
Train_EnvstepsSoFar : 770196
TimeSinceStart : 510.2313675880432
Done logging...



********** Iteration 190 ************

Collecting data for eval...
Eval_AverageReturn : 116.75
Eval_StdReturn : 44.673118591308594
Eval_MaxReturn : 163.0
Eval_MinReturn : 56.0
Eval_AverageEpLen : 116.75
Train_AverageReturn : 92.19999694824219
Train_StdReturn : 42.302406311035156
Train_MaxReturn : 200.0
Train_MinReturn : 39.0
Train_AverageEpLen : 92.2
Actor Loss : -189.19119262695312
Train_EnvstepsSoFar : 774345
TimeSinceStart : 513.580160856247
Done logging...



********** Iteration 191 ************

Collecting data for eval...
Eval_AverageReturn : 124.25
Eval_StdReturn : 70.13691711425781
Eval_MaxReturn : 200.0
Eval_MinReturn : 46.0
Eval_AverageEpLen : 124.25
Train_AverageReturn : 122.30303192138672
Train_StdReturn : 51.78772735595703
Train_MaxReturn : 200.0
Train_MinReturn : 38.0
Train_AverageEpLen : 122.3030303030303
Actor Loss : -177.60174560546875
Train_EnvstepsSoFar : 778381
TimeSinceStart : 516.8353927135468
Done logging...



********** Iteration 192 ************

Collecting data for eval...
Eval_AverageReturn : 94.33333587646484
Eval_StdReturn : 57.904136657714844
Eval_MaxReturn : 200.0
Eval_MinReturn : 44.0
Eval_AverageEpLen : 94.33333333333333
Train_AverageReturn : 99.0243911743164
Train_StdReturn : 50.91719055175781
Train_MaxReturn : 200.0
Train_MinReturn : 31.0
Train_AverageEpLen : 99.02439024390245
Actor Loss : -237.41485595703125
Train_EnvstepsSoFar : 782441
TimeSinceStart : 519.6135659217834
Done logging...



********** Iteration 193 ************

Collecting data for eval...
Eval_AverageReturn : 134.0
Eval_StdReturn : 64.20280456542969
Eval_MaxReturn : 200.0
Eval_MinReturn : 47.0
Eval_AverageEpLen : 134.0
Train_AverageReturn : 120.20587921142578
Train_StdReturn : 58.315460205078125
Train_MaxReturn : 200.0
Train_MinReturn : 38.0
Train_AverageEpLen : 120.20588235294117
Actor Loss : -189.54754638671875
Train_EnvstepsSoFar : 786528
TimeSinceStart : 522.8810949325562
Done logging...



********** Iteration 194 ************

Collecting data for eval...
Eval_AverageReturn : 126.5
Eval_StdReturn : 54.039337158203125
Eval_MaxReturn : 200.0
Eval_MinReturn : 49.0
Eval_AverageEpLen : 126.5
Train_AverageReturn : 115.0
Train_StdReturn : 53.0692253112793
Train_MaxReturn : 200.0
Train_MinReturn : 44.0
Train_AverageEpLen : 115.0
Actor Loss : -187.07196044921875
Train_EnvstepsSoFar : 790553
TimeSinceStart : 527.620926618576
Done logging...



********** Iteration 195 ************

Collecting data for eval...
Eval_AverageReturn : 91.33333587646484
Eval_StdReturn : 41.60795974731445
Eval_MaxReturn : 168.0
Eval_MinReturn : 54.0
Eval_AverageEpLen : 91.33333333333333
Train_AverageReturn : 109.8108139038086
Train_StdReturn : 57.71122360229492
Train_MaxReturn : 200.0
Train_MinReturn : 47.0
Train_AverageEpLen : 109.8108108108108
Actor Loss : -247.89425659179688
Train_EnvstepsSoFar : 794616
TimeSinceStart : 530.8827924728394
Done logging...



********** Iteration 196 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 115.31428527832031
Train_StdReturn : 52.109100341796875
Train_MaxReturn : 200.0
Train_MinReturn : 38.0
Train_AverageEpLen : 115.31428571428572
Actor Loss : -147.00881958007812
Train_EnvstepsSoFar : 798652
TimeSinceStart : 534.1518704891205
Done logging...



********** Iteration 197 ************

Collecting data for eval...
Eval_AverageReturn : 156.3333282470703
Eval_StdReturn : 18.6964054107666
Eval_MaxReturn : 182.0
Eval_MinReturn : 138.0
Eval_AverageEpLen : 156.33333333333334
Train_AverageReturn : 115.85713958740234
Train_StdReturn : 53.69445037841797
Train_MaxReturn : 200.0
Train_MinReturn : 44.0
Train_AverageEpLen : 115.85714285714286
Actor Loss : -240.12783813476562
Train_EnvstepsSoFar : 802707
TimeSinceStart : 537.1675095558167
Done logging...



********** Iteration 198 ************

Collecting data for eval...
Eval_AverageReturn : 100.25
Eval_StdReturn : 58.98463821411133
Eval_MaxReturn : 200.0
Eval_MinReturn : 52.0
Eval_AverageEpLen : 100.25
Train_AverageReturn : 125.81818389892578
Train_StdReturn : 62.64060592651367
Train_MaxReturn : 200.0
Train_MinReturn : 38.0
Train_AverageEpLen : 125.81818181818181
Actor Loss : -258.6958312988281
Train_EnvstepsSoFar : 806859
TimeSinceStart : 540.4514067173004
Done logging...



********** Iteration 199 ************

Collecting data for eval...
Eval_AverageReturn : 112.5999984741211
Eval_StdReturn : 61.61363220214844
Eval_MaxReturn : 199.0
Eval_MinReturn : 46.0
Eval_AverageEpLen : 112.6
Train_AverageReturn : 117.97058868408203
Train_StdReturn : 57.575775146484375
Train_MaxReturn : 200.0
Train_MinReturn : 42.0
Train_AverageEpLen : 117.97058823529412
Actor Loss : -228.83251953125
Train_EnvstepsSoFar : 810870
TimeSinceStart : 543.5847249031067
Done logging...



********** Iteration 200 ************

Collecting data for eval...
Eval_AverageReturn : 126.5
Eval_StdReturn : 35.80851745605469
Eval_MaxReturn : 153.0
Eval_MinReturn : 65.0
Eval_AverageEpLen : 126.5
Train_AverageReturn : 133.25807189941406
Train_StdReturn : 55.80205154418945
Train_MaxReturn : 200.0
Train_MinReturn : 49.0
Train_AverageEpLen : 133.25806451612902
Actor Loss : -183.3251190185547
Train_EnvstepsSoFar : 815001
TimeSinceStart : 548.3865911960602
Done logging...



********** Iteration 201 ************

Collecting data for eval...
Eval_AverageReturn : 142.0
Eval_StdReturn : 46.968074798583984
Eval_MaxReturn : 200.0
Eval_MinReturn : 90.0
Eval_AverageEpLen : 142.0
Train_AverageReturn : 120.38235473632812
Train_StdReturn : 57.80546188354492
Train_MaxReturn : 200.0
Train_MinReturn : 31.0
Train_AverageEpLen : 120.38235294117646
Actor Loss : -184.60479736328125
Train_EnvstepsSoFar : 819094
TimeSinceStart : 550.9557974338531
Done logging...



********** Iteration 202 ************

Collecting data for eval...
Eval_AverageReturn : 111.5
Eval_StdReturn : 45.855751037597656
Eval_MaxReturn : 169.0
Eval_MinReturn : 53.0
Eval_AverageEpLen : 111.5
Train_AverageReturn : 108.21621704101562
Train_StdReturn : 49.951942443847656
Train_MaxReturn : 200.0
Train_MinReturn : 43.0
Train_AverageEpLen : 108.21621621621621
Actor Loss : -162.25753784179688
Train_EnvstepsSoFar : 823098
TimeSinceStart : 553.7236895561218
Done logging...



********** Iteration 203 ************

Collecting data for eval...
Eval_AverageReturn : 156.3333282470703
Eval_StdReturn : 56.19213104248047
Eval_MaxReturn : 200.0
Eval_MinReturn : 77.0
Eval_AverageEpLen : 156.33333333333334
Train_AverageReturn : 109.1351318359375
Train_StdReturn : 58.763916015625
Train_MaxReturn : 200.0
Train_MinReturn : 37.0
Train_AverageEpLen : 109.13513513513513
Actor Loss : -211.86123657226562
Train_EnvstepsSoFar : 827136
TimeSinceStart : 556.2341504096985
Done logging...



********** Iteration 204 ************

Collecting data for eval...
Eval_AverageReturn : 88.4000015258789
Eval_StdReturn : 41.55767059326172
Eval_MaxReturn : 164.0
Eval_MinReturn : 49.0
Eval_AverageEpLen : 88.4
Train_AverageReturn : 94.13953399658203
Train_StdReturn : 44.25801086425781
Train_MaxReturn : 200.0
Train_MinReturn : 33.0
Train_AverageEpLen : 94.13953488372093
Actor Loss : -201.88206481933594
Train_EnvstepsSoFar : 831184
TimeSinceStart : 558.7341477870941
Done logging...



********** Iteration 205 ************

Collecting data for eval...
Eval_AverageReturn : 81.5999984741211
Eval_StdReturn : 17.18836784362793
Eval_MaxReturn : 109.0
Eval_MinReturn : 55.0
Eval_AverageEpLen : 81.6
Train_AverageReturn : 96.9047622680664
Train_StdReturn : 52.51340103149414
Train_MaxReturn : 200.0
Train_MinReturn : 32.0
Train_AverageEpLen : 96.9047619047619
Actor Loss : -246.67266845703125
Train_EnvstepsSoFar : 835254
TimeSinceStart : 562.727710723877
Done logging...



********** Iteration 206 ************

Collecting data for eval...
Eval_AverageReturn : 104.5
Eval_StdReturn : 56.38040542602539
Eval_MaxReturn : 200.0
Eval_MinReturn : 54.0
Eval_AverageEpLen : 104.5
Train_AverageReturn : 101.4749984741211
Train_StdReturn : 47.56731414794922
Train_MaxReturn : 200.0
Train_MinReturn : 45.0
Train_AverageEpLen : 101.475
Actor Loss : -272.3355407714844
Train_EnvstepsSoFar : 839313
TimeSinceStart : 565.1787712574005
Done logging...



********** Iteration 207 ************

Collecting data for eval...
Eval_AverageReturn : 145.5
Eval_StdReturn : 54.95680236816406
Eval_MaxReturn : 200.0
Eval_MinReturn : 81.0
Eval_AverageEpLen : 145.5
Train_AverageReturn : 107.0
Train_StdReturn : 43.6408805847168
Train_MaxReturn : 200.0
Train_MinReturn : 39.0
Train_AverageEpLen : 107.0
Actor Loss : -222.0298309326172
Train_EnvstepsSoFar : 843379
TimeSinceStart : 567.7325608730316
Done logging...



********** Iteration 208 ************

Collecting data for eval...
Eval_AverageReturn : 158.6666717529297
Eval_StdReturn : 58.45416259765625
Eval_MaxReturn : 200.0
Eval_MinReturn : 76.0
Eval_AverageEpLen : 158.66666666666666
Train_AverageReturn : 115.22856903076172
Train_StdReturn : 50.787559509277344
Train_MaxReturn : 200.0
Train_MinReturn : 55.0
Train_AverageEpLen : 115.22857142857143
Actor Loss : -319.973876953125
Train_EnvstepsSoFar : 847412
TimeSinceStart : 571.771077632904
Done logging...



********** Iteration 209 ************

Collecting data for eval...
Eval_AverageReturn : 88.0
Eval_StdReturn : 24.947946548461914
Eval_MaxReturn : 137.0
Eval_MinReturn : 67.0
Eval_AverageEpLen : 88.0
Train_AverageReturn : 113.61111450195312
Train_StdReturn : 48.77002716064453
Train_MaxReturn : 200.0
Train_MinReturn : 60.0
Train_AverageEpLen : 113.61111111111111
Actor Loss : -307.65740966796875
Train_EnvstepsSoFar : 851502
TimeSinceStart : 577.0903644561768
Done logging...



********** Iteration 210 ************

Collecting data for eval...
Eval_AverageReturn : 82.0
Eval_StdReturn : 16.08311653137207
Eval_MaxReturn : 113.0
Eval_MinReturn : 67.0
Eval_AverageEpLen : 82.0
Train_AverageReturn : 102.19999694824219
Train_StdReturn : 36.79347610473633
Train_MaxReturn : 200.0
Train_MinReturn : 64.0
Train_AverageEpLen : 102.2
Actor Loss : -210.90603637695312
Train_EnvstepsSoFar : 855590
TimeSinceStart : 579.730751991272
Done logging...



********** Iteration 211 ************

Collecting data for eval...
Eval_AverageReturn : 109.5
Eval_StdReturn : 30.826126098632812
Eval_MaxReturn : 162.0
Eval_MinReturn : 83.0
Eval_AverageEpLen : 109.5
Train_AverageReturn : 109.24324035644531
Train_StdReturn : 36.04082107543945
Train_MaxReturn : 200.0
Train_MinReturn : 68.0
Train_AverageEpLen : 109.24324324324324
Actor Loss : -249.26504516601562
Train_EnvstepsSoFar : 859632
TimeSinceStart : 582.2453737258911
Done logging...



********** Iteration 212 ************

Collecting data for eval...
Eval_AverageReturn : 89.4000015258789
Eval_StdReturn : 17.995553970336914
Eval_MaxReturn : 112.0
Eval_MinReturn : 69.0
Eval_AverageEpLen : 89.4
Train_AverageReturn : 109.48648834228516
Train_StdReturn : 38.1912841796875
Train_MaxReturn : 200.0
Train_MinReturn : 70.0
Train_AverageEpLen : 109.48648648648648
Actor Loss : -290.4248962402344
Train_EnvstepsSoFar : 863683
TimeSinceStart : 584.7784509658813
Done logging...



********** Iteration 213 ************

Collecting data for eval...
Eval_AverageReturn : 110.75
Eval_StdReturn : 26.195180892944336
Eval_MaxReturn : 155.0
Eval_MinReturn : 87.0
Eval_AverageEpLen : 110.75
Train_AverageReturn : 109.8108139038086
Train_StdReturn : 38.83077621459961
Train_MaxReturn : 200.0
Train_MinReturn : 67.0
Train_AverageEpLen : 109.8108108108108
Actor Loss : -267.15374755859375
Train_EnvstepsSoFar : 867746
TimeSinceStart : 587.3176493644714
Done logging...



********** Iteration 214 ************

Collecting data for eval...
Eval_AverageReturn : 118.75
Eval_StdReturn : 41.08755874633789
Eval_MaxReturn : 181.0
Eval_MinReturn : 77.0
Eval_AverageEpLen : 118.75
Train_AverageReturn : 106.68421173095703
Train_StdReturn : 42.55034637451172
Train_MaxReturn : 200.0
Train_MinReturn : 67.0
Train_AverageEpLen : 106.6842105263158
Actor Loss : -359.3564453125
Train_EnvstepsSoFar : 871800
TimeSinceStart : 589.8269076347351
Done logging...



********** Iteration 215 ************

Collecting data for eval...
Eval_AverageReturn : 95.80000305175781
Eval_StdReturn : 49.563697814941406
Eval_MaxReturn : 177.0
Eval_MinReturn : 23.0
Eval_AverageEpLen : 95.8
Train_AverageReturn : 78.7254867553711
Train_StdReturn : 30.198740005493164
Train_MaxReturn : 200.0
Train_MinReturn : 23.0
Train_AverageEpLen : 78.72549019607843
Actor Loss : -188.36849975585938
Train_EnvstepsSoFar : 875815
TimeSinceStart : 592.3188645839691
Done logging...



********** Iteration 216 ************

Collecting data for eval...
Eval_AverageReturn : 101.5
Eval_StdReturn : 77.78335571289062
Eval_MaxReturn : 200.0
Eval_MinReturn : 19.0
Eval_AverageEpLen : 101.5
Train_AverageReturn : 93.27906799316406
Train_StdReturn : 42.290977478027344
Train_MaxReturn : 200.0
Train_MinReturn : 26.0
Train_AverageEpLen : 93.27906976744185
Actor Loss : -267.6444396972656
Train_EnvstepsSoFar : 879826
TimeSinceStart : 594.7757089138031
Done logging...



********** Iteration 217 ************

Collecting data for eval...
Eval_AverageReturn : 134.0
Eval_StdReturn : 46.73328399658203
Eval_MaxReturn : 200.0
Eval_MinReturn : 98.0
Eval_AverageEpLen : 134.0
Train_AverageReturn : 89.75555419921875
Train_StdReturn : 46.78231430053711
Train_MaxReturn : 200.0
Train_MinReturn : 22.0
Train_AverageEpLen : 89.75555555555556
Actor Loss : -254.56268310546875
Train_EnvstepsSoFar : 883865
TimeSinceStart : 597.5292716026306
Done logging...



********** Iteration 218 ************

Collecting data for eval...
Eval_AverageReturn : 145.6666717529297
Eval_StdReturn : 38.784305572509766
Eval_MaxReturn : 200.0
Eval_MinReturn : 112.0
Eval_AverageEpLen : 145.66666666666666
Train_AverageReturn : 110.59459686279297
Train_StdReturn : 46.30595397949219
Train_MaxReturn : 200.0
Train_MinReturn : 21.0
Train_AverageEpLen : 110.5945945945946
Actor Loss : -303.34393310546875
Train_EnvstepsSoFar : 887957
TimeSinceStart : 603.0243632793427
Done logging...



********** Iteration 219 ************

Collecting data for eval...
Eval_AverageReturn : 89.0
Eval_StdReturn : 30.44995880126953
Eval_MaxReturn : 118.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 89.0
Train_AverageReturn : 110.51351165771484
Train_StdReturn : 45.01749038696289
Train_MaxReturn : 200.0
Train_MinReturn : 21.0
Train_AverageEpLen : 110.51351351351352
Actor Loss : -294.6309509277344
Train_EnvstepsSoFar : 892046
TimeSinceStart : 606.137366771698
Done logging...



********** Iteration 220 ************

Collecting data for eval...
Eval_AverageReturn : 163.6666717529297
Eval_StdReturn : 11.585432052612305
Eval_MaxReturn : 179.0
Eval_MinReturn : 151.0
Eval_AverageEpLen : 163.66666666666666
Train_AverageReturn : 109.56756591796875
Train_StdReturn : 47.06093978881836
Train_MaxReturn : 200.0
Train_MinReturn : 24.0
Train_AverageEpLen : 109.56756756756756
Actor Loss : -214.27658081054688
Train_EnvstepsSoFar : 896100
TimeSinceStart : 609.4435222148895
Done logging...



********** Iteration 221 ************

Collecting data for eval...
Eval_AverageReturn : 133.3333282470703
Eval_StdReturn : 37.2409553527832
Eval_MaxReturn : 186.0
Eval_MinReturn : 107.0
Eval_AverageEpLen : 133.33333333333334
Train_AverageReturn : 122.33333587646484
Train_StdReturn : 39.122703552246094
Train_MaxReturn : 200.0
Train_MinReturn : 31.0
Train_AverageEpLen : 122.33333333333333
Actor Loss : -181.40762329101562
Train_EnvstepsSoFar : 900137
TimeSinceStart : 612.4572894573212
Done logging...



********** Iteration 222 ************

Collecting data for eval...
Eval_AverageReturn : 103.0
Eval_StdReturn : 21.01190185546875
Eval_MaxReturn : 124.0
Eval_MinReturn : 76.0
Eval_AverageEpLen : 103.0
Train_AverageReturn : 110.0540542602539
Train_StdReturn : 44.60453414916992
Train_MaxReturn : 200.0
Train_MinReturn : 35.0
Train_AverageEpLen : 110.05405405405405
Actor Loss : -149.19793701171875
Train_EnvstepsSoFar : 904209
TimeSinceStart : 615.635801076889
Done logging...



********** Iteration 223 ************

Collecting data for eval...
Eval_AverageReturn : 166.0
Eval_StdReturn : 25.66450309753418
Eval_MaxReturn : 200.0
Eval_MinReturn : 138.0
Eval_AverageEpLen : 166.0
Train_AverageReturn : 122.54545593261719
Train_StdReturn : 52.95228576660156
Train_MaxReturn : 200.0
Train_MinReturn : 27.0
Train_AverageEpLen : 122.54545454545455
Actor Loss : -204.30755615234375
Train_EnvstepsSoFar : 908253
TimeSinceStart : 618.7748260498047
Done logging...



********** Iteration 224 ************

Collecting data for eval...
Eval_AverageReturn : 89.0
Eval_StdReturn : 60.84406280517578
Eval_MaxReturn : 200.0
Eval_MinReturn : 27.0
Eval_AverageEpLen : 89.0
Train_AverageReturn : 134.60000610351562
Train_StdReturn : 41.19271469116211
Train_MaxReturn : 200.0
Train_MinReturn : 25.0
Train_AverageEpLen : 134.6
Actor Loss : -329.64776611328125
Train_EnvstepsSoFar : 912291
TimeSinceStart : 621.4992983341217
Done logging...



********** Iteration 225 ************

Collecting data for eval...
Eval_AverageReturn : 101.25
Eval_StdReturn : 61.77934646606445
Eval_MaxReturn : 200.0
Eval_MinReturn : 30.0
Eval_AverageEpLen : 101.25
Train_AverageReturn : 128.6875
Train_StdReturn : 52.354820251464844
Train_MaxReturn : 200.0
Train_MinReturn : 20.0
Train_AverageEpLen : 128.6875
Actor Loss : -259.06439208984375
Train_EnvstepsSoFar : 916409
TimeSinceStart : 624.0998783111572
Done logging...



********** Iteration 226 ************

Collecting data for eval...
Eval_AverageReturn : 179.0
Eval_StdReturn : 29.698484420776367
Eval_MaxReturn : 200.0
Eval_MinReturn : 137.0
Eval_AverageEpLen : 179.0
Train_AverageReturn : 138.96551513671875
Train_StdReturn : 53.387638092041016
Train_MaxReturn : 200.0
Train_MinReturn : 35.0
Train_AverageEpLen : 138.9655172413793
Actor Loss : -267.1692810058594
Train_EnvstepsSoFar : 920439
TimeSinceStart : 626.859855890274
Done logging...



********** Iteration 227 ************

Collecting data for eval...
Eval_AverageReturn : 141.0
Eval_StdReturn : 58.086143493652344
Eval_MaxReturn : 200.0
Eval_MinReturn : 62.0
Eval_AverageEpLen : 141.0
Train_AverageReturn : 141.72413635253906
Train_StdReturn : 60.44370651245117
Train_MaxReturn : 200.0
Train_MinReturn : 29.0
Train_AverageEpLen : 141.72413793103448
Actor Loss : -312.1732482910156
Train_EnvstepsSoFar : 924549
TimeSinceStart : 629.5933883190155
Done logging...



********** Iteration 228 ************

Collecting data for eval...
Eval_AverageReturn : 171.3333282470703
Eval_StdReturn : 40.54079055786133
Eval_MaxReturn : 200.0
Eval_MinReturn : 114.0
Eval_AverageEpLen : 171.33333333333334
Train_AverageReturn : 144.57142639160156
Train_StdReturn : 62.14408874511719
Train_MaxReturn : 200.0
Train_MinReturn : 30.0
Train_AverageEpLen : 144.57142857142858
Actor Loss : -347.0482177734375
Train_EnvstepsSoFar : 928597
TimeSinceStart : 632.7521080970764
Done logging...



********** Iteration 229 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 186.68182373046875
Train_StdReturn : 24.495615005493164
Train_MaxReturn : 200.0
Train_MinReturn : 117.0
Train_AverageEpLen : 186.6818181818182
Actor Loss : -336.3126220703125
Train_EnvstepsSoFar : 932704
TimeSinceStart : 635.609402179718
Done logging...



********** Iteration 230 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 174.69564819335938
Train_StdReturn : 34.90911865234375
Train_MaxReturn : 200.0
Train_MinReturn : 55.0
Train_AverageEpLen : 174.69565217391303
Actor Loss : -292.2068176269531
Train_EnvstepsSoFar : 936722
TimeSinceStart : 638.5684757232666
Done logging...



********** Iteration 231 ************

Collecting data for eval...
Eval_AverageReturn : 146.3333282470703
Eval_StdReturn : 54.847259521484375
Eval_MaxReturn : 200.0
Eval_MinReturn : 71.0
Eval_AverageEpLen : 146.33333333333334
Train_AverageReturn : 178.9130401611328
Train_StdReturn : 45.02455139160156
Train_MaxReturn : 200.0
Train_MinReturn : 44.0
Train_AverageEpLen : 178.91304347826087
Actor Loss : -224.38584899902344
Train_EnvstepsSoFar : 940837
TimeSinceStart : 641.1673762798309
Done logging...



********** Iteration 232 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 182.4545440673828
Train_StdReturn : 41.4375
Train_MaxReturn : 200.0
Train_MinReturn : 41.0
Train_AverageEpLen : 182.45454545454547
Actor Loss : -191.07351684570312
Train_EnvstepsSoFar : 944851
TimeSinceStart : 643.7001543045044
Done logging...



********** Iteration 233 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 171.0833282470703
Train_StdReturn : 50.30897521972656
Train_MaxReturn : 200.0
Train_MinReturn : 41.0
Train_AverageEpLen : 171.08333333333334
Actor Loss : -199.20460510253906
Train_EnvstepsSoFar : 948957
TimeSinceStart : 646.7546648979187
Done logging...



********** Iteration 234 ************

Collecting data for eval...
Eval_AverageReturn : 173.0
Eval_StdReturn : 38.18376541137695
Eval_MaxReturn : 200.0
Eval_MinReturn : 119.0
Eval_AverageEpLen : 173.0
Train_AverageReturn : 147.67857360839844
Train_StdReturn : 54.17765426635742
Train_MaxReturn : 200.0
Train_MinReturn : 35.0
Train_AverageEpLen : 147.67857142857142
Actor Loss : -218.515625
Train_EnvstepsSoFar : 953092
TimeSinceStart : 649.7562067508698
Done logging...



********** Iteration 235 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 125.84375
Train_StdReturn : 67.18217468261719
Train_MaxReturn : 200.0
Train_MinReturn : 30.0
Train_AverageEpLen : 125.84375
Actor Loss : -226.82733154296875
Train_EnvstepsSoFar : 957119
TimeSinceStart : 652.4958555698395
Done logging...



********** Iteration 236 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 130.09375
Train_StdReturn : 64.861083984375
Train_MaxReturn : 200.0
Train_MinReturn : 35.0
Train_AverageEpLen : 130.09375
Actor Loss : -203.68853759765625
Train_EnvstepsSoFar : 961282
TimeSinceStart : 655.0673294067383
Done logging...



********** Iteration 237 ************

Collecting data for eval...
Eval_AverageReturn : 162.6666717529297
Eval_StdReturn : 52.797306060791016
Eval_MaxReturn : 200.0
Eval_MinReturn : 88.0
Eval_AverageEpLen : 162.66666666666666
Train_AverageReturn : 182.13636779785156
Train_StdReturn : 35.404541015625
Train_MaxReturn : 200.0
Train_MinReturn : 70.0
Train_AverageEpLen : 182.13636363636363
Actor Loss : -84.38573455810547
Train_EnvstepsSoFar : 965289
TimeSinceStart : 658.3878054618835
Done logging...



********** Iteration 238 ************

Collecting data for eval...
Eval_AverageReturn : 161.6666717529297
Eval_StdReturn : 54.21152114868164
Eval_MaxReturn : 200.0
Eval_MinReturn : 85.0
Eval_AverageEpLen : 161.66666666666666
Train_AverageReturn : 169.7916717529297
Train_StdReturn : 59.089603424072266
Train_MaxReturn : 200.0
Train_MinReturn : 46.0
Train_AverageEpLen : 169.79166666666666
Actor Loss : -185.53884887695312
Train_EnvstepsSoFar : 969364
TimeSinceStart : 661.1795485019684
Done logging...



********** Iteration 239 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 138.1999969482422
Train_StdReturn : 61.292415618896484
Train_MaxReturn : 200.0
Train_MinReturn : 42.0
Train_AverageEpLen : 138.2
Actor Loss : -349.22686767578125
Train_EnvstepsSoFar : 973510
TimeSinceStart : 664.1154844760895
Done logging...



********** Iteration 240 ************

Collecting data for eval...
Eval_AverageReturn : 180.3333282470703
Eval_StdReturn : 17.249799728393555
Eval_MaxReturn : 200.0
Eval_MinReturn : 158.0
Eval_AverageEpLen : 180.33333333333334
Train_AverageReturn : 180.43478393554688
Train_StdReturn : 39.273651123046875
Train_MaxReturn : 200.0
Train_MinReturn : 80.0
Train_AverageEpLen : 180.43478260869566
Actor Loss : -203.2409210205078
Train_EnvstepsSoFar : 977660
TimeSinceStart : 666.9087929725647
Done logging...



********** Iteration 241 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 195.5238037109375
Train_StdReturn : 15.032088279724121
Train_MaxReturn : 200.0
Train_MinReturn : 133.0
Train_AverageEpLen : 195.52380952380952
Actor Loss : -102.77470397949219
Train_EnvstepsSoFar : 981766
TimeSinceStart : 669.657306432724
Done logging...



********** Iteration 242 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 194.38095092773438
Train_StdReturn : 10.63003921508789
Train_MaxReturn : 200.0
Train_MinReturn : 166.0
Train_AverageEpLen : 194.38095238095238
Actor Loss : -344.15447998046875
Train_EnvstepsSoFar : 985848
TimeSinceStart : 672.5124931335449
Done logging...



********** Iteration 243 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 193.6666717529297
Train_StdReturn : 11.192400932312012
Train_MaxReturn : 200.0
Train_MinReturn : 163.0
Train_AverageEpLen : 193.66666666666666
Actor Loss : -368.668212890625
Train_EnvstepsSoFar : 989915
TimeSinceStart : 675.6855909824371
Done logging...



********** Iteration 244 ************

Collecting data for eval...
Eval_AverageReturn : 178.3333282470703
Eval_StdReturn : 21.51485252380371
Eval_MaxReturn : 200.0
Eval_MinReturn : 149.0
Eval_AverageEpLen : 178.33333333333334
Train_AverageReturn : 193.61904907226562
Train_StdReturn : 16.46489906311035
Train_MaxReturn : 200.0
Train_MinReturn : 136.0
Train_AverageEpLen : 193.61904761904762
Actor Loss : -258.77691650390625
Train_EnvstepsSoFar : 993981
TimeSinceStart : 678.4551017284393
Done logging...



********** Iteration 245 ************

Collecting data for eval...
Eval_AverageReturn : 181.3333282470703
Eval_StdReturn : 26.398653030395508
Eval_MaxReturn : 200.0
Eval_MinReturn : 144.0
Eval_AverageEpLen : 181.33333333333334
Train_AverageReturn : 193.7142791748047
Train_StdReturn : 13.35644245147705
Train_MaxReturn : 200.0
Train_MinReturn : 152.0
Train_AverageEpLen : 193.71428571428572
Actor Loss : -242.71890258789062
Train_EnvstepsSoFar : 998049
TimeSinceStart : 681.5258049964905
Done logging...



********** Iteration 246 ************

Collecting data for eval...
Eval_AverageReturn : 165.3333282470703
Eval_StdReturn : 25.170528411865234
Eval_MaxReturn : 200.0
Eval_MinReturn : 141.0
Eval_AverageEpLen : 165.33333333333334
Train_AverageReturn : 178.86956787109375
Train_StdReturn : 34.30465316772461
Train_MaxReturn : 200.0
Train_MinReturn : 103.0
Train_AverageEpLen : 178.8695652173913
Actor Loss : -417.9541015625
Train_EnvstepsSoFar : 1002163
TimeSinceStart : 684.4728872776031
Done logging...



********** Iteration 247 ************

Collecting data for eval...
Eval_AverageReturn : 134.6666717529297
Eval_StdReturn : 46.226497650146484
Eval_MaxReturn : 200.0
Eval_MinReturn : 100.0
Eval_AverageEpLen : 134.66666666666666
Train_AverageReturn : 156.96153259277344
Train_StdReturn : 48.69645309448242
Train_MaxReturn : 200.0
Train_MinReturn : 43.0
Train_AverageEpLen : 156.96153846153845
Actor Loss : -349.3156433105469
Train_EnvstepsSoFar : 1006244
TimeSinceStart : 687.0937881469727
Done logging...



********** Iteration 248 ************

Collecting data for eval...
Eval_AverageReturn : 139.25
Eval_StdReturn : 62.79878616333008
Eval_MaxReturn : 200.0
Eval_MinReturn : 56.0
Eval_AverageEpLen : 139.25
Train_AverageReturn : 145.67857360839844
Train_StdReturn : 54.302757263183594
Train_MaxReturn : 200.0
Train_MinReturn : 39.0
Train_AverageEpLen : 145.67857142857142
Actor Loss : -371.3509521484375
Train_EnvstepsSoFar : 1010323
TimeSinceStart : 691.6226096153259
Done logging...



********** Iteration 249 ************

Collecting data for eval...
Eval_AverageReturn : 169.0
Eval_StdReturn : 33.17629623413086
Eval_MaxReturn : 200.0
Eval_MinReturn : 123.0
Eval_AverageEpLen : 169.0
Train_AverageReturn : 159.53846740722656
Train_StdReturn : 50.248023986816406
Train_MaxReturn : 200.0
Train_MinReturn : 40.0
Train_AverageEpLen : 159.53846153846155
Actor Loss : -322.12506103515625
Train_EnvstepsSoFar : 1014471
TimeSinceStart : 695.1357653141022
Done logging...



********** Iteration 250 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 153.92591857910156
Train_StdReturn : 54.49833679199219
Train_MaxReturn : 200.0
Train_MinReturn : 56.0
Train_AverageEpLen : 153.92592592592592
Actor Loss : -375.504150390625
Train_EnvstepsSoFar : 1018627
TimeSinceStart : 697.783611536026
Done logging...



********** Iteration 251 ************

Collecting data for eval...
Eval_AverageReturn : 162.0
Eval_StdReturn : 53.740116119384766
Eval_MaxReturn : 200.0
Eval_MinReturn : 86.0
Eval_AverageEpLen : 162.0
Train_AverageReturn : 152.3333282470703
Train_StdReturn : 50.5766716003418
Train_MaxReturn : 200.0
Train_MinReturn : 48.0
Train_AverageEpLen : 152.33333333333334
Actor Loss : -357.45684814453125
Train_EnvstepsSoFar : 1022740
TimeSinceStart : 700.3265907764435
Done logging...



********** Iteration 252 ************

Collecting data for eval...
Eval_AverageReturn : 168.6666717529297
Eval_StdReturn : 44.3120231628418
Eval_MaxReturn : 200.0
Eval_MinReturn : 106.0
Eval_AverageEpLen : 168.66666666666666
Train_AverageReturn : 154.46153259277344
Train_StdReturn : 51.39606857299805
Train_MaxReturn : 200.0
Train_MinReturn : 52.0
Train_AverageEpLen : 154.46153846153845
Actor Loss : -354.11883544921875
Train_EnvstepsSoFar : 1026756
TimeSinceStart : 703.4036269187927
Done logging...



********** Iteration 253 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 164.0
Train_StdReturn : 40.407920837402344
Train_MaxReturn : 200.0
Train_MinReturn : 79.0
Train_AverageEpLen : 164.0
Actor Loss : -349.4151916503906
Train_EnvstepsSoFar : 1030856
TimeSinceStart : 706.7175161838531
Done logging...



********** Iteration 254 ************

Collecting data for eval...
Eval_AverageReturn : 181.0
Eval_StdReturn : 26.870058059692383
Eval_MaxReturn : 200.0
Eval_MinReturn : 143.0
Eval_AverageEpLen : 181.0
Train_AverageReturn : 151.9629669189453
Train_StdReturn : 46.33891296386719
Train_MaxReturn : 200.0
Train_MinReturn : 51.0
Train_AverageEpLen : 151.96296296296296
Actor Loss : -426.634033203125
Train_EnvstepsSoFar : 1034959
TimeSinceStart : 712.9085803031921
Done logging...



********** Iteration 255 ************

Collecting data for eval...
Eval_AverageReturn : 181.3333282470703
Eval_StdReturn : 26.398653030395508
Eval_MaxReturn : 200.0
Eval_MinReturn : 144.0
Eval_AverageEpLen : 181.33333333333334
Train_AverageReturn : 158.88461303710938
Train_StdReturn : 40.700904846191406
Train_MaxReturn : 200.0
Train_MinReturn : 63.0
Train_AverageEpLen : 158.8846153846154
Actor Loss : -411.82000732421875
Train_EnvstepsSoFar : 1039090
TimeSinceStart : 715.5263888835907
Done logging...



********** Iteration 256 ************

Collecting data for eval...
Eval_AverageReturn : 148.0
Eval_StdReturn : 25.139610290527344
Eval_MaxReturn : 182.0
Eval_MinReturn : 122.0
Eval_AverageEpLen : 148.0
Train_AverageReturn : 175.43478393554688
Train_StdReturn : 31.528902053833008
Train_MaxReturn : 200.0
Train_MinReturn : 97.0
Train_AverageEpLen : 175.43478260869566
Actor Loss : -476.9331970214844
Train_EnvstepsSoFar : 1043125
TimeSinceStart : 718.4463248252869
Done logging...



********** Iteration 257 ************

Collecting data for eval...
Eval_AverageReturn : 149.25
Eval_StdReturn : 54.34783935546875
Eval_MaxReturn : 200.0
Eval_MinReturn : 71.0
Eval_AverageEpLen : 149.25
Train_AverageReturn : 181.9130401611328
Train_StdReturn : 31.740680694580078
Train_MaxReturn : 200.0
Train_MinReturn : 102.0
Train_AverageEpLen : 181.91304347826087
Actor Loss : -327.81317138671875
Train_EnvstepsSoFar : 1047309
TimeSinceStart : 721.6862192153931
Done logging...



********** Iteration 258 ************

Collecting data for eval...
Eval_AverageReturn : 138.25
Eval_StdReturn : 47.782711029052734
Eval_MaxReturn : 200.0
Eval_MinReturn : 77.0
Eval_AverageEpLen : 138.25
Train_AverageReturn : 158.11538696289062
Train_StdReturn : 52.088924407958984
Train_MaxReturn : 200.0
Train_MinReturn : 56.0
Train_AverageEpLen : 158.1153846153846
Actor Loss : -337.8846130371094
Train_EnvstepsSoFar : 1051420
TimeSinceStart : 724.2596280574799
Done logging...



********** Iteration 259 ************

Collecting data for eval...
Eval_AverageReturn : 148.0
Eval_StdReturn : 62.09669876098633
Eval_MaxReturn : 200.0
Eval_MinReturn : 48.0
Eval_AverageEpLen : 148.0
Train_AverageReturn : 139.96551513671875
Train_StdReturn : 59.646942138671875
Train_MaxReturn : 200.0
Train_MinReturn : 54.0
Train_AverageEpLen : 139.9655172413793
Actor Loss : -367.58770751953125
Train_EnvstepsSoFar : 1055479
TimeSinceStart : 727.3906226158142
Done logging...



********** Iteration 260 ************

Collecting data for eval...
Eval_AverageReturn : 148.0
Eval_StdReturn : 57.41080093383789
Eval_MaxReturn : 200.0
Eval_MinReturn : 68.0
Eval_AverageEpLen : 148.0
Train_AverageReturn : 127.40625
Train_StdReturn : 57.09195327758789
Train_MaxReturn : 200.0
Train_MinReturn : 48.0
Train_AverageEpLen : 127.40625
Actor Loss : -364.1051330566406
Train_EnvstepsSoFar : 1059556
TimeSinceStart : 730.2553067207336
Done logging...



********** Iteration 261 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 150.51852416992188
Train_StdReturn : 61.5848503112793
Train_MaxReturn : 200.0
Train_MinReturn : 38.0
Train_AverageEpLen : 150.5185185185185
Actor Loss : -248.13291931152344
Train_EnvstepsSoFar : 1063620
TimeSinceStart : 732.7244629859924
Done logging...



********** Iteration 262 ************

Collecting data for eval...
Eval_AverageReturn : 92.5999984741211
Eval_StdReturn : 55.040348052978516
Eval_MaxReturn : 200.0
Eval_MinReturn : 50.0
Eval_AverageEpLen : 92.6
Train_AverageReturn : 138.7586212158203
Train_StdReturn : 66.51038360595703
Train_MaxReturn : 200.0
Train_MinReturn : 37.0
Train_AverageEpLen : 138.75862068965517
Actor Loss : -175.85342407226562
Train_EnvstepsSoFar : 1067644
TimeSinceStart : 735.3102924823761
Done logging...



********** Iteration 263 ************

Collecting data for eval...
Eval_AverageReturn : 120.0
Eval_StdReturn : 57.27565002441406
Eval_MaxReturn : 200.0
Eval_MinReturn : 41.0
Eval_AverageEpLen : 120.0
Train_AverageReturn : 143.25
Train_StdReturn : 65.92887115478516
Train_MaxReturn : 200.0
Train_MinReturn : 41.0
Train_AverageEpLen : 143.25
Actor Loss : -157.03553771972656
Train_EnvstepsSoFar : 1071655
TimeSinceStart : 737.786776304245
Done logging...



********** Iteration 264 ************

Collecting data for eval...
Eval_AverageReturn : 157.3333282470703
Eval_StdReturn : 56.84090805053711
Eval_MaxReturn : 200.0
Eval_MinReturn : 77.0
Eval_AverageEpLen : 157.33333333333334
Train_AverageReturn : 118.23529052734375
Train_StdReturn : 67.70831298828125
Train_MaxReturn : 200.0
Train_MinReturn : 33.0
Train_AverageEpLen : 118.23529411764706
Actor Loss : -248.51434326171875
Train_EnvstepsSoFar : 1075675
TimeSinceStart : 740.6992590427399
Done logging...



********** Iteration 265 ************

Collecting data for eval...
Eval_AverageReturn : 76.16666412353516
Eval_StdReturn : 46.03410720825195
Eval_MaxReturn : 176.0
Eval_MinReturn : 42.0
Eval_AverageEpLen : 76.16666666666667
Train_AverageReturn : 122.26470947265625
Train_StdReturn : 68.86402130126953
Train_MaxReturn : 200.0
Train_MinReturn : 37.0
Train_AverageEpLen : 122.26470588235294
Actor Loss : -269.4884033203125
Train_EnvstepsSoFar : 1079832
TimeSinceStart : 743.2726299762726
Done logging...



********** Iteration 266 ************

Collecting data for eval...
Eval_AverageReturn : 163.3333282470703
Eval_StdReturn : 51.854496002197266
Eval_MaxReturn : 200.0
Eval_MinReturn : 90.0
Eval_AverageEpLen : 163.33333333333334
Train_AverageReturn : 136.8000030517578
Train_StdReturn : 63.5271110534668
Train_MaxReturn : 200.0
Train_MinReturn : 43.0
Train_AverageEpLen : 136.8
Actor Loss : -310.21044921875
Train_EnvstepsSoFar : 1083936
TimeSinceStart : 746.2278106212616
Done logging...



********** Iteration 267 ************

Collecting data for eval...
Eval_AverageReturn : 161.3333282470703
Eval_StdReturn : 54.682926177978516
Eval_MaxReturn : 200.0
Eval_MinReturn : 84.0
Eval_AverageEpLen : 161.33333333333334
Train_AverageReturn : 148.22222900390625
Train_StdReturn : 60.28041458129883
Train_MaxReturn : 200.0
Train_MinReturn : 48.0
Train_AverageEpLen : 148.22222222222223
Actor Loss : -314.3324279785156
Train_EnvstepsSoFar : 1087938
TimeSinceStart : 748.6794378757477
Done logging...



********** Iteration 268 ************

Collecting data for eval...
Eval_AverageReturn : 181.6666717529297
Eval_StdReturn : 25.927248001098633
Eval_MaxReturn : 200.0
Eval_MinReturn : 145.0
Eval_AverageEpLen : 181.66666666666666
Train_AverageReturn : 151.88888549804688
Train_StdReturn : 59.00240707397461
Train_MaxReturn : 200.0
Train_MinReturn : 61.0
Train_AverageEpLen : 151.88888888888889
Actor Loss : -288.49517822265625
Train_EnvstepsSoFar : 1092039
TimeSinceStart : 751.7248296737671
Done logging...



********** Iteration 269 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 164.1199951171875
Train_StdReturn : 51.663002014160156
Train_MaxReturn : 200.0
Train_MinReturn : 61.0
Train_AverageEpLen : 164.12
Actor Loss : -297.5335693359375
Train_EnvstepsSoFar : 1096142
TimeSinceStart : 754.655876159668
Done logging...



********** Iteration 270 ************

Collecting data for eval...
Eval_AverageReturn : 115.0
Eval_StdReturn : 50.06495666503906
Eval_MaxReturn : 200.0
Eval_MinReturn : 73.0
Eval_AverageEpLen : 115.0
Train_AverageReturn : 143.39285278320312
Train_StdReturn : 56.44993591308594
Train_MaxReturn : 200.0
Train_MinReturn : 50.0
Train_AverageEpLen : 143.39285714285714
Actor Loss : -431.76214599609375
Train_EnvstepsSoFar : 1100157
TimeSinceStart : 757.2958409786224
Done logging...



********** Iteration 271 ************

Collecting data for eval...
Eval_AverageReturn : 119.4000015258789
Eval_StdReturn : 54.76714324951172
Eval_MaxReturn : 200.0
Eval_MinReturn : 55.0
Eval_AverageEpLen : 119.4
Train_AverageReturn : 148.2857208251953
Train_StdReturn : 51.396121978759766
Train_MaxReturn : 200.0
Train_MinReturn : 65.0
Train_AverageEpLen : 148.28571428571428
Actor Loss : -425.0499267578125
Train_EnvstepsSoFar : 1104309
TimeSinceStart : 760.1083874702454
Done logging...



********** Iteration 272 ************

Collecting data for eval...
Eval_AverageReturn : 173.6666717529297
Eval_StdReturn : 37.2409553527832
Eval_MaxReturn : 200.0
Eval_MinReturn : 121.0
Eval_AverageEpLen : 173.66666666666666
Train_AverageReturn : 147.64285278320312
Train_StdReturn : 63.526268005371094
Train_MaxReturn : 200.0
Train_MinReturn : 54.0
Train_AverageEpLen : 147.64285714285714
Actor Loss : -356.54583740234375
Train_EnvstepsSoFar : 1108443
TimeSinceStart : 763.2519648075104
Done logging...



********** Iteration 273 ************

Collecting data for eval...
Eval_AverageReturn : 103.75
Eval_StdReturn : 24.447649002075195
Eval_MaxReturn : 145.0
Eval_MinReturn : 85.0
Eval_AverageEpLen : 103.75
Train_AverageReturn : 168.5833282470703
Train_StdReturn : 50.1214485168457
Train_MaxReturn : 200.0
Train_MinReturn : 55.0
Train_AverageEpLen : 168.58333333333334
Actor Loss : -230.19276428222656
Train_EnvstepsSoFar : 1112489
TimeSinceStart : 765.7257254123688
Done logging...



********** Iteration 274 ************

Collecting data for eval...
Eval_AverageReturn : 148.5
Eval_StdReturn : 51.809749603271484
Eval_MaxReturn : 200.0
Eval_MinReturn : 89.0
Eval_AverageEpLen : 148.5
Train_AverageReturn : 149.1851806640625
Train_StdReturn : 59.78420639038086
Train_MaxReturn : 200.0
Train_MinReturn : 43.0
Train_AverageEpLen : 149.1851851851852
Actor Loss : -307.46490478515625
Train_EnvstepsSoFar : 1116517
TimeSinceStart : 768.271821975708
Done logging...



********** Iteration 275 ************

Collecting data for eval...
Eval_AverageReturn : 169.6666717529297
Eval_StdReturn : 42.89781188964844
Eval_MaxReturn : 200.0
Eval_MinReturn : 109.0
Eval_AverageEpLen : 169.66666666666666
Train_AverageReturn : 128.59375
Train_StdReturn : 66.87201690673828
Train_MaxReturn : 200.0
Train_MinReturn : 45.0
Train_AverageEpLen : 128.59375
Actor Loss : -336.50909423828125
Train_EnvstepsSoFar : 1120632
TimeSinceStart : 771.4817085266113
Done logging...



********** Iteration 276 ************

Collecting data for eval...
Eval_AverageReturn : 187.3333282470703
Eval_StdReturn : 17.913372039794922
Eval_MaxReturn : 200.0
Eval_MinReturn : 162.0
Eval_AverageEpLen : 187.33333333333334
Train_AverageReturn : 134.63333129882812
Train_StdReturn : 67.13741302490234
Train_MaxReturn : 200.0
Train_MinReturn : 41.0
Train_AverageEpLen : 134.63333333333333
Actor Loss : -290.6473388671875
Train_EnvstepsSoFar : 1124671
TimeSinceStart : 774.0135726928711
Done logging...



********** Iteration 277 ************

Collecting data for eval...
Eval_AverageReturn : 131.0
Eval_StdReturn : 52.96697235107422
Eval_MaxReturn : 200.0
Eval_MinReturn : 51.0
Eval_AverageEpLen : 131.0
Train_AverageReturn : 143.6896514892578
Train_StdReturn : 63.097686767578125
Train_MaxReturn : 200.0
Train_MinReturn : 38.0
Train_AverageEpLen : 143.68965517241378
Actor Loss : -243.2544403076172
Train_EnvstepsSoFar : 1128838
TimeSinceStart : 776.5777134895325
Done logging...



********** Iteration 278 ************

Collecting data for eval...
Eval_AverageReturn : 116.19999694824219
Eval_StdReturn : 69.22831726074219
Eval_MaxReturn : 200.0
Eval_MinReturn : 43.0
Eval_AverageEpLen : 116.2
Train_AverageReturn : 136.63333129882812
Train_StdReturn : 68.02816772460938
Train_MaxReturn : 200.0
Train_MinReturn : 34.0
Train_AverageEpLen : 136.63333333333333
Actor Loss : -270.60272216796875
Train_EnvstepsSoFar : 1132937
TimeSinceStart : 779.6619110107422
Done logging...



********** Iteration 279 ************

Collecting data for eval...
Eval_AverageReturn : 193.3333282470703
Eval_StdReturn : 9.428091049194336
Eval_MaxReturn : 200.0
Eval_MinReturn : 180.0
Eval_AverageEpLen : 193.33333333333334
Train_AverageReturn : 152.9629669189453
Train_StdReturn : 60.70052719116211
Train_MaxReturn : 200.0
Train_MinReturn : 52.0
Train_AverageEpLen : 152.96296296296296
Actor Loss : -210.88473510742188
Train_EnvstepsSoFar : 1137067
TimeSinceStart : 782.2457966804504
Done logging...



********** Iteration 280 ************

Collecting data for eval...
Eval_AverageReturn : 142.6666717529297
Eval_StdReturn : 72.76140594482422
Eval_MaxReturn : 200.0
Eval_MinReturn : 40.0
Eval_AverageEpLen : 142.66666666666666
Train_AverageReturn : 105.17948913574219
Train_StdReturn : 66.19856262207031
Train_MaxReturn : 200.0
Train_MinReturn : 37.0
Train_AverageEpLen : 105.17948717948718
Actor Loss : -324.2431640625
Train_EnvstepsSoFar : 1141169
TimeSinceStart : 786.1322631835938
Done logging...



********** Iteration 281 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 139.23333740234375
Train_StdReturn : 67.3249282836914
Train_MaxReturn : 200.0
Train_MinReturn : 40.0
Train_AverageEpLen : 139.23333333333332
Actor Loss : -274.0887451171875
Train_EnvstepsSoFar : 1145346
TimeSinceStart : 789.4238939285278
Done logging...



********** Iteration 282 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 125.125
Train_StdReturn : 67.01993560791016
Train_MaxReturn : 200.0
Train_MinReturn : 44.0
Train_AverageEpLen : 125.125
Actor Loss : -309.46484375
Train_EnvstepsSoFar : 1149350
TimeSinceStart : 792.186838388443
Done logging...



********** Iteration 283 ************

Collecting data for eval...
Eval_AverageReturn : 188.6666717529297
Eval_StdReturn : 8.99382495880127
Eval_MaxReturn : 200.0
Eval_MinReturn : 178.0
Eval_AverageEpLen : 188.66666666666666
Train_AverageReturn : 158.38461303710938
Train_StdReturn : 56.67591857910156
Train_MaxReturn : 200.0
Train_MinReturn : 51.0
Train_AverageEpLen : 158.3846153846154
Actor Loss : -353.21087646484375
Train_EnvstepsSoFar : 1153468
TimeSinceStart : 794.7419152259827
Done logging...



********** Iteration 284 ************

Collecting data for eval...
Eval_AverageReturn : 194.0
Eval_StdReturn : 8.485280990600586
Eval_MaxReturn : 200.0
Eval_MinReturn : 182.0
Eval_AverageEpLen : 194.0
Train_AverageReturn : 193.23809814453125
Train_StdReturn : 12.086610794067383
Train_MaxReturn : 200.0
Train_MinReturn : 162.0
Train_AverageEpLen : 193.23809523809524
Actor Loss : -422.38214111328125
Train_EnvstepsSoFar : 1157526
TimeSinceStart : 797.2715742588043
Done logging...



********** Iteration 285 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 195.2857208251953
Train_StdReturn : 11.747919082641602
Train_MaxReturn : 200.0
Train_MinReturn : 162.0
Train_AverageEpLen : 195.28571428571428
Actor Loss : -346.48590087890625
Train_EnvstepsSoFar : 1161627
TimeSinceStart : 799.6969017982483
Done logging...



********** Iteration 286 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 198.2857208251953
Train_StdReturn : 7.666518211364746
Train_MaxReturn : 200.0
Train_MinReturn : 164.0
Train_AverageEpLen : 198.28571428571428
Actor Loss : -152.06094360351562
Train_EnvstepsSoFar : 1165791
TimeSinceStart : 803.7517216205597
Done logging...



********** Iteration 287 ************

Collecting data for eval...
Eval_AverageReturn : 199.0
Eval_StdReturn : 1.4142135381698608
Eval_MaxReturn : 200.0
Eval_MinReturn : 197.0
Eval_AverageEpLen : 199.0
Train_AverageReturn : 199.42857360839844
Train_StdReturn : 2.3415794372558594
Train_MaxReturn : 200.0
Train_MinReturn : 189.0
Train_AverageEpLen : 199.42857142857142
Actor Loss : -157.34664916992188
Train_EnvstepsSoFar : 1169979
TimeSinceStart : 807.4149374961853
Done logging...



********** Iteration 288 ************

Collecting data for eval...
Eval_AverageReturn : 163.3333282470703
Eval_StdReturn : 39.81066131591797
Eval_MaxReturn : 200.0
Eval_MinReturn : 108.0
Eval_AverageEpLen : 163.33333333333334
Train_AverageReturn : 186.68182373046875
Train_StdReturn : 28.43235206604004
Train_MaxReturn : 200.0
Train_MinReturn : 104.0
Train_AverageEpLen : 186.6818181818182
Actor Loss : -384.7978515625
Train_EnvstepsSoFar : 1174086
TimeSinceStart : 809.9773879051208
Done logging...



********** Iteration 289 ************

Collecting data for eval...
Eval_AverageReturn : 167.0
Eval_StdReturn : 46.66904830932617
Eval_MaxReturn : 200.0
Eval_MinReturn : 101.0
Eval_AverageEpLen : 167.0
Train_AverageReturn : 169.9583282470703
Train_StdReturn : 42.427860260009766
Train_MaxReturn : 200.0
Train_MinReturn : 97.0
Train_AverageEpLen : 169.95833333333334
Actor Loss : -437.2523193359375
Train_EnvstepsSoFar : 1178165
TimeSinceStart : 814.0786988735199
Done logging...



********** Iteration 290 ************

Collecting data for eval...
Eval_AverageReturn : 166.3333282470703
Eval_StdReturn : 47.61185836791992
Eval_MaxReturn : 200.0
Eval_MinReturn : 99.0
Eval_AverageEpLen : 166.33333333333334
Train_AverageReturn : 177.0
Train_StdReturn : 40.86988830566406
Train_MaxReturn : 200.0
Train_MinReturn : 42.0
Train_AverageEpLen : 177.0
Actor Loss : -288.1668701171875
Train_EnvstepsSoFar : 1182236
TimeSinceStart : 816.5621795654297
Done logging...



********** Iteration 291 ************

Collecting data for eval...
Eval_AverageReturn : 149.3333282470703
Eval_StdReturn : 68.84442901611328
Eval_MaxReturn : 200.0
Eval_MinReturn : 52.0
Eval_AverageEpLen : 149.33333333333334
Train_AverageReturn : 148.5357208251953
Train_StdReturn : 53.36296081542969
Train_MaxReturn : 200.0
Train_MinReturn : 40.0
Train_AverageEpLen : 148.53571428571428
Actor Loss : -330.02197265625
Train_EnvstepsSoFar : 1186395
TimeSinceStart : 819.4979658126831
Done logging...



********** Iteration 292 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 139.53334045410156
Train_StdReturn : 72.28034973144531
Train_MaxReturn : 200.0
Train_MinReturn : 42.0
Train_AverageEpLen : 139.53333333333333
Actor Loss : -256.41558837890625
Train_EnvstepsSoFar : 1190581
TimeSinceStart : 825.8221065998077
Done logging...



********** Iteration 293 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 126.9375
Train_StdReturn : 69.45679473876953
Train_MaxReturn : 200.0
Train_MinReturn : 32.0
Train_AverageEpLen : 126.9375
Actor Loss : -294.6763916015625
Train_EnvstepsSoFar : 1194643
TimeSinceStart : 828.2862765789032
Done logging...



********** Iteration 294 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 149.0357208251953
Train_StdReturn : 62.292213439941406
Train_MaxReturn : 200.0
Train_MinReturn : 39.0
Train_AverageEpLen : 149.03571428571428
Actor Loss : -327.61004638671875
Train_EnvstepsSoFar : 1198816
TimeSinceStart : 830.9478795528412
Done logging...



********** Iteration 295 ************

Collecting data for eval...
Eval_AverageReturn : 200.0
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.0
Eval_MinReturn : 200.0
Eval_AverageEpLen : 200.0
Train_AverageReturn : 195.14285278320312
Train_StdReturn : 13.79194164276123
Train_MaxReturn : 200.0
Train_MinReturn : 140.0
Train_AverageEpLen : 195.14285714285714
Actor Loss : -188.99954223632812
Train_EnvstepsSoFar : 1202914
TimeSinceStart : 833.5591015815735
Done logging...



********** Iteration 296 ************
/home/jaehyun-jeong/UCBerkeley_cs285/hw2/cs285/agents/pg_agent.py:155: RuntimeWarning: invalid value encountered in divide
  advantages = (advantages - np.mean(advantages)) / np.std(advantages)

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.636886715888977
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 200.0
Train_StdReturn : 0.0
Train_MaxReturn : 200.0
Train_MinReturn : 200.0
Train_AverageEpLen : 200.0
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1206914
TimeSinceStart : 836.133947134018
Done logging...



********** Iteration 297 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.6867359280586243
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.384075164794922
Train_StdReturn : 0.7450251579284668
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.38407494145199
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1210921
TimeSinceStart : 838.8148241043091
Done logging...



********** Iteration 298 ************

Collecting data for eval...
Eval_AverageReturn : 9.295454978942871
Eval_StdReturn : 0.8415231108665466
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.295454545454545
Train_AverageReturn : 9.35981273651123
Train_StdReturn : 0.7651717066764832
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.35981308411215
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1214927
TimeSinceStart : 841.3258137702942
Done logging...



********** Iteration 299 ************

Collecting data for eval...
Eval_AverageReturn : 9.204545021057129
Eval_StdReturn : 0.7254949808120728
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.204545454545455
Train_AverageReturn : 9.32325553894043
Train_StdReturn : 0.777694046497345
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.32325581395349
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1218936
TimeSinceStart : 843.8100833892822
Done logging...



********** Iteration 300 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7865830063819885
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.302325248718262
Train_StdReturn : 0.7512744069099426
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.30232558139535
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1222936
TimeSinceStart : 846.2189984321594
Done logging...



********** Iteration 301 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.7272788286209106
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.472813606262207
Train_StdReturn : 0.7679104208946228
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.472813238770685
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1226943
TimeSinceStart : 848.710860490799
Done logging...



********** Iteration 302 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.83591628074646
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.403756141662598
Train_StdReturn : 0.7545698285102844
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.4037558685446
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1230949
TimeSinceStart : 851.3148248195648
Done logging...



********** Iteration 303 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.8136211633682251
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.342657089233398
Train_StdReturn : 0.7704164981842041
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.342657342657343
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1234957
TimeSinceStart : 853.8438372612
Done logging...



********** Iteration 304 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.8417191505432129
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.290022850036621
Train_StdReturn : 0.7285161018371582
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.29002320185615
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1238961
TimeSinceStart : 856.3659462928772
Done logging...



********** Iteration 305 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.8076165318489075
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.340326309204102
Train_StdReturn : 0.7421890497207642
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.34032634032634
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1242968
TimeSinceStart : 858.9765954017639
Done logging...



********** Iteration 306 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.738349199295044
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.352804183959961
Train_StdReturn : 0.7358106970787048
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.352803738317757
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1246971
TimeSinceStart : 861.6598510742188
Done logging...



********** Iteration 307 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.7324658036231995
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.320930480957031
Train_StdReturn : 0.7308988571166992
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.320930232558139
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1250979
TimeSinceStart : 864.1788928508759
Done logging...



********** Iteration 308 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.7114911079406738
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.342657089233398
Train_StdReturn : 0.7582173943519592
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.342657342657343
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1254987
TimeSinceStart : 866.7911221981049
Done logging...



********** Iteration 309 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.6982323527336121
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.408451080322266
Train_StdReturn : 0.7362664341926575
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.408450704225352
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1258995
TimeSinceStart : 869.2171723842621
Done logging...



********** Iteration 310 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.7324658036231995
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.384075164794922
Train_StdReturn : 0.7727982401847839
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.38407494145199
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1263002
TimeSinceStart : 871.6941828727722
Done logging...



********** Iteration 311 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.7741076946258545
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.736274242401123
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1267006
TimeSinceStart : 876.648136138916
Done logging...



********** Iteration 312 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.7324658632278442
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.388758659362793
Train_StdReturn : 0.7394315004348755
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.388758782201405
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1271015
TimeSinceStart : 879.1434869766235
Done logging...



********** Iteration 313 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.726534903049469
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.306976318359375
Train_StdReturn : 0.7305287718772888
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.306976744186047
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1275017
TimeSinceStart : 881.5555272102356
Done logging...



********** Iteration 314 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.6108802556991577
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.299304008483887
Train_StdReturn : 0.7468259334564209
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.299303944315545
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1279025
TimeSinceStart : 884.0264494419098
Done logging...



********** Iteration 315 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.7845175862312317
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7252781987190247
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1283033
TimeSinceStart : 886.5298483371735
Done logging...



********** Iteration 316 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7692016363143921
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.381732940673828
Train_StdReturn : 0.7287625670433044
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.381733021077283
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1287039
TimeSinceStart : 889.0193655490875
Done logging...



********** Iteration 317 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.798863410949707
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.377049446105957
Train_StdReturn : 0.7470395565032959
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.37704918032787
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1291043
TimeSinceStart : 891.4851179122925
Done logging...



********** Iteration 318 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.747810959815979
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7629568576812744
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1295051
TimeSinceStart : 893.9332172870636
Done logging...



********** Iteration 319 ************

Collecting data for eval...
Eval_AverageReturn : 9.159090995788574
Eval_StdReturn : 0.8241574764251709
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.159090909090908
Train_AverageReturn : 9.340326309204102
Train_StdReturn : 0.7484440803527832
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.34032634032634
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1299058
TimeSinceStart : 896.4371070861816
Done logging...



********** Iteration 320 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.716037392616272
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.416470527648926
Train_StdReturn : 0.7472060918807983
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.416470588235294
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1303060
TimeSinceStart : 902.4238855838776
Done logging...



********** Iteration 321 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.716037392616272
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.320930480957031
Train_StdReturn : 0.7212902307510376
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.320930232558139
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1307068
TimeSinceStart : 904.841112613678
Done logging...



********** Iteration 322 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.77938312292099
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.374707221984863
Train_StdReturn : 0.7371805906295776
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.374707259953162
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1311071
TimeSinceStart : 908.0829360485077
Done logging...



********** Iteration 323 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7692016363143921
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.352804183959961
Train_StdReturn : 0.7099536061286926
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.352803738317757
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1315074
TimeSinceStart : 910.8289484977722
Done logging...



********** Iteration 324 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.8234103322029114
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.313953399658203
Train_StdReturn : 0.7386603951454163
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.313953488372093
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1319079
TimeSinceStart : 913.3320338726044
Done logging...



********** Iteration 325 ************

Collecting data for eval...
Eval_AverageReturn : 9.295454978942871
Eval_StdReturn : 0.7561728954315186
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.295454545454545
Train_AverageReturn : 9.362149238586426
Train_StdReturn : 0.7344443202018738
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36214953271028
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1323086
TimeSinceStart : 915.82111120224
Done logging...



********** Iteration 326 ************

Collecting data for eval...
Eval_AverageReturn : 9.04444408416748
Eval_StdReturn : 0.7875576019287109
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.044444444444444
Train_AverageReturn : 9.320930480957031
Train_StdReturn : 0.7435171604156494
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.320930232558139
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1327094
TimeSinceStart : 918.7654802799225
Done logging...



********** Iteration 327 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.8455654978752136
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7568073868751526
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1331102
TimeSinceStart : 921.1977260112762
Done logging...



********** Iteration 328 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.7817551493644714
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.318604469299316
Train_StdReturn : 0.7706100940704346
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.31860465116279
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1335109
TimeSinceStart : 924.5390076637268
Done logging...



********** Iteration 329 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.6827868223190308
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.313953399658203
Train_StdReturn : 0.7634320855140686
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.313953488372093
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1339114
TimeSinceStart : 926.968014717102
Done logging...



********** Iteration 330 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.6368866562843323
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.331002235412598
Train_StdReturn : 0.7369654774665833
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.331002331002331
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1343117
TimeSinceStart : 929.3898470401764
Done logging...



********** Iteration 331 ************

Collecting data for eval...
Eval_AverageReturn : 9.136363983154297
Eval_StdReturn : 0.7258508801460266
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.136363636363637
Train_AverageReturn : 9.335664749145508
Train_StdReturn : 0.7284820675849915
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.335664335664335
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1347122
TimeSinceStart : 932.5643594264984
Done logging...



********** Iteration 332 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.716037392616272
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.268518447875977
Train_StdReturn : 0.7559208273887634
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.268518518518519
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1351126
TimeSinceStart : 935.1431908607483
Done logging...



********** Iteration 333 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.716037392616272
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.396713256835938
Train_StdReturn : 0.734711766242981
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.396713615023474
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1355129
TimeSinceStart : 937.7226526737213
Done logging...



********** Iteration 334 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.8136211633682251
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.302325248718262
Train_StdReturn : 0.7481724619865417
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.30232558139535
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1359129
TimeSinceStart : 941.2623329162598
Done logging...



********** Iteration 335 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.5762563347816467
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.4188232421875
Train_StdReturn : 0.7443108558654785
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.418823529411764
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1363132
TimeSinceStart : 944.502448797226
Done logging...



********** Iteration 336 ************

Collecting data for eval...
Eval_AverageReturn : 9.227272987365723
Eval_StdReturn : 0.7938295006752014
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.227272727272727
Train_AverageReturn : 9.366822242736816
Train_StdReturn : 0.760301411151886
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.366822429906541
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1367141
TimeSinceStart : 947.7303586006165
Done logging...



********** Iteration 337 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.747810959815979
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.331002235412598
Train_StdReturn : 0.7557050585746765
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.331002331002331
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1371144
TimeSinceStart : 950.9185001850128
Done logging...



********** Iteration 338 ************

Collecting data for eval...
Eval_AverageReturn : 9.227272987365723
Eval_StdReturn : 0.764663815498352
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.227272727272727
Train_AverageReturn : 9.340326309204102
Train_StdReturn : 0.7638577818870544
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.34032634032634
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1375151
TimeSinceStart : 957.0302693843842
Done logging...



********** Iteration 339 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.672410786151886
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.374707221984863
Train_StdReturn : 0.7113118171691895
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.374707259953162
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1379154
TimeSinceStart : 959.4588842391968
Done logging...



********** Iteration 340 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.6428034901618958
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.370023727416992
Train_StdReturn : 0.7427026629447937
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.370023419203747
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1383155
TimeSinceStart : 962.7013177871704
Done logging...



********** Iteration 341 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.77938312292099
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.39201831817627
Train_StdReturn : 0.7744949460029602
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392018779342724
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1387156
TimeSinceStart : 965.6190888881683
Done logging...



********** Iteration 342 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.6300565600395203
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.344987869262695
Train_StdReturn : 0.7045336365699768
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.344988344988344
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1391165
TimeSinceStart : 970.212329864502
Done logging...



********** Iteration 343 ************

Collecting data for eval...
Eval_AverageReturn : 9.227272987365723
Eval_StdReturn : 0.5585548281669617
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.227272727272727
Train_AverageReturn : 9.389671325683594
Train_StdReturn : 0.7495139837265015
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.389671361502348
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1395165
TimeSinceStart : 972.8294832706451
Done logging...



********** Iteration 344 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.7114911079406738
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.384075164794922
Train_StdReturn : 0.741875171661377
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.38407494145199
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1399172
TimeSinceStart : 975.2503108978271
Done logging...



********** Iteration 345 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.672410786151886
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.34813117980957
Train_StdReturn : 0.7988433241844177
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.348130841121495
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1403173
TimeSinceStart : 978.311642408371
Done logging...



********** Iteration 346 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.6231517195701599
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.35981273651123
Train_StdReturn : 0.7921766042709351
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.35981308411215
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1407179
TimeSinceStart : 980.7423536777496
Done logging...



********** Iteration 347 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.738349199295044
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.362149238586426
Train_StdReturn : 0.7344443798065186
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36214953271028
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1411186
TimeSinceStart : 983.188850402832
Done logging...



********** Iteration 348 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.8109578490257263
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.384075164794922
Train_StdReturn : 0.7758227586746216
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.38407494145199
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1415193
TimeSinceStart : 987.1724779605865
Done logging...



********** Iteration 349 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.6519927978515625
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.362149238586426
Train_StdReturn : 0.7312561869621277
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36214953271028
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1419200
TimeSinceStart : 990.1535229682922
Done logging...



********** Iteration 350 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.8080176711082458
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.294663429260254
Train_StdReturn : 0.7517616152763367
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.294663573085847
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1423206
TimeSinceStart : 993.2630798816681
Done logging...



********** Iteration 351 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.8818830251693726
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.318604469299316
Train_StdReturn : 0.7914531230926514
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.31860465116279
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1427213
TimeSinceStart : 996.054276227951
Done logging...



********** Iteration 352 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.7578684091567993
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.350467681884766
Train_StdReturn : 0.7725275158882141
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.350467289719626
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1431215
TimeSinceStart : 999.0720436573029
Done logging...



********** Iteration 353 ************

Collecting data for eval...
Eval_AverageReturn : 9.227272987365723
Eval_StdReturn : 0.821960985660553
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.227272727272727
Train_AverageReturn : 9.345794677734375
Train_StdReturn : 0.7150296568870544
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.345794392523365
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1435215
TimeSinceStart : 1001.5651319026947
Done logging...



********** Iteration 354 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.7496556043624878
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.388758659362793
Train_StdReturn : 0.7704526782035828
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.388758782201405
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1439224
TimeSinceStart : 1004.5022509098053
Done logging...



********** Iteration 355 ************

Collecting data for eval...
Eval_AverageReturn : 9.227272987365723
Eval_StdReturn : 0.901101291179657
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.227272727272727
Train_AverageReturn : 9.273148536682129
Train_StdReturn : 0.7754456400871277
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.273148148148149
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1443230
TimeSinceStart : 1007.4646215438843
Done logging...



********** Iteration 356 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.652395486831665
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.4188232421875
Train_StdReturn : 0.7347660064697266
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.418823529411764
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1447233
TimeSinceStart : 1010.2490863800049
Done logging...



********** Iteration 357 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.7114911079406738
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.406103134155273
Train_StdReturn : 0.761059582233429
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.406103286384976
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1451240
TimeSinceStart : 1012.7137532234192
Done logging...



********** Iteration 358 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7061499953269958
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.396713256835938
Train_StdReturn : 0.7250634431838989
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.396713615023474
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1455243
TimeSinceStart : 1015.2385056018829
Done logging...



********** Iteration 359 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.754291832447052
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.333333015441895
Train_StdReturn : 0.7084789276123047
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.333333333333334
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1459247
TimeSinceStart : 1017.7224228382111
Done logging...



********** Iteration 360 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.754291832447052
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.335664749145508
Train_StdReturn : 0.762868344783783
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.335664335664335
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1463252
TimeSinceStart : 1020.138885974884
Done logging...



********** Iteration 361 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.787956953048706
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.357476234436035
Train_StdReturn : 0.7430458068847656
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.357476635514018
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1467257
TimeSinceStart : 1022.5836899280548
Done logging...



********** Iteration 362 ************

Collecting data for eval...
Eval_AverageReturn : 9.511628150939941
Eval_StdReturn : 0.7585816383361816
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.511627906976743
Train_AverageReturn : 9.331002235412598
Train_StdReturn : 0.7649027109146118
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.331002331002331
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1471260
TimeSinceStart : 1025.0124368667603
Done logging...



********** Iteration 363 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.8664156794548035
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.377049446105957
Train_StdReturn : 0.7438979744911194
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.37704918032787
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1475264
TimeSinceStart : 1027.7606194019318
Done logging...



********** Iteration 364 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.8222171664237976
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.3864164352417
Train_StdReturn : 0.7327105402946472
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.386416861826698
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1479272
TimeSinceStart : 1030.2000353336334
Done logging...



********** Iteration 365 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.772392988204956
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.32400894165039
Train_StdReturn : 0.7416398525238037
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.324009324009324
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1483272
TimeSinceStart : 1032.708800315857
Done logging...



********** Iteration 366 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7250445485115051
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.7457334995269775
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1487276
TimeSinceStart : 1037.379844903946
Done logging...



********** Iteration 367 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.7496556043624878
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.388758659362793
Train_StdReturn : 0.7488728165626526
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.388758782201405
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1491285
TimeSinceStart : 1042.120687007904
Done logging...



********** Iteration 368 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.726534903049469
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.370023727416992
Train_StdReturn : 0.7427026629447937
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.370023419203747
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1495286
TimeSinceStart : 1044.535207748413
Done logging...



********** Iteration 369 ************

Collecting data for eval...
Eval_AverageReturn : 9.066666603088379
Eval_StdReturn : 0.7717224359512329
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.066666666666666
Train_AverageReturn : 9.384075164794922
Train_StdReturn : 0.7636528015136719
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.38407494145199
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1499293
TimeSinceStart : 1046.948651790619
Done logging...



********** Iteration 370 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.7578014135360718
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 9.306976318359375
Train_StdReturn : 0.730528712272644
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.306976744186047
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1503295
TimeSinceStart : 1049.3742599487305
Done logging...



********** Iteration 371 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.605544924736023
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.350467681884766
Train_StdReturn : 0.7694972157478333
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.350467289719626
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1507297
TimeSinceStart : 1051.8307065963745
Done logging...



********** Iteration 372 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.6428034901618958
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.3286714553833
Train_StdReturn : 0.7551800012588501
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.328671328671328
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1511299
TimeSinceStart : 1054.4336049556732
Done logging...



********** Iteration 373 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.7478108406066895
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.337995529174805
Train_StdReturn : 0.7225806713104248
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.337995337995338
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1515305
TimeSinceStart : 1058.479216337204
Done logging...



********** Iteration 374 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.6553024649620056
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.39201831817627
Train_StdReturn : 0.7653482556343079
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392018779342724
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1519306
TimeSinceStart : 1062.54904794693
Done logging...



********** Iteration 375 ************

Collecting data for eval...
Eval_AverageReturn : 9.0
Eval_StdReturn : 0.8164966106414795
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.0
Train_AverageReturn : 9.37236499786377
Train_StdReturn : 0.7556096315383911
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.372365339578455
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1523308
TimeSinceStart : 1066.5253660678864
Done logging...



********** Iteration 376 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.630056619644165
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.357476234436035
Train_StdReturn : 0.7616786956787109
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.357476635514018
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1527313
TimeSinceStart : 1068.9331181049347
Done logging...



********** Iteration 377 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.8818830251693726
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.367681503295898
Train_StdReturn : 0.7731955647468567
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36768149882904
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1531313
TimeSinceStart : 1071.297521352768
Done logging...



********** Iteration 378 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.6922268271446228
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.326340675354004
Train_StdReturn : 0.7453231811523438
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.326340326340326
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1535314
TimeSinceStart : 1073.7654919624329
Done logging...



********** Iteration 379 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.5827890634536743
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.30930233001709
Train_StdReturn : 0.7468737959861755
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.309302325581395
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1539317
TimeSinceStart : 1076.194435596466
Done logging...



********** Iteration 380 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.538411021232605
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.306976318359375
Train_StdReturn : 0.7827783823013306
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.306976744186047
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1543319
TimeSinceStart : 1078.8719820976257
Done logging...



********** Iteration 381 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.6231517195701599
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.428235054016113
Train_StdReturn : 0.7639851570129395
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.428235294117647
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1547326
TimeSinceStart : 1081.2799999713898
Done logging...



********** Iteration 382 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.6898789405822754
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.448113441467285
Train_StdReturn : 0.7052004933357239
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.44811320754717
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1551332
TimeSinceStart : 1083.6650953292847
Done logging...



********** Iteration 383 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.726534903049469
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.342657089233398
Train_StdReturn : 0.7612855434417725
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.342657342657343
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1555340
TimeSinceStart : 1086.0817148685455
Done logging...



********** Iteration 384 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.7633914351463318
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7443559765815735
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1559348
TimeSinceStart : 1088.4865055084229
Done logging...



********** Iteration 385 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.7496556043624878
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.410798072814941
Train_StdReturn : 0.7646999359130859
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.410798122065728
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1563357
TimeSinceStart : 1090.9239115715027
Done logging...



********** Iteration 386 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.719804048538208
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.416470527648926
Train_StdReturn : 0.7248280644416809
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.416470588235294
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1567359
TimeSinceStart : 1094.598215341568
Done logging...



********** Iteration 387 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.6898789405822754
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.377049446105957
Train_StdReturn : 0.7247628569602966
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.37704918032787
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1571363
TimeSinceStart : 1097.3512544631958
Done logging...



********** Iteration 388 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.6553024649620056
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.370023727416992
Train_StdReturn : 0.7521029114723206
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.370023419203747
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1575364
TimeSinceStart : 1099.7776210308075
Done logging...



********** Iteration 389 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.8136211633682251
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.403756141662598
Train_StdReturn : 0.7420217394828796
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.4037558685446
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1579370
TimeSinceStart : 1102.176347732544
Done logging...



********** Iteration 390 ************

Collecting data for eval...
Eval_AverageReturn : 9.113636016845703
Eval_StdReturn : 0.714012622833252
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.113636363636363
Train_AverageReturn : 9.381732940673828
Train_StdReturn : 0.7540329098701477
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.381733021077283
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1583376
TimeSinceStart : 1104.5506510734558
Done logging...



********** Iteration 391 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.7635560035705566
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7690572142601013
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1587384
TimeSinceStart : 1106.9667508602142
Done logging...



********** Iteration 392 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.7782883644104004
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.342657089233398
Train_StdReturn : 0.7764442563056946
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.342657342657343
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1591392
TimeSinceStart : 1109.3747243881226
Done logging...



********** Iteration 393 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7865830063819885
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.340326309204102
Train_StdReturn : 0.748444139957428
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.34032634032634
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1595399
TimeSinceStart : 1112.1505210399628
Done logging...



********** Iteration 394 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.8818830251693726
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.39906120300293
Train_StdReturn : 0.7023762464523315
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.39906103286385
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1599403
TimeSinceStart : 1114.5392282009125
Done logging...



********** Iteration 395 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.7228032350540161
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.445755004882812
Train_StdReturn : 0.7312955856323242
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.445754716981131
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1603408
TimeSinceStart : 1117.689742565155
Done logging...



********** Iteration 396 ************

Collecting data for eval...
Eval_AverageReturn : 9.227272987365723
Eval_StdReturn : 0.8755163550376892
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.227272727272727
Train_AverageReturn : 9.357476234436035
Train_StdReturn : 0.7768648266792297
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.357476635514018
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1607413
TimeSinceStart : 1122.3155794143677
Done logging...



********** Iteration 397 ************

Collecting data for eval...
Eval_AverageReturn : 9.511628150939941
Eval_StdReturn : 0.7272788882255554
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.511627906976743
Train_AverageReturn : 9.394366264343262
Train_StdReturn : 0.7279569506645203
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.394366197183098
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1611415
TimeSinceStart : 1125.577865600586
Done logging...



********** Iteration 398 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.7633914351463318
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.318604469299316
Train_StdReturn : 0.7142261266708374
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.31860465116279
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1615422
TimeSinceStart : 1128.468058347702
Done logging...



********** Iteration 399 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.747810959815979
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.342657089233398
Train_StdReturn : 0.7643412947654724
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.342657342657343
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1619430
TimeSinceStart : 1132.8043084144592
Done logging...



********** Iteration 400 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.5855664014816284
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.377049446105957
Train_StdReturn : 0.7532833218574524
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.37704918032787
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1623434
TimeSinceStart : 1135.1814231872559
Done logging...



********** Iteration 401 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.6784005165100098
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.448113441467285
Train_StdReturn : 0.7314667701721191
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.44811320754717
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1627440
TimeSinceStart : 1137.6329426765442
Done logging...



********** Iteration 402 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.7886430025100708
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.367681503295898
Train_StdReturn : 0.7454373240470886
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36768149882904
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1631440
TimeSinceStart : 1139.9867367744446
Done logging...



********** Iteration 403 ************

Collecting data for eval...
Eval_AverageReturn : 9.113636016845703
Eval_StdReturn : 0.7451634407043457
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.113636363636363
Train_AverageReturn : 9.35981273651123
Train_StdReturn : 0.7340019345283508
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.35981308411215
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1635446
TimeSinceStart : 1142.3550305366516
Done logging...



********** Iteration 404 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.7111130952835083
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.331002235412598
Train_StdReturn : 0.773991048336029
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.331002331002331
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1639449
TimeSinceStart : 1144.73966050148
Done logging...



********** Iteration 405 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.8012773990631104
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.316279411315918
Train_StdReturn : 0.7548078894615173
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.316279069767441
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1643455
TimeSinceStart : 1147.1070239543915
Done logging...



********** Iteration 406 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.7782883644104004
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.333333015441895
Train_StdReturn : 0.7469179630279541
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.333333333333334
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1647459
TimeSinceStart : 1149.4853467941284
Done logging...



********** Iteration 407 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.798863410949707
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.423529624938965
Train_StdReturn : 0.7158125638961792
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.423529411764706
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1651464
TimeSinceStart : 1151.8477473258972
Done logging...



********** Iteration 408 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7692015767097473
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.331002235412598
Train_StdReturn : 0.7432644963264465
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.331002331002331
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1655467
TimeSinceStart : 1154.2446429729462
Done logging...



********** Iteration 409 ************

Collecting data for eval...
Eval_AverageReturn : 9.295454978942871
Eval_StdReturn : 0.6934612393379211
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.295454545454545
Train_AverageReturn : 9.342657089233398
Train_StdReturn : 0.736382782459259
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.342657342657343
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1659475
TimeSinceStart : 1157.0579841136932
Done logging...



********** Iteration 410 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.6970133781433105
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 9.37236499786377
Train_StdReturn : 0.733593225479126
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.372365339578455
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1663477
TimeSinceStart : 1159.4643683433533
Done logging...



********** Iteration 411 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.659416139125824
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.29698371887207
Train_StdReturn : 0.7706719040870667
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.296983758700696
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1667484
TimeSinceStart : 1161.8715810775757
Done logging...



********** Iteration 412 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.793428897857666
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.37236499786377
Train_StdReturn : 0.7648512125015259
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.372365339578455
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1671486
TimeSinceStart : 1164.5947661399841
Done logging...



********** Iteration 413 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.7423856258392334
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.39906120300293
Train_StdReturn : 0.7318373918533325
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.39906103286385
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1675490
TimeSinceStart : 1168.3267486095428
Done logging...



********** Iteration 414 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7564398050308228
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.425882339477539
Train_StdReturn : 0.7880210280418396
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.425882352941176
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1679496
TimeSinceStart : 1170.9522759914398
Done logging...



********** Iteration 415 ************

Collecting data for eval...
Eval_AverageReturn : 9.295454978942871
Eval_StdReturn : 0.8939073085784912
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.295454545454545
Train_AverageReturn : 9.318604469299316
Train_StdReturn : 0.7553701996803284
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.31860465116279
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1683503
TimeSinceStart : 1173.4002640247345
Done logging...



********** Iteration 416 ************

Collecting data for eval...
Eval_AverageReturn : 9.181818008422852
Eval_StdReturn : 0.6833316683769226
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.181818181818182
Train_AverageReturn : 9.3286714553833
Train_StdReturn : 0.7643839716911316
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.328671328671328
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1687505
TimeSinceStart : 1175.889353275299
Done logging...



********** Iteration 417 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.9226434826850891
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.290022850036621
Train_StdReturn : 0.7984135746955872
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.29002320185615
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1691509
TimeSinceStart : 1178.7761936187744
Done logging...



********** Iteration 418 ************

Collecting data for eval...
Eval_AverageReturn : 9.136363983154297
Eval_StdReturn : 0.7859825491905212
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.136363636363637
Train_AverageReturn : 9.379390716552734
Train_StdReturn : 0.7900710701942444
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.379391100702577
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1695514
TimeSinceStart : 1181.2452788352966
Done logging...



********** Iteration 419 ************

Collecting data for eval...
Eval_AverageReturn : 9.619047164916992
Eval_StdReturn : 0.785353422164917
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.619047619047619
Train_AverageReturn : 9.352804183959961
Train_StdReturn : 0.7294324040412903
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.352803738317757
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1699517
TimeSinceStart : 1183.901980638504
Done logging...



********** Iteration 420 ************

Collecting data for eval...
Eval_AverageReturn : 9.642857551574707
Eval_StdReturn : 0.7502833604812622
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.642857142857142
Train_AverageReturn : 9.411765098571777
Train_StdReturn : 0.7403356432914734
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.411764705882353
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1703517
TimeSinceStart : 1187.183116197586
Done logging...



********** Iteration 421 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.6863486170768738
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.294663429260254
Train_StdReturn : 0.7455633878707886
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.294663573085847
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1707523
TimeSinceStart : 1189.8900203704834
Done logging...



********** Iteration 422 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.6195052862167358
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 9.357476234436035
Train_StdReturn : 0.7616786956787109
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.357476635514018
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1711528
TimeSinceStart : 1192.9132809638977
Done logging...



********** Iteration 423 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.8500309586524963
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.423529624938965
Train_StdReturn : 0.735270619392395
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.423529411764706
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1715533
TimeSinceStart : 1196.591762304306
Done logging...



********** Iteration 424 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.6368866562843323
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.345794677734375
Train_StdReturn : 0.7925211787223816
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.345794392523365
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1719533
TimeSinceStart : 1199.0162327289581
Done logging...



********** Iteration 425 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.6982323527336121
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.35981273651123
Train_StdReturn : 0.7371782064437866
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.35981308411215
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1723539
TimeSinceStart : 1201.4451551437378
Done logging...



********** Iteration 426 ************

Collecting data for eval...
Eval_AverageReturn : 9.204545021057129
Eval_StdReturn : 0.6244832277297974
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.204545454545455
Train_AverageReturn : 9.337995529174805
Train_StdReturn : 0.716099739074707
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.337995337995338
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1727545
TimeSinceStart : 1203.899997472763
Done logging...



********** Iteration 427 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.8500309586524963
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.7643008828163147
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1731549
TimeSinceStart : 1207.1808745861053
Done logging...



********** Iteration 428 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.6231517195701599
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.396713256835938
Train_StdReturn : 0.7690543532371521
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.396713615023474
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1735552
TimeSinceStart : 1210.1967871189117
Done logging...



********** Iteration 429 ************

Collecting data for eval...
Eval_AverageReturn : 9.227272987365723
Eval_StdReturn : 0.764663815498352
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.227272727272727
Train_AverageReturn : 9.401408195495605
Train_StdReturn : 0.738541841506958
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.401408450704226
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1739557
TimeSinceStart : 1213.0500628948212
Done logging...



********** Iteration 430 ************

Collecting data for eval...
Eval_AverageReturn : 9.619047164916992
Eval_StdReturn : 0.6884205937385559
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.619047619047619
Train_AverageReturn : 9.377049446105957
Train_StdReturn : 0.7470395565032959
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.37704918032787
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1743561
TimeSinceStart : 1216.087954044342
Done logging...



********** Iteration 431 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.8818830847740173
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.320930480957031
Train_StdReturn : 0.7340737581253052
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.320930232558139
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1747569
TimeSinceStart : 1218.5630202293396
Done logging...



********** Iteration 432 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.738349199295044
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.37236499786377
Train_StdReturn : 0.7075933218002319
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.372365339578455
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1751571
TimeSinceStart : 1221.2072105407715
Done logging...



********** Iteration 433 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7988634705543518
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.290022850036621
Train_StdReturn : 0.7867037653923035
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.29002320185615
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1755575
TimeSinceStart : 1223.6863045692444
Done logging...



********** Iteration 434 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.7886430025100708
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.34813117980957
Train_StdReturn : 0.7598704099655151
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.348130841121495
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1759576
TimeSinceStart : 1226.1494970321655
Done logging...



********** Iteration 435 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.6619732975959778
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 9.379390716552734
Train_StdReturn : 0.7536618113517761
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.379391100702577
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1763581
TimeSinceStart : 1229.00750207901
Done logging...



********** Iteration 436 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.7585816383361816
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.342657089233398
Train_StdReturn : 0.7643413543701172
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.342657342657343
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1767589
TimeSinceStart : 1231.491046667099
Done logging...



********** Iteration 437 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.6970134377479553
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 9.331002235412598
Train_StdReturn : 0.7526141405105591
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.331002331002331
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1771592
TimeSinceStart : 1233.9427373409271
Done logging...



********** Iteration 438 ************

Collecting data for eval...
Eval_AverageReturn : 9.227272987365723
Eval_StdReturn : 0.7938295006752014
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.227272727272727
Train_AverageReturn : 9.35981273651123
Train_StdReturn : 0.7832784056663513
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.35981308411215
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1775598
TimeSinceStart : 1236.4209427833557
Done logging...



********** Iteration 439 ************

Collecting data for eval...
Eval_AverageReturn : 9.295454978942871
Eval_StdReturn : 0.7856538891792297
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.295454545454545
Train_AverageReturn : 9.331002235412598
Train_StdReturn : 0.7046261429786682
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.331002331002331
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1779601
TimeSinceStart : 1238.9817996025085
Done logging...



********** Iteration 440 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.7845175862312317
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.35981273651123
Train_StdReturn : 0.7528586983680725
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.35981308411215
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1783607
TimeSinceStart : 1241.5574233531952
Done logging...



********** Iteration 441 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.7741077542304993
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7506074905395508
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1787615
TimeSinceStart : 1244.0977561473846
Done logging...



********** Iteration 442 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.5434103608131409
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.370023727416992
Train_StdReturn : 0.7363691926002502
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.370023419203747
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1791616
TimeSinceStart : 1246.9370481967926
Done logging...



********** Iteration 443 ************

Collecting data for eval...
Eval_AverageReturn : 9.295454978942871
Eval_StdReturn : 0.7254949808120728
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.295454545454545
Train_AverageReturn : 9.381732940673828
Train_StdReturn : 0.702583909034729
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.381733021077283
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1795622
TimeSinceStart : 1249.4612436294556
Done logging...



********** Iteration 444 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.652395486831665
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.401408195495605
Train_StdReturn : 0.7727141976356506
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.401408450704226
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1799627
TimeSinceStart : 1251.9370257854462
Done logging...



********** Iteration 445 ************

Collecting data for eval...
Eval_AverageReturn : 9.204545021057129
Eval_StdReturn : 0.8681104183197021
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.204545454545455
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.7488600611686707
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1803631
TimeSinceStart : 1254.3691158294678
Done logging...



********** Iteration 446 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.6577737927436829
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.438679695129395
Train_StdReturn : 0.7209886908531189
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.43867924528302
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1807633
TimeSinceStart : 1256.8665888309479
Done logging...



********** Iteration 447 ************

Collecting data for eval...
Eval_AverageReturn : 9.511628150939941
Eval_StdReturn : 0.7585816383361816
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.511627906976743
Train_AverageReturn : 9.294663429260254
Train_StdReturn : 0.7790434956550598
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.294663573085847
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1811639
TimeSinceStart : 1259.3415234088898
Done logging...



********** Iteration 448 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.793428897857666
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.352804183959961
Train_StdReturn : 0.7879445552825928
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.352803738317757
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1815642
TimeSinceStart : 1262.188980102539
Done logging...



********** Iteration 449 ************

Collecting data for eval...
Eval_AverageReturn : 9.227272987365723
Eval_StdReturn : 0.7027102112770081
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.227272727272727
Train_AverageReturn : 9.302325248718262
Train_StdReturn : 0.7450576424598694
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.30232558139535
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1819642
TimeSinceStart : 1264.6829178333282
Done logging...



********** Iteration 450 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.7585816383361816
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.7488600611686707
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1823646
TimeSinceStart : 1267.1210362911224
Done logging...



********** Iteration 451 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.6577737927436829
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.366822242736816
Train_StdReturn : 0.7510256171226501
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.366822429906541
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1827655
TimeSinceStart : 1270.8159251213074
Done logging...



********** Iteration 452 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.6922268271446228
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.388758659362793
Train_StdReturn : 0.7234222292900085
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.388758782201405
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1831664
TimeSinceStart : 1273.3066883087158
Done logging...



********** Iteration 453 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7061500549316406
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.362149238586426
Train_StdReturn : 0.7955290079116821
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36214953271028
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1835671
TimeSinceStart : 1275.7414684295654
Done logging...



********** Iteration 454 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.6519927978515625
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.294663429260254
Train_StdReturn : 0.7361682057380676
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.294663573085847
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1839677
TimeSinceStart : 1278.218327999115
Done logging...



********** Iteration 455 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.6187969446182251
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.350467681884766
Train_StdReturn : 0.7694972157478333
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.350467289719626
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1843679
TimeSinceStart : 1280.6354928016663
Done logging...



********** Iteration 456 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.7886430025100708
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.377049446105957
Train_StdReturn : 0.7407431602478027
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.37704918032787
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1847683
TimeSinceStart : 1283.225085258484
Done logging...



********** Iteration 457 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.7635560035705566
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.396713256835938
Train_StdReturn : 0.7781575322151184
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.396713615023474
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1851686
TimeSinceStart : 1286.3943588733673
Done logging...



********** Iteration 458 ************

Collecting data for eval...
Eval_AverageReturn : 9.227272987365723
Eval_StdReturn : 0.764663815498352
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.227272727272727
Train_AverageReturn : 9.342657089233398
Train_StdReturn : 0.7458187341690063
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.342657342657343
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1855694
TimeSinceStart : 1289.8446633815765
Done logging...



********** Iteration 459 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.7186995148658752
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.326340675354004
Train_StdReturn : 0.7484441995620728
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.326340326340326
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1859695
TimeSinceStart : 1292.304747581482
Done logging...



********** Iteration 460 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.754291832447052
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.350467681884766
Train_StdReturn : 0.7510582804679871
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.350467289719626
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1863697
TimeSinceStart : 1294.8011922836304
Done logging...



********** Iteration 461 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.8632888197898865
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.39201831817627
Train_StdReturn : 0.7178686261177063
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392018779342724
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1867698
TimeSinceStart : 1297.2851004600525
Done logging...



********** Iteration 462 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7692015767097473
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7598883509635925
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1871706
TimeSinceStart : 1299.7921221256256
Done logging...



********** Iteration 463 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.738349199295044
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.326340675354004
Train_StdReturn : 0.7453231811523438
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.326340326340326
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1875707
TimeSinceStart : 1304.45290350914
Done logging...



********** Iteration 464 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.7741077542304993
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.357476234436035
Train_StdReturn : 0.7398947477340698
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.357476635514018
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1879712
TimeSinceStart : 1306.8629841804504
Done logging...



********** Iteration 465 ************

Collecting data for eval...
Eval_AverageReturn : 9.181818008422852
Eval_StdReturn : 0.8331955671310425
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.181818181818182
Train_AverageReturn : 9.384075164794922
Train_StdReturn : 0.7543964982032776
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.38407494145199
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1883719
TimeSinceStart : 1309.3040308952332
Done logging...



********** Iteration 466 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.7496556043624878
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.340326309204102
Train_StdReturn : 0.751552164554596
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.34032634032634
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1887726
TimeSinceStart : 1311.8059175014496
Done logging...



********** Iteration 467 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.726534903049469
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.408451080322266
Train_StdReturn : 0.7201486229896545
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.408450704225352
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1891734
TimeSinceStart : 1314.225566625595
Done logging...



********** Iteration 468 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.6553024649620056
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.326340675354004
Train_StdReturn : 0.7849285006523132
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.326340326340326
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1895735
TimeSinceStart : 1318.7390117645264
Done logging...



********** Iteration 469 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.6478319764137268
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.30930233001709
Train_StdReturn : 0.7499811053276062
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.309302325581395
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1899738
TimeSinceStart : 1321.1537079811096
Done logging...



********** Iteration 470 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.77938312292099
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.340326309204102
Train_StdReturn : 0.7699368000030518
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.34032634032634
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1903745
TimeSinceStart : 1323.6177678108215
Done logging...



********** Iteration 471 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.7186995148658752
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.389671325683594
Train_StdReturn : 0.771125853061676
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.389671361502348
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1907745
TimeSinceStart : 1326.105786561966
Done logging...



********** Iteration 472 ************

Collecting data for eval...
Eval_AverageReturn : 9.159090995788574
Eval_StdReturn : 0.8241574764251709
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.159090909090908
Train_AverageReturn : 9.37236499786377
Train_StdReturn : 0.7648512125015259
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.372365339578455
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1911747
TimeSinceStart : 1328.5999870300293
Done logging...



********** Iteration 473 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.829156219959259
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.7883774042129517
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1915751
TimeSinceStart : 1331.0391805171967
Done logging...



********** Iteration 474 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.8012773990631104
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.313953399658203
Train_StdReturn : 0.738660454750061
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.313953488372093
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1919756
TimeSinceStart : 1334.3256795406342
Done logging...



********** Iteration 475 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.6937876343727112
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.389671325683594
Train_StdReturn : 0.727260172367096
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.389671361502348
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1923756
TimeSinceStart : 1336.7674088478088
Done logging...



********** Iteration 476 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.6921162605285645
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 9.428235054016113
Train_StdReturn : 0.7195769548416138
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.428235294117647
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1927763
TimeSinceStart : 1342.0877323150635
Done logging...



********** Iteration 477 ************

Collecting data for eval...
Eval_AverageReturn : 9.204545021057129
Eval_StdReturn : 0.6934611797332764
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.204545454545455
Train_AverageReturn : 9.39906120300293
Train_StdReturn : 0.7724111080169678
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.39906103286385
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1931767
TimeSinceStart : 1344.5326063632965
Done logging...



********** Iteration 478 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.774107813835144
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.316279411315918
Train_StdReturn : 0.7760754823684692
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.316279069767441
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1935773
TimeSinceStart : 1347.7098588943481
Done logging...



********** Iteration 479 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.7228032350540161
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.340326309204102
Train_StdReturn : 0.7638577222824097
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.34032634032634
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1939780
TimeSinceStart : 1350.2151114940643
Done logging...



********** Iteration 480 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.7434589266777039
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.352804183959961
Train_StdReturn : 0.754622220993042
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.352803738317757
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1943783
TimeSinceStart : 1352.8213455677032
Done logging...



********** Iteration 481 ************

Collecting data for eval...
Eval_AverageReturn : 9.511628150939941
Eval_StdReturn : 0.5855664610862732
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.511627906976743
Train_AverageReturn : 9.370023727416992
Train_StdReturn : 0.7552103400230408
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.370023419203747
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1947784
TimeSinceStart : 1358.875654220581
Done logging...



********** Iteration 482 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.6249716281890869
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.6937954425811768
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1951788
TimeSinceStart : 1361.9611043930054
Done logging...



********** Iteration 483 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.8417191505432129
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.345794677734375
Train_StdReturn : 0.7624702453613281
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.345794392523365
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1955788
TimeSinceStart : 1365.1410977840424
Done logging...



********** Iteration 484 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7692016363143921
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.377049446105957
Train_StdReturn : 0.7747403383255005
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.37704918032787
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1959792
TimeSinceStart : 1367.9323768615723
Done logging...



********** Iteration 485 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7988634705543518
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.396713256835938
Train_StdReturn : 0.7282937169075012
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.396713615023474
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1963795
TimeSinceStart : 1370.3869910240173
Done logging...



********** Iteration 486 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.7272788882255554
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.411765098571777
Train_StdReturn : 0.7307388186454773
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.411764705882353
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1967795
TimeSinceStart : 1373.6273794174194
Done logging...



********** Iteration 487 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.6784005165100098
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.779435932636261
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1971799
TimeSinceStart : 1376.1402909755707
Done logging...



********** Iteration 488 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.9078708291053772
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.352804183959961
Train_StdReturn : 0.7165054082870483
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.352803738317757
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1975802
TimeSinceStart : 1378.6338739395142
Done logging...



********** Iteration 489 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.6553024649620056
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.362149238586426
Train_StdReturn : 0.7686418890953064
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36214953271028
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1979809
TimeSinceStart : 1381.1589841842651
Done logging...



********** Iteration 490 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.6780176162719727
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.414117813110352
Train_StdReturn : 0.7374284267425537
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.414117647058823
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1983810
TimeSinceStart : 1383.6591720581055
Done logging...



********** Iteration 491 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.726534903049469
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.3286714553833
Train_StdReturn : 0.7704588770866394
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.328671328671328
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1987812
TimeSinceStart : 1386.1017713546753
Done logging...



********** Iteration 492 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.787956953048706
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.344987869262695
Train_StdReturn : 0.7400335669517517
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.344988344988344
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1991821
TimeSinceStart : 1389.3444209098816
Done logging...



********** Iteration 493 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.6780176758766174
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.366822242736816
Train_StdReturn : 0.7724958062171936
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.366822429906541
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1995830
TimeSinceStart : 1391.885041475296
Done logging...



********** Iteration 494 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.6780176162719727
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.337995529174805
Train_StdReturn : 0.7385342717170715
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.337995337995338
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 1999836
TimeSinceStart : 1394.364580154419
Done logging...



********** Iteration 495 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.8632888197898865
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.275463104248047
Train_StdReturn : 0.7790960073471069
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.275462962962964
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 2003843
TimeSinceStart : 1397.3981943130493
Done logging...



********** Iteration 496 ************

Collecting data for eval...
Eval_AverageReturn : 9.159090995788574
Eval_StdReturn : 0.7367984652519226
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.159090909090908
Train_AverageReturn : 9.35981273651123
Train_StdReturn : 0.7772897481918335
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.35981308411215
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 2007849
TimeSinceStart : 1399.8718347549438
Done logging...



********** Iteration 497 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7692016363143921
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.362149238586426
Train_StdReturn : 0.7655961513519287
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36214953271028
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 2011856
TimeSinceStart : 1402.423032283783
Done logging...



********** Iteration 498 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.83591628074646
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.381732940673828
Train_StdReturn : 0.7287625670433044
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.381733021077283
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 2015862
TimeSinceStart : 1404.9087119102478
Done logging...



********** Iteration 499 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7692016363143921
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.318604469299316
Train_StdReturn : 0.7796111106872559
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.31860465116279
Actor Loss : nan
NaN or Inf found in input tensor.
Train_EnvstepsSoFar : 2019869
TimeSinceStart : 1407.3381686210632
Done logging...


########################
logging outputs to  /home/jaehyun-jeong/UCBerkeley_cs285/hw2/cs285/scripts/../../data/q2_pg_cartpole_lb_rtg_na_CartPole-v0_17-08-2024_02-45-19
########################
Using GPU id 0
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/envs/registration.py:593: UserWarning: [33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.[0m
  logger.warn(
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/core.py:317: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  deprecation(

********** Iteration 0 ************
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
/home/jaehyun-jeong/venv/cs285/lib/python3.10/site-packages/tensorboardX/summary.py:153: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
  scalar = float(scalar)
Eval_StdReturn : 0.5762563347816467
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 37.839622497558594
Train_StdReturn : 12.895177841186523
Train_MaxReturn : 80.0
Train_MinReturn : 20.0
Train_AverageEpLen : 37.839622641509436
Actor Loss : -0.1611328125
Train_EnvstepsSoFar : 4011
TimeSinceStart : 3.040332555770874
Initial_DataCollection_AverageReturn : 37.839622497558594
Done logging...



********** Iteration 1 ************

Collecting data for eval...
Eval_AverageReturn : 11.19444465637207
Eval_StdReturn : 1.2653379440307617
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 11.194444444444445
Train_AverageReturn : 9.430587768554688
Train_StdReturn : 0.7854595184326172
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.430588235294117
Actor Loss : -128.04493713378906
Train_EnvstepsSoFar : 8019
TimeSinceStart : 5.819972276687622
Done logging...



********** Iteration 2 ************

Collecting data for eval...
Eval_AverageReturn : 11.08108139038086
Eval_StdReturn : 1.0998371839523315
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 11.08108108108108
Train_AverageReturn : 11.049723625183105
Train_StdReturn : 1.3266342878341675
Train_MaxReturn : 14.0
Train_MinReturn : 9.0
Train_AverageEpLen : 11.049723756906078
Actor Loss : -272.21868896484375
Train_EnvstepsSoFar : 12019
TimeSinceStart : 9.429166793823242
Done logging...



********** Iteration 3 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.9486547112464905
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 10.643616676330566
Train_StdReturn : 1.0771375894546509
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.643617021276595
Actor Loss : -418.004638671875
Train_EnvstepsSoFar : 16021
TimeSinceStart : 12.656832456588745
Done logging...



********** Iteration 4 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7250445485115051
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.594724655151367
Train_StdReturn : 0.9375057220458984
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.594724220623501
Actor Loss : -606.3680419921875
Train_EnvstepsSoFar : 20022
TimeSinceStart : 15.187395334243774
Done logging...



********** Iteration 5 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.8720154166221619
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.337995529174805
Train_StdReturn : 0.7321945428848267
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.337995337995338
Actor Loss : -681.5076904296875
Train_EnvstepsSoFar : 24028
TimeSinceStart : 18.057419776916504
Done logging...



********** Iteration 6 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.9577330350875854
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.333333015441895
Train_StdReturn : 0.7311473488807678
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.333333333333334
Actor Loss : -699.086181640625
Train_EnvstepsSoFar : 28032
TimeSinceStart : 20.554369926452637
Done logging...



********** Iteration 7 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.8436444997787476
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.411765098571777
Train_StdReturn : 0.7653391361236572
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.411764705882353
Actor Loss : -781.756591796875
Train_EnvstepsSoFar : 32032
TimeSinceStart : 23.10102367401123
Done logging...



********** Iteration 8 ************

Collecting data for eval...
Eval_AverageReturn : 9.829268455505371
Eval_StdReturn : 0.8526126146316528
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.829268292682928
Train_AverageReturn : 9.526190757751465
Train_StdReturn : 0.8953742384910583
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.526190476190477
Actor Loss : -832.0799560546875
Train_EnvstepsSoFar : 36033
TimeSinceStart : 25.599255084991455
Done logging...



********** Iteration 9 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.7633914351463318
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.690073013305664
Train_StdReturn : 0.9494860768318176
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.690072639225182
Actor Loss : -849.7658081054688
Train_EnvstepsSoFar : 40035
TimeSinceStart : 28.678019762039185
Done logging...



********** Iteration 10 ************

Collecting data for eval...
Eval_AverageReturn : 9.7380952835083
Eval_StdReturn : 0.9013091325759888
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.738095238095237
Train_AverageReturn : 9.661835670471191
Train_StdReturn : 0.90444016456604
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.66183574879227
Actor Loss : -857.4122924804688
Train_EnvstepsSoFar : 44035
TimeSinceStart : 31.651004791259766
Done logging...



********** Iteration 11 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 1.0421096086502075
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.558472633361816
Train_StdReturn : 0.9182807803153992
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.558472553699284
Actor Loss : -855.7022705078125
Train_EnvstepsSoFar : 48040
TimeSinceStart : 34.71246027946472
Done logging...



********** Iteration 12 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.9273496270179749
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 9.546539306640625
Train_StdReturn : 0.9596171379089355
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.54653937947494
Actor Loss : -857.7221069335938
Train_EnvstepsSoFar : 52040
TimeSinceStart : 37.22796559333801
Done logging...



********** Iteration 13 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 0.9294866919517517
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 9.648192405700684
Train_StdReturn : 0.921805739402771
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.648192771084338
Actor Loss : -856.9246826171875
Train_EnvstepsSoFar : 56044
TimeSinceStart : 39.868966817855835
Done logging...



********** Iteration 14 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.9435098767280579
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.583731651306152
Train_StdReturn : 0.9326217174530029
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.583732057416269
Actor Loss : -847.8211669921875
Train_EnvstepsSoFar : 60050
TimeSinceStart : 42.3080632686615
Done logging...



********** Iteration 15 ************

Collecting data for eval...
Eval_AverageReturn : 9.113636016845703
Eval_StdReturn : 0.8038517832756042
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.113636363636363
Train_AverageReturn : 9.44339656829834
Train_StdReturn : 0.8222172856330872
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.443396226415095
Actor Loss : -836.5816650390625
Train_EnvstepsSoFar : 64054
TimeSinceStart : 45.63576579093933
Done logging...



********** Iteration 16 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.928486704826355
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.481042861938477
Train_StdReturn : 0.8106932640075684
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.481042654028435
Actor Loss : -819.5697021484375
Train_EnvstepsSoFar : 68055
TimeSinceStart : 48.14708161354065
Done logging...



********** Iteration 17 ************

Collecting data for eval...
Eval_AverageReturn : 9.534883499145508
Eval_StdReturn : 0.7578684091567993
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.534883720930232
Train_AverageReturn : 9.441038131713867
Train_StdReturn : 0.847479522228241
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.441037735849056
Actor Loss : -820.1588134765625
Train_EnvstepsSoFar : 72058
TimeSinceStart : 50.6238157749176
Done logging...



********** Iteration 18 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.7315376996994019
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.445755004882812
Train_StdReturn : 0.8990985155105591
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.445754716981131
Actor Loss : -830.18994140625
Train_EnvstepsSoFar : 76063
TimeSinceStart : 53.13748121261597
Done logging...



********** Iteration 19 ************

Collecting data for eval...
Eval_AverageReturn : 9.690476417541504
Eval_StdReturn : 0.8306077718734741
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.69047619047619
Train_AverageReturn : 9.490521430969238
Train_StdReturn : 0.8835811614990234
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.490521327014218
Actor Loss : -837.67724609375
Train_EnvstepsSoFar : 80068
TimeSinceStart : 55.66253328323364
Done logging...



********** Iteration 20 ************

Collecting data for eval...
Eval_AverageReturn : 9.619047164916992
Eval_StdReturn : 0.9747375845909119
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.619047619047619
Train_AverageReturn : 9.508313179016113
Train_StdReturn : 0.8816159963607788
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.508313539192399
Actor Loss : -838.6907958984375
Train_EnvstepsSoFar : 84071
TimeSinceStart : 58.63643288612366
Done logging...



********** Iteration 21 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.8551058769226074
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.445755004882812
Train_StdReturn : 0.853340208530426
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.445754716981131
Actor Loss : -833.807373046875
Train_EnvstepsSoFar : 88076
TimeSinceStart : 61.12352681159973
Done logging...



********** Iteration 22 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.9319231510162354
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.408451080322266
Train_StdReturn : 0.8893337249755859
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.408450704225352
Actor Loss : -820.7579345703125
Train_EnvstepsSoFar : 92084
TimeSinceStart : 63.60313844680786
Done logging...



********** Iteration 23 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7564398050308228
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.45283031463623
Train_StdReturn : 0.8256738185882568
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.452830188679245
Actor Loss : -836.7129516601562
Train_EnvstepsSoFar : 96092
TimeSinceStart : 66.1211588382721
Done logging...



********** Iteration 24 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.7939682006835938
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.396713256835938
Train_StdReturn : 0.8906865119934082
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.396713615023474
Actor Loss : -843.8051147460938
Train_EnvstepsSoFar : 100095
TimeSinceStart : 68.62539052963257
Done logging...



********** Iteration 25 ************

Collecting data for eval...
Eval_AverageReturn : 9.511628150939941
Eval_StdReturn : 0.8175997734069824
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.511627906976743
Train_AverageReturn : 9.492891311645508
Train_StdReturn : 0.8282321095466614
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.492890995260664
Actor Loss : -867.5678100585938
Train_EnvstepsSoFar : 104101
TimeSinceStart : 71.13314485549927
Done logging...



********** Iteration 26 ************

Collecting data for eval...
Eval_AverageReturn : 9.642857551574707
Eval_StdReturn : 0.7502833604812622
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.642857142857142
Train_AverageReturn : 9.495260238647461
Train_StdReturn : 0.8916284441947937
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.495260663507109
Actor Loss : -871.3023681640625
Train_EnvstepsSoFar : 108108
TimeSinceStart : 74.31868600845337
Done logging...



********** Iteration 27 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7988634705543518
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.492891311645508
Train_StdReturn : 0.8563655018806458
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.492890995260664
Actor Loss : -875.8697509765625
Train_EnvstepsSoFar : 112114
TimeSinceStart : 76.81509590148926
Done logging...



********** Iteration 28 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.9136250615119934
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.44339656829834
Train_StdReturn : 0.8803964257240295
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.443396226415095
Actor Loss : -862.8333740234375
Train_EnvstepsSoFar : 116118
TimeSinceStart : 79.47155737876892
Done logging...



********** Iteration 29 ************

Collecting data for eval...
Eval_AverageReturn : 9.511628150939941
Eval_StdReturn : 0.9244003295898438
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.511627906976743
Train_AverageReturn : 9.406103134155273
Train_StdReturn : 0.8146892786026001
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.406103286384976
Actor Loss : -873.1531372070312
Train_EnvstepsSoFar : 120125
TimeSinceStart : 81.9816951751709
Done logging...



********** Iteration 30 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.8707742094993591
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.389671325683594
Train_StdReturn : 0.8765523433685303
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.389671361502348
Actor Loss : -889.5313720703125
Train_EnvstepsSoFar : 124125
TimeSinceStart : 84.59118795394897
Done logging...



********** Iteration 31 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.7885949611663818
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 9.51306438446045
Train_StdReturn : 0.8429928421974182
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.513064133016627
Actor Loss : -908.9737548828125
Train_EnvstepsSoFar : 128130
TimeSinceStart : 87.07019281387329
Done logging...



********** Iteration 32 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.8818830251693726
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.533333778381348
Train_StdReturn : 0.8653836250305176
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.533333333333333
Actor Loss : -911.571533203125
Train_EnvstepsSoFar : 132134
TimeSinceStart : 89.56152415275574
Done logging...



********** Iteration 33 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.8222171664237976
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.445755004882812
Train_StdReturn : 0.853340208530426
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.445754716981131
Actor Loss : -908.5123291015625
Train_EnvstepsSoFar : 136139
TimeSinceStart : 92.06306385993958
Done logging...



********** Iteration 34 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.8234103322029114
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.411765098571777
Train_StdReturn : 0.8330541253089905
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.411764705882353
Actor Loss : -909.754150390625
Train_EnvstepsSoFar : 140139
TimeSinceStart : 94.52678656578064
Done logging...



********** Iteration 35 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.8182304501533508
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 9.445755004882812
Train_StdReturn : 0.8990985155105591
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.445754716981131
Actor Loss : -920.484130859375
Train_EnvstepsSoFar : 144144
TimeSinceStart : 97.01721215248108
Done logging...



********** Iteration 36 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.8988906145095825
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.5
Train_StdReturn : 0.8889793753623962
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.5
Actor Loss : -928.9006958007812
Train_EnvstepsSoFar : 148153
TimeSinceStart : 99.88778185844421
Done logging...



********** Iteration 37 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.8035884499549866
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.457547187805176
Train_StdReturn : 0.8287805318832397
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.45754716981132
Actor Loss : -935.4498901367188
Train_EnvstepsSoFar : 152163
TimeSinceStart : 102.33870601654053
Done logging...



********** Iteration 38 ************

Collecting data for eval...
Eval_AverageReturn : 9.181818008422852
Eval_StdReturn : 0.7158189415931702
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.181818181818182
Train_AverageReturn : 9.425882339477539
Train_StdReturn : 0.8703147172927856
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.425882352941176
Actor Loss : -928.6556396484375
Train_EnvstepsSoFar : 156169
TimeSinceStart : 106.21166324615479
Done logging...



********** Iteration 39 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 0.9035078883171082
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 9.4857816696167
Train_StdReturn : 0.8781371712684631
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.485781990521327
Actor Loss : -938.9561767578125
Train_EnvstepsSoFar : 160172
TimeSinceStart : 109.13735818862915
Done logging...



********** Iteration 40 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.745356023311615
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 9.483412742614746
Train_StdReturn : 0.8562343716621399
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.483412322274882
Actor Loss : -942.9638061523438
Train_EnvstepsSoFar : 164174
TimeSinceStart : 111.95404434204102
Done logging...



********** Iteration 41 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.8689089417457581
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.430587768554688
Train_StdReturn : 0.8488086462020874
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.430588235294117
Actor Loss : -948.0087890625
Train_EnvstepsSoFar : 168182
TimeSinceStart : 114.38323736190796
Done logging...



********** Iteration 42 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.9492247700691223
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.384075164794922
Train_StdReturn : 0.8831120133399963
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.38407494145199
Actor Loss : -944.6669921875
Train_EnvstepsSoFar : 172189
TimeSinceStart : 116.90800976753235
Done logging...



********** Iteration 43 ************

Collecting data for eval...
Eval_AverageReturn : 9.756097793579102
Eval_StdReturn : 1.0307583808898926
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.75609756097561
Train_AverageReturn : 9.570405960083008
Train_StdReturn : 0.8638497591018677
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.570405727923628
Actor Loss : -956.9398803710938
Train_EnvstepsSoFar : 176199
TimeSinceStart : 119.80371594429016
Done logging...



********** Iteration 44 ************

Collecting data for eval...
Eval_AverageReturn : 9.853658676147461
Eval_StdReturn : 0.9768284559249878
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.853658536585366
Train_AverageReturn : 9.707021713256836
Train_StdReturn : 0.938224732875824
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.707021791767554
Actor Loss : -955.4130859375
Train_EnvstepsSoFar : 180208
TimeSinceStart : 122.31224870681763
Done logging...



********** Iteration 45 ************

Collecting data for eval...
Eval_AverageReturn : 9.7619047164917
Eval_StdReturn : 0.9954544305801392
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.761904761904763
Train_AverageReturn : 9.615385055541992
Train_StdReturn : 0.9908978939056396
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.615384615384615
Actor Loss : -952.4171142578125
Train_EnvstepsSoFar : 184208
TimeSinceStart : 124.79383301734924
Done logging...



********** Iteration 46 ************

Collecting data for eval...
Eval_AverageReturn : 9.511628150939941
Eval_StdReturn : 0.8988906145095825
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.511627906976743
Train_AverageReturn : 9.590909004211426
Train_StdReturn : 0.9032708406448364
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.590909090909092
Actor Loss : -969.1410522460938
Train_EnvstepsSoFar : 188217
TimeSinceStart : 127.26305842399597
Done logging...



********** Iteration 47 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.7303743958473206
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 9.475177764892578
Train_StdReturn : 0.8329634666442871
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.47517730496454
Actor Loss : -978.6329345703125
Train_EnvstepsSoFar : 192225
TimeSinceStart : 129.93050456047058
Done logging...



********** Iteration 48 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.8982886672019958
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.523809432983398
Train_StdReturn : 0.8490357398986816
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.523809523809524
Actor Loss : -983.54541015625
Train_EnvstepsSoFar : 196225
TimeSinceStart : 132.4015772342682
Done logging...



********** Iteration 49 ************

Collecting data for eval...
Eval_AverageReturn : 9.511628150939941
Eval_StdReturn : 0.7886430025100708
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.511627906976743
Train_AverageReturn : 9.460992813110352
Train_StdReturn : 0.8180967569351196
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.460992907801419
Actor Loss : -991.0238037109375
Train_EnvstepsSoFar : 200227
TimeSinceStart : 134.89936113357544
Done logging...



********** Iteration 50 ************

Collecting data for eval...
Eval_AverageReturn : 9.87804889678955
Eval_StdReturn : 0.9676504731178284
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.878048780487806
Train_AverageReturn : 9.411765098571777
Train_StdReturn : 0.821678638458252
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.411764705882353
Actor Loss : -993.9242553710938
Train_EnvstepsSoFar : 204227
TimeSinceStart : 137.37403845787048
Done logging...



********** Iteration 51 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.9920316934585571
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 9.637019157409668
Train_StdReturn : 0.9382239580154419
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.63701923076923
Actor Loss : -992.8433837890625
Train_EnvstepsSoFar : 208236
TimeSinceStart : 139.87653708457947
Done logging...



********** Iteration 52 ************

Collecting data for eval...
Eval_AverageReturn : 9.642857551574707
Eval_StdReturn : 0.8401084542274475
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.642857142857142
Train_AverageReturn : 9.604316711425781
Train_StdReturn : 0.9415944814682007
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.60431654676259
Actor Loss : -994.628662109375
Train_EnvstepsSoFar : 212241
TimeSinceStart : 142.68771600723267
Done logging...



********** Iteration 53 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.8391450643539429
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.526190757751465
Train_StdReturn : 0.9545778036117554
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.526190476190477
Actor Loss : -999.0834350585938
Train_EnvstepsSoFar : 216242
TimeSinceStart : 145.1919949054718
Done logging...



********** Iteration 54 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.7111130952835083
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.588517189025879
Train_StdReturn : 0.8928543329238892
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.588516746411484
Actor Loss : -1015.0325927734375
Train_EnvstepsSoFar : 220250
TimeSinceStart : 147.71388339996338
Done logging...



********** Iteration 55 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 0.9547589421272278
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 9.333333015441895
Train_StdReturn : 0.7592986822128296
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.333333333333334
Actor Loss : -1019.2135009765625
Train_EnvstepsSoFar : 224254
TimeSinceStart : 150.3760211467743
Done logging...



********** Iteration 56 ************

Collecting data for eval...
Eval_AverageReturn : 9.756097793579102
Eval_StdReturn : 0.849116861820221
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.75609756097561
Train_AverageReturn : 9.702178955078125
Train_StdReturn : 0.9672207236289978
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.702179176755449
Actor Loss : -1015.34765625
Train_EnvstepsSoFar : 228261
TimeSinceStart : 153.01250386238098
Done logging...



********** Iteration 57 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.8035884499549866
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.847665786743164
Train_StdReturn : 0.8420101404190063
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.847665847665848
Actor Loss : -1007.3010864257812
Train_EnvstepsSoFar : 232269
TimeSinceStart : 155.66816473007202
Done logging...



********** Iteration 58 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.7782883644104004
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.403756141662598
Train_StdReturn : 0.8620235323905945
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.4037558685446
Actor Loss : -1036.656494140625
Train_EnvstepsSoFar : 236275
TimeSinceStart : 158.3145513534546
Done logging...



********** Iteration 59 ************

Collecting data for eval...
Eval_AverageReturn : 10.710526466369629
Eval_StdReturn : 1.0236132144927979
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.710526315789474
Train_AverageReturn : 9.425882339477539
Train_StdReturn : 0.7355114817619324
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.425882352941176
Actor Loss : -1015.5887451171875
Train_EnvstepsSoFar : 240281
TimeSinceStart : 160.97006249427795
Done logging...



********** Iteration 60 ************

Collecting data for eval...
Eval_AverageReturn : 11.25
Eval_StdReturn : 1.2774758338928223
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 11.25
Train_AverageReturn : 10.711230278015137
Train_StdReturn : 1.0429452657699585
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.711229946524064
Actor Loss : -885.8768310546875
Train_EnvstepsSoFar : 244287
TimeSinceStart : 163.56573390960693
Done logging...



********** Iteration 61 ************

Collecting data for eval...
Eval_AverageReturn : 11.657142639160156
Eval_StdReturn : 1.3297230005264282
Eval_MaxReturn : 14.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 11.657142857142857
Train_AverageReturn : 11.24438190460205
Train_StdReturn : 1.2175434827804565
Train_MaxReturn : 14.0
Train_MinReturn : 9.0
Train_AverageEpLen : 11.24438202247191
Actor Loss : -758.5899658203125
Train_EnvstepsSoFar : 248290
TimeSinceStart : 166.35643076896667
Done logging...



********** Iteration 62 ************

Collecting data for eval...
Eval_AverageReturn : 11.45714282989502
Eval_StdReturn : 1.4211233854293823
Eval_MaxReturn : 14.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 11.457142857142857
Train_AverageReturn : 11.553314208984375
Train_StdReturn : 1.2191598415374756
Train_MaxReturn : 14.0
Train_MinReturn : 9.0
Train_AverageEpLen : 11.553314121037465
Actor Loss : -711.3463134765625
Train_EnvstepsSoFar : 252299
TimeSinceStart : 169.79970383644104
Done logging...



********** Iteration 63 ************

Collecting data for eval...
Eval_AverageReturn : 11.08108139038086
Eval_StdReturn : 1.3023549318313599
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 11.08108108108108
Train_AverageReturn : 11.396011352539062
Train_StdReturn : 1.2287561893463135
Train_MaxReturn : 14.0
Train_MinReturn : 9.0
Train_AverageEpLen : 11.396011396011396
Actor Loss : -734.7850341796875
Train_EnvstepsSoFar : 256299
TimeSinceStart : 172.39044547080994
Done logging...



********** Iteration 64 ************

Collecting data for eval...
Eval_AverageReturn : 10.125
Eval_StdReturn : 1.029259443283081
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.125
Train_AverageReturn : 10.978082656860352
Train_StdReturn : 1.3667527437210083
Train_MaxReturn : 14.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.978082191780821
Actor Loss : -810.331298828125
Train_EnvstepsSoFar : 260306
TimeSinceStart : 174.94726490974426
Done logging...



********** Iteration 65 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.9428091049194336
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 10.258974075317383
Train_StdReturn : 0.9803761839866638
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.25897435897436
Actor Loss : -933.6500854492188
Train_EnvstepsSoFar : 264307
TimeSinceStart : 177.75116419792175
Done logging...



********** Iteration 66 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.8561276793479919
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.448113441467285
Train_StdReturn : 0.8109778761863708
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.44811320754717
Actor Loss : -1038.0013427734375
Train_EnvstepsSoFar : 268313
TimeSinceStart : 181.55908870697021
Done logging...



********** Iteration 67 ************

Collecting data for eval...
Eval_AverageReturn : 9.642857551574707
Eval_StdReturn : 0.5265081524848938
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 9.642857142857142
Train_AverageReturn : 9.335664749145508
Train_StdReturn : 0.7567325234413147
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.335664335664335
Actor Loss : -783.6167602539062
Train_EnvstepsSoFar : 272318
TimeSinceStart : 184.09478998184204
Done logging...



********** Iteration 68 ************

Collecting data for eval...
Eval_AverageReturn : 9.7619047164917
Eval_StdReturn : 0.9464098215103149
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.761904761904763
Train_AverageReturn : 9.367681503295898
Train_StdReturn : 0.7359519600868225
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36768149882904
Actor Loss : -846.32958984375
Train_EnvstepsSoFar : 276318
TimeSinceStart : 187.07110953330994
Done logging...



********** Iteration 69 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.9370425939559937
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 9.643373489379883
Train_StdReturn : 0.9303700923919678
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.643373493975904
Actor Loss : -1021.3820190429688
Train_EnvstepsSoFar : 280320
TimeSinceStart : 191.94145154953003
Done logging...



********** Iteration 70 ************

Collecting data for eval...
Eval_AverageReturn : 10.710526466369629
Eval_StdReturn : 0.9150179028511047
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.710526315789474
Train_AverageReturn : 10.15989875793457
Train_StdReturn : 1.0482357740402222
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.15989847715736
Actor Loss : -940.45751953125
Train_EnvstepsSoFar : 284323
TimeSinceStart : 194.5123267173767
Done logging...



********** Iteration 71 ************

Collecting data for eval...
Eval_AverageReturn : 10.972972869873047
Eval_StdReturn : 0.9996346831321716
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.972972972972974
Train_AverageReturn : 10.61273193359375
Train_StdReturn : 1.029355525970459
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.612732095490717
Actor Loss : -874.8621826171875
Train_EnvstepsSoFar : 288324
TimeSinceStart : 197.0805263519287
Done logging...



********** Iteration 72 ************

Collecting data for eval...
Eval_AverageReturn : 11.08108139038086
Eval_StdReturn : 0.9117366671562195
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 11.08108108108108
Train_AverageReturn : 10.76075267791748
Train_StdReturn : 1.0596548318862915
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.760752688172044
Actor Loss : -852.2147216796875
Train_EnvstepsSoFar : 292327
TimeSinceStart : 201.9578001499176
Done logging...



********** Iteration 73 ************

Collecting data for eval...
Eval_AverageReturn : 10.435897827148438
Eval_StdReturn : 0.9817532896995544
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.435897435897436
Train_AverageReturn : 10.57519817352295
Train_StdReturn : 1.0203818082809448
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.575197889182059
Actor Loss : -865.3123779296875
Train_EnvstepsSoFar : 296335
TimeSinceStart : 204.95047187805176
Done logging...



********** Iteration 74 ************

Collecting data for eval...
Eval_AverageReturn : 9.97560977935791
Eval_StdReturn : 0.999702513217926
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.975609756097562
Train_AverageReturn : 10.506561279296875
Train_StdReturn : 1.015927791595459
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.506561679790027
Actor Loss : -886.5126342773438
Train_EnvstepsSoFar : 300338
TimeSinceStart : 209.1004569530487
Done logging...



********** Iteration 75 ************

Collecting data for eval...
Eval_AverageReturn : 9.90243911743164
Eval_StdReturn : 0.849817156791687
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.902439024390244
Train_AverageReturn : 10.047618865966797
Train_StdReturn : 1.043052315711975
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.047619047619047
Actor Loss : -938.2987060546875
Train_EnvstepsSoFar : 304347
TimeSinceStart : 211.6539866924286
Done logging...



********** Iteration 76 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.5846421122550964
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.813725471496582
Train_StdReturn : 0.8601230382919312
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.813725490196079
Actor Loss : -1004.9063720703125
Train_EnvstepsSoFar : 308351
TimeSinceStart : 214.9409191608429
Done logging...



********** Iteration 77 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7692015767097473
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.340326309204102
Train_StdReturn : 0.748444139957428
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.34032634032634
Actor Loss : -999.94091796875
Train_EnvstepsSoFar : 312358
TimeSinceStart : 217.49084401130676
Done logging...



********** Iteration 78 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.738349199295044
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.384075164794922
Train_StdReturn : 0.7387115955352783
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.38407494145199
Actor Loss : -879.3123779296875
Train_EnvstepsSoFar : 316365
TimeSinceStart : 220.6195912361145
Done logging...



********** Iteration 79 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.787956953048706
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.34813117980957
Train_StdReturn : 0.7750919461250305
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.348130841121495
Actor Loss : -989.259521484375
Train_EnvstepsSoFar : 320366
TimeSinceStart : 223.1680133342743
Done logging...



********** Iteration 80 ************

Collecting data for eval...
Eval_AverageReturn : 9.714285850524902
Eval_StdReturn : 0.8531653881072998
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 9.714285714285714
Train_AverageReturn : 9.61151123046875
Train_StdReturn : 0.9758041501045227
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.611510791366907
Actor Loss : -1018.5419311523438
Train_EnvstepsSoFar : 324374
TimeSinceStart : 227.3892364501953
Done logging...



********** Iteration 81 ************

Collecting data for eval...
Eval_AverageReturn : 10.050000190734863
Eval_StdReturn : 1.0943033695220947
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.05
Train_AverageReturn : 10.047618865966797
Train_StdReturn : 0.968288242816925
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.047619047619047
Actor Loss : -987.3760375976562
Train_EnvstepsSoFar : 328383
TimeSinceStart : 230.0096275806427
Done logging...



********** Iteration 82 ************

Collecting data for eval...
Eval_AverageReturn : 9.92682933807373
Eval_StdReturn : 0.9471457600593567
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.926829268292684
Train_AverageReturn : 10.072864532470703
Train_StdReturn : 1.0784398317337036
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.07286432160804
Actor Loss : -956.073974609375
Train_EnvstepsSoFar : 332392
TimeSinceStart : 234.97663831710815
Done logging...



********** Iteration 83 ************

Collecting data for eval...
Eval_AverageReturn : 10.149999618530273
Eval_StdReturn : 0.9367496371269226
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.15
Train_AverageReturn : 10.188295364379883
Train_StdReturn : 1.0338619947433472
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.188295165394402
Actor Loss : -961.7905883789062
Train_EnvstepsSoFar : 336396
TimeSinceStart : 237.59121131896973
Done logging...



********** Iteration 84 ************

Collecting data for eval...
Eval_AverageReturn : 9.829268455505371
Eval_StdReturn : 0.9344996809959412
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.829268292682928
Train_AverageReturn : 10.042606353759766
Train_StdReturn : 0.9915377497673035
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.042606516290727
Actor Loss : -994.4112548828125
Train_EnvstepsSoFar : 340403
TimeSinceStart : 240.8160469532013
Done logging...



********** Iteration 85 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.6827868819236755
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.588517189025879
Train_StdReturn : 0.8901708126068115
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.588516746411484
Actor Loss : -1038.842529296875
Train_EnvstepsSoFar : 344411
TimeSinceStart : 243.483962059021
Done logging...



********** Iteration 86 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.6898789405822754
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.352804183959961
Train_StdReturn : 0.7789980173110962
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.352803738317757
Actor Loss : -1025.7059326171875
Train_EnvstepsSoFar : 348414
TimeSinceStart : 246.03170108795166
Done logging...



********** Iteration 87 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 1.0788291692733765
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.377049446105957
Train_StdReturn : 0.7625531554222107
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.37704918032787
Actor Loss : -990.6363525390625
Train_EnvstepsSoFar : 352418
TimeSinceStart : 248.6135699748993
Done logging...



********** Iteration 88 ************

Collecting data for eval...
Eval_AverageReturn : 10.256410598754883
Eval_StdReturn : 0.8978021144866943
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.256410256410257
Train_AverageReturn : 9.526190757751465
Train_StdReturn : 0.908572793006897
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.526190476190477
Actor Loss : -1049.1680908203125
Train_EnvstepsSoFar : 356419
TimeSinceStart : 251.53272342681885
Done logging...



********** Iteration 89 ************

Collecting data for eval...
Eval_AverageReturn : 10.435897827148438
Eval_StdReturn : 1.0572065114974976
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.435897435897436
Train_AverageReturn : 10.050251007080078
Train_StdReturn : 1.0137187242507935
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.050251256281408
Actor Loss : -1008.41650390625
Train_EnvstepsSoFar : 360419
TimeSinceStart : 254.07561564445496
Done logging...



********** Iteration 90 ************

Collecting data for eval...
Eval_AverageReturn : 10.526315689086914
Eval_StdReturn : 1.0447070598602295
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.526315789473685
Train_AverageReturn : 10.190839767456055
Train_StdReturn : 1.034625768661499
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.19083969465649
Actor Loss : -973.5828247070312
Train_EnvstepsSoFar : 364424
TimeSinceStart : 259.000305891037
Done logging...



********** Iteration 91 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 1.0836857557296753
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 10.279487609863281
Train_StdReturn : 1.0083445310592651
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.27948717948718
Actor Loss : -968.7896728515625
Train_EnvstepsSoFar : 368433
TimeSinceStart : 261.63474774360657
Done logging...



********** Iteration 92 ************

Collecting data for eval...
Eval_AverageReturn : 9.804878234863281
Eval_StdReturn : 0.8616352081298828
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.804878048780488
Train_AverageReturn : 10.209183692932129
Train_StdReturn : 1.0361413955688477
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.209183673469388
Actor Loss : -987.706298828125
Train_EnvstepsSoFar : 372435
TimeSinceStart : 264.5551426410675
Done logging...



********** Iteration 93 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.8664156794548035
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.975062370300293
Train_StdReturn : 0.8674648404121399
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.975062344139651
Actor Loss : -1040.6138916015625
Train_EnvstepsSoFar : 376435
TimeSinceStart : 267.09654784202576
Done logging...



********** Iteration 94 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.6519927978515625
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.475177764892578
Train_StdReturn : 0.8608771562576294
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.47517730496454
Actor Loss : -1064.028076171875
Train_EnvstepsSoFar : 380443
TimeSinceStart : 269.9639608860016
Done logging...



********** Iteration 95 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 0.7604151964187622
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 9.342657089233398
Train_StdReturn : 0.7612855434417725
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.342657342657343
Actor Loss : -993.4171142578125
Train_EnvstepsSoFar : 384451
TimeSinceStart : 273.2995743751526
Done logging...



********** Iteration 96 ************

Collecting data for eval...
Eval_AverageReturn : 9.853658676147461
Eval_StdReturn : 0.898806095123291
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.853658536585366
Train_AverageReturn : 9.320930480957031
Train_StdReturn : 0.8036423921585083
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.320930232558139
Actor Loss : -1066.1129150390625
Train_EnvstepsSoFar : 388459
TimeSinceStart : 275.8538134098053
Done logging...



********** Iteration 97 ************

Collecting data for eval...
Eval_AverageReturn : 10.074999809265137
Eval_StdReturn : 1.034105896949768
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.075
Train_AverageReturn : 9.80637264251709
Train_StdReturn : 0.8542044758796692
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.806372549019608
Actor Loss : -1049.4320068359375
Train_EnvstepsSoFar : 392460
TimeSinceStart : 278.7113220691681
Done logging...



********** Iteration 98 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 1.1723374128341675
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 10.055275917053223
Train_StdReturn : 1.0233259201049805
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.055276381909549
Actor Loss : -1011.8723754882812
Train_EnvstepsSoFar : 396462
TimeSinceStart : 281.8441767692566
Done logging...



********** Iteration 99 ************

Collecting data for eval...
Eval_AverageReturn : 10.175000190734863
Eval_StdReturn : 0.8627716898918152
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.175
Train_AverageReturn : 10.15989875793457
Train_StdReturn : 1.0626640319824219
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.15989847715736
Actor Loss : -1003.907958984375
Train_EnvstepsSoFar : 400465
TimeSinceStart : 284.3950433731079
Done logging...



********** Iteration 100 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.7126966118812561
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 9.99002456665039
Train_StdReturn : 0.9631102085113525
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.99002493765586
Actor Loss : -1030.5205078125
Train_EnvstepsSoFar : 404471
TimeSinceStart : 287.36862897872925
Done logging...



********** Iteration 101 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.6970133781433105
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 9.681159019470215
Train_StdReturn : 0.8845330476760864
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.681159420289855
Actor Loss : -1067.822509765625
Train_EnvstepsSoFar : 408479
TimeSinceStart : 289.8300726413727
Done logging...



********** Iteration 102 ************

Collecting data for eval...
Eval_AverageReturn : 9.619047164916992
Eval_StdReturn : 0.9245946407318115
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.619047619047619
Train_AverageReturn : 9.357476234436035
Train_StdReturn : 0.7076123356819153
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.357476635514018
Actor Loss : -1058.1265869140625
Train_EnvstepsSoFar : 412484
TimeSinceStart : 292.79733085632324
Done logging...



********** Iteration 103 ************

Collecting data for eval...
Eval_AverageReturn : 9.690476417541504
Eval_StdReturn : 0.7396296858787537
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.69047619047619
Train_AverageReturn : 9.470449447631836
Train_StdReturn : 0.8797439932823181
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.470449172576831
Actor Loss : -1075.0699462890625
Train_EnvstepsSoFar : 416490
TimeSinceStart : 295.265743970871
Done logging...



********** Iteration 104 ************

Collecting data for eval...
Eval_AverageReturn : 9.804878234863281
Eval_StdReturn : 0.9165021777153015
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.804878048780488
Train_AverageReturn : 9.681159019470215
Train_StdReturn : 0.8817980885505676
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.681159420289855
Actor Loss : -1069.881103515625
Train_EnvstepsSoFar : 420498
TimeSinceStart : 297.79531836509705
Done logging...



********** Iteration 105 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.9486547112464905
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.739659309387207
Train_StdReturn : 0.8416522145271301
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.739659367396595
Actor Loss : -1069.51025390625
Train_EnvstepsSoFar : 424501
TimeSinceStart : 302.50950598716736
Done logging...



********** Iteration 106 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.7585816383361816
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.568018913269043
Train_StdReturn : 0.9508336186408997
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.568019093078759
Actor Loss : -1073.83935546875
Train_EnvstepsSoFar : 428510
TimeSinceStart : 306.539874792099
Done logging...



********** Iteration 107 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.6519927978515625
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.441038131713867
Train_StdReturn : 0.8104941844940186
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.441037735849056
Actor Loss : -1083.8505859375
Train_EnvstepsSoFar : 432513
TimeSinceStart : 309.0550322532654
Done logging...



********** Iteration 108 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.8455654978752136
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.438679695129395
Train_StdReturn : 0.777644157409668
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.43867924528302
Actor Loss : -1087.686279296875
Train_EnvstepsSoFar : 436515
TimeSinceStart : 312.97751474380493
Done logging...



********** Iteration 109 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.7817551493644714
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.51306438446045
Train_StdReturn : 0.9107149839401245
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.513064133016627
Actor Loss : -1080.397705078125
Train_EnvstepsSoFar : 440520
TimeSinceStart : 315.50123381614685
Done logging...



********** Iteration 110 ************

Collecting data for eval...
Eval_AverageReturn : 9.690476417541504
Eval_StdReturn : 0.9382886290550232
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.69047619047619
Train_AverageReturn : 9.629807472229004
Train_StdReturn : 0.8673988580703735
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.629807692307692
Actor Loss : -1076.9310302734375
Train_EnvstepsSoFar : 444526
TimeSinceStart : 318.00627636909485
Done logging...



********** Iteration 111 ************

Collecting data for eval...
Eval_AverageReturn : 9.181818008422852
Eval_StdReturn : 0.7767276167869568
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.181818181818182
Train_AverageReturn : 9.613908767700195
Train_StdReturn : 0.8771538734436035
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.613908872901678
Actor Loss : -1085.4688720703125
Train_EnvstepsSoFar : 448535
TimeSinceStart : 322.5826635360718
Done logging...



********** Iteration 112 ************

Collecting data for eval...
Eval_AverageReturn : 9.829268455505371
Eval_StdReturn : 0.9344996809959412
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.829268292682928
Train_AverageReturn : 9.313953399658203
Train_StdReturn : 0.7418020963668823
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.313953488372093
Actor Loss : -1093.2410888671875
Train_EnvstepsSoFar : 452540
TimeSinceStart : 325.47608399391174
Done logging...



********** Iteration 113 ************

Collecting data for eval...
Eval_AverageReturn : 10.256410598754883
Eval_StdReturn : 0.9259214997291565
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.256410256410257
Train_AverageReturn : 10.055275917053223
Train_StdReturn : 0.9755606055259705
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.055276381909549
Actor Loss : -1055.65625
Train_EnvstepsSoFar : 456542
TimeSinceStart : 330.20819187164307
Done logging...



********** Iteration 114 ************

Collecting data for eval...
Eval_AverageReturn : 10.256410598754883
Eval_StdReturn : 1.0055729150772095
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.256410256410257
Train_AverageReturn : 10.177664756774902
Train_StdReturn : 1.0170668363571167
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.17766497461929
Actor Loss : -1021.72900390625
Train_EnvstepsSoFar : 460552
TimeSinceStart : 332.80409240722656
Done logging...



********** Iteration 115 ************

Collecting data for eval...
Eval_AverageReturn : 9.87804889678955
Eval_StdReturn : 1.016812801361084
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.878048780487806
Train_AverageReturn : 10.285346984863281
Train_StdReturn : 1.008098840713501
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.2853470437018
Actor Loss : -1018.6618041992188
Train_EnvstepsSoFar : 464553
TimeSinceStart : 335.86646795272827
Done logging...



********** Iteration 116 ************

Collecting data for eval...
Eval_AverageReturn : 9.204545021057129
Eval_StdReturn : 0.7561728954315186
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.204545454545455
Train_AverageReturn : 10.005000114440918
Train_StdReturn : 1.0606483221054077
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.005
Actor Loss : -1044.91796875
Train_EnvstepsSoFar : 468555
TimeSinceStart : 339.08201789855957
Done logging...



********** Iteration 117 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.7514183521270752
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.569377899169922
Train_StdReturn : 0.8728877305984497
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.569377990430622
Actor Loss : -1099.432861328125
Train_EnvstepsSoFar : 472555
TimeSinceStart : 341.7686104774475
Done logging...



********** Iteration 118 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.787956953048706
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.326340675354004
Train_StdReturn : 0.77896648645401
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.326340326340326
Actor Loss : -1026.07861328125
Train_EnvstepsSoFar : 476556
TimeSinceStart : 344.35396122932434
Done logging...



********** Iteration 119 ************

Collecting data for eval...
Eval_AverageReturn : 10.282051086425781
Eval_StdReturn : 1.0609313249588013
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.282051282051283
Train_AverageReturn : 9.34813117980957
Train_StdReturn : 0.7750919461250305
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.348130841121495
Actor Loss : -1104.8095703125
Train_EnvstepsSoFar : 480557
TimeSinceStart : 347.42877292633057
Done logging...



********** Iteration 120 ************

Collecting data for eval...
Eval_AverageReturn : 10.6578950881958
Eval_StdReturn : 1.05820894241333
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.657894736842104
Train_AverageReturn : 10.15989875793457
Train_StdReturn : 0.9884182810783386
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.15989847715736
Actor Loss : -1021.6914672851562
Train_EnvstepsSoFar : 484560
TimeSinceStart : 349.91568636894226
Done logging...



********** Iteration 121 ************

Collecting data for eval...
Eval_AverageReturn : 10.86486530303955
Eval_StdReturn : 1.1189320087432861
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.864864864864865
Train_AverageReturn : 10.582010269165039
Train_StdReturn : 1.0388710498809814
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.582010582010582
Actor Loss : -965.6460571289062
Train_EnvstepsSoFar : 488560
TimeSinceStart : 352.6771938800812
Done logging...



********** Iteration 122 ************

Collecting data for eval...
Eval_AverageReturn : 10.684210777282715
Eval_StdReturn : 0.8916354775428772
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.68421052631579
Train_AverageReturn : 10.69518756866455
Train_StdReturn : 1.1153419017791748
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.695187165775401
Actor Loss : -938.28857421875
Train_EnvstepsSoFar : 492560
TimeSinceStart : 355.1794490814209
Done logging...



********** Iteration 123 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 1.0121140480041504
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 10.677332878112793
Train_StdReturn : 1.00393545627594
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.677333333333333
Actor Loss : -960.0756225585938
Train_EnvstepsSoFar : 496564
TimeSinceStart : 358.943706035614
Done logging...



********** Iteration 124 ************

Collecting data for eval...
Eval_AverageReturn : 10.100000381469727
Eval_StdReturn : 0.9695360064506531
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.1
Train_AverageReturn : 10.391191482543945
Train_StdReturn : 1.0229618549346924
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.39119170984456
Actor Loss : -992.9830322265625
Train_EnvstepsSoFar : 500575
TimeSinceStart : 361.43775939941406
Done logging...



********** Iteration 125 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 0.8206517696380615
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 10.108586311340332
Train_StdReturn : 0.9800159931182861
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.108585858585858
Actor Loss : -1046.6107177734375
Train_EnvstepsSoFar : 504578
TimeSinceStart : 363.92779874801636
Done logging...



********** Iteration 126 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.6827868819236755
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.481042861938477
Train_StdReturn : 0.907248854637146
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.481042654028435
Actor Loss : -1092.022705078125
Train_EnvstepsSoFar : 508579
TimeSinceStart : 366.41616344451904
Done logging...



********** Iteration 127 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.6999961137771606
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.352804183959961
Train_StdReturn : 0.722997784614563
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.352803738317757
Actor Loss : -1013.7384033203125
Train_EnvstepsSoFar : 512582
TimeSinceStart : 369.7718496322632
Done logging...



********** Iteration 128 ************

Collecting data for eval...
Eval_AverageReturn : 10.149999618530273
Eval_StdReturn : 0.7921489477157593
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.15
Train_AverageReturn : 9.37236499786377
Train_StdReturn : 0.7399504780769348
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.372365339578455
Actor Loss : -1056.56787109375
Train_EnvstepsSoFar : 516584
TimeSinceStart : 372.6781995296478
Done logging...



********** Iteration 129 ************

Collecting data for eval...
Eval_AverageReturn : 10.149999618530273
Eval_StdReturn : 0.9367496371269226
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.15
Train_AverageReturn : 9.90099048614502
Train_StdReturn : 0.9414014220237732
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.900990099009901
Actor Loss : -1062.637939453125
Train_EnvstepsSoFar : 520584
TimeSinceStart : 376.0300362110138
Done logging...



********** Iteration 130 ************

Collecting data for eval...
Eval_AverageReturn : 10.631579399108887
Eval_StdReturn : 1.1566979885101318
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.631578947368421
Train_AverageReturn : 10.427083015441895
Train_StdReturn : 1.087282419204712
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.427083333333334
Actor Loss : -994.4631958007812
Train_EnvstepsSoFar : 524588
TimeSinceStart : 378.67453145980835
Done logging...



********** Iteration 131 ************

Collecting data for eval...
Eval_AverageReturn : 10.605262756347656
Eval_StdReturn : 1.0397236347198486
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.605263157894736
Train_AverageReturn : 10.55672836303711
Train_StdReturn : 1.0189889669418335
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.556728232189974
Actor Loss : -958.9567260742188
Train_EnvstepsSoFar : 528589
TimeSinceStart : 381.17523527145386
Done logging...



********** Iteration 132 ************

Collecting data for eval...
Eval_AverageReturn : 10.605262756347656
Eval_StdReturn : 1.1130677461624146
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.605263157894736
Train_AverageReturn : 10.723860740661621
Train_StdReturn : 1.091715931892395
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.723860589812332
Actor Loss : -940.1287841796875
Train_EnvstepsSoFar : 532589
TimeSinceStart : 383.6527621746063
Done logging...



********** Iteration 133 ************

Collecting data for eval...
Eval_AverageReturn : 10.25
Eval_StdReturn : 0.9420721530914307
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.25
Train_AverageReturn : 10.603174209594727
Train_StdReturn : 1.047137975692749
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.603174603174603
Actor Loss : -956.8505249023438
Train_EnvstepsSoFar : 536597
TimeSinceStart : 386.1458079814911
Done logging...



********** Iteration 134 ************

Collecting data for eval...
Eval_AverageReturn : 9.95121955871582
Eval_StdReturn : 1.1466008424758911
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.951219512195122
Train_AverageReturn : 10.424479484558105
Train_StdReturn : 1.0126928091049194
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.424479166666666
Actor Loss : -991.05126953125
Train_EnvstepsSoFar : 540600
TimeSinceStart : 388.6411464214325
Done logging...



********** Iteration 135 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.8707742094993591
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 10.083123207092285
Train_StdReturn : 1.05307137966156
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.083123425692696
Actor Loss : -1033.24267578125
Train_EnvstepsSoFar : 544603
TimeSinceStart : 391.9937663078308
Done logging...



********** Iteration 136 ************

Collecting data for eval...
Eval_AverageReturn : 9.227272987365723
Eval_StdReturn : 0.7027102112770081
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.227272727272727
Train_AverageReturn : 9.576555252075195
Train_StdReturn : 0.9459688067436218
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.576555023923445
Actor Loss : -1084.632568359375
Train_EnvstepsSoFar : 548606
TimeSinceStart : 395.01735639572144
Done logging...



********** Iteration 137 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.711491048336029
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.35981273651123
Train_StdReturn : 0.7621120810508728
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.35981308411215
Actor Loss : -1024.016357421875
Train_EnvstepsSoFar : 552612
TimeSinceStart : 398.26082038879395
Done logging...



********** Iteration 138 ************

Collecting data for eval...
Eval_AverageReturn : 9.90243911743164
Eval_StdReturn : 0.9577636122703552
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.902439024390244
Train_AverageReturn : 9.389671325683594
Train_StdReturn : 0.7741640210151672
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.389671361502348
Actor Loss : -1032.5802001953125
Train_EnvstepsSoFar : 556612
TimeSinceStart : 401.2724425792694
Done logging...



********** Iteration 139 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.8660253882408142
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 9.661835670471191
Train_StdReturn : 0.9229455590248108
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.66183574879227
Actor Loss : -1086.1131591796875
Train_EnvstepsSoFar : 560612
TimeSinceStart : 404.462922334671
Done logging...



********** Iteration 140 ************

Collecting data for eval...
Eval_AverageReturn : 10.605262756347656
Eval_StdReturn : 1.0647331476211548
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.605263157894736
Train_AverageReturn : 9.937965393066406
Train_StdReturn : 0.9703406691551208
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.937965260545905
Actor Loss : -1053.0479736328125
Train_EnvstepsSoFar : 564617
TimeSinceStart : 407.7847189903259
Done logging...



********** Iteration 141 ************

Collecting data for eval...
Eval_AverageReturn : 9.97560977935791
Eval_StdReturn : 0.9749998450279236
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.975609756097562
Train_AverageReturn : 10.11111068725586
Train_StdReturn : 1.0139321088790894
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.11111111111111
Actor Loss : -1030.3079833984375
Train_EnvstepsSoFar : 568621
TimeSinceStart : 411.096782207489
Done logging...



********** Iteration 142 ************

Collecting data for eval...
Eval_AverageReturn : 10.050000190734863
Eval_StdReturn : 1.0234744548797607
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.05
Train_AverageReturn : 10.075566291809082
Train_StdReturn : 0.9676544666290283
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.075566750629722
Actor Loss : -1031.0164794921875
Train_EnvstepsSoFar : 572621
TimeSinceStart : 414.0770523548126
Done logging...



********** Iteration 143 ************

Collecting data for eval...
Eval_AverageReturn : 9.7619047164917
Eval_StdReturn : 0.8397710919380188
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.761904761904763
Train_AverageReturn : 9.985037803649902
Train_StdReturn : 0.9500101804733276
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.98503740648379
Actor Loss : -1051.062255859375
Train_EnvstepsSoFar : 576625
TimeSinceStart : 416.5829164981842
Done logging...



********** Iteration 144 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.534377932548523
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.85960578918457
Train_StdReturn : 0.8946990966796875
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.85960591133005
Actor Loss : -1084.454833984375
Train_EnvstepsSoFar : 580628
TimeSinceStart : 419.6768271923065
Done logging...



********** Iteration 145 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.738349199295044
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.8059630393981934
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : -1100.2928466796875
Train_EnvstepsSoFar : 584632
TimeSinceStart : 422.1916103363037
Done logging...



********** Iteration 146 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.9060142040252686
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.345794677734375
Train_StdReturn : 0.7532212138175964
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.345794392523365
Actor Loss : -1060.581298828125
Train_EnvstepsSoFar : 588632
TimeSinceStart : 424.7138090133667
Done logging...



********** Iteration 147 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 0.9079509973526001
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 9.576555252075195
Train_StdReturn : 0.8444162607192993
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.576555023923445
Actor Loss : -1106.367431640625
Train_EnvstepsSoFar : 592635
TimeSinceStart : 427.96654081344604
Done logging...



********** Iteration 148 ************

Collecting data for eval...
Eval_AverageReturn : 9.780488014221191
Eval_StdReturn : 0.9242583513259888
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.78048780487805
Train_AverageReturn : 9.905941009521484
Train_StdReturn : 0.8988796472549438
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.905940594059405
Actor Loss : -1087.7447509765625
Train_EnvstepsSoFar : 596637
TimeSinceStart : 431.2230381965637
Done logging...



********** Iteration 149 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.8944271802902222
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 9.960199356079102
Train_StdReturn : 0.9481104016304016
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.960199004975124
Actor Loss : -1071.235595703125
Train_EnvstepsSoFar : 600641
TimeSinceStart : 434.57050037384033
Done logging...



********** Iteration 150 ************

Collecting data for eval...
Eval_AverageReturn : 9.714285850524902
Eval_StdReturn : 0.9072647094726562
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.714285714285714
Train_AverageReturn : 10.116161346435547
Train_StdReturn : 0.9622372388839722
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.116161616161616
Actor Loss : -1075.725341796875
Train_EnvstepsSoFar : 604647
TimeSinceStart : 437.4671812057495
Done logging...



********** Iteration 151 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.6577737927436829
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.74695873260498
Train_StdReturn : 0.8249214887619019
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.746958637469586
Actor Loss : -1105.5191650390625
Train_EnvstepsSoFar : 608653
TimeSinceStart : 439.9651050567627
Done logging...



********** Iteration 152 ************

Collecting data for eval...
Eval_AverageReturn : 9.853658676147461
Eval_StdReturn : 0.871247410774231
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.853658536585366
Train_AverageReturn : 9.364485740661621
Train_StdReturn : 0.7660130858421326
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36448598130841
Actor Loss : -1098.4794921875
Train_EnvstepsSoFar : 612661
TimeSinceStart : 442.47795057296753
Done logging...



********** Iteration 153 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 0.9079509973526001
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 9.74209213256836
Train_StdReturn : 0.8832887411117554
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.742092457420924
Actor Loss : -1109.8671875
Train_EnvstepsSoFar : 616665
TimeSinceStart : 445.0171194076538
Done logging...



********** Iteration 154 ************

Collecting data for eval...
Eval_AverageReturn : 9.87804889678955
Eval_StdReturn : 0.9676504731178284
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.878048780487806
Train_AverageReturn : 9.91089153289795
Train_StdReturn : 0.8714277744293213
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.910891089108912
Actor Loss : -1102.363037109375
Train_EnvstepsSoFar : 620669
TimeSinceStart : 447.53367137908936
Done logging...



********** Iteration 155 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.8908708691596985
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 9.828009605407715
Train_StdReturn : 0.9085462093353271
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.828009828009828
Actor Loss : -1100.20703125
Train_EnvstepsSoFar : 624669
TimeSinceStart : 451.37180852890015
Done logging...



********** Iteration 156 ************

Collecting data for eval...
Eval_AverageReturn : 9.272727012634277
Eval_StdReturn : 0.8080177307128906
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.272727272727273
Train_AverageReturn : 9.604316711425781
Train_StdReturn : 0.9313514232635498
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.60431654676259
Actor Loss : -1111.6466064453125
Train_EnvstepsSoFar : 628674
TimeSinceStart : 453.87052869796753
Done logging...



********** Iteration 157 ************

Collecting data for eval...
Eval_AverageReturn : 9.804878234863281
Eval_StdReturn : 0.942738950252533
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.804878048780488
Train_AverageReturn : 9.370023727416992
Train_StdReturn : 0.7644567489624023
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.370023419203747
Actor Loss : -1096.008544921875
Train_EnvstepsSoFar : 632675
TimeSinceStart : 456.7725284099579
Done logging...



********** Iteration 158 ************

Collecting data for eval...
Eval_AverageReturn : 10.307692527770996
Eval_StdReturn : 0.9101661443710327
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.307692307692308
Train_AverageReturn : 9.997506141662598
Train_StdReturn : 0.9002597332000732
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.997506234413965
Actor Loss : -1100.152587890625
Train_EnvstepsSoFar : 636684
TimeSinceStart : 459.2526912689209
Done logging...



********** Iteration 159 ************

Collecting data for eval...
Eval_AverageReturn : 10.256410598754883
Eval_StdReturn : 1.0055729150772095
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.256410256410257
Train_AverageReturn : 10.139240264892578
Train_StdReturn : 1.0425647497177124
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.139240506329115
Actor Loss : -1062.330810546875
Train_EnvstepsSoFar : 640689
TimeSinceStart : 462.9203927516937
Done logging...



********** Iteration 160 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 0.821203351020813
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 10.242966651916504
Train_StdReturn : 1.0412442684173584
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.242966751918159
Actor Loss : -1063.9886474609375
Train_EnvstepsSoFar : 644694
TimeSinceStart : 465.4378318786621
Done logging...



********** Iteration 161 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.754291832447052
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.940446853637695
Train_StdReturn : 0.9219823479652405
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.94044665012407
Actor Loss : -1098.670654296875
Train_EnvstepsSoFar : 648700
TimeSinceStart : 467.956228017807
Done logging...



********** Iteration 162 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.8263939023017883
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 9.423529624938965
Train_StdReturn : 0.735270619392395
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.423529411764706
Actor Loss : -1110.85498046875
Train_EnvstepsSoFar : 652705
TimeSinceStart : 470.4304678440094
Done logging...



********** Iteration 163 ************

Collecting data for eval...
Eval_AverageReturn : 9.853658676147461
Eval_StdReturn : 0.8712473511695862
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.853658536585366
Train_AverageReturn : 9.935483932495117
Train_StdReturn : 0.8803374171257019
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.935483870967742
Actor Loss : -1110.91064453125
Train_EnvstepsSoFar : 656709
TimeSinceStart : 472.920401096344
Done logging...



********** Iteration 164 ************

Collecting data for eval...
Eval_AverageReturn : 9.7380952835083
Eval_StdReturn : 1.070369839668274
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.738095238095237
Train_AverageReturn : 9.970149040222168
Train_StdReturn : 0.9768995642662048
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.970149253731343
Actor Loss : -1088.5941162109375
Train_EnvstepsSoFar : 660717
TimeSinceStart : 475.6488583087921
Done logging...



********** Iteration 165 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.917207658290863
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 9.960199356079102
Train_StdReturn : 0.9295631051063538
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.960199004975124
Actor Loss : -1100.209228515625
Train_EnvstepsSoFar : 664721
TimeSinceStart : 478.5392656326294
Done logging...



********** Iteration 166 ************

Collecting data for eval...
Eval_AverageReturn : 9.159090995788574
Eval_StdReturn : 0.6375800371170044
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.159090909090908
Train_AverageReturn : 9.54285717010498
Train_StdReturn : 0.8341356515884399
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.542857142857143
Actor Loss : -1127.9833984375
Train_EnvstepsSoFar : 668729
TimeSinceStart : 482.3936152458191
Done logging...



********** Iteration 167 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.9370425939559937
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 9.357476234436035
Train_StdReturn : 0.7493082880973816
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.357476635514018
Actor Loss : -1100.9912109375
Train_EnvstepsSoFar : 672734
TimeSinceStart : 484.8923804759979
Done logging...



********** Iteration 168 ************

Collecting data for eval...
Eval_AverageReturn : 10.199999809265137
Eval_StdReturn : 1.0049875974655151
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.2
Train_AverageReturn : 9.920791625976562
Train_StdReturn : 0.9458943605422974
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.92079207920792
Actor Loss : -1101.45703125
Train_EnvstepsSoFar : 676742
TimeSinceStart : 487.67982602119446
Done logging...



********** Iteration 169 ************

Collecting data for eval...
Eval_AverageReturn : 10.225000381469727
Eval_StdReturn : 0.9614441990852356
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.225
Train_AverageReturn : 10.193384170532227
Train_StdReturn : 1.0155317783355713
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.193384223918574
Actor Loss : -1072.940185546875
Train_EnvstepsSoFar : 680748
TimeSinceStart : 490.1902937889099
Done logging...



********** Iteration 170 ************

Collecting data for eval...
Eval_AverageReturn : 9.97560977935791
Eval_StdReturn : 0.8111360669136047
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 9.975609756097562
Train_AverageReturn : 10.083123207092285
Train_StdReturn : 0.9709338545799255
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.083123425692696
Actor Loss : -1076.88525390625
Train_EnvstepsSoFar : 684751
TimeSinceStart : 492.7252538204193
Done logging...



********** Iteration 171 ************

Collecting data for eval...
Eval_AverageReturn : 9.181818008422852
Eval_StdReturn : 0.7468944191932678
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.181818181818182
Train_AverageReturn : 9.91089153289795
Train_StdReturn : 0.8657281398773193
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.910891089108912
Actor Loss : -1110.319091796875
Train_EnvstepsSoFar : 688755
TimeSinceStart : 495.2305679321289
Done logging...



********** Iteration 172 ************

Collecting data for eval...
Eval_AverageReturn : 10.149999618530273
Eval_StdReturn : 0.7921489477157593
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.15
Train_AverageReturn : 9.306976318359375
Train_StdReturn : 0.8090750575065613
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.306976744186047
Actor Loss : -1112.2392578125
Train_EnvstepsSoFar : 692757
TimeSinceStart : 500.18419075012207
Done logging...



********** Iteration 173 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.8660253882408142
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 9.87192153930664
Train_StdReturn : 0.8643741011619568
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.87192118226601
Actor Loss : -1115.9940185546875
Train_EnvstepsSoFar : 696765
TimeSinceStart : 503.4952292442322
Done logging...



********** Iteration 174 ************

Collecting data for eval...
Eval_AverageReturn : 9.97560977935791
Eval_StdReturn : 0.840667724609375
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 9.975609756097562
Train_AverageReturn : 9.972637176513672
Train_StdReturn : 0.9097303748130798
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.972636815920398
Actor Loss : -1099.8179931640625
Train_EnvstepsSoFar : 700774
TimeSinceStart : 506.32156348228455
Done logging...



********** Iteration 175 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.9319231510162354
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.903465270996094
Train_StdReturn : 0.8861352205276489
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.903465346534654
Actor Loss : -1107.014892578125
Train_EnvstepsSoFar : 704775
TimeSinceStart : 508.8218083381653
Done logging...



********** Iteration 176 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.738349199295044
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.594724655151367
Train_StdReturn : 0.9062908887863159
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.594724220623501
Actor Loss : -1122.774658203125
Train_EnvstepsSoFar : 708776
TimeSinceStart : 511.3861548900604
Done logging...



********** Iteration 177 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.7928964495658875
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 9.357476234436035
Train_StdReturn : 0.782856822013855
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.357476635514018
Actor Loss : -1090.497802734375
Train_EnvstepsSoFar : 712781
TimeSinceStart : 513.8841614723206
Done logging...



********** Iteration 178 ************

Collecting data for eval...
Eval_AverageReturn : 9.804878234863281
Eval_StdReturn : 1.0173977613449097
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.804878048780488
Train_AverageReturn : 9.711165428161621
Train_StdReturn : 0.8427714109420776
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.71116504854369
Actor Loss : -1123.50830078125
Train_EnvstepsSoFar : 716782
TimeSinceStart : 516.3694579601288
Done logging...



********** Iteration 179 ************

Collecting data for eval...
Eval_AverageReturn : 9.87804889678955
Eval_StdReturn : 1.1517775058746338
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.878048780487806
Train_AverageReturn : 10.010000228881836
Train_StdReturn : 0.9898990392684937
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.01
Actor Loss : -1099.1544189453125
Train_EnvstepsSoFar : 720786
TimeSinceStart : 519.2579822540283
Done logging...



********** Iteration 180 ************

Collecting data for eval...
Eval_AverageReturn : 9.780488014221191
Eval_StdReturn : 0.8118691444396973
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 9.78048780487805
Train_AverageReturn : 10.075566291809082
Train_StdReturn : 0.9358962178230286
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.075566750629722
Actor Loss : -1104.1082763671875
Train_EnvstepsSoFar : 724786
TimeSinceStart : 521.8276650905609
Done logging...



********** Iteration 181 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.7514182925224304
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.725728034973145
Train_StdReturn : 0.8155158758163452
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.725728155339805
Actor Loss : -1132.5811767578125
Train_EnvstepsSoFar : 728793
TimeSinceStart : 524.4101955890656
Done logging...



********** Iteration 182 ************

Collecting data for eval...
Eval_AverageReturn : 9.90243911743164
Eval_StdReturn : 0.8206148147583008
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.902439024390244
Train_AverageReturn : 9.411765098571777
Train_StdReturn : 0.7307387590408325
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.411764705882353
Actor Loss : -1095.2093505859375
Train_EnvstepsSoFar : 732793
TimeSinceStart : 526.8728613853455
Done logging...



********** Iteration 183 ************

Collecting data for eval...
Eval_AverageReturn : 9.90243911743164
Eval_StdReturn : 0.9577636122703552
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 9.902439024390244
Train_AverageReturn : 9.749391555786133
Train_StdReturn : 0.832998514175415
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.749391727493917
Actor Loss : -1129.142333984375
Train_EnvstepsSoFar : 736800
TimeSinceStart : 529.407683134079
Done logging...



********** Iteration 184 ************

Collecting data for eval...
Eval_AverageReturn : 10.074999809265137
Eval_StdReturn : 0.9588404893875122
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.075
Train_AverageReturn : 10.067839622497559
Train_StdReturn : 0.9499647617340088
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.0678391959799
Actor Loss : -1102.0042724609375
Train_EnvstepsSoFar : 740807
TimeSinceStart : 533.0079441070557
Done logging...



********** Iteration 185 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.8234103322029114
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 10.042606353759766
Train_StdReturn : 0.9940622448921204
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.042606516290727
Actor Loss : -1103.99267578125
Train_EnvstepsSoFar : 744814
TimeSinceStart : 535.5967981815338
Done logging...



********** Iteration 186 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.7324658036231995
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.510688781738281
Train_StdReturn : 0.8373721837997437
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.510688836104514
Actor Loss : -1133.041259765625
Train_EnvstepsSoFar : 748818
TimeSinceStart : 538.4516913890839
Done logging...



********** Iteration 187 ************

Collecting data for eval...
Eval_AverageReturn : 10.199999809265137
Eval_StdReturn : 1.0770330429077148
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.2
Train_AverageReturn : 9.428235054016113
Train_StdReturn : 0.7293207049369812
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.428235294117647
Actor Loss : -1126.530517578125
Train_EnvstepsSoFar : 752825
TimeSinceStart : 543.2897939682007
Done logging...



********** Iteration 188 ************

Collecting data for eval...
Eval_AverageReturn : 10.435897827148438
Eval_StdReturn : 0.9280492067337036
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.435897435897436
Train_AverageReturn : 10.327319145202637
Train_StdReturn : 1.0069736242294312
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.327319587628866
Actor Loss : -1076.713134765625
Train_EnvstepsSoFar : 756832
TimeSinceStart : 545.7642493247986
Done logging...



********** Iteration 189 ************

Collecting data for eval...
Eval_AverageReturn : 10.48717975616455
Eval_StdReturn : 0.9573411345481873
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.487179487179487
Train_AverageReturn : 10.424479484558105
Train_StdReturn : 1.03053617477417
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.424479166666666
Actor Loss : -1038.990478515625
Train_EnvstepsSoFar : 760835
TimeSinceStart : 548.5835983753204
Done logging...



********** Iteration 190 ************

Collecting data for eval...
Eval_AverageReturn : 10.51282024383545
Eval_StdReturn : 0.9837602972984314
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.512820512820513
Train_AverageReturn : 10.61273193359375
Train_StdReturn : 1.0598268508911133
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.612732095490717
Actor Loss : -1032.0604248046875
Train_EnvstepsSoFar : 764836
TimeSinceStart : 551.9043972492218
Done logging...



********** Iteration 191 ************

Collecting data for eval...
Eval_AverageReturn : 9.92682933807373
Eval_StdReturn : 0.9973194003105164
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.926829268292684
Train_AverageReturn : 10.45169734954834
Train_StdReturn : 0.9945758581161499
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.451697127937337
Actor Loss : -1061.965576171875
Train_EnvstepsSoFar : 768839
TimeSinceStart : 554.4415447711945
Done logging...



********** Iteration 192 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.659416139125824
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.95522403717041
Train_StdReturn : 1.0014839172363281
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.955223880597014
Actor Loss : -1101.416748046875
Train_EnvstepsSoFar : 772841
TimeSinceStart : 556.9691174030304
Done logging...



********** Iteration 193 ************

Collecting data for eval...
Eval_AverageReturn : 9.227272987365723
Eval_StdReturn : 0.764663815498352
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.227272727272727
Train_AverageReturn : 9.381732940673828
Train_StdReturn : 0.6992426514625549
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.381733021077283
Actor Loss : -1101.8388671875
Train_EnvstepsSoFar : 776847
TimeSinceStart : 559.4560220241547
Done logging...



********** Iteration 194 ************

Collecting data for eval...
Eval_AverageReturn : 10.333333015441895
Eval_StdReturn : 0.9957174062728882
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.333333333333334
Train_AverageReturn : 9.311628341674805
Train_StdReturn : 0.768934428691864
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.311627906976744
Actor Loss : -1124.6939697265625
Train_EnvstepsSoFar : 780851
TimeSinceStart : 561.9557454586029
Done logging...



********** Iteration 195 ************

Collecting data for eval...
Eval_AverageReturn : 10.631579399108887
Eval_StdReturn : 1.0110197067260742
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.631578947368421
Train_AverageReturn : 10.473821640014648
Train_StdReturn : 1.009429693222046
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.473821989528796
Actor Loss : -1065.4666748046875
Train_EnvstepsSoFar : 784852
TimeSinceStart : 564.5082068443298
Done logging...



********** Iteration 196 ************

Collecting data for eval...
Eval_AverageReturn : 10.837838172912598
Eval_StdReturn : 1.1031529903411865
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.837837837837839
Train_AverageReturn : 10.61273193359375
Train_StdReturn : 1.0573211908340454
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.612732095490717
Actor Loss : -999.9345703125
Train_EnvstepsSoFar : 788853
TimeSinceStart : 566.9856998920441
Done logging...



********** Iteration 197 ************

Collecting data for eval...
Eval_AverageReturn : 11.027027130126953
Eval_StdReturn : 1.1267385482788086
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 11.027027027027026
Train_AverageReturn : 10.840108871459961
Train_StdReturn : 1.1541916131973267
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.840108401084011
Actor Loss : -967.0377197265625
Train_EnvstepsSoFar : 792853
TimeSinceStart : 570.0138120651245
Done logging...



********** Iteration 198 ************

Collecting data for eval...
Eval_AverageReturn : 10.333333015441895
Eval_StdReturn : 0.9428090453147888
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.333333333333334
Train_AverageReturn : 10.755376815795898
Train_StdReturn : 1.1272996664047241
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.755376344086022
Actor Loss : -974.330322265625
Train_EnvstepsSoFar : 796854
TimeSinceStart : 572.480982542038
Done logging...



********** Iteration 199 ************

Collecting data for eval...
Eval_AverageReturn : 10.225000381469727
Eval_StdReturn : 0.9871044158935547
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.225
Train_AverageReturn : 10.638298034667969
Train_StdReturn : 1.0679175853729248
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.638297872340425
Actor Loss : -1011.4166259765625
Train_EnvstepsSoFar : 800854
TimeSinceStart : 575.3412692546844
Done logging...



********** Iteration 200 ************

Collecting data for eval...
Eval_AverageReturn : 9.829268455505371
Eval_StdReturn : 0.9080248475074768
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.829268292682928
Train_AverageReturn : 10.31185531616211
Train_StdReturn : 1.076058030128479
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.311855670103093
Actor Loss : -1065.6695556640625
Train_EnvstepsSoFar : 804855
TimeSinceStart : 578.4212441444397
Done logging...



********** Iteration 201 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.6784005165100098
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.720873832702637
Train_StdReturn : 0.9122952818870544
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.720873786407767
Actor Loss : -1124.657958984375
Train_EnvstepsSoFar : 808860
TimeSinceStart : 581.3680672645569
Done logging...



********** Iteration 202 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7061499953269958
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.273148536682129
Train_StdReturn : 0.7542603015899658
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.273148148148149
Actor Loss : -1043.339599609375
Train_EnvstepsSoFar : 812866
TimeSinceStart : 584.6208167076111
Done logging...



********** Iteration 203 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 0.8767596483230591
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 9.384075164794922
Train_StdReturn : 0.7355345487594604
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.38407494145199
Actor Loss : -1059.48779296875
Train_EnvstepsSoFar : 816873
TimeSinceStart : 587.6899063587189
Done logging...



********** Iteration 204 ************

Collecting data for eval...
Eval_AverageReturn : 10.410256385803223
Eval_StdReturn : 1.0055729150772095
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.41025641025641
Train_AverageReturn : 9.749391555786133
Train_StdReturn : 0.9057632684707642
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.749391727493917
Actor Loss : -1118.068603515625
Train_EnvstepsSoFar : 820880
TimeSinceStart : 590.5905616283417
Done logging...



********** Iteration 205 ************

Collecting data for eval...
Eval_AverageReturn : 10.526315689086914
Eval_StdReturn : 0.9385555386543274
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.526315789473685
Train_AverageReturn : 10.256410598754883
Train_StdReturn : 1.0769840478897095
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.256410256410257
Actor Loss : -1069.549072265625
Train_EnvstepsSoFar : 824880
TimeSinceStart : 593.3531415462494
Done logging...



********** Iteration 206 ************

Collecting data for eval...
Eval_AverageReturn : 10.333333015441895
Eval_StdReturn : 0.9696242213249207
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.333333333333334
Train_AverageReturn : 10.427083015441895
Train_StdReturn : 1.043280005455017
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.427083333333334
Actor Loss : -1055.90576171875
Train_EnvstepsSoFar : 828884
TimeSinceStart : 595.8339285850525
Done logging...



********** Iteration 207 ************

Collecting data for eval...
Eval_AverageReturn : 10.307692527770996
Eval_StdReturn : 1.2639750242233276
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.307692307692308
Train_AverageReturn : 10.37564754486084
Train_StdReturn : 1.0362986326217651
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.375647668393782
Actor Loss : -1055.3011474609375
Train_EnvstepsSoFar : 832889
TimeSinceStart : 598.4582140445709
Done logging...



********** Iteration 208 ************

Collecting data for eval...
Eval_AverageReturn : 9.90243911743164
Eval_StdReturn : 0.7903342247009277
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.902439024390244
Train_AverageReturn : 10.31185531616211
Train_StdReturn : 1.0567229986190796
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.311855670103093
Actor Loss : -1071.259033203125
Train_EnvstepsSoFar : 836890
TimeSinceStart : 602.7101385593414
Done logging...



********** Iteration 209 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.6922268271446228
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.862069129943848
Train_StdReturn : 0.8798173666000366
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.862068965517242
Actor Loss : -1119.7413330078125
Train_EnvstepsSoFar : 840894
TimeSinceStart : 606.9171457290649
Done logging...



********** Iteration 210 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.6187969446182251
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.379390716552734
Train_StdReturn : 0.7720810770988464
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.379391100702577
Actor Loss : -1096.7537841796875
Train_EnvstepsSoFar : 844899
TimeSinceStart : 609.4412801265717
Done logging...



********** Iteration 211 ************

Collecting data for eval...
Eval_AverageReturn : 9.90243911743164
Eval_StdReturn : 0.9577635526657104
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.902439024390244
Train_AverageReturn : 9.326340675354004
Train_StdReturn : 0.7327063679695129
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.326340326340326
Actor Loss : -1119.754638671875
Train_EnvstepsSoFar : 848900
TimeSinceStart : 612.3102881908417
Done logging...



********** Iteration 212 ************

Collecting data for eval...
Eval_AverageReturn : 10.307692527770996
Eval_StdReturn : 1.1357555389404297
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.307692307692308
Train_AverageReturn : 10.271795272827148
Train_StdReturn : 1.0465936660766602
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.271794871794873
Actor Loss : -1080.518310546875
Train_EnvstepsSoFar : 852906
TimeSinceStart : 614.7548739910126
Done logging...



********** Iteration 213 ************

Collecting data for eval...
Eval_AverageReturn : 10.763157844543457
Eval_StdReturn : 1.1340242624282837
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.763157894736842
Train_AverageReturn : 10.486910820007324
Train_StdReturn : 1.0846798419952393
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.486910994764397
Actor Loss : -1036.68701171875
Train_EnvstepsSoFar : 856912
TimeSinceStart : 620.0815124511719
Done logging...



********** Iteration 214 ************

Collecting data for eval...
Eval_AverageReturn : 10.35897445678711
Eval_StdReturn : 0.9996712803840637
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.35897435897436
Train_AverageReturn : 10.61273193359375
Train_StdReturn : 1.1063584089279175
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.612732095490717
Actor Loss : -1014.3739013671875
Train_EnvstepsSoFar : 860913
TimeSinceStart : 623.1721723079681
Done logging...



********** Iteration 215 ************

Collecting data for eval...
Eval_AverageReturn : 10.410256385803223
Eval_StdReturn : 1.1484203338623047
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.41025641025641
Train_AverageReturn : 10.48952865600586
Train_StdReturn : 1.0871188640594482
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.489528795811518
Actor Loss : -1028.6475830078125
Train_EnvstepsSoFar : 864920
TimeSinceStart : 626.0120706558228
Done logging...



********** Iteration 216 ************

Collecting data for eval...
Eval_AverageReturn : 9.619047164916992
Eval_StdReturn : 0.8984743356704712
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.619047619047619
Train_AverageReturn : 10.388601303100586
Train_StdReturn : 1.0889337062835693
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.38860103626943
Actor Loss : -1065.7529296875
Train_EnvstepsSoFar : 868930
TimeSinceStart : 628.5131161212921
Done logging...



********** Iteration 217 ************

Collecting data for eval...
Eval_AverageReturn : 9.511628150939941
Eval_StdReturn : 0.8175997734069824
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.511627906976743
Train_AverageReturn : 9.90099048614502
Train_StdReturn : 0.8646518588066101
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.900990099009901
Actor Loss : -1118.3804931640625
Train_EnvstepsSoFar : 872930
TimeSinceStart : 631.673476934433
Done logging...



********** Iteration 218 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7564398050308228
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.374707221984863
Train_StdReturn : 0.7466503977775574
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.374707259953162
Actor Loss : -1087.41748046875
Train_EnvstepsSoFar : 876933
TimeSinceStart : 634.2133674621582
Done logging...



********** Iteration 219 ************

Collecting data for eval...
Eval_AverageReturn : 9.804878234863281
Eval_StdReturn : 0.9682650566101074
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.804878048780488
Train_AverageReturn : 9.39201831817627
Train_StdReturn : 0.730831503868103
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.392018779342724
Actor Loss : -1090.5399169921875
Train_EnvstepsSoFar : 880934
TimeSinceStart : 637.1623909473419
Done logging...



********** Iteration 220 ************

Collecting data for eval...
Eval_AverageReturn : 10.100000381469727
Eval_StdReturn : 1.1135529279708862
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.1
Train_AverageReturn : 9.823529243469238
Train_StdReturn : 0.8874038457870483
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.823529411764707
Actor Loss : -1119.783935546875
Train_EnvstepsSoFar : 884942
TimeSinceStart : 640.0546722412109
Done logging...



********** Iteration 221 ************

Collecting data for eval...
Eval_AverageReturn : 10.435897827148438
Eval_StdReturn : 1.0572065114974976
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.435897435897436
Train_AverageReturn : 10.206632614135742
Train_StdReturn : 0.9744998216629028
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.206632653061224
Actor Loss : -1084.531982421875
Train_EnvstepsSoFar : 888943
TimeSinceStart : 642.5757896900177
Done logging...



********** Iteration 222 ************

Collecting data for eval...
Eval_AverageReturn : 10.307692527770996
Eval_StdReturn : 0.9648659825325012
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.307692307692308
Train_AverageReturn : 10.30927848815918
Train_StdReturn : 1.1155954599380493
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.309278350515465
Actor Loss : -1063.03173828125
Train_EnvstepsSoFar : 892943
TimeSinceStart : 645.0990147590637
Done logging...



********** Iteration 223 ************

Collecting data for eval...
Eval_AverageReturn : 10.256410598754883
Eval_StdReturn : 0.8687730431556702
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.256410256410257
Train_AverageReturn : 10.341085433959961
Train_StdReturn : 1.0794974565505981
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.34108527131783
Actor Loss : -1067.5477294921875
Train_EnvstepsSoFar : 896945
TimeSinceStart : 649.3952219486237
Done logging...



********** Iteration 224 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.7928965091705322
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 10.193384170532227
Train_StdReturn : 0.9481504559516907
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.193384223918574
Actor Loss : -1094.69775390625
Train_EnvstepsSoFar : 900951
TimeSinceStart : 651.9112379550934
Done logging...



********** Iteration 225 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.8136211633682251
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.779951095581055
Train_StdReturn : 0.9173625707626343
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.7799511002445
Actor Loss : -1117.769287109375
Train_EnvstepsSoFar : 904951
TimeSinceStart : 654.4308450222015
Done logging...



********** Iteration 226 ************

Collecting data for eval...
Eval_AverageReturn : 9.159090995788574
Eval_StdReturn : 0.7367984652519226
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.159090909090908
Train_AverageReturn : 9.357476234436035
Train_StdReturn : 0.7335518598556519
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.357476635514018
Actor Loss : -1108.552734375
Train_EnvstepsSoFar : 908956
TimeSinceStart : 656.943742275238
Done logging...



********** Iteration 227 ************

Collecting data for eval...
Eval_AverageReturn : 9.7619047164917
Eval_StdReturn : 0.8946806788444519
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.761904761904763
Train_AverageReturn : 9.406103134155273
Train_StdReturn : 0.788330614566803
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.406103286384976
Actor Loss : -1130.0567626953125
Train_EnvstepsSoFar : 912963
TimeSinceStart : 659.468868970871
Done logging...



********** Iteration 228 ************

Collecting data for eval...
Eval_AverageReturn : 9.853658676147461
Eval_StdReturn : 0.8988061547279358
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.853658536585366
Train_AverageReturn : 9.784841537475586
Train_StdReturn : 0.8996957540512085
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.78484107579462
Actor Loss : -1122.798583984375
Train_EnvstepsSoFar : 916965
TimeSinceStart : 661.9790806770325
Done logging...



********** Iteration 229 ************

Collecting data for eval...
Eval_AverageReturn : 9.780488014221191
Eval_StdReturn : 0.7812496423721313
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.78048780487805
Train_AverageReturn : 9.915842056274414
Train_StdReturn : 0.9135105609893799
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.915841584158416
Actor Loss : -1114.663330078125
Train_EnvstepsSoFar : 920971
TimeSinceStart : 664.4729995727539
Done logging...



********** Iteration 230 ************

Collecting data for eval...
Eval_AverageReturn : 9.780488014221191
Eval_StdReturn : 0.8698806762695312
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.78048780487805
Train_AverageReturn : 9.923267364501953
Train_StdReturn : 0.8683393597602844
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.923267326732674
Actor Loss : -1125.267578125
Train_EnvstepsSoFar : 924980
TimeSinceStart : 667.8929362297058
Done logging...



********** Iteration 231 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7250445485115051
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.54892635345459
Train_StdReturn : 0.8653320074081421
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.54892601431981
Actor Loss : -1136.445068359375
Train_EnvstepsSoFar : 928981
TimeSinceStart : 670.3920483589172
Done logging...



********** Iteration 232 ************

Collecting data for eval...
Eval_AverageReturn : 9.804878234863281
Eval_StdReturn : 0.942738950252533
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.804878048780488
Train_AverageReturn : 9.401408195495605
Train_StdReturn : 0.7757461667060852
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.401408450704226
Actor Loss : -1111.558349609375
Train_EnvstepsSoFar : 932986
TimeSinceStart : 672.8861689567566
Done logging...



********** Iteration 233 ************

Collecting data for eval...
Eval_AverageReturn : 9.92682933807373
Eval_StdReturn : 0.9725561738014221
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.926829268292684
Train_AverageReturn : 9.879012107849121
Train_StdReturn : 0.8707476854324341
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.879012345679012
Actor Loss : -1131.6134033203125
Train_EnvstepsSoFar : 936987
TimeSinceStart : 675.39710521698
Done logging...



********** Iteration 234 ************

Collecting data for eval...
Eval_AverageReturn : 10.35897445678711
Eval_StdReturn : 0.8911870121955872
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.35897435897436
Train_AverageReturn : 10.090680122375488
Train_StdReturn : 0.9844323992729187
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.090680100755668
Actor Loss : -1108.295166015625
Train_EnvstepsSoFar : 940993
TimeSinceStart : 677.9044597148895
Done logging...



********** Iteration 235 ************

Collecting data for eval...
Eval_AverageReturn : 10.175000190734863
Eval_StdReturn : 0.8627716302871704
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.175
Train_AverageReturn : 10.134177207946777
Train_StdReturn : 0.9492016434669495
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.134177215189874
Actor Loss : -1111.607666015625
Train_EnvstepsSoFar : 944996
TimeSinceStart : 680.4344916343689
Done logging...



********** Iteration 236 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.8012773990631104
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.850122451782227
Train_StdReturn : 0.8640477657318115
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.85012285012285
Actor Loss : -1139.7801513671875
Train_EnvstepsSoFar : 949005
TimeSinceStart : 682.9638497829437
Done logging...



********** Iteration 237 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.738349199295044
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.362149238586426
Train_StdReturn : 0.7777075171470642
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36214953271028
Actor Loss : -1099.250244140625
Train_EnvstepsSoFar : 953012
TimeSinceStart : 685.4950220584869
Done logging...



********** Iteration 238 ************

Collecting data for eval...
Eval_AverageReturn : 10.552631378173828
Eval_StdReturn : 0.9651115536689758
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.552631578947368
Train_AverageReturn : 9.408451080322266
Train_StdReturn : 0.7266386151313782
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.408450704225352
Actor Loss : -1146.96142578125
Train_EnvstepsSoFar : 957020
TimeSinceStart : 687.9654841423035
Done logging...



********** Iteration 239 ************

Collecting data for eval...
Eval_AverageReturn : 10.810811042785645
Eval_StdReturn : 1.0613055229187012
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.81081081081081
Train_AverageReturn : 10.517060279846191
Train_StdReturn : 1.0413234233856201
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.517060367454068
Actor Loss : -1059.0283203125
Train_EnvstepsSoFar : 961027
TimeSinceStart : 690.469131231308
Done logging...



********** Iteration 240 ************

Collecting data for eval...
Eval_AverageReturn : 10.789473533630371
Eval_StdReturn : 1.259864091873169
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.789473684210526
Train_AverageReturn : 10.861788749694824
Train_StdReturn : 1.114028811454773
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.861788617886178
Actor Loss : -1012.0291748046875
Train_EnvstepsSoFar : 965035
TimeSinceStart : 692.9900953769684
Done logging...



********** Iteration 241 ************

Collecting data for eval...
Eval_AverageReturn : 11.08108139038086
Eval_StdReturn : 1.023464560508728
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 11.08108108108108
Train_AverageReturn : 10.891304016113281
Train_StdReturn : 1.244173526763916
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.891304347826088
Actor Loss : -994.0072631835938
Train_EnvstepsSoFar : 969043
TimeSinceStart : 695.5296955108643
Done logging...



********** Iteration 242 ************

Collecting data for eval...
Eval_AverageReturn : 10.256410598754883
Eval_StdReturn : 1.0553392171859741
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.256410256410257
Train_AverageReturn : 10.78975772857666
Train_StdReturn : 1.214913010597229
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.789757412398922
Actor Loss : -1010.357421875
Train_EnvstepsSoFar : 973046
TimeSinceStart : 698.07040143013
Done logging...



********** Iteration 243 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.8783745765686035
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 10.464752197265625
Train_StdReturn : 1.0512633323669434
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.464751958224543
Actor Loss : -1068.6375732421875
Train_EnvstepsSoFar : 977054
TimeSinceStart : 701.0736367702484
Done logging...



********** Iteration 244 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.6187969446182251
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.739659309387207
Train_StdReturn : 0.8811951875686646
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.739659367396595
Actor Loss : -1134.2242431640625
Train_EnvstepsSoFar : 981057
TimeSinceStart : 704.1863677501678
Done logging...



********** Iteration 245 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.7324658036231995
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.342657089233398
Train_StdReturn : 0.7458187937736511
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.342657342657343
Actor Loss : -1069.3665771484375
Train_EnvstepsSoFar : 985065
TimeSinceStart : 708.0652997493744
Done logging...



********** Iteration 246 ************

Collecting data for eval...
Eval_AverageReturn : 9.92682933807373
Eval_StdReturn : 0.8664546012878418
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.926829268292684
Train_AverageReturn : 9.335664749145508
Train_StdReturn : 0.7380190491676331
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.335664335664335
Actor Loss : -1074.671630859375
Train_EnvstepsSoFar : 989070
TimeSinceStart : 710.9690697193146
Done logging...



********** Iteration 247 ************

Collecting data for eval...
Eval_AverageReturn : 9.97560977935791
Eval_StdReturn : 0.7804878354072571
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.975609756097562
Train_AverageReturn : 9.711165428161621
Train_StdReturn : 0.839886486530304
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.71116504854369
Actor Loss : -1131.53271484375
Train_EnvstepsSoFar : 993071
TimeSinceStart : 713.4540157318115
Done logging...



********** Iteration 248 ************

Collecting data for eval...
Eval_AverageReturn : 10.605262756347656
Eval_StdReturn : 1.0140974521636963
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.605263157894736
Train_AverageReturn : 10.30334186553955
Train_StdReturn : 1.0293952226638794
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.303341902313624
Actor Loss : -1092.5758056640625
Train_EnvstepsSoFar : 997079
TimeSinceStart : 715.9811804294586
Done logging...



********** Iteration 249 ************

Collecting data for eval...
Eval_AverageReturn : 10.256410598754883
Eval_StdReturn : 1.0055729150772095
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.256410256410257
Train_AverageReturn : 10.421875
Train_StdReturn : 1.1059218645095825
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.421875
Actor Loss : -1070.504150390625
Train_EnvstepsSoFar : 1001081
TimeSinceStart : 718.4907116889954
Done logging...



********** Iteration 250 ************

Collecting data for eval...
Eval_AverageReturn : 10.225000381469727
Eval_StdReturn : 0.821203351020813
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.225
Train_AverageReturn : 10.416666984558105
Train_StdReturn : 1.1149240732192993
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.416666666666666
Actor Loss : -1076.830810546875
Train_EnvstepsSoFar : 1005081
TimeSinceStart : 720.969660282135
Done logging...



********** Iteration 251 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.7928965091705322
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 10.027568817138672
Train_StdReturn : 0.9638800024986267
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.027568922305765
Actor Loss : -1110.406005859375
Train_EnvstepsSoFar : 1009082
TimeSinceStart : 723.6161766052246
Done logging...



********** Iteration 252 ************

Collecting data for eval...
Eval_AverageReturn : 9.295454978942871
Eval_StdReturn : 0.7254949808120728
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.295454545454545
Train_AverageReturn : 9.432941436767578
Train_StdReturn : 0.8762739300727844
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.432941176470589
Actor Loss : -1126.952880859375
Train_EnvstepsSoFar : 1013091
TimeSinceStart : 726.0999388694763
Done logging...



********** Iteration 253 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.8518354296684265
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.377049446105957
Train_StdReturn : 0.7311968803405762
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.37704918032787
Actor Loss : -1088.90576171875
Train_EnvstepsSoFar : 1017095
TimeSinceStart : 728.5614333152771
Done logging...



********** Iteration 254 ************

Collecting data for eval...
Eval_AverageReturn : 9.829268455505371
Eval_StdReturn : 0.9344996809959412
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.829268292682928
Train_AverageReturn : 9.370023727416992
Train_StdReturn : 0.78560870885849
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.370023419203747
Actor Loss : -1127.8468017578125
Train_EnvstepsSoFar : 1021096
TimeSinceStart : 731.0590841770172
Done logging...



********** Iteration 255 ************

Collecting data for eval...
Eval_AverageReturn : 10.100000381469727
Eval_StdReturn : 0.994987428188324
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.1
Train_AverageReturn : 9.975062370300293
Train_StdReturn : 0.8845453262329102
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.975062344139651
Actor Loss : -1122.54443359375
Train_EnvstepsSoFar : 1025096
TimeSinceStart : 733.547536611557
Done logging...



********** Iteration 256 ************

Collecting data for eval...
Eval_AverageReturn : 10.199999809265137
Eval_StdReturn : 1.228820562362671
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.2
Train_AverageReturn : 10.216836929321289
Train_StdReturn : 0.9617279171943665
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.216836734693878
Actor Loss : -1103.77880859375
Train_EnvstepsSoFar : 1029101
TimeSinceStart : 738.2002999782562
Done logging...



********** Iteration 257 ************

Collecting data for eval...
Eval_AverageReturn : 10.074999809265137
Eval_StdReturn : 0.9845684170722961
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.075
Train_AverageReturn : 10.149367332458496
Train_StdReturn : 1.036287546157837
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.149367088607596
Actor Loss : -1099.2244873046875
Train_EnvstepsSoFar : 1033110
TimeSinceStart : 740.7183787822723
Done logging...



********** Iteration 258 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.7939682006835938
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.960199356079102
Train_StdReturn : 0.9481104016304016
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.960199004975124
Actor Loss : -1117.01171875
Train_EnvstepsSoFar : 1037114
TimeSinceStart : 743.238870382309
Done logging...



********** Iteration 259 ************

Collecting data for eval...
Eval_AverageReturn : 9.295454978942871
Eval_StdReturn : 0.6598741412162781
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.295454545454545
Train_AverageReturn : 9.558472633361816
Train_StdReturn : 0.9078251719474792
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.558472553699284
Actor Loss : -1137.52978515625
Train_EnvstepsSoFar : 1041119
TimeSinceStart : 746.1195919513702
Done logging...



********** Iteration 260 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.716037392616272
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 9.35981273651123
Train_StdReturn : 0.7466260194778442
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.35981308411215
Actor Loss : -1100.822509765625
Train_EnvstepsSoFar : 1045125
TimeSinceStart : 748.649112701416
Done logging...



********** Iteration 261 ************

Collecting data for eval...
Eval_AverageReturn : 10.51282024383545
Eval_StdReturn : 1.1064331531524658
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.512820512820513
Train_AverageReturn : 9.374707221984863
Train_StdReturn : 0.7833855152130127
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.374707259953162
Actor Loss : -1143.984375
Train_EnvstepsSoFar : 1049128
TimeSinceStart : 751.519054889679
Done logging...



********** Iteration 262 ************

Collecting data for eval...
Eval_AverageReturn : 10.8421049118042
Eval_StdReturn : 1.2881304025650024
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.842105263157896
Train_AverageReturn : 10.456918716430664
Train_StdReturn : 1.0851949453353882
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.45691906005222
Actor Loss : -1074.235595703125
Train_EnvstepsSoFar : 1053133
TimeSinceStart : 754.097216129303
Done logging...



********** Iteration 263 ************

Collecting data for eval...
Eval_AverageReturn : 10.86486530303955
Eval_StdReturn : 1.318520188331604
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.864864864864865
Train_AverageReturn : 10.850948333740234
Train_StdReturn : 1.1603220701217651
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.850948509485095
Actor Loss : -1020.9949340820312
Train_EnvstepsSoFar : 1057137
TimeSinceStart : 756.6933372020721
Done logging...



********** Iteration 264 ************

Collecting data for eval...
Eval_AverageReturn : 10.837838172912598
Eval_StdReturn : 1.2842814922332764
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.837837837837839
Train_AverageReturn : 10.912806510925293
Train_StdReturn : 1.2143665552139282
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.912806539509537
Actor Loss : -1006.8726196289062
Train_EnvstepsSoFar : 1061142
TimeSinceStart : 759.2530100345612
Done logging...



********** Iteration 265 ************

Collecting data for eval...
Eval_AverageReturn : 10.710526466369629
Eval_StdReturn : 1.23347806930542
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.710526315789474
Train_AverageReturn : 10.8804349899292
Train_StdReturn : 1.1963930130004883
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.880434782608695
Actor Loss : -1012.4111328125
Train_EnvstepsSoFar : 1065146
TimeSinceStart : 761.7847366333008
Done logging...



********** Iteration 266 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 1.0836858749389648
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 10.674666404724121
Train_StdReturn : 1.100677728652954
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.674666666666667
Actor Loss : -1049.613525390625
Train_EnvstepsSoFar : 1069149
TimeSinceStart : 764.3397481441498
Done logging...



********** Iteration 267 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.8222171664237976
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 10.266666412353516
Train_StdReturn : 1.0430067777633667
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.266666666666667
Actor Loss : -1103.3394775390625
Train_EnvstepsSoFar : 1073153
TimeSinceStart : 766.9020004272461
Done logging...



********** Iteration 268 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.6921162605285645
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 9.350467681884766
Train_StdReturn : 0.7541627883911133
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.350467289719626
Actor Loss : -1131.063720703125
Train_EnvstepsSoFar : 1077155
TimeSinceStart : 770.2974028587341
Done logging...



********** Iteration 269 ************

Collecting data for eval...
Eval_AverageReturn : 9.95121955871582
Eval_StdReturn : 0.9357720017433167
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.951219512195122
Train_AverageReturn : 9.316279411315918
Train_StdReturn : 0.7790663242340088
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.316279069767441
Actor Loss : -1137.325439453125
Train_EnvstepsSoFar : 1081161
TimeSinceStart : 772.7925641536713
Done logging...



********** Iteration 270 ************

Collecting data for eval...
Eval_AverageReturn : 10.333333015441895
Eval_StdReturn : 0.9696241617202759
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.333333333333334
Train_AverageReturn : 9.862069129943848
Train_StdReturn : 0.95499187707901
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.862068965517242
Actor Loss : -1123.505615234375
Train_EnvstepsSoFar : 1085165
TimeSinceStart : 775.259521484375
Done logging...



********** Iteration 271 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.8660253882408142
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 10.227041244506836
Train_StdReturn : 0.9856022000312805
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.22704081632653
Actor Loss : -1112.1412353515625
Train_EnvstepsSoFar : 1089174
TimeSinceStart : 777.7232568264008
Done logging...



********** Iteration 272 ************

Collecting data for eval...
Eval_AverageReturn : 9.95121955871582
Eval_StdReturn : 0.8821044564247131
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.951219512195122
Train_AverageReturn : 10.090680122375488
Train_StdReturn : 1.0146726369857788
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.090680100755668
Actor Loss : -1109.0948486328125
Train_EnvstepsSoFar : 1093180
TimeSinceStart : 780.3005044460297
Done logging...



********** Iteration 273 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.7514183521270752
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.852216720581055
Train_StdReturn : 0.8612241148948669
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.852216748768473
Actor Loss : -1130.14892578125
Train_EnvstepsSoFar : 1097180
TimeSinceStart : 782.7855467796326
Done logging...



********** Iteration 274 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.8109578490257263
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.367681503295898
Train_StdReturn : 0.7671138644218445
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36768149882904
Actor Loss : -1137.248291015625
Train_EnvstepsSoFar : 1101180
TimeSinceStart : 785.2859778404236
Done logging...



********** Iteration 275 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.8834521770477295
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 9.337995529174805
Train_StdReturn : 0.8049825429916382
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.337995337995338
Actor Loss : -1119.229248046875
Train_EnvstepsSoFar : 1105186
TimeSinceStart : 787.7972497940063
Done logging...



********** Iteration 276 ************

Collecting data for eval...
Eval_AverageReturn : 9.95121955871582
Eval_StdReturn : 0.9865243434906006
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.951219512195122
Train_AverageReturn : 9.866994857788086
Train_StdReturn : 0.8521455526351929
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.866995073891626
Actor Loss : -1135.4287109375
Train_EnvstepsSoFar : 1109192
TimeSinceStart : 790.3148481845856
Done logging...



********** Iteration 277 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 0.8511022329330444
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 10.274358749389648
Train_StdReturn : 1.0903346538543701
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.274358974358975
Actor Loss : -1103.0548095703125
Train_EnvstepsSoFar : 1113199
TimeSinceStart : 792.7370338439941
Done logging...



********** Iteration 278 ************

Collecting data for eval...
Eval_AverageReturn : 10.02439022064209
Eval_StdReturn : 0.9749998450279236
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.024390243902438
Train_AverageReturn : 10.274358749389648
Train_StdReturn : 1.1181986331939697
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.274358974358975
Actor Loss : -1099.5
Train_EnvstepsSoFar : 1117206
TimeSinceStart : 795.1536731719971
Done logging...



********** Iteration 279 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.798863410949707
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.913366317749023
Train_StdReturn : 0.8954890370368958
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.913366336633663
Actor Loss : -1131.51806640625
Train_EnvstepsSoFar : 1121211
TimeSinceStart : 797.6137487888336
Done logging...



********** Iteration 280 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.8664156198501587
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.331002235412598
Train_StdReturn : 0.7557050585746765
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.331002331002331
Actor Loss : -1142.065673828125
Train_EnvstepsSoFar : 1125214
TimeSinceStart : 800.0554091930389
Done logging...



********** Iteration 281 ************

Collecting data for eval...
Eval_AverageReturn : 9.829268455505371
Eval_StdReturn : 0.8807546496391296
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.829268292682928
Train_AverageReturn : 9.565632820129395
Train_StdReturn : 0.8697311878204346
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.56563245823389
Actor Loss : -1144.764404296875
Train_EnvstepsSoFar : 1129222
TimeSinceStart : 802.5213901996613
Done logging...



********** Iteration 282 ************

Collecting data for eval...
Eval_AverageReturn : 9.804878234863281
Eval_StdReturn : 0.889491856098175
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.804878048780488
Train_AverageReturn : 9.940446853637695
Train_StdReturn : 0.8549530506134033
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.94044665012407
Actor Loss : -1144.200439453125
Train_EnvstepsSoFar : 1133228
TimeSinceStart : 804.9787585735321
Done logging...



********** Iteration 283 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.8551058769226074
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.87192153930664
Train_StdReturn : 0.9088236093521118
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.87192118226601
Actor Loss : -1144.631103515625
Train_EnvstepsSoFar : 1137236
TimeSinceStart : 807.4614217281342
Done logging...



********** Iteration 284 ************

Collecting data for eval...
Eval_AverageReturn : 10.100000381469727
Eval_StdReturn : 0.943398118019104
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.1
Train_AverageReturn : 9.35513973236084
Train_StdReturn : 0.7643008828163147
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.355140186915888
Actor Loss : -1148.42822265625
Train_EnvstepsSoFar : 1141240
TimeSinceStart : 809.9015519618988
Done logging...



********** Iteration 285 ************

Collecting data for eval...
Eval_AverageReturn : 10.526315689086914
Eval_StdReturn : 0.9385555386543274
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.526315789473685
Train_AverageReturn : 10.2615385055542
Train_StdReturn : 1.0661734342575073
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.261538461538462
Actor Loss : -1114.587890625
Train_EnvstepsSoFar : 1145242
TimeSinceStart : 812.9806215763092
Done logging...



********** Iteration 286 ************

Collecting data for eval...
Eval_AverageReturn : 9.90243911743164
Eval_StdReturn : 0.9054005146026611
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.902439024390244
Train_AverageReturn : 10.250638961791992
Train_StdReturn : 1.0406535863876343
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.250639386189258
Actor Loss : -1103.743896484375
Train_EnvstepsSoFar : 1149250
TimeSinceStart : 815.3830404281616
Done logging...



********** Iteration 287 ************

Collecting data for eval...
Eval_AverageReturn : 9.295454978942871
Eval_StdReturn : 0.7561728954315186
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.295454545454545
Train_AverageReturn : 10.18066120147705
Train_StdReturn : 1.0265843868255615
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.180661577608143
Actor Loss : -1118.993896484375
Train_EnvstepsSoFar : 1153251
TimeSinceStart : 817.8221442699432
Done logging...



********** Iteration 288 ************

Collecting data for eval...
Eval_AverageReturn : 10.100000381469727
Eval_StdReturn : 0.943398118019104
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.1
Train_AverageReturn : 9.292343139648438
Train_StdReturn : 0.7227889895439148
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.292343387470998
Actor Loss : -1144.15673828125
Train_EnvstepsSoFar : 1157256
TimeSinceStart : 820.8228302001953
Done logging...



********** Iteration 289 ************

Collecting data for eval...
Eval_AverageReturn : 10.552631378173828
Eval_StdReturn : 0.965111494064331
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.552631578947368
Train_AverageReturn : 10.057788848876953
Train_StdReturn : 0.9346362948417664
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.057788944723619
Actor Loss : -1134.071533203125
Train_EnvstepsSoFar : 1161259
TimeSinceStart : 823.2298905849457
Done logging...



********** Iteration 290 ************

Collecting data for eval...
Eval_AverageReturn : 10.050000190734863
Eval_StdReturn : 0.8351646661758423
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.05
Train_AverageReturn : 10.232736587524414
Train_StdReturn : 1.0187764167785645
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.232736572890026
Actor Loss : -1123.3662109375
Train_EnvstepsSoFar : 1165260
TimeSinceStart : 825.7377641201019
Done logging...



********** Iteration 291 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.636886715888977
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.9825439453125
Train_StdReturn : 0.9433820247650146
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.982543640897756
Actor Loss : -1138.2393798828125
Train_EnvstepsSoFar : 1169263
TimeSinceStart : 828.1788692474365
Done logging...



********** Iteration 292 ************

Collecting data for eval...
Eval_AverageReturn : 10.100000381469727
Eval_StdReturn : 0.9165151119232178
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.1
Train_AverageReturn : 9.374707221984863
Train_StdReturn : 0.7307992577552795
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.374707259953162
Actor Loss : -1138.4368896484375
Train_EnvstepsSoFar : 1173266
TimeSinceStart : 830.6477138996124
Done logging...



********** Iteration 293 ************

Collecting data for eval...
Eval_AverageReturn : 10.410256385803223
Eval_StdReturn : 0.9532118439674377
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.41025641025641
Train_AverageReturn : 10.129114151000977
Train_StdReturn : 0.95256507396698
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.129113924050634
Actor Loss : -1132.8204345703125
Train_EnvstepsSoFar : 1177267
TimeSinceStart : 833.1148953437805
Done logging...



********** Iteration 294 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 0.9871042966842651
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 10.399999618530273
Train_StdReturn : 1.0887858867645264
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.4
Actor Loss : -1110.0057373046875
Train_EnvstepsSoFar : 1181271
TimeSinceStart : 835.7378268241882
Done logging...



********** Iteration 295 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.8436444997787476
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 10.167512893676758
Train_StdReturn : 0.9650546908378601
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.16751269035533
Actor Loss : -1129.1195068359375
Train_EnvstepsSoFar : 1185277
TimeSinceStart : 839.7423484325409
Done logging...



********** Iteration 296 ************

Collecting data for eval...
Eval_AverageReturn : 9.714285850524902
Eval_StdReturn : 0.880630612373352
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.714285714285714
Train_AverageReturn : 9.546539306640625
Train_StdReturn : 0.8172403573989868
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.54653937947494
Actor Loss : -1150.9495849609375
Train_EnvstepsSoFar : 1189277
TimeSinceStart : 843.9981453418732
Done logging...



********** Iteration 297 ************

Collecting data for eval...
Eval_AverageReturn : 9.804878234863281
Eval_StdReturn : 0.942738950252533
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.804878048780488
Train_AverageReturn : 9.733009338378906
Train_StdReturn : 0.8542172312736511
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.733009708737864
Actor Loss : -1151.612060546875
Train_EnvstepsSoFar : 1193287
TimeSinceStart : 847.2738044261932
Done logging...



********** Iteration 298 ************

Collecting data for eval...
Eval_AverageReturn : 9.90243911743164
Eval_StdReturn : 0.9577636122703552
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.902439024390244
Train_AverageReturn : 9.905941009521484
Train_StdReturn : 0.8793925046920776
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.905940594059405
Actor Loss : -1148.220703125
Train_EnvstepsSoFar : 1197289
TimeSinceStart : 851.1140291690826
Done logging...



********** Iteration 299 ************

Collecting data for eval...
Eval_AverageReturn : 9.619047164916992
Eval_StdReturn : 0.785353422164917
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.619047619047619
Train_AverageReturn : 9.72330093383789
Train_StdReturn : 0.8901515007019043
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.723300970873787
Actor Loss : -1149.9444580078125
Train_EnvstepsSoFar : 1201295
TimeSinceStart : 855.6063163280487
Done logging...



********** Iteration 300 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 0.8212034106254578
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 9.852580070495605
Train_StdReturn : 0.8340935707092285
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.852579852579852
Actor Loss : -1154.96630859375
Train_EnvstepsSoFar : 1205305
TimeSinceStart : 858.9483008384705
Done logging...



********** Iteration 301 ************

Collecting data for eval...
Eval_AverageReturn : 9.780488014221191
Eval_StdReturn : 0.8974814414978027
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.78048780487805
Train_AverageReturn : 9.950248718261719
Train_StdReturn : 0.8681840896606445
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.950248756218905
Actor Loss : -1148.89208984375
Train_EnvstepsSoFar : 1209305
TimeSinceStart : 863.0062093734741
Done logging...



********** Iteration 302 ************

Collecting data for eval...
Eval_AverageReturn : 10.256410598754883
Eval_StdReturn : 0.8687730431556702
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.256410256410257
Train_AverageReturn : 9.76097583770752
Train_StdReturn : 0.8618975877761841
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.760975609756098
Actor Loss : -1153.1663818359375
Train_EnvstepsSoFar : 1213307
TimeSinceStart : 865.4140214920044
Done logging...



********** Iteration 303 ************

Collecting data for eval...
Eval_AverageReturn : 9.95121955871582
Eval_StdReturn : 0.8821044564247131
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.951219512195122
Train_AverageReturn : 10.216836929321289
Train_StdReturn : 0.9348262548446655
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.216836734693878
Actor Loss : -1143.5782470703125
Train_EnvstepsSoFar : 1217312
TimeSinceStart : 867.8655195236206
Done logging...



********** Iteration 304 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.9486832618713379
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 9.881481170654297
Train_StdReturn : 0.8407977819442749
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.881481481481481
Actor Loss : -1153.532958984375
Train_EnvstepsSoFar : 1221314
TimeSinceStart : 870.3268990516663
Done logging...



********** Iteration 305 ************

Collecting data for eval...
Eval_AverageReturn : 10.410256385803223
Eval_StdReturn : 0.9797422885894775
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.41025641025641
Train_AverageReturn : 9.92803955078125
Train_StdReturn : 0.8583456873893738
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.928039702233251
Actor Loss : -1151.088623046875
Train_EnvstepsSoFar : 1225315
TimeSinceStart : 872.7808792591095
Done logging...



********** Iteration 306 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.859521746635437
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 10.31185531616211
Train_StdReturn : 1.0295448303222656
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.311855670103093
Actor Loss : -1128.500244140625
Train_EnvstepsSoFar : 1229316
TimeSinceStart : 875.1942281723022
Done logging...



********** Iteration 307 ************

Collecting data for eval...
Eval_AverageReturn : 10.684210777282715
Eval_StdReturn : 1.1263649463653564
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.68421052631579
Train_AverageReturn : 9.438679695129395
Train_StdReturn : 0.7466998100280762
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.43867924528302
Actor Loss : -1143.1494140625
Train_EnvstepsSoFar : 1233318
TimeSinceStart : 877.5855329036713
Done logging...



********** Iteration 308 ************

Collecting data for eval...
Eval_AverageReturn : 10.684210777282715
Eval_StdReturn : 1.1263649463653564
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.68421052631579
Train_AverageReturn : 10.595237731933594
Train_StdReturn : 1.0802109241485596
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.595238095238095
Actor Loss : -1098.369873046875
Train_EnvstepsSoFar : 1237323
TimeSinceStart : 879.9901611804962
Done logging...



********** Iteration 309 ************

Collecting data for eval...
Eval_AverageReturn : 10.35897445678711
Eval_StdReturn : 0.9195088148117065
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.35897435897436
Train_AverageReturn : 10.615385055541992
Train_StdReturn : 1.0793832540512085
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.615384615384615
Actor Loss : -1086.324462890625
Train_EnvstepsSoFar : 1241325
TimeSinceStart : 882.3795425891876
Done logging...



********** Iteration 310 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7692016363143921
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 10.48952865600586
Train_StdReturn : 1.0602999925613403
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.489528795811518
Actor Loss : -1109.225341796875
Train_EnvstepsSoFar : 1245332
TimeSinceStart : 884.7772579193115
Done logging...



********** Iteration 311 ************

Collecting data for eval...
Eval_AverageReturn : 9.87804889678955
Eval_StdReturn : 0.9925360679626465
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.878048780487806
Train_AverageReturn : 9.367681503295898
Train_StdReturn : 0.7516944408416748
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36768149882904
Actor Loss : -1125.584228515625
Train_EnvstepsSoFar : 1249332
TimeSinceStart : 887.1833019256592
Done logging...



********** Iteration 312 ************

Collecting data for eval...
Eval_AverageReturn : 10.48717975616455
Eval_StdReturn : 1.034576416015625
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.487179487179487
Train_AverageReturn : 10.012499809265137
Train_StdReturn : 0.8816710114479065
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.0125
Actor Loss : -1153.48876953125
Train_EnvstepsSoFar : 1253337
TimeSinceStart : 891.36501121521
Done logging...



********** Iteration 313 ************

Collecting data for eval...
Eval_AverageReturn : 10.125
Eval_StdReturn : 0.8120191097259521
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.125
Train_AverageReturn : 10.285346984863281
Train_StdReturn : 1.0357695817947388
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.2853470437018
Actor Loss : -1126.419677734375
Train_EnvstepsSoFar : 1257338
TimeSinceStart : 893.8106961250305
Done logging...



********** Iteration 314 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7865830063819885
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 9.905941009521484
Train_StdReturn : 0.8850040435791016
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.905940594059405
Actor Loss : -1153.1290283203125
Train_EnvstepsSoFar : 1261340
TimeSinceStart : 896.2174305915833
Done logging...



********** Iteration 315 ************

Collecting data for eval...
Eval_AverageReturn : 9.92682933807373
Eval_StdReturn : 0.9471457600593567
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 9.926829268292684
Train_AverageReturn : 9.379390716552734
Train_StdReturn : 0.7347809672355652
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.379391100702577
Actor Loss : -1142.9742431640625
Train_EnvstepsSoFar : 1265345
TimeSinceStart : 898.6880950927734
Done logging...



********** Iteration 316 ************

Collecting data for eval...
Eval_AverageReturn : 10.48717975616455
Eval_StdReturn : 1.0094881057739258
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.487179487179487
Train_AverageReturn : 10.394804954528809
Train_StdReturn : 1.0714592933654785
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.394805194805194
Actor Loss : -1112.923583984375
Train_EnvstepsSoFar : 1269347
TimeSinceStart : 902.4102826118469
Done logging...



********** Iteration 317 ************

Collecting data for eval...
Eval_AverageReturn : 10.175000190734863
Eval_StdReturn : 0.8912771940231323
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.175
Train_AverageReturn : 10.479057312011719
Train_StdReturn : 1.055194616317749
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.479057591623036
Actor Loss : -1107.3148193359375
Train_EnvstepsSoFar : 1273350
TimeSinceStart : 904.8585629463196
Done logging...



********** Iteration 318 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.716037392616272
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 10.164974212646484
Train_StdReturn : 0.9210960268974304
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.16497461928934
Actor Loss : -1140.216796875
Train_EnvstepsSoFar : 1277355
TimeSinceStart : 907.3115086555481
Done logging...



********** Iteration 319 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 0.8212034106254578
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 9.394366264343262
Train_StdReturn : 0.7343779802322388
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.394366197183098
Actor Loss : -1144.560546875
Train_EnvstepsSoFar : 1281357
TimeSinceStart : 909.7753252983093
Done logging...



********** Iteration 320 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 0.9614442586898804
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 9.816176414489746
Train_StdReturn : 0.9225035905838013
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.816176470588236
Actor Loss : -1143.99853515625
Train_EnvstepsSoFar : 1285362
TimeSinceStart : 912.2564380168915
Done logging...



********** Iteration 321 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.8508366346359253
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 9.950248718261719
Train_StdReturn : 0.9397323131561279
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.950248756218905
Actor Loss : -1137.119384765625
Train_EnvstepsSoFar : 1289362
TimeSinceStart : 914.645191192627
Done logging...



********** Iteration 322 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7061500549316406
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.690073013305664
Train_StdReturn : 0.8120301365852356
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.690072639225182
Actor Loss : -1148.9462890625
Train_EnvstepsSoFar : 1293364
TimeSinceStart : 917.2485103607178
Done logging...



********** Iteration 323 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.8508365750312805
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 9.313953399658203
Train_StdReturn : 0.7785142064094543
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.313953488372093
Actor Loss : -1139.8931884765625
Train_EnvstepsSoFar : 1297369
TimeSinceStart : 919.6937928199768
Done logging...



********** Iteration 324 ************

Collecting data for eval...
Eval_AverageReturn : 10.149999618530273
Eval_StdReturn : 0.9096702337265015
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.15
Train_AverageReturn : 9.687651634216309
Train_StdReturn : 0.8812095522880554
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.687651331719128
Actor Loss : -1145.3974609375
Train_EnvstepsSoFar : 1301370
TimeSinceStart : 922.57945561409
Done logging...



********** Iteration 325 ************

Collecting data for eval...
Eval_AverageReturn : 9.90243911743164
Eval_StdReturn : 0.8780487775802612
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.902439024390244
Train_AverageReturn : 9.915842056274414
Train_StdReturn : 0.8690763115882874
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.915841584158416
Actor Loss : -1146.2098388671875
Train_EnvstepsSoFar : 1305376
TimeSinceStart : 925.0700809955597
Done logging...



********** Iteration 326 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.8769631385803223
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.852580070495605
Train_StdReturn : 0.8515844941139221
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.852579852579852
Actor Loss : -1152.0662841796875
Train_EnvstepsSoFar : 1309386
TimeSinceStart : 928.4131104946136
Done logging...



********** Iteration 327 ************

Collecting data for eval...
Eval_AverageReturn : 9.90243911743164
Eval_StdReturn : 0.8206148147583008
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.902439024390244
Train_AverageReturn : 9.546539306640625
Train_StdReturn : 0.8487566113471985
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.54653937947494
Actor Loss : -1149.6685791015625
Train_EnvstepsSoFar : 1313386
TimeSinceStart : 931.6716675758362
Done logging...



********** Iteration 328 ************

Collecting data for eval...
Eval_AverageReturn : 10.050000190734863
Eval_StdReturn : 0.8930285573005676
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.05
Train_AverageReturn : 9.787285804748535
Train_StdReturn : 0.8712942600250244
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.787286063569683
Actor Loss : -1152.3729248046875
Train_EnvstepsSoFar : 1317389
TimeSinceStart : 934.5816431045532
Done logging...



********** Iteration 329 ************

Collecting data for eval...
Eval_AverageReturn : 9.90243911743164
Eval_StdReturn : 0.98289954662323
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.902439024390244
Train_AverageReturn : 9.977556228637695
Train_StdReturn : 0.9719225168228149
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.977556109725686
Actor Loss : -1142.4774169921875
Train_EnvstepsSoFar : 1321390
TimeSinceStart : 937.7573328018188
Done logging...



********** Iteration 330 ************

Collecting data for eval...
Eval_AverageReturn : 9.780488014221191
Eval_StdReturn : 0.9502809643745422
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.78048780487805
Train_AverageReturn : 9.90099048614502
Train_StdReturn : 0.895588219165802
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.900990099009901
Actor Loss : -1149.49853515625
Train_EnvstepsSoFar : 1325390
TimeSinceStart : 940.8868963718414
Done logging...



********** Iteration 331 ************

Collecting data for eval...
Eval_AverageReturn : 10.074999809265137
Eval_StdReturn : 1.0813764333724976
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.075
Train_AverageReturn : 9.792176246643066
Train_StdReturn : 0.8752714991569519
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.792176039119804
Actor Loss : -1155.61474609375
Train_EnvstepsSoFar : 1329395
TimeSinceStart : 944.0308182239532
Done logging...



********** Iteration 332 ************

Collecting data for eval...
Eval_AverageReturn : 10.91891860961914
Eval_StdReturn : 1.1241422891616821
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.91891891891892
Train_AverageReturn : 10.486910820007324
Train_StdReturn : 1.05283784866333
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.486910994764397
Actor Loss : -1114.31591796875
Train_EnvstepsSoFar : 1333401
TimeSinceStart : 947.3722248077393
Done logging...



********** Iteration 333 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.7741077542304993
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 10.459529876708984
Train_StdReturn : 1.007961392402649
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.459530026109661
Actor Loss : -1121.8094482421875
Train_EnvstepsSoFar : 1337407
TimeSinceStart : 949.8465573787689
Done logging...



********** Iteration 334 ************

Collecting data for eval...
Eval_AverageReturn : 10.435897827148438
Eval_StdReturn : 1.1722183227539062
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.435897435897436
Train_AverageReturn : 9.335664749145508
Train_StdReturn : 0.7567325234413147
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.335664335664335
Actor Loss : -1143.2593994140625
Train_EnvstepsSoFar : 1341412
TimeSinceStart : 952.3522112369537
Done logging...



********** Iteration 335 ************

Collecting data for eval...
Eval_AverageReturn : 10.578947067260742
Eval_StdReturn : 0.963316023349762
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.578947368421053
Train_AverageReturn : 10.415584564208984
Train_StdReturn : 1.0829330682754517
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.415584415584416
Actor Loss : -1121.009033203125
Train_EnvstepsSoFar : 1345422
TimeSinceStart : 954.8252394199371
Done logging...



********** Iteration 336 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.6577737927436829
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 10.412986755371094
Train_StdReturn : 1.0535469055175781
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.412987012987013
Actor Loss : -1126.342529296875
Train_EnvstepsSoFar : 1349431
TimeSinceStart : 957.3145666122437
Done logging...



********** Iteration 337 ************

Collecting data for eval...
Eval_AverageReturn : 10.125
Eval_StdReturn : 1.0532686710357666
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.125
Train_AverageReturn : 9.34813117980957
Train_StdReturn : 0.7089687585830688
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.348130841121495
Actor Loss : -1136.5531005859375
Train_EnvstepsSoFar : 1353432
TimeSinceStart : 959.7987375259399
Done logging...



********** Iteration 338 ************

Collecting data for eval...
Eval_AverageReturn : 10.384614944458008
Eval_StdReturn : 0.9770544171333313
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.384615384615385
Train_AverageReturn : 10.295629501342773
Train_StdReturn : 1.0403214693069458
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.295629820051413
Actor Loss : -1133.4229736328125
Train_EnvstepsSoFar : 1357437
TimeSinceStart : 962.2983968257904
Done logging...



********** Iteration 339 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.6945666670799255
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 10.348836898803711
Train_StdReturn : 1.0925008058547974
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.348837209302326
Actor Loss : -1128.714111328125
Train_EnvstepsSoFar : 1361442
TimeSinceStart : 964.7939517498016
Done logging...



********** Iteration 340 ************

Collecting data for eval...
Eval_AverageReturn : 10.461538314819336
Eval_StdReturn : 1.0339406728744507
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.461538461538462
Train_AverageReturn : 9.51306438446045
Train_StdReturn : 0.7631323337554932
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.513064133016627
Actor Loss : -1152.24951171875
Train_EnvstepsSoFar : 1365447
TimeSinceStart : 967.3003189563751
Done logging...



********** Iteration 341 ************

Collecting data for eval...
Eval_AverageReturn : 10.35897445678711
Eval_StdReturn : 1.0974839925765991
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.35897435897436
Train_AverageReturn : 10.30077075958252
Train_StdReturn : 1.0486983060836792
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.300771208226221
Actor Loss : -1124.2611083984375
Train_EnvstepsSoFar : 1369454
TimeSinceStart : 969.7801232337952
Done logging...



********** Iteration 342 ************

Collecting data for eval...
Eval_AverageReturn : 9.90243911743164
Eval_StdReturn : 0.9319498538970947
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.902439024390244
Train_AverageReturn : 10.378238677978516
Train_StdReturn : 1.0661747455596924
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.378238341968911
Actor Loss : -1124.230224609375
Train_EnvstepsSoFar : 1373460
TimeSinceStart : 972.3207139968872
Done logging...



********** Iteration 343 ************

Collecting data for eval...
Eval_AverageReturn : 9.714285850524902
Eval_StdReturn : 0.9072647094726562
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.714285714285714
Train_AverageReturn : 9.765853881835938
Train_StdReturn : 0.8489906787872314
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.765853658536585
Actor Loss : -1156.534912109375
Train_EnvstepsSoFar : 1377464
TimeSinceStart : 974.8683316707611
Done logging...



********** Iteration 344 ************

Collecting data for eval...
Eval_AverageReturn : 10.256410598754883
Eval_StdReturn : 1.0307564735412598
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.256410256410257
Train_AverageReturn : 9.643373489379883
Train_StdReturn : 0.8348137140274048
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.643373493975904
Actor Loss : -1155.10009765625
Train_EnvstepsSoFar : 1381466
TimeSinceStart : 977.4078166484833
Done logging...



********** Iteration 345 ************

Collecting data for eval...
Eval_AverageReturn : 10.307692527770996
Eval_StdReturn : 1.0166269540786743
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.307692307692308
Train_AverageReturn : 10.232736587524414
Train_StdReturn : 1.0187764167785645
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.232736572890026
Actor Loss : -1127.824462890625
Train_EnvstepsSoFar : 1385467
TimeSinceStart : 979.9308197498322
Done logging...



********** Iteration 346 ************

Collecting data for eval...
Eval_AverageReturn : 9.87804889678955
Eval_StdReturn : 0.8022870421409607
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.878048780487806
Train_AverageReturn : 10.287918090820312
Train_StdReturn : 1.0680607557296753
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.287917737789202
Actor Loss : -1120.6531982421875
Train_EnvstepsSoFar : 1389469
TimeSinceStart : 982.4848999977112
Done logging...



********** Iteration 347 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.8035885095596313
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 9.886419296264648
Train_StdReturn : 0.9118902683258057
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.88641975308642
Actor Loss : -1147.6119384765625
Train_EnvstepsSoFar : 1393473
TimeSinceStart : 985.0303938388824
Done logging...



********** Iteration 348 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 1.0365206003189087
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 9.367681503295898
Train_StdReturn : 0.7609836459159851
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36768149882904
Actor Loss : -1134.3062744140625
Train_EnvstepsSoFar : 1397473
TimeSinceStart : 987.5657117366791
Done logging...



********** Iteration 349 ************

Collecting data for eval...
Eval_AverageReturn : 10.149999618530273
Eval_StdReturn : 1.0851267576217651
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.15
Train_AverageReturn : 9.970149040222168
Train_StdReturn : 0.9666603803634644
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.970149253731343
Actor Loss : -1142.71337890625
Train_EnvstepsSoFar : 1401481
TimeSinceStart : 991.4768776893616
Done logging...



********** Iteration 350 ************

Collecting data for eval...
Eval_AverageReturn : 10.175000190734863
Eval_StdReturn : 0.8912771940231323
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.175
Train_AverageReturn : 10.402597427368164
Train_StdReturn : 1.103238821029663
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.402597402597403
Actor Loss : -1122.2784423828125
Train_EnvstepsSoFar : 1405486
TimeSinceStart : 994.0278239250183
Done logging...



********** Iteration 351 ************

Collecting data for eval...
Eval_AverageReturn : 9.756097793579102
Eval_StdReturn : 0.8773710131645203
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.75609756097561
Train_AverageReturn : 10.18066120147705
Train_StdReturn : 0.9887060523033142
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.180661577608143
Actor Loss : -1133.4862060546875
Train_EnvstepsSoFar : 1409487
TimeSinceStart : 996.9307534694672
Done logging...



********** Iteration 352 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.6784005165100098
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.758536338806152
Train_StdReturn : 0.8598002791404724
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.758536585365853
Actor Loss : -1152.3427734375
Train_EnvstepsSoFar : 1413488
TimeSinceStart : 999.6018962860107
Done logging...



********** Iteration 353 ************

Collecting data for eval...
Eval_AverageReturn : 10.333333015441895
Eval_StdReturn : 1.0701864957809448
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.333333333333334
Train_AverageReturn : 9.35981273651123
Train_StdReturn : 0.7621121406555176
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.35981308411215
Actor Loss : -1145.5882568359375
Train_EnvstepsSoFar : 1417494
TimeSinceStart : 1002.1072316169739
Done logging...



********** Iteration 354 ************

Collecting data for eval...
Eval_AverageReturn : 10.763157844543457
Eval_StdReturn : 1.0621281862258911
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.763157894736842
Train_AverageReturn : 10.317009925842285
Train_StdReturn : 1.0697429180145264
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.31701030927835
Actor Loss : -1125.7476806640625
Train_EnvstepsSoFar : 1421497
TimeSinceStart : 1004.6262550354004
Done logging...



********** Iteration 355 ************

Collecting data for eval...
Eval_AverageReturn : 10.384614944458008
Eval_StdReturn : 0.8948681354522705
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.384615384615385
Train_AverageReturn : 10.45169734954834
Train_StdReturn : 1.0179286003112793
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.451697127937337
Actor Loss : -1107.3660888671875
Train_EnvstepsSoFar : 1425500
TimeSinceStart : 1007.6568293571472
Done logging...



********** Iteration 356 ************

Collecting data for eval...
Eval_AverageReturn : 9.97560977935791
Eval_StdReturn : 0.9236144423484802
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.975609756097562
Train_AverageReturn : 10.467363357543945
Train_StdReturn : 1.0538281202316284
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.467362924281984
Actor Loss : -1115.86865234375
Train_EnvstepsSoFar : 1429509
TimeSinceStart : 1010.2057375907898
Done logging...



********** Iteration 357 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.738349199295044
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.866994857788086
Train_StdReturn : 0.8693150877952576
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.866995073891626
Actor Loss : -1154.7762451171875
Train_EnvstepsSoFar : 1433515
TimeSinceStart : 1013.1084871292114
Done logging...



********** Iteration 358 ************

Collecting data for eval...
Eval_AverageReturn : 9.780488014221191
Eval_StdReturn : 0.6443827152252197
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 9.78048780487805
Train_AverageReturn : 9.401408195495605
Train_StdReturn : 0.7126607298851013
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.401408450704226
Actor Loss : -1128.958740234375
Train_EnvstepsSoFar : 1437520
TimeSinceStart : 1015.5905840396881
Done logging...



********** Iteration 359 ************

Collecting data for eval...
Eval_AverageReturn : 10.605262756347656
Eval_StdReturn : 1.0647331476211548
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.605263157894736
Train_AverageReturn : 9.768292427062988
Train_StdReturn : 0.8539546132087708
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.768292682926829
Actor Loss : -1156.676513671875
Train_EnvstepsSoFar : 1441525
TimeSinceStart : 1018.4367008209229
Done logging...



********** Iteration 360 ************

Collecting data for eval...
Eval_AverageReturn : 10.435897827148438
Eval_StdReturn : 1.0811880826950073
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.435897435897436
Train_AverageReturn : 10.36528491973877
Train_StdReturn : 1.0839083194732666
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.365284974093264
Actor Loss : -1114.9765625
Train_EnvstepsSoFar : 1445526
TimeSinceStart : 1020.8851671218872
Done logging...



********** Iteration 361 ************

Collecting data for eval...
Eval_AverageReturn : 10.149999618530273
Eval_StdReturn : 0.8529360890388489
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.15
Train_AverageReturn : 10.419270515441895
Train_StdReturn : 1.0148601531982422
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.419270833333334
Actor Loss : -1117.54541015625
Train_EnvstepsSoFar : 1449527
TimeSinceStart : 1023.7522337436676
Done logging...



********** Iteration 362 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.6368865966796875
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 10.030075073242188
Train_StdReturn : 0.9280360341072083
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.030075187969924
Actor Loss : -1146.351806640625
Train_EnvstepsSoFar : 1453529
TimeSinceStart : 1026.2078201770782
Done logging...



********** Iteration 363 ************

Collecting data for eval...
Eval_AverageReturn : 9.90243911743164
Eval_StdReturn : 0.9054005146026611
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.902439024390244
Train_AverageReturn : 9.430587768554688
Train_StdReturn : 0.7423370480537415
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.430588235294117
Actor Loss : -1139.203125
Train_EnvstepsSoFar : 1457537
TimeSinceStart : 1029.0454151630402
Done logging...



********** Iteration 364 ************

Collecting data for eval...
Eval_AverageReturn : 10.578947067260742
Eval_StdReturn : 1.067007064819336
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.578947368421053
Train_AverageReturn : 9.850122451782227
Train_StdReturn : 0.8583417534828186
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.85012285012285
Actor Loss : -1156.713134765625
Train_EnvstepsSoFar : 1461546
TimeSinceStart : 1031.5637485980988
Done logging...



********** Iteration 365 ************

Collecting data for eval...
Eval_AverageReturn : 10.736842155456543
Eval_StdReturn : 1.0178462266921997
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.736842105263158
Train_AverageReturn : 10.378238677978516
Train_StdReturn : 1.092576503753662
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.378238341968911
Actor Loss : -1124.785400390625
Train_EnvstepsSoFar : 1465552
TimeSinceStart : 1034.0763311386108
Done logging...



********** Iteration 366 ************

Collecting data for eval...
Eval_AverageReturn : 10.074999809265137
Eval_StdReturn : 0.9051933884620667
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.075
Train_AverageReturn : 10.343668937683105
Train_StdReturn : 1.058119773864746
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.343669250645995
Actor Loss : -1126.3564453125
Train_EnvstepsSoFar : 1469555
TimeSinceStart : 1036.5706889629364
Done logging...



********** Iteration 367 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.7423856258392334
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 9.883950233459473
Train_StdReturn : 0.9183260202407837
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.88395061728395
Actor Loss : -1150.11328125
Train_EnvstepsSoFar : 1473558
TimeSinceStart : 1039.4561796188354
Done logging...



********** Iteration 368 ************

Collecting data for eval...
Eval_AverageReturn : 10.307692527770996
Eval_StdReturn : 1.201576828956604
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.307692307692308
Train_AverageReturn : 9.34813117980957
Train_StdReturn : 0.7781004905700684
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.348130841121495
Actor Loss : -1147.098388671875
Train_EnvstepsSoFar : 1477559
TimeSinceStart : 1042.1042068004608
Done logging...



********** Iteration 369 ************

Collecting data for eval...
Eval_AverageReturn : 10.605262756347656
Eval_StdReturn : 1.1593891382217407
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.605263157894736
Train_AverageReturn : 10.298200607299805
Train_StdReturn : 1.0914586782455444
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.298200514138818
Actor Loss : -1128.7119140625
Train_EnvstepsSoFar : 1481565
TimeSinceStart : 1044.6130633354187
Done logging...



********** Iteration 370 ************

Collecting data for eval...
Eval_AverageReturn : 10.48717975616455
Eval_StdReturn : 1.034576416015625
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.487179487179487
Train_AverageReturn : 10.434895515441895
Train_StdReturn : 1.061117172241211
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.434895833333334
Actor Loss : -1113.831787109375
Train_EnvstepsSoFar : 1485572
TimeSinceStart : 1047.1279349327087
Done logging...



********** Iteration 371 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.8908708095550537
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 10.443863868713379
Train_StdReturn : 1.0700565576553345
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.443864229765014
Actor Loss : -1123.795654296875
Train_EnvstepsSoFar : 1489572
TimeSinceStart : 1049.9242448806763
Done logging...



********** Iteration 372 ************

Collecting data for eval...
Eval_AverageReturn : 9.181818008422852
Eval_StdReturn : 0.7468944191932678
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.181818181818182
Train_AverageReturn : 9.69975757598877
Train_StdReturn : 0.853379487991333
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.699757869249394
Actor Loss : -1157.271728515625
Train_EnvstepsSoFar : 1493578
TimeSinceStart : 1052.4179055690765
Done logging...



********** Iteration 373 ************

Collecting data for eval...
Eval_AverageReturn : 10.526315689086914
Eval_StdReturn : 1.0696001052856445
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.526315789473685
Train_AverageReturn : 9.340326309204102
Train_StdReturn : 0.7390416860580444
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.34032634032634
Actor Loss : -1152.0224609375
Train_EnvstepsSoFar : 1497585
TimeSinceStart : 1055.6799561977386
Done logging...



********** Iteration 374 ************

Collecting data for eval...
Eval_AverageReturn : 10.256410598754883
Eval_StdReturn : 0.8978021740913391
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.256410256410257
Train_AverageReturn : 10.471203804016113
Train_StdReturn : 1.052525281906128
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.471204188481675
Actor Loss : -1124.995361328125
Train_EnvstepsSoFar : 1501585
TimeSinceStart : 1059.4273693561554
Done logging...



********** Iteration 375 ************

Collecting data for eval...
Eval_AverageReturn : 10.307692527770996
Eval_StdReturn : 1.0166269540786743
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.307692307692308
Train_AverageReturn : 10.509186744689941
Train_StdReturn : 1.0906641483306885
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.509186351706036
Actor Loss : -1103.63037109375
Train_EnvstepsSoFar : 1505589
TimeSinceStart : 1061.8994491100311
Done logging...



********** Iteration 376 ************

Collecting data for eval...
Eval_AverageReturn : 10.100000381469727
Eval_StdReturn : 0.9165151715278625
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.1
Train_AverageReturn : 10.522309303283691
Train_StdReturn : 1.1048216819763184
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.52230971128609
Actor Loss : -1112.7750244140625
Train_EnvstepsSoFar : 1509598
TimeSinceStart : 1064.5692210197449
Done logging...



********** Iteration 377 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.8222171664237976
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.997506141662598
Train_StdReturn : 0.9592670202255249
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.997506234413965
Actor Loss : -1147.627685546875
Train_EnvstepsSoFar : 1513607
TimeSinceStart : 1068.26167345047
Done logging...



********** Iteration 378 ************

Collecting data for eval...
Eval_AverageReturn : 9.488371849060059
Eval_StdReturn : 0.9244003891944885
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.488372093023257
Train_AverageReturn : 9.34813117980957
Train_StdReturn : 0.7505893111228943
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.348130841121495
Actor Loss : -1132.3179931640625
Train_EnvstepsSoFar : 1517608
TimeSinceStart : 1070.7288193702698
Done logging...



********** Iteration 379 ************

Collecting data for eval...
Eval_AverageReturn : 10.282051086425781
Eval_StdReturn : 1.1082144975662231
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.282051282051283
Train_AverageReturn : 9.617788314819336
Train_StdReturn : 0.8607749342918396
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.617788461538462
Actor Loss : -1150.4908447265625
Train_EnvstepsSoFar : 1521609
TimeSinceStart : 1073.1941266059875
Done logging...



********** Iteration 380 ************

Collecting data for eval...
Eval_AverageReturn : 10.736842155456543
Eval_StdReturn : 0.964752733707428
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.736842105263158
Train_AverageReturn : 10.367876052856445
Train_StdReturn : 1.067370057106018
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.367875647668393
Actor Loss : -1126.8072509765625
Train_EnvstepsSoFar : 1525611
TimeSinceStart : 1076.299792289734
Done logging...



********** Iteration 381 ************

Collecting data for eval...
Eval_AverageReturn : 10.307692527770996
Eval_StdReturn : 1.0415432453155518
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.307692307692308
Train_AverageReturn : 10.462141036987305
Train_StdReturn : 1.043694257736206
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.462140992167102
Actor Loss : -1119.545654296875
Train_EnvstepsSoFar : 1529618
TimeSinceStart : 1079.121703863144
Done logging...



********** Iteration 382 ************

Collecting data for eval...
Eval_AverageReturn : 9.642857551574707
Eval_StdReturn : 0.8949974179267883
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.642857142857142
Train_AverageReturn : 10.19847297668457
Train_StdReturn : 1.0095210075378418
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.198473282442748
Actor Loss : -1133.2908935546875
Train_EnvstepsSoFar : 1533626
TimeSinceStart : 1082.1166672706604
Done logging...



********** Iteration 383 ************

Collecting data for eval...
Eval_AverageReturn : 9.159090995788574
Eval_StdReturn : 0.7052782773971558
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.159090909090908
Train_AverageReturn : 9.634614944458008
Train_StdReturn : 0.917853832244873
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.634615384615385
Actor Loss : -1149.277587890625
Train_EnvstepsSoFar : 1537634
TimeSinceStart : 1084.9611475467682
Done logging...



********** Iteration 384 ************

Collecting data for eval...
Eval_AverageReturn : 10.149999618530273
Eval_StdReturn : 0.9886859655380249
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.15
Train_AverageReturn : 9.340326309204102
Train_StdReturn : 0.7789664268493652
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.34032634032634
Actor Loss : -1146.9017333984375
Train_EnvstepsSoFar : 1541641
TimeSinceStart : 1087.6083018779755
Done logging...



********** Iteration 385 ************

Collecting data for eval...
Eval_AverageReturn : 10.6578950881958
Eval_StdReturn : 0.9807708859443665
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.657894736842104
Train_AverageReturn : 10.062813758850098
Train_StdReturn : 0.9555834531784058
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.06281407035176
Actor Loss : -1146.2176513671875
Train_EnvstepsSoFar : 1545646
TimeSinceStart : 1091.5087757110596
Done logging...



********** Iteration 386 ************

Collecting data for eval...
Eval_AverageReturn : 10.307692527770996
Eval_StdReturn : 1.0166269540786743
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.307692307692308
Train_AverageReturn : 10.440104484558105
Train_StdReturn : 1.0832802057266235
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.440104166666666
Actor Loss : -1125.8546142578125
Train_EnvstepsSoFar : 1549655
TimeSinceStart : 1094.7050535678864
Done logging...



********** Iteration 387 ************

Collecting data for eval...
Eval_AverageReturn : 9.780488014221191
Eval_StdReturn : 0.7812496423721313
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.78048780487805
Train_AverageReturn : 10.314433097839355
Train_StdReturn : 1.0692988634109497
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.314432989690722
Actor Loss : -1129.7509765625
Train_EnvstepsSoFar : 1553657
TimeSinceStart : 1097.9625861644745
Done logging...



********** Iteration 388 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.672410786151886
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.857142448425293
Train_StdReturn : 0.8447378277778625
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.857142857142858
Actor Loss : -1157.62939453125
Train_EnvstepsSoFar : 1557659
TimeSinceStart : 1100.9781577587128
Done logging...



********** Iteration 389 ************

Collecting data for eval...
Eval_AverageReturn : 10.461538314819336
Eval_StdReturn : 0.9566542506217957
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.461538461538462
Train_AverageReturn : 9.401408195495605
Train_StdReturn : 0.7877572178840637
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.401408450704226
Actor Loss : -1153.8857421875
Train_EnvstepsSoFar : 1561664
TimeSinceStart : 1105.2889521121979
Done logging...



********** Iteration 390 ************

Collecting data for eval...
Eval_AverageReturn : 10.552631378173828
Eval_StdReturn : 0.8174853920936584
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.552631578947368
Train_AverageReturn : 10.378238677978516
Train_StdReturn : 1.08305025100708
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.378238341968911
Actor Loss : -1132.383544921875
Train_EnvstepsSoFar : 1565670
TimeSinceStart : 1108.135181427002
Done logging...



********** Iteration 391 ************

Collecting data for eval...
Eval_AverageReturn : 10.256410598754883
Eval_StdReturn : 1.0553392171859741
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.256410256410257
Train_AverageReturn : 10.48952865600586
Train_StdReturn : 1.037841796875
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.489528795811518
Actor Loss : -1120.5439453125
Train_EnvstepsSoFar : 1569677
TimeSinceStart : 1111.1330194473267
Done logging...



********** Iteration 392 ************

Collecting data for eval...
Eval_AverageReturn : 9.690476417541504
Eval_StdReturn : 0.8860854506492615
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.69047619047619
Train_AverageReturn : 10.332473754882812
Train_StdReturn : 0.9975625276565552
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.332474226804123
Actor Loss : -1137.806640625
Train_EnvstepsSoFar : 1573686
TimeSinceStart : 1114.0502281188965
Done logging...



********** Iteration 393 ************

Collecting data for eval...
Eval_AverageReturn : 10.149999618530273
Eval_StdReturn : 0.8817596435546875
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.15
Train_AverageReturn : 9.460992813110352
Train_StdReturn : 0.865829348564148
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.460992907801419
Actor Loss : -1153.6800537109375
Train_EnvstepsSoFar : 1577688
TimeSinceStart : 1117.006973028183
Done logging...



********** Iteration 394 ************

Collecting data for eval...
Eval_AverageReturn : 10.48717975616455
Eval_StdReturn : 1.1293699741363525
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.487179487179487
Train_AverageReturn : 10.055275917053223
Train_StdReturn : 0.9625968933105469
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.055276381909549
Actor Loss : -1150.576904296875
Train_EnvstepsSoFar : 1581690
TimeSinceStart : 1120.202952861786
Done logging...



********** Iteration 395 ************

Collecting data for eval...
Eval_AverageReturn : 9.97560977935791
Eval_StdReturn : 0.949654757976532
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.975609756097562
Train_AverageReturn : 10.343668937683105
Train_StdReturn : 1.030907392501831
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.343669250645995
Actor Loss : -1136.4512939453125
Train_EnvstepsSoFar : 1585693
TimeSinceStart : 1123.5292811393738
Done logging...



********** Iteration 396 ************

Collecting data for eval...
Eval_AverageReturn : 9.642857551574707
Eval_StdReturn : 0.8949974179267883
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.642857142857142
Train_AverageReturn : 10.227041244506836
Train_StdReturn : 0.9486744403839111
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.22704081632653
Actor Loss : -1148.77783203125
Train_EnvstepsSoFar : 1589702
TimeSinceStart : 1126.7606587409973
Done logging...



********** Iteration 397 ************

Collecting data for eval...
Eval_AverageReturn : 10.435897827148438
Eval_StdReturn : 1.1046491861343384
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.435897435897436
Train_AverageReturn : 9.72330093383789
Train_StdReturn : 0.8680638074874878
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.723300970873787
Actor Loss : -1158.826904296875
Train_EnvstepsSoFar : 1593708
TimeSinceStart : 1129.9199497699738
Done logging...



********** Iteration 398 ************

Collecting data for eval...
Eval_AverageReturn : 10.35897445678711
Eval_StdReturn : 1.024999976158142
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.35897435897436
Train_AverageReturn : 10.285346984863281
Train_StdReturn : 1.0257937908172607
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.2853470437018
Actor Loss : -1141.180908203125
Train_EnvstepsSoFar : 1597709
TimeSinceStart : 1133.16139960289
Done logging...



********** Iteration 399 ************

Collecting data for eval...
Eval_AverageReturn : 10.050000190734863
Eval_StdReturn : 0.8930285573005676
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.05
Train_AverageReturn : 10.45430850982666
Train_StdReturn : 1.0558185577392578
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.454308093994777
Actor Loss : -1138.73388671875
Train_EnvstepsSoFar : 1601713
TimeSinceStart : 1136.166445016861
Done logging...



********** Iteration 400 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.8062257766723633
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 9.913366317749023
Train_StdReturn : 0.8843633532524109
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.913366336633663
Actor Loss : -1158.767578125
Train_EnvstepsSoFar : 1605718
TimeSinceStart : 1139.2294476032257
Done logging...



********** Iteration 401 ************

Collecting data for eval...
Eval_AverageReturn : 10.175000190734863
Eval_StdReturn : 0.8912771940231323
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.175
Train_AverageReturn : 10.232736587524414
Train_StdReturn : 0.9672660231590271
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.232736572890026
Actor Loss : -1148.8997802734375
Train_EnvstepsSoFar : 1609719
TimeSinceStart : 1142.521549463272
Done logging...



********** Iteration 402 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.8944271802902222
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 10.152284622192383
Train_StdReturn : 0.9219033718109131
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.152284263959391
Actor Loss : -1152.1246337890625
Train_EnvstepsSoFar : 1613719
TimeSinceStart : 1145.1606106758118
Done logging...



********** Iteration 403 ************

Collecting data for eval...
Eval_AverageReturn : 10.333333015441895
Eval_StdReturn : 1.0459527969360352
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.333333333333334
Train_AverageReturn : 10.020000457763672
Train_StdReturn : 0.8914034366607666
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.02
Actor Loss : -1160.653076171875
Train_EnvstepsSoFar : 1617727
TimeSinceStart : 1148.100742816925
Done logging...



********** Iteration 404 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.8637312650680542
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 10.407792091369629
Train_StdReturn : 1.0306681394577026
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.407792207792207
Actor Loss : -1140.0294189453125
Train_EnvstepsSoFar : 1621734
TimeSinceStart : 1151.3307855129242
Done logging...



********** Iteration 405 ************

Collecting data for eval...
Eval_AverageReturn : 10.605262756347656
Eval_StdReturn : 1.1818691492080688
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.605263157894736
Train_AverageReturn : 9.488151550292969
Train_StdReturn : 0.7810564041137695
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.488151658767773
Actor Loss : -1155.83837890625
Train_EnvstepsSoFar : 1625738
TimeSinceStart : 1154.1015417575836
Done logging...



********** Iteration 406 ************

Collecting data for eval...
Eval_AverageReturn : 10.710526466369629
Eval_StdReturn : 0.9708350300788879
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.710526315789474
Train_AverageReturn : 10.639257431030273
Train_StdReturn : 1.1105223894119263
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.639257294429708
Actor Loss : -1123.0048828125
Train_EnvstepsSoFar : 1629749
TimeSinceStart : 1156.7363047599792
Done logging...



********** Iteration 407 ************

Collecting data for eval...
Eval_AverageReturn : 9.780488014221191
Eval_StdReturn : 0.9242583513259888
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.78048780487805
Train_AverageReturn : 10.55672836303711
Train_StdReturn : 1.0866549015045166
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.556728232189974
Actor Loss : -1120.884033203125
Train_EnvstepsSoFar : 1633750
TimeSinceStart : 1159.9592957496643
Done logging...



********** Iteration 408 ************

Collecting data for eval...
Eval_AverageReturn : 10.100000381469727
Eval_StdReturn : 0.9165151119232178
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.1
Train_AverageReturn : 9.74209213256836
Train_StdReturn : 0.8722008466720581
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.742092457420924
Actor Loss : -1159.759033203125
Train_EnvstepsSoFar : 1637754
TimeSinceStart : 1163.184003353119
Done logging...



********** Iteration 409 ************

Collecting data for eval...
Eval_AverageReturn : 10.100000381469727
Eval_StdReturn : 0.8306623697280884
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.1
Train_AverageReturn : 10.095717430114746
Train_StdReturn : 0.9038996696472168
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.095717884130982
Actor Loss : -1161.47607421875
Train_EnvstepsSoFar : 1641762
TimeSinceStart : 1165.720866203308
Done logging...



********** Iteration 410 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.7692016363143921
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 10.258974075317383
Train_StdReturn : 0.9321103096008301
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.25897435897436
Actor Loss : -1154.3310546875
Train_EnvstepsSoFar : 1645763
TimeSinceStart : 1168.7936840057373
Done logging...



********** Iteration 411 ************

Collecting data for eval...
Eval_AverageReturn : 10.538461685180664
Eval_StdReturn : 1.0339407920837402
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.538461538461538
Train_AverageReturn : 9.510688781738281
Train_StdReturn : 0.7816206812858582
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.510688836104514
Actor Loss : -1158.608154296875
Train_EnvstepsSoFar : 1649767
TimeSinceStart : 1171.8797760009766
Done logging...



********** Iteration 412 ************

Collecting data for eval...
Eval_AverageReturn : 10.6578950881958
Eval_StdReturn : 1.05820894241333
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.657894736842104
Train_AverageReturn : 10.666666984558105
Train_StdReturn : 1.104334831237793
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.666666666666666
Actor Loss : -1117.890380859375
Train_EnvstepsSoFar : 1653767
TimeSinceStart : 1176.6143643856049
Done logging...



********** Iteration 413 ************

Collecting data for eval...
Eval_AverageReturn : 10.282051086425781
Eval_StdReturn : 1.0114401578903198
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.282051282051283
Train_AverageReturn : 10.539473533630371
Train_StdReturn : 1.119689702987671
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.539473684210526
Actor Loss : -1110.5662841796875
Train_EnvstepsSoFar : 1657772
TimeSinceStart : 1181.4025127887726
Done logging...



********** Iteration 414 ************

Collecting data for eval...
Eval_AverageReturn : 9.25
Eval_StdReturn : 0.7423856258392334
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.25
Train_AverageReturn : 10.250638961791992
Train_StdReturn : 1.0480005741119385
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.250639386189258
Actor Loss : -1138.021484375
Train_EnvstepsSoFar : 1661780
TimeSinceStart : 1185.1839962005615
Done logging...



********** Iteration 415 ************

Collecting data for eval...
Eval_AverageReturn : 9.511628150939941
Eval_StdReturn : 0.8455654978752136
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.511627906976743
Train_AverageReturn : 9.230414390563965
Train_StdReturn : 0.7135271430015564
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.23041474654378
Actor Loss : -1133.9755859375
Train_EnvstepsSoFar : 1665786
TimeSinceStart : 1189.1500525474548
Done logging...



********** Iteration 416 ************

Collecting data for eval...
Eval_AverageReturn : 10.384614944458008
Eval_StdReturn : 1.0769232511520386
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.384615384615385
Train_AverageReturn : 9.367681503295898
Train_StdReturn : 0.8029133677482605
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.36768149882904
Actor Loss : -1150.0072021484375
Train_EnvstepsSoFar : 1669786
TimeSinceStart : 1191.5635499954224
Done logging...



********** Iteration 417 ************

Collecting data for eval...
Eval_AverageReturn : 10.461538314819336
Eval_StdReturn : 0.9830917119979858
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.461538461538462
Train_AverageReturn : 10.314433097839355
Train_StdReturn : 1.0224783420562744
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.314432989690722
Actor Loss : -1136.0400390625
Train_EnvstepsSoFar : 1673788
TimeSinceStart : 1194.6560983657837
Done logging...



********** Iteration 418 ************

Collecting data for eval...
Eval_AverageReturn : 9.853658676147461
Eval_StdReturn : 0.8427879214286804
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 9.853658536585366
Train_AverageReturn : 10.4464750289917
Train_StdReturn : 1.0379894971847534
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.446475195822455
Actor Loss : -1127.7918701171875
Train_EnvstepsSoFar : 1677789
TimeSinceStart : 1197.1141526699066
Done logging...



********** Iteration 419 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 0.8491692543029785
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 10.065326690673828
Train_StdReturn : 0.9775128960609436
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.06532663316583
Actor Loss : -1145.8140869140625
Train_EnvstepsSoFar : 1681795
TimeSinceStart : 1200.0018208026886
Done logging...



********** Iteration 420 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.6659451127052307
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.465721130371094
Train_StdReturn : 0.8522712588310242
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.465721040189125
Actor Loss : -1145.2093505859375
Train_EnvstepsSoFar : 1685799
TimeSinceStart : 1203.165831565857
Done logging...



********** Iteration 421 ************

Collecting data for eval...
Eval_AverageReturn : 9.690476417541504
Eval_StdReturn : 0.9125603437423706
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.69047619047619
Train_AverageReturn : 9.357476234436035
Train_StdReturn : 0.7271537184715271
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.357476635514018
Actor Loss : -1144.583984375
Train_EnvstepsSoFar : 1689804
TimeSinceStart : 1205.5862658023834
Done logging...



********** Iteration 422 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 0.9614441990852356
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 9.811274528503418
Train_StdReturn : 0.8495502471923828
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.811274509803921
Actor Loss : -1155.147216796875
Train_EnvstepsSoFar : 1693807
TimeSinceStart : 1208.0563900470734
Done logging...



********** Iteration 423 ************

Collecting data for eval...
Eval_AverageReturn : 10.149999618530273
Eval_StdReturn : 0.9367496371269226
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.15
Train_AverageReturn : 10.264102935791016
Train_StdReturn : 1.0497831106185913
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.264102564102565
Actor Loss : -1132.75390625
Train_EnvstepsSoFar : 1697810
TimeSinceStart : 1210.8558247089386
Done logging...



********** Iteration 424 ************

Collecting data for eval...
Eval_AverageReturn : 10.225000381469727
Eval_StdReturn : 0.9079509973526001
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.225
Train_AverageReturn : 10.402597427368164
Train_StdReturn : 1.0377265214920044
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.402597402597403
Actor Loss : -1131.5341796875
Train_EnvstepsSoFar : 1701815
TimeSinceStart : 1213.2734589576721
Done logging...



********** Iteration 425 ************

Collecting data for eval...
Eval_AverageReturn : 9.44186019897461
Eval_StdReturn : 0.7250445485115051
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.44186046511628
Train_AverageReturn : 10.098237037658691
Train_StdReturn : 0.9772845506668091
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.09823677581864
Actor Loss : -1149.963623046875
Train_EnvstepsSoFar : 1705824
TimeSinceStart : 1215.7292585372925
Done logging...



********** Iteration 426 ************

Collecting data for eval...
Eval_AverageReturn : 9.666666984558105
Eval_StdReturn : 0.8067178130149841
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.666666666666666
Train_AverageReturn : 9.306976318359375
Train_StdReturn : 0.8204919695854187
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.306976744186047
Actor Loss : -1151.25537109375
Train_EnvstepsSoFar : 1709826
TimeSinceStart : 1218.12295627594
Done logging...



********** Iteration 427 ************

Collecting data for eval...
Eval_AverageReturn : 10.435897827148438
Eval_StdReturn : 1.0326682329177856
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.435897435897436
Train_AverageReturn : 9.520190238952637
Train_StdReturn : 0.8760177493095398
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.520190023752969
Actor Loss : -1156.7049560546875
Train_EnvstepsSoFar : 1713834
TimeSinceStart : 1220.5320718288422
Done logging...



********** Iteration 428 ************

Collecting data for eval...
Eval_AverageReturn : 10.86486530303955
Eval_StdReturn : 0.9053045511245728
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.864864864864865
Train_AverageReturn : 10.412986755371094
Train_StdReturn : 1.0386492013931274
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.412987012987013
Actor Loss : -1134.8065185546875
Train_EnvstepsSoFar : 1717843
TimeSinceStart : 1222.9115302562714
Done logging...



********** Iteration 429 ************

Collecting data for eval...
Eval_AverageReturn : 10.333333015441895
Eval_StdReturn : 1.0211440324783325
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.333333333333334
Train_AverageReturn : 10.73458480834961
Train_StdReturn : 1.0287083387374878
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.734584450402144
Actor Loss : -1125.8162841796875
Train_EnvstepsSoFar : 1721847
TimeSinceStart : 1225.3861064910889
Done logging...



********** Iteration 430 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.6780176162719727
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 10.324742317199707
Train_StdReturn : 1.0065282583236694
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.324742268041238
Actor Loss : -1142.2939453125
Train_EnvstepsSoFar : 1725853
TimeSinceStart : 1227.872799396515
Done logging...



********** Iteration 431 ************

Collecting data for eval...
Eval_AverageReturn : 10.710526466369629
Eval_StdReturn : 1.0980339050292969
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.710526315789474
Train_AverageReturn : 9.406103134155273
Train_StdReturn : 0.7942636609077454
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.406103286384976
Actor Loss : -1158.3466796875
Train_EnvstepsSoFar : 1729860
TimeSinceStart : 1230.4456417560577
Done logging...



********** Iteration 432 ************

Collecting data for eval...
Eval_AverageReturn : 11.0
Eval_StdReturn : 0.9004503488540649
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 11.0
Train_AverageReturn : 10.610079765319824
Train_StdReturn : 1.0322154760360718
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.610079575596817
Actor Loss : -1128.17431640625
Train_EnvstepsSoFar : 1733860
TimeSinceStart : 1232.9672691822052
Done logging...



********** Iteration 433 ************

Collecting data for eval...
Eval_AverageReturn : 10.461538314819336
Eval_StdReturn : 1.1058387756347656
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.461538461538462
Train_AverageReturn : 10.856369018554688
Train_StdReturn : 1.158668875694275
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.856368563685637
Actor Loss : -1113.427490234375
Train_EnvstepsSoFar : 1737866
TimeSinceStart : 1235.4346733093262
Done logging...



********** Iteration 434 ************

Collecting data for eval...
Eval_AverageReturn : 9.181818008422852
Eval_StdReturn : 0.7767276167869568
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.181818181818182
Train_AverageReturn : 10.473821640014648
Train_StdReturn : 1.0146031379699707
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.473821989528796
Actor Loss : -1140.18115234375
Train_EnvstepsSoFar : 1741867
TimeSinceStart : 1237.9413878917694
Done logging...



********** Iteration 435 ************

Collecting data for eval...
Eval_AverageReturn : 10.526315689086914
Eval_StdReturn : 0.9661873579025269
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.526315789473685
Train_AverageReturn : 9.313953399658203
Train_StdReturn : 0.7418020963668823
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.313953488372093
Actor Loss : -1152.1949462890625
Train_EnvstepsSoFar : 1745872
TimeSinceStart : 1240.4432063102722
Done logging...



********** Iteration 436 ************

Collecting data for eval...
Eval_AverageReturn : 10.736842155456543
Eval_StdReturn : 0.9085618853569031
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.736842105263158
Train_AverageReturn : 10.473821640014648
Train_StdReturn : 1.0820261240005493
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.473821989528796
Actor Loss : -1140.326171875
Train_EnvstepsSoFar : 1749873
TimeSinceStart : 1242.911078453064
Done logging...



********** Iteration 437 ************

Collecting data for eval...
Eval_AverageReturn : 10.631579399108887
Eval_StdReturn : 1.0367218255996704
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.631578947368421
Train_AverageReturn : 10.589946746826172
Train_StdReturn : 1.1096519231796265
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.58994708994709
Actor Loss : -1122.467041015625
Train_EnvstepsSoFar : 1753876
TimeSinceStart : 1245.3564596176147
Done logging...



********** Iteration 438 ************

Collecting data for eval...
Eval_AverageReturn : 9.853658676147461
Eval_StdReturn : 0.81333327293396
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 9.853658536585366
Train_AverageReturn : 10.421875
Train_StdReturn : 1.0626914501190186
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.421875
Actor Loss : -1135.376708984375
Train_EnvstepsSoFar : 1757878
TimeSinceStart : 1247.8228912353516
Done logging...



********** Iteration 439 ************

Collecting data for eval...
Eval_AverageReturn : 9.87804889678955
Eval_StdReturn : 0.771287202835083
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 9.878048780487806
Train_AverageReturn : 9.465721130371094
Train_StdReturn : 0.8467053771018982
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.465721040189125
Actor Loss : -1156.5906982421875
Train_EnvstepsSoFar : 1761882
TimeSinceStart : 1250.2898771762848
Done logging...



********** Iteration 440 ************

Collecting data for eval...
Eval_AverageReturn : 10.384614944458008
Eval_StdReturn : 1.0769232511520386
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.384615384615385
Train_AverageReturn : 9.779951095581055
Train_StdReturn : 0.8567231893539429
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.7799511002445
Actor Loss : -1159.2099609375
Train_EnvstepsSoFar : 1765882
TimeSinceStart : 1253.0624570846558
Done logging...



********** Iteration 441 ************

Collecting data for eval...
Eval_AverageReturn : 10.631579399108887
Eval_StdReturn : 0.9296590685844421
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.631578947368421
Train_AverageReturn : 10.476439476013184
Train_StdReturn : 1.0351011753082275
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.476439790575917
Actor Loss : -1139.05224609375
Train_EnvstepsSoFar : 1769884
TimeSinceStart : 1255.5564391613007
Done logging...



********** Iteration 442 ************

Collecting data for eval...
Eval_AverageReturn : 9.780488014221191
Eval_StdReturn : 0.9502809643745422
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.78048780487805
Train_AverageReturn : 10.356589317321777
Train_StdReturn : 1.0402626991271973
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.356589147286822
Actor Loss : -1141.388671875
Train_EnvstepsSoFar : 1773892
TimeSinceStart : 1258.8785710334778
Done logging...



********** Iteration 443 ************

Collecting data for eval...
Eval_AverageReturn : 9.619047164916992
Eval_StdReturn : 0.8438116908073425
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.619047619047619
Train_AverageReturn : 9.852216720581055
Train_StdReturn : 0.8468036651611328
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.852216748768473
Actor Loss : -1159.981201171875
Train_EnvstepsSoFar : 1777892
TimeSinceStart : 1261.3858306407928
Done logging...



********** Iteration 444 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 0.9079509973526001
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 9.655421257019043
Train_StdReturn : 0.9336097836494446
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.655421686746989
Actor Loss : -1154.274169921875
Train_EnvstepsSoFar : 1781899
TimeSinceStart : 1263.9110977649689
Done logging...



********** Iteration 445 ************

Collecting data for eval...
Eval_AverageReturn : 10.605262756347656
Eval_StdReturn : 1.0140974521636963
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.605263157894736
Train_AverageReturn : 10.139240264892578
Train_StdReturn : 0.8849541544914246
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.139240506329115
Actor Loss : -1157.5086669921875
Train_EnvstepsSoFar : 1785904
TimeSinceStart : 1266.3853619098663
Done logging...



********** Iteration 446 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.8834521770477295
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 10.3974027633667
Train_StdReturn : 1.064415454864502
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.397402597402598
Actor Loss : -1140.428466796875
Train_EnvstepsSoFar : 1789907
TimeSinceStart : 1268.9241383075714
Done logging...



********** Iteration 447 ************

Collecting data for eval...
Eval_AverageReturn : 9.804878234863281
Eval_StdReturn : 0.8616352081298828
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.804878048780488
Train_AverageReturn : 10.080604553222656
Train_StdReturn : 0.89698725938797
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.080604534005039
Actor Loss : -1158.856201171875
Train_EnvstepsSoFar : 1793909
TimeSinceStart : 1271.3883521556854
Done logging...



********** Iteration 448 ************

Collecting data for eval...
Eval_AverageReturn : 10.461538314819336
Eval_StdReturn : 1.0584495067596436
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.461538461538462
Train_AverageReturn : 9.643373489379883
Train_StdReturn : 0.8519562482833862
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.643373493975904
Actor Loss : -1160.0313720703125
Train_EnvstepsSoFar : 1797911
TimeSinceStart : 1273.8523993492126
Done logging...



********** Iteration 449 ************

Collecting data for eval...
Eval_AverageReturn : 10.125
Eval_StdReturn : 1.0046765804290771
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.125
Train_AverageReturn : 10.36528491973877
Train_StdReturn : 1.0474430322647095
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.365284974093264
Actor Loss : -1143.164794921875
Train_EnvstepsSoFar : 1801912
TimeSinceStart : 1279.5560538768768
Done logging...



********** Iteration 450 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.659416139125824
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 10.322164535522461
Train_StdReturn : 0.9931847453117371
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.322164948453608
Actor Loss : -1152.373779296875
Train_EnvstepsSoFar : 1805917
TimeSinceStart : 1282.113846063614
Done logging...



********** Iteration 451 ************

Collecting data for eval...
Eval_AverageReturn : 10.789473533630371
Eval_StdReturn : 0.950287938117981
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.789473684210526
Train_AverageReturn : 9.617788314819336
Train_StdReturn : 0.8352630138397217
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.617788461538462
Actor Loss : -1161.7158203125
Train_EnvstepsSoFar : 1809918
TimeSinceStart : 1284.569115638733
Done logging...



********** Iteration 452 ************

Collecting data for eval...
Eval_AverageReturn : 10.815789222717285
Eval_StdReturn : 1.0725096464157104
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.81578947368421
Train_AverageReturn : 10.697860717773438
Train_StdReturn : 1.0758136510849
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.697860962566844
Actor Loss : -1127.763427734375
Train_EnvstepsSoFar : 1813919
TimeSinceStart : 1287.0951941013336
Done logging...



********** Iteration 453 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 0.9793792366981506
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 10.745307922363281
Train_StdReturn : 1.1447564363479614
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.745308310991957
Actor Loss : -1126.3341064453125
Train_EnvstepsSoFar : 1817927
TimeSinceStart : 1290.847814798355
Done logging...



********** Iteration 454 ************

Collecting data for eval...
Eval_AverageReturn : 10.48717975616455
Eval_StdReturn : 1.0590705871582031
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.487179487179487
Train_AverageReturn : 9.773170471191406
Train_StdReturn : 0.8524067997932434
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.773170731707317
Actor Loss : -1163.935546875
Train_EnvstepsSoFar : 1821934
TimeSinceStart : 1293.377456188202
Done logging...



********** Iteration 455 ************

Collecting data for eval...
Eval_AverageReturn : 10.552631378173828
Eval_StdReturn : 0.9089428782463074
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.552631578947368
Train_AverageReturn : 10.230178833007812
Train_StdReturn : 0.9204745292663574
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.230179028132993
Actor Loss : -1156.38525390625
Train_EnvstepsSoFar : 1825934
TimeSinceStart : 1296.29101896286
Done logging...



********** Iteration 456 ************

Collecting data for eval...
Eval_AverageReturn : 9.571428298950195
Eval_StdReturn : 0.9294866919517517
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.571428571428571
Train_AverageReturn : 10.3974027633667
Train_StdReturn : 1.034718632698059
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.397402597402598
Actor Loss : -1150.28662109375
Train_EnvstepsSoFar : 1829937
TimeSinceStart : 1298.7345447540283
Done logging...



********** Iteration 457 ************

Collecting data for eval...
Eval_AverageReturn : 10.578947067260742
Eval_StdReturn : 0.990257203578949
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.578947368421053
Train_AverageReturn : 9.638554573059082
Train_StdReturn : 0.8356270790100098
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.63855421686747
Actor Loss : -1162.505859375
Train_EnvstepsSoFar : 1833937
TimeSinceStart : 1301.8796668052673
Done logging...



********** Iteration 458 ************

Collecting data for eval...
Eval_AverageReturn : 10.461538314819336
Eval_StdReturn : 1.128787636756897
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.461538461538462
Train_AverageReturn : 10.434895515441895
Train_StdReturn : 1.066014289855957
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.434895833333334
Actor Loss : -1138.6978759765625
Train_EnvstepsSoFar : 1837944
TimeSinceStart : 1304.5986392498016
Done logging...



********** Iteration 459 ************

Collecting data for eval...
Eval_AverageReturn : 9.372093200683594
Eval_StdReturn : 0.716037392616272
Eval_MaxReturn : 10.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.372093023255815
Train_AverageReturn : 10.38341999053955
Train_StdReturn : 0.9700887203216553
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.38341968911917
Actor Loss : -1150.676025390625
Train_EnvstepsSoFar : 1841952
TimeSinceStart : 1308.5675485134125
Done logging...



********** Iteration 460 ************

Collecting data for eval...
Eval_AverageReturn : 10.461538314819336
Eval_StdReturn : 0.9014562964439392
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.461538461538462
Train_AverageReturn : 9.374707221984863
Train_StdReturn : 0.7403506636619568
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.374707259953162
Actor Loss : -1152.24560546875
Train_EnvstepsSoFar : 1845955
TimeSinceStart : 1313.4322073459625
Done logging...



********** Iteration 461 ************

Collecting data for eval...
Eval_AverageReturn : 10.552631378173828
Eval_StdReturn : 0.8174853920936584
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.552631578947368
Train_AverageReturn : 10.305912971496582
Train_StdReturn : 0.9839279055595398
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.305912596401027
Actor Loss : -1153.908447265625
Train_EnvstepsSoFar : 1849964
TimeSinceStart : 1316.033076763153
Done logging...



********** Iteration 462 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.8944271802902222
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 10.459529876708984
Train_StdReturn : 1.0535563230514526
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.459530026109661
Actor Loss : -1140.481689453125
Train_EnvstepsSoFar : 1853970
TimeSinceStart : 1318.6010801792145
Done logging...



********** Iteration 463 ************

Collecting data for eval...
Eval_AverageReturn : 9.39534854888916
Eval_StdReturn : 0.8109578490257263
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.395348837209303
Train_AverageReturn : 9.985037803649902
Train_StdReturn : 0.887584388256073
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.98503740648379
Actor Loss : -1161.103515625
Train_EnvstepsSoFar : 1857974
TimeSinceStart : 1321.105610370636
Done logging...



********** Iteration 464 ************

Collecting data for eval...
Eval_AverageReturn : 9.547618865966797
Eval_StdReturn : 0.8783745765686035
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.547619047619047
Train_AverageReturn : 9.465721130371094
Train_StdReturn : 0.815414309501648
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.465721040189125
Actor Loss : -1155.34716796875
Train_EnvstepsSoFar : 1861978
TimeSinceStart : 1323.5906558036804
Done logging...



********** Iteration 465 ************

Collecting data for eval...
Eval_AverageReturn : 10.225000381469727
Eval_StdReturn : 1.0365206003189087
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.225
Train_AverageReturn : 9.615385055541992
Train_StdReturn : 0.8470275402069092
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.615384615384615
Actor Loss : -1159.072021484375
Train_EnvstepsSoFar : 1865978
TimeSinceStart : 1327.6990811824799
Done logging...



********** Iteration 466 ************

Collecting data for eval...
Eval_AverageReturn : 10.384614944458008
Eval_StdReturn : 0.9504489302635193
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.384615384615385
Train_AverageReturn : 10.253196716308594
Train_StdReturn : 0.9514204263687134
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.253196930946292
Actor Loss : -1152.952392578125
Train_EnvstepsSoFar : 1869987
TimeSinceStart : 1332.3474326133728
Done logging...



********** Iteration 467 ************

Collecting data for eval...
Eval_AverageReturn : 9.87804889678955
Eval_StdReturn : 0.771287202835083
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.878048780487806
Train_AverageReturn : 10.36528491973877
Train_StdReturn : 1.0523780584335327
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.365284974093264
Actor Loss : -1143.78173828125
Train_EnvstepsSoFar : 1873988
TimeSinceStart : 1334.8453872203827
Done logging...



********** Iteration 468 ************

Collecting data for eval...
Eval_AverageReturn : 9.619047164916992
Eval_StdReturn : 0.9988656044006348
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.619047619047619
Train_AverageReturn : 9.903465270996094
Train_StdReturn : 0.8606283068656921
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.903465346534654
Actor Loss : -1161.3404541015625
Train_EnvstepsSoFar : 1877989
TimeSinceStart : 1337.3257479667664
Done logging...



********** Iteration 469 ************

Collecting data for eval...
Eval_AverageReturn : 10.282051086425781
Eval_StdReturn : 0.9322901964187622
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.282051282051283
Train_AverageReturn : 9.70460033416748
Train_StdReturn : 0.882931113243103
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.704600484261501
Actor Loss : -1162.1241455078125
Train_EnvstepsSoFar : 1881997
TimeSinceStart : 1340.1917066574097
Done logging...



********** Iteration 470 ************

Collecting data for eval...
Eval_AverageReturn : 10.6578950881958
Eval_StdReturn : 0.9807708263397217
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.657894736842104
Train_AverageReturn : 10.214285850524902
Train_StdReturn : 0.9285714030265808
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.214285714285714
Actor Loss : -1159.005615234375
Train_EnvstepsSoFar : 1886001
TimeSinceStart : 1342.7059817314148
Done logging...



********** Iteration 471 ************

Collecting data for eval...
Eval_AverageReturn : 9.690476417541504
Eval_StdReturn : 0.8014301061630249
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.69047619047619
Train_AverageReturn : 10.402597427368164
Train_StdReturn : 1.0551018714904785
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.402597402597403
Actor Loss : -1142.3760986328125
Train_EnvstepsSoFar : 1890006
TimeSinceStart : 1345.262491941452
Done logging...



********** Iteration 472 ************

Collecting data for eval...
Eval_AverageReturn : 10.684210777282715
Eval_StdReturn : 0.9761703610420227
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.68421052631579
Train_AverageReturn : 9.70460033416748
Train_StdReturn : 0.8801844716072083
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.704600484261501
Actor Loss : -1165.3057861328125
Train_EnvstepsSoFar : 1894014
TimeSinceStart : 1347.7608098983765
Done logging...



********** Iteration 473 ************

Collecting data for eval...
Eval_AverageReturn : 9.90243911743164
Eval_StdReturn : 0.6915827989578247
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 9.902439024390244
Train_AverageReturn : 10.569920539855957
Train_StdReturn : 1.0233385562896729
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.569920844327177
Actor Loss : -1142.94775390625
Train_EnvstepsSoFar : 1898020
TimeSinceStart : 1350.2768261432648
Done logging...



********** Iteration 474 ************

Collecting data for eval...
Eval_AverageReturn : 10.125
Eval_StdReturn : 0.871421217918396
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.125
Train_AverageReturn : 10.151898384094238
Train_StdReturn : 0.8900094032287598
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.151898734177216
Actor Loss : -1164.496337890625
Train_EnvstepsSoFar : 1902030
TimeSinceStart : 1353.370007276535
Done logging...



********** Iteration 475 ************

Collecting data for eval...
Eval_AverageReturn : 10.810811042785645
Eval_StdReturn : 1.2266815900802612
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.81081081081081
Train_AverageReturn : 9.823529243469238
Train_StdReturn : 0.8678547739982605
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.823529411764707
Actor Loss : -1167.4744873046875
Train_EnvstepsSoFar : 1906038
TimeSinceStart : 1355.8796045780182
Done logging...



********** Iteration 476 ************

Collecting data for eval...
Eval_AverageReturn : 10.736842155456543
Eval_StdReturn : 0.9916549324989319
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.736842105263158
Train_AverageReturn : 10.713903427124023
Train_StdReturn : 1.1474077701568604
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.713903743315509
Actor Loss : -1119.7054443359375
Train_EnvstepsSoFar : 1910045
TimeSinceStart : 1359.631591796875
Done logging...



********** Iteration 477 ************

Collecting data for eval...
Eval_AverageReturn : 9.348836898803711
Eval_StdReturn : 0.7114911079406738
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.348837209302326
Train_AverageReturn : 10.554089546203613
Train_StdReturn : 1.0547558069229126
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.554089709762533
Actor Loss : -1145.745361328125
Train_EnvstepsSoFar : 1914045
TimeSinceStart : 1362.1321759223938
Done logging...



********** Iteration 478 ************

Collecting data for eval...
Eval_AverageReturn : 9.418604850769043
Eval_StdReturn : 0.8952733874320984
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.418604651162791
Train_AverageReturn : 9.411765098571777
Train_StdReturn : 0.7714633345603943
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.411764705882353
Actor Loss : -1125.3651123046875
Train_EnvstepsSoFar : 1918045
TimeSinceStart : 1364.793699979782
Done logging...



********** Iteration 479 ************

Collecting data for eval...
Eval_AverageReturn : 11.36111068725586
Eval_StdReturn : 1.2506171464920044
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 11.36111111111111
Train_AverageReturn : 9.39906120300293
Train_StdReturn : 0.7784655094146729
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.39906103286385
Actor Loss : -1161.253173828125
Train_EnvstepsSoFar : 1922049
TimeSinceStart : 1367.273759841919
Done logging...



********** Iteration 480 ************

Collecting data for eval...
Eval_AverageReturn : 11.30555534362793
Eval_StdReturn : 1.329566478729248
Eval_MaxReturn : 14.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 11.305555555555555
Train_AverageReturn : 11.264044761657715
Train_StdReturn : 1.2420305013656616
Train_MaxReturn : 14.0
Train_MinReturn : 9.0
Train_AverageEpLen : 11.264044943820224
Actor Loss : -1075.0255126953125
Train_EnvstepsSoFar : 1926059
TimeSinceStart : 1371.0241396427155
Done logging...



********** Iteration 481 ************

Collecting data for eval...
Eval_AverageReturn : 11.514286041259766
Eval_StdReturn : 1.1801071166992188
Eval_MaxReturn : 14.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 11.514285714285714
Train_AverageReturn : 11.386363983154297
Train_StdReturn : 1.2101070880889893
Train_MaxReturn : 14.0
Train_MinReturn : 9.0
Train_AverageEpLen : 11.386363636363637
Actor Loss : -1043.521728515625
Train_EnvstepsSoFar : 1930067
TimeSinceStart : 1373.5215620994568
Done logging...



********** Iteration 482 ************

Collecting data for eval...
Eval_AverageReturn : 11.13888931274414
Eval_StdReturn : 1.2282050848007202
Eval_MaxReturn : 13.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 11.13888888888889
Train_AverageReturn : 11.375
Train_StdReturn : 1.2391575574874878
Train_MaxReturn : 14.0
Train_MinReturn : 9.0
Train_AverageEpLen : 11.375
Actor Loss : -1050.1690673828125
Train_EnvstepsSoFar : 1934071
TimeSinceStart : 1377.7239167690277
Done logging...



********** Iteration 483 ************

Collecting data for eval...
Eval_AverageReturn : 9.595237731933594
Eval_StdReturn : 0.9273496270179749
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.595238095238095
Train_AverageReturn : 10.920980453491211
Train_StdReturn : 1.1539629697799683
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.920980926430518
Actor Loss : -1099.884765625
Train_EnvstepsSoFar : 1938079
TimeSinceStart : 1380.2294900417328
Done logging...



********** Iteration 484 ************

Collecting data for eval...
Eval_AverageReturn : 9.204545021057129
Eval_StdReturn : 0.7254949808120728
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.204545454545455
Train_AverageReturn : 9.72330093383789
Train_StdReturn : 0.9405331611633301
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.723300970873787
Actor Loss : -1149.0159912109375
Train_EnvstepsSoFar : 1942085
TimeSinceStart : 1382.7216441631317
Done logging...



********** Iteration 485 ************

Collecting data for eval...
Eval_AverageReturn : 9.302325248718262
Eval_StdReturn : 0.8769631385803223
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.30232558139535
Train_AverageReturn : 9.342657089233398
Train_StdReturn : 0.7300244569778442
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.342657342657343
Actor Loss : -1098.028076171875
Train_EnvstepsSoFar : 1946093
TimeSinceStart : 1385.1990020275116
Done logging...



********** Iteration 486 ************

Collecting data for eval...
Eval_AverageReturn : 10.074999809265137
Eval_StdReturn : 0.87714022397995
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.075
Train_AverageReturn : 9.381732940673828
Train_StdReturn : 0.7190573215484619
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.381733021077283
Actor Loss : -1136.670166015625
Train_EnvstepsSoFar : 1950099
TimeSinceStart : 1387.6870782375336
Done logging...



********** Iteration 487 ************

Collecting data for eval...
Eval_AverageReturn : 10.410256385803223
Eval_StdReturn : 1.0055729150772095
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.41025641025641
Train_AverageReturn : 10.04010009765625
Train_StdReturn : 0.9802029728889465
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.040100250626567
Actor Loss : -1139.3031005859375
Train_EnvstepsSoFar : 1954105
TimeSinceStart : 1390.1814467906952
Done logging...



********** Iteration 488 ************

Collecting data for eval...
Eval_AverageReturn : 10.410256385803223
Eval_StdReturn : 1.1258718967437744
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.41025641025641
Train_AverageReturn : 10.392208099365234
Train_StdReturn : 1.0760396718978882
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.392207792207792
Actor Loss : -1118.1837158203125
Train_EnvstepsSoFar : 1958106
TimeSinceStart : 1392.6562223434448
Done logging...



********** Iteration 489 ************

Collecting data for eval...
Eval_AverageReturn : 10.024999618530273
Eval_StdReturn : 0.8799857497215271
Eval_MaxReturn : 11.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.025
Train_AverageReturn : 10.421875
Train_StdReturn : 1.0772943496704102
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.421875
Actor Loss : -1123.186279296875
Train_EnvstepsSoFar : 1962108
TimeSinceStart : 1395.1322610378265
Done logging...



********** Iteration 490 ************

Collecting data for eval...
Eval_AverageReturn : 9.523809432983398
Eval_StdReturn : 0.6982323527336121
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.523809523809524
Train_AverageReturn : 9.957711219787598
Train_StdReturn : 0.951930582523346
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.957711442786069
Actor Loss : -1138.982177734375
Train_EnvstepsSoFar : 1966111
TimeSinceStart : 1401.0202882289886
Done logging...



********** Iteration 491 ************

Collecting data for eval...
Eval_AverageReturn : 9.204545021057129
Eval_StdReturn : 0.7254949808120728
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.204545454545455
Train_AverageReturn : 9.483412742614746
Train_StdReturn : 0.9125038981437683
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.483412322274882
Actor Loss : -1134.6697998046875
Train_EnvstepsSoFar : 1970113
TimeSinceStart : 1404.2936668395996
Done logging...



********** Iteration 492 ************

Collecting data for eval...
Eval_AverageReturn : 9.325581550598145
Eval_StdReturn : 0.8551058769226074
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.325581395348838
Train_AverageReturn : 9.337995529174805
Train_StdReturn : 0.7572349905967712
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.337995337995338
Actor Loss : -1131.06103515625
Train_EnvstepsSoFar : 1974119
TimeSinceStart : 1406.794261455536
Done logging...



********** Iteration 493 ************

Collecting data for eval...
Eval_AverageReturn : 10.0
Eval_StdReturn : 0.962719738483429
Eval_MaxReturn : 12.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 10.0
Train_AverageReturn : 9.535714149475098
Train_StdReturn : 0.9467541575431824
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.535714285714286
Actor Loss : -1139.430419921875
Train_EnvstepsSoFar : 1978124
TimeSinceStart : 1409.274078130722
Done logging...



********** Iteration 494 ************

Collecting data for eval...
Eval_AverageReturn : 10.526315689086914
Eval_StdReturn : 1.019206166267395
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.526315789473685
Train_AverageReturn : 10.04010009765625
Train_StdReturn : 0.9802029728889465
Train_MaxReturn : 12.0
Train_MinReturn : 8.0
Train_AverageEpLen : 10.040100250626567
Actor Loss : -1142.2552490234375
Train_EnvstepsSoFar : 1982130
TimeSinceStart : 1411.7537405490875
Done logging...



********** Iteration 495 ************

Collecting data for eval...
Eval_AverageReturn : 10.48717975616455
Eval_StdReturn : 1.1064331531524658
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.487179487179487
Train_AverageReturn : 10.440104484558105
Train_StdReturn : 1.051564335823059
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.440104166666666
Actor Loss : -1130.28076171875
Train_EnvstepsSoFar : 1986139
TimeSinceStart : 1414.2458407878876
Done logging...



********** Iteration 496 ************

Collecting data for eval...
Eval_AverageReturn : 10.410256385803223
Eval_StdReturn : 0.9532119035720825
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.41025641025641
Train_AverageReturn : 10.509186744689941
Train_StdReturn : 1.066327691078186
Train_MaxReturn : 13.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.509186351706036
Actor Loss : -1125.8095703125
Train_EnvstepsSoFar : 1990143
TimeSinceStart : 1416.9727835655212
Done logging...



********** Iteration 497 ************

Collecting data for eval...
Eval_AverageReturn : 9.690476417541504
Eval_StdReturn : 0.8306077718734741
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.69047619047619
Train_AverageReturn : 10.343668937683105
Train_StdReturn : 1.0208321809768677
Train_MaxReturn : 12.0
Train_MinReturn : 9.0
Train_AverageEpLen : 10.343669250645995
Actor Loss : -1139.95068359375
Train_EnvstepsSoFar : 1994146
TimeSinceStart : 1419.4552421569824
Done logging...



********** Iteration 498 ************

Collecting data for eval...
Eval_AverageReturn : 9.465116500854492
Eval_StdReturn : 0.9728604555130005
Eval_MaxReturn : 11.0
Eval_MinReturn : 8.0
Eval_AverageEpLen : 9.465116279069768
Train_AverageReturn : 9.718446731567383
Train_StdReturn : 0.8831483125686646
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.718446601941748
Actor Loss : -1157.58544921875
Train_EnvstepsSoFar : 1998150
TimeSinceStart : 1421.961219072342
Done logging...



********** Iteration 499 ************

Collecting data for eval...
Eval_AverageReturn : 10.461538314819336
Eval_StdReturn : 0.8426501750946045
Eval_MaxReturn : 12.0
Eval_MinReturn : 9.0
Eval_AverageEpLen : 10.461538461538462
Train_AverageReturn : 9.558472633361816
Train_StdReturn : 0.875709593296051
Train_MaxReturn : 11.0
Train_MinReturn : 8.0
Train_AverageEpLen : 9.558472553699284
Actor Loss : -1155.4915771484375
Train_EnvstepsSoFar : 2002155
TimeSinceStart : 1424.449547290802
Done logging...


